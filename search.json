[
  {
    "objectID": "introduction_to_control_problem.html",
    "href": "introduction_to_control_problem.html",
    "title": "Introduction to the control problem",
    "section": "",
    "text": "A typical radar application involves steering an antenna such that it remains aligned with a target - like tracking an aircraft in flight. This alignment and tracking mechanism is achieved using a servo mechanism.\n\n\n\n \n\n\n\n\ncommand signal for the servo: deviation between the antenna axis and the target’s position\nthis is needed to steer the antenna and reduce the error to zero\n\nAs you observe in the above diagram, our antenna configuration has two main degrees of freedom:\n\nElevation angle around the horizontal axis.\nAzimuth angle (denoted as \\(\\beta\\)) around the vertical axis.\n\nThis makes our system a multivariable one. But wait, is there a way to simplify it?\nThought Bubble: Can you recall a scenario where we can treat a multivariable system almost like a series of single-input-single-output systems?\nIf the interaction (or coupling) between the variables (azimuth and elevation) can be neglected, we can design our control systems separately for each degree of freedom.\nTo elucidate, let’s zoom into the azimuth control (\\(\\beta\\)).\n\n\n\n\n\n\n\n\n\nFigure: Azimuthal servomechanism for steering of antenna (from Control systems principles and design)\n\nAzimuth angle is \\(\\beta\\) (controlled angle)\nCommand signal given by the radar sensor: \\(\\beta_r\\)\n‘Computer’ does error detection and control, which means that we need a suitable sensor to read the angle \\(\\beta\\).\n\noutput of the computing element is \\(u\\) (manipulated signal)\n\nShaft-angle encoder: transform the analog signal \\(\\beta\\) (angular displacement) into a digital signal\nPower amplifier generated the signal that drives the motor (DC armature control motor) - change the power level to meet the requirement of the motor\nBetween the motor shaft and the antenna we have a gear train because the torque required to move the antenna is larger than the torque produced by a typical motor.\n\n\n\n\nAs you might’ve observed in the diagram, we have introduced an additional feedback mechanism via a tachogenerator.\nThe tachogenerator, attached to the motor shaft, produces a voltage signal proportional to the shaft’s velocity. This allows us not just to feedback the antenna’s position but also its rate of change (or velocity).\n\nthe velocity is the derivative of the controlled variable \\(\\beta\\).\n\nPop-Up Question: Can you think of why feedback about the velocity might be useful in our control system?\nThis dual feedback mechanism is what we refer to as “proportional plus derivative control”. It’s an essential concept in control system design, as it helps in precise control by considering both the position and its rate of change.\nWe can put this into our standard block diagram form:\n\n\n\n\n\n\n\nFigure: Azimuthal servomechanism for steering of antenna (from Control systems principles and design)\n\nThe load is the antenna.\nThe antenna, the gear and the motor shaft all they represent the plan. If we want to come up with a model of the system we need to model all this, which in practise will mean:\n\nKnowing the moment of inertia \\(J\\) and the friction \\(B\\).",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#servo-mechanism-for-antenna-steering",
    "href": "introduction_to_control_problem.html#servo-mechanism-for-antenna-steering",
    "title": "Introduction to the control problem",
    "section": "",
    "text": "A typical radar application involves steering an antenna such that it remains aligned with a target - like tracking an aircraft in flight. This alignment and tracking mechanism is achieved using a servo mechanism.\n\n\n\n \n\n\n\n\ncommand signal for the servo: deviation between the antenna axis and the target’s position\nthis is needed to steer the antenna and reduce the error to zero\n\nAs you observe in the above diagram, our antenna configuration has two main degrees of freedom:\n\nElevation angle around the horizontal axis.\nAzimuth angle (denoted as \\(\\beta\\)) around the vertical axis.\n\nThis makes our system a multivariable one. But wait, is there a way to simplify it?\nThought Bubble: Can you recall a scenario where we can treat a multivariable system almost like a series of single-input-single-output systems?\nIf the interaction (or coupling) between the variables (azimuth and elevation) can be neglected, we can design our control systems separately for each degree of freedom.\nTo elucidate, let’s zoom into the azimuth control (\\(\\beta\\)).\n\n\n\n\n\n\n\n\n\nFigure: Azimuthal servomechanism for steering of antenna (from Control systems principles and design)\n\nAzimuth angle is \\(\\beta\\) (controlled angle)\nCommand signal given by the radar sensor: \\(\\beta_r\\)\n‘Computer’ does error detection and control, which means that we need a suitable sensor to read the angle \\(\\beta\\).\n\noutput of the computing element is \\(u\\) (manipulated signal)\n\nShaft-angle encoder: transform the analog signal \\(\\beta\\) (angular displacement) into a digital signal\nPower amplifier generated the signal that drives the motor (DC armature control motor) - change the power level to meet the requirement of the motor\nBetween the motor shaft and the antenna we have a gear train because the torque required to move the antenna is larger than the torque produced by a typical motor.\n\n\n\n\nAs you might’ve observed in the diagram, we have introduced an additional feedback mechanism via a tachogenerator.\nThe tachogenerator, attached to the motor shaft, produces a voltage signal proportional to the shaft’s velocity. This allows us not just to feedback the antenna’s position but also its rate of change (or velocity).\n\nthe velocity is the derivative of the controlled variable \\(\\beta\\).\n\nPop-Up Question: Can you think of why feedback about the velocity might be useful in our control system?\nThis dual feedback mechanism is what we refer to as “proportional plus derivative control”. It’s an essential concept in control system design, as it helps in precise control by considering both the position and its rate of change.\nWe can put this into our standard block diagram form:\n\n\n\n\n\n\n\nFigure: Azimuthal servomechanism for steering of antenna (from Control systems principles and design)\n\nThe load is the antenna.\nThe antenna, the gear and the motor shaft all they represent the plan. If we want to come up with a model of the system we need to model all this, which in practise will mean:\n\nKnowing the moment of inertia \\(J\\) and the friction \\(B\\).",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#speed-control-in-industry",
    "href": "introduction_to_control_problem.html#speed-control-in-industry",
    "title": "Introduction to the control problem",
    "section": "Speed Control in Industry",
    "text": "Speed Control in Industry\nSpeed control is important in many industries, especially where consistency is crucial. Think of paper mills or steel production plants, where rollers must maintain a consistent speed to produce a uniform product, ensuring product quality and safety.\n\n\n\n\n\n\n\nTo ensure consistent speed, despite disturbances like varying material thickness or power fluctuations, we employ a control system.\n\n\n\n\n\n\n\n\nCommanded Speed Position: The commanded speed position is represented by \\(\\omega_r\\). In the illustrated diagram, this denotes the commanded speed. This is the reference signal that gets compared to the actual feedback signal from the system \\(\\omega\\).\nFeedback Mechanism:\n\nThe tachogenerator, which is attached to the motor shaft, provides the feedback in this system. This mechanism captures the actual speed and sends a feedback signal to the main system. To provide a clearer image, imagine a DC motor (as depicted in our diagram). The tachogenerator is coupled to this motor’s shaft. The load attached to this motor has certain parameters – namely \\(J\\) (moment of inertia) and \\(B\\) (viscous friction).\n\nTranslating Speed to Voltage:\n\nThe tachogenerator does not directly generate a speed signal. Instead, it generates a voltage signal that is proportional to the speed. This is crucial because it means our reference signal, \\(\\omega_r\\), will also be a voltage proportional to the desired speed. Hence, in this system, the error detector could be an operational amplifier (often called an op-amp). This op-amp circuit accepts the voltage signals that represent the commanded and actual speeds, compares them, and then generates a signal proportional to the error between these two signals.\n\n\nPop-up Question: Why is the speed translated to voltage in this system? Answer: It’s to ensure that the feedback and reference signals are in the same format (voltage) for the error detector to compare.\nDigital Control Adaptation: For those keen on a digital control scheme, introducing an A to D (Analog to Digital) converter block can digitize the analog signal generated from the error detection. This digital signal can then be processed by a computer system.\nPower Delivery Control:\n\nThe main aim of this control scheme is to modulate the power supplied to the motor based on the difference (error) between the commanded and actual positions.\nIn the provided scheme, a silicon control rectifier (SCR) manages this. Without delving into the hardware specifics just yet, the feedback structure inherent in the control scheme reveals a SCR trigger control. The triggering of the SCR dictates the power supply to the motor, thus influencing the torque generated by the motor to achieve \\(\\omega=\\omega_r\\).\n\nWhether \\(\\omega_r\\) is a changing signal over time or a fixed set point, the control scheme can function as either a tracking system or a regulator. We will delve deeper into these types of applications and their speed controls later.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#why-mathematical-models",
    "href": "introduction_to_control_problem.html#why-mathematical-models",
    "title": "Introduction to the control problem",
    "section": "Why Mathematical Models?",
    "text": "Why Mathematical Models?\nDefinition: A mathematical model is an abstract representation of a physical system in the form of mathematical equations. It describes the system’s behavior and how it responds to various inputs.\nBenefits:\n\nPredictive Analysis: Allows for predictions about future behavior.\nSystem Optimization: Facilitates adjustments for optimal performance.\nSimulation: Enables system simulation before actual implementation.\nCost-Efficient: Reduces the need for expensive and time-consuming real-world testing.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#types-of-physical-systems",
    "href": "introduction_to_control_problem.html#types-of-physical-systems",
    "title": "Introduction to the control problem",
    "section": "Types of Physical Systems:",
    "text": "Types of Physical Systems:\nPhysical systems can be broadly categorized based on their inherent nature:\n\nLinear vs. Non-linear Systems: Linear systems obey the principle of superposition and homogeneity, while non-linear systems do not.\nTime-Invariant vs. Time-Variant Systems: In time-invariant systems, the parameters don’t change with time. In contrast, they do in time-variant systems.\nContinuous-time vs. Discrete-time Systems: Continuous-time systems operate over a continuous range of time, while discrete-time systems operate at specific intervals.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#steps-in-formulating-mathematical-models",
    "href": "introduction_to_control_problem.html#steps-in-formulating-mathematical-models",
    "title": "Introduction to the control problem",
    "section": "Steps in Formulating Mathematical Models:",
    "text": "Steps in Formulating Mathematical Models:\n\nSystem Identification: Determine the type of system (e.g., mechanical, electrical, thermal).\nSimplification: Make reasonable approximations and neglect insignificant effects.\nSelection of Variables: Choose appropriate state variables to describe the system.\nApplication of Fundamental Laws: Apply basic laws (like Ohm’s law for electrical systems, Newton’s laws for mechanical systems) to derive equations.\nRepresentation: Use differential equations, transfer functions, or state-space models as needed.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#linear-time-invariant-systems",
    "href": "introduction_to_control_problem.html#linear-time-invariant-systems",
    "title": "Introduction to the control problem",
    "section": "Linear Time Invariant Systems",
    "text": "Linear Time Invariant Systems\nIn our upcoming discussions, all systems will be linear time invariant. Thus, our focus will pivot towards modeling these types of systems. It’s presumed that at some point in your studies, you’ve encountered modeling of various systems, such as electrical, mechanical, fluidic, or thermal systems.\nWhen we solve the mathematical model of a physical system under different input scenarios, the outcome depicts the system’s dynamic behavior.\n\n A system’s mathematical model is considered linear if it adheres to the principles of superposition and homogeneity.\n\nif a system model has responses \\(y_1(t)\\) and \\(y_2(t)\\) to any two inputs \\(x_1(t)\\) and \\(x_2,(t)\\), the system response to the linear combination of these inputs:\n\\[ \\alpha_1 x_1(t) + \\alpha_2 x_2(t) \\]\nis given by the linear combination of the individual responses:\n\\[ \\alpha_1 y_1(t) + \\alpha_2 y_2(t) \\]",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#review-of-foundational-physics-laws",
    "href": "introduction_to_control_problem.html#review-of-foundational-physics-laws",
    "title": "Introduction to the control problem",
    "section": "Review of foundational physics laws",
    "text": "Review of foundational physics laws\n\nBefore diving further, a recap of the foundational physics laws, as they apply to linear time-invariant systems, will be beneficial. Although it might seem repetitive, this will ensure everyone is on the same page and understands the terminology.\nThe application of the basic law of physics will provide differential equations. However, these equations might not be directly usable for analysis or design, and need to be transformed into a form that is more useful for control.\n\nTwo main forms\nThere are two main forms in control systems that are often leveraged: 1. state variable models 2. transfer functions.\n\n Differential equations often characterize the mathematical representations of many physical systems. A model is deemed linear when its defining differential equation possesses coefficients that are either solely dependent on the independent variable or remain constant. If these coefficients change over time (where time is the independent variable), the model is described as linear time-varying. Conversely, if the coefficients remain constant throughout, the model is labeled as linear time-invariant.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#state-variable-models",
    "href": "introduction_to_control_problem.html#state-variable-models",
    "title": "Introduction to the control problem",
    "section": "State Variable Models",
    "text": "State Variable Models\nUsing a simple electrical circuit as an example we can illustrate the concept of state variable models.\nIn this circuit, the input variable is \\(e_i\\). The output variable, in any system, is the attribute of focus. In our example, it could be the current through an element or the voltage across an element.\n\n\n\n\n\n\n\nIn this case, if we know the voltage through the capacitor \\(e(t)\\) and the current through the inductor \\(i(t)\\), we can derive any other variable of interest.\n\nCharacterising variables: \\(e(t)\\) and \\(i(t)\\) completely characterise the system (a simple electrical network in this case)\n\nAny output of interest can be obtained as a function of these variables - For example, the energy stored in the capacitor is given by: \\[ \\frac{1}{2}Ce^2\\]\n\nFor example, the energy stored in the inductor is given by: \\[ \\frac{1}{2}Li^2\\]\n\nThe dynamic changes in our characterizing variables, \\(e(t)\\) and \\(i(t)\\), signify the redistribution of energy within the system.\nRecognizing these variables, which represent the energy state, provides comprehensive insight into the system’s behavior.\nHow do I get \\(e(t)\\) and \\(i(t)\\): - \\(e(t)\\) and \\(i(t)\\) at any time \\(t \\ge 0\\) is available to me if: - \\(e(0), i(0)\\) at \\(t = 0\\) are known (initial energy state of the system) - external input \\(e_i(t)\\) is known for \\(t \\ge 0\\)\nWe call \\(e(t)\\) and \\(i(t)\\) state variables.\n\nState Variable (informal) definition\n\nThe state variables are a set of characterizing variable which provide the total information about the system at any time provided the initial state and the external input.\n\nComing back to our electrical system:\n\nResistance parameter: \\(R\\)\nCapacitance: \\(C\\)\nInductance: \\(L\\)\nCurrent: \\(i\\)\n\nApplying the basic laws:\nThe loop equation is given by: \\[\ne_i= R i + e + L\\frac{di}{dt}\n\\]\nAnd also:\n\\[\ni = C\\frac{de}{dt}\n\\]\nThese two equations constitute our mathematical system model.\n\nState Variable Model of the circuit\nWith our mathematical model in place, we proceed to the State Variable Model, which is nothing else than a re-organisation of our model.\nThe goal here is to have the state variable model express the derivatives of our characterizing variables.\nFor this system, the characterizing variables are \\(e(t)\\) and \\(i(t)\\).\nThis means:\n\\[\n\\frac{de(t)}{dt} = \\frac{1}{C}i(t)\n\\]\n\\[\n\\frac{di(t)}{dt} = \\frac{R}{L}i(t) + \\frac{1}{L}e(t) + \\frac{1}{L}e_i(t)\n\\]\nFor ease of representation and standardization, we define:\n\\[x_1=e(t)\\] \\[x_2=i(t)\\]\nand I call the input variable:\n\\[\nr=e_i(t)\n\\]\nSo the system model in state variable form is:\n\\[\n\\begin{aligned}\n    \\frac{dx_1}{dt} &= \\frac{1}{C} x_2 \\\\\n    \\frac{dx_2}{dt} &= \\frac{R}{L} x_2 + \\frac{1}{L} x_1 + \\frac{1}{L} R\n\\end{aligned}\n\\]\nThese equations together represent the State Equations of the system.\nOutput Information: It’s essential to know what information we are interested in or what we wish to observe from the system.\nBy definition, we can get any output from the state variables.\nSuppose we are interested in the voltage across the inductor \\(y(t)\\).\n\n\n\n\n\n\n\nUsing the given state variables, we can express:\n\\[\ny(t) = -Ri - e + e_i = -Rx_2 - x_1+r\n\\]\nThis equation is an Output Equation, showing how the output depends on our state and input variables.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#standard-state-variable-model",
    "href": "introduction_to_control_problem.html#standard-state-variable-model",
    "title": "Introduction to the control problem",
    "section": "Standard State Variable Model",
    "text": "Standard State Variable Model\nThe generalized state-variable model for a system with $ n $ state variables, one input and one output is represented by the following matrix-vector differential equations:\n\\[\\begin{aligned}\n\\dot{\\mathbf{x}}(t) &= \\mathbf{A} \\mathbf{x}(t) + \\mathbf{b} u(t) \\\\\ny(t) &= \\mathbf{c} \\mathbf{x}(t) + d u(t)\n\\end{aligned}\\]\nWhere:\n\n$ (t) $ is the state vector of dimension $ n $:\n\n\\[\n\\mathbf{x}(t) = \\begin{bmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_n(t)\n\\end{bmatrix}\n\\]\n\n$ u(t) $ is a scalar input\n$ y(t) $ is a scalar output\n$ $ is the system matrix of dimension $ n n $\n$ $ is the input vector of dimension $ n $\n$ $ is the output vector of dimension $ 1 n $\n$ d $ is the direct transmission matrix of dimension $ 1 $ (scalar constant).\n\nWe can generalise it to a system with $ n $ state variables, \\(m\\) inputs and \\(p\\) outputs\n\\[\\begin{aligned}\n\\dot{\\mathbf{x}}(t) &= \\mathbf{A} \\mathbf{x}(t) + \\mathbf{B} \\mathbf{u}(t) \\\\\n\\mathbf{y}(t) &= \\mathbf{C} \\mathbf{x}(t) + \\mathbf{D} \\mathbf{u}(t)\n\\end{aligned}\\]\nWhere:\n\n$ (t) $ is the state vector of dimension $ n $:\n\n\\[\n\\mathbf{x}(t) = \\begin{bmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_n(t)\n\\end{bmatrix}\n\\]\n\n$ $ is the system matrix of dimension $ n n $.\n$ $ is the input matrix of dimension $ n m $ (assuming there are $ m $ inputs).\n$ $ is the output matrix of dimension $ p n $ (assuming there are $ p $ outputs).\n$ $ is the direct transmission matrix of dimension $ p m $.\n$ (t) $ is the input vector (scalar - SISO system).\n$ (t) $ is the output vector (scalar - SISO system).\n\nThis format is often referred to as the “state-space” representation of dynamic systems. It provides a compact and modular way to describe the behavior of a wide range of systems, including electrical, mechanical, thermal, and more.\n\nTerminology\n\nBold lowercase letters or lowercase letters with an underline indicate vectors.\nBold uppercase letters or uppercase letters with an underline indicate matrices.\nNo underline indicates a scalar.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "introduction_to_control_problem.html#understanding-state-variables",
    "href": "introduction_to_control_problem.html#understanding-state-variables",
    "title": "Introduction to the control problem",
    "section": "Understanding State Variables",
    "text": "Understanding State Variables\nIn the examples so far, we’ve considered physical variables as the system’s state variables.\nHowever, it’s important to note: state variables are introduced primarily for mathematical convenience.\nState variables need not always be physical variables. They can be defined based on mathematical or modeling needs.\n\nInput and output variables need to be physical variables.\n\nIn the cart example above, can we define $ x_1 $ as $ x(t) + v(t) $ and $ x_2 $ as just $ v(t) $?\nThe answer is, theoretically, yes.\n\n\\(x_2\\) remains the velocity, \\(x_1\\) - the sum of displacement and velocity - doesn’t correspond to a distinct physical variable.\nThe sum of displacement and velocity is a numerical value, with no physical meaning.\nHence, while \\(x_1\\) and \\(x_2\\) aren’t independent physical variables, state equations can still be defined in their terms.\nThe resulting output can be represented using \\(x_1\\) and \\(x_2\\), although the output equation might differ from the previous case. However, for every input, the output remains uniquely defined.\n\nState variables, such as \\(x_1\\) and \\(x_2\\), aren’t unique. They can be redefined in countless ways, but for any specific input, a unique output is guaranteed. These state variables are largely matters of convenience. Depending on the requirements of analysis and design, state variables may vary.\nIf we go back to our electrical circuit example.\nWe previously set the capacitor’s voltage as a state variable.\nNonetheless, there’s no constraint preventing us from selecting the stored charge in the capacitor as the state variable.\nWhether the state variable is designated as \\(q\\) (charge) or \\(e\\) (voltage), for a given input, the output remains consistent across all state variable definitions.\nFin.",
    "crumbs": [
      "Introduction to the control problem"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html",
    "href": "getting_started_with_python_and_jupyter_notebook.html",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "",
    "text": "https://github.com/andreamunafo/principles-of-automatic-controls\nThe purpose of this Jupyter Notebook is to get you started using Python and Jupyter Notebooks for routine engineering calculations. This introduction assumes this is your first exposure to Python or Jupyter notebooks.\nThis notebook composes information available here and here\nThe easiest way to use Jupyter notebooks is to use a cloud-based service such as Google Colaboratory. You will need continuous internet connectivity to access your work, but the advantages are there is no software to install or maintain.\nconda activate control_env\npython -m pip install chardet",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#installing-jupyterpython-on-your-laptop",
    "href": "getting_started_with_python_and_jupyter_notebook.html#installing-jupyterpython-on-your-laptop",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "1. Installing Jupyter/Python on your Laptop",
    "text": "1. Installing Jupyter/Python on your Laptop\nFor regular off-line use you should consider installing a Jupyter Notebook/Python environment directly on your laptop. This will provide you with reliable off-line access to a computational environment. This will also allow you to install additional code libraries to meet particular needs.\nChoosing this option will require an initial software installation and routine updates. For this course the recommended package is Anaconda available from Continuum Analytics. Downloading and installing the software is well documented and easy to follow. Allow about 10-30 minutes for the installation depending on your connection speed.\nhttps://www.anaconda.com/download\nAfter installing be sure to check for updates before proceeding further. With the Anaconda package this is done by executing the following two commands in a terminal window:\n&gt; conda update conda\n&gt; conda update anaconda\nAnaconda includes an ‘Anaconda Navigator’ application that simplifies startup of the notebook environment and manage the update process.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment",
    "href": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "2. Installing the Course Environment",
    "text": "2. Installing the Course Environment\n\nDownloading the environment from GitHub (Recommended)\n\nStep 1: Clone the GitHub Repository\nFirst, you need to clone the repository to your local machine. To do this, you’ll use the git clone command. Ensure you have Git installed on your computer before proceeding. Open your terminal or command prompt and run the following command:\ngit clone https://github.com/andreamunafo/principles-of-automatic-controls.git\nThis command creates a local copy of the repository on your machine.\n\n\nStep 2: Navigate to the Repository Directory\nAfter cloning, move into the repository’s directory using the cd (change directory) command:\ncd principles-of-automatic-controls\n\n\nStep 3: Locate the tclab_environment.yml File\nEnsure the environment.yml file is present in the directory by listing the contents of the directory. You can use the ls command on Unix/Linux/Mac or dir on Windows to view the directory contents.\n\n\nStep 4: Create the Conda Environment\nAssuming you have Anaconda or Miniconda installed, you can create a new conda environment using the environment.yml file. This file contains all the necessary package specifications. Run the following command:\nconda env create -f environment.yml\nThis command reads the environment.yml file and creates a new conda environment with the name and dependencies specified in the file.\n\n\nStep 5: Activate the New Conda Environment\nOnce the environment is created, you need to activate it to use it. You can activate the conda environment by running:\nconda activate environment_name\nReplace environment_name with the name of the environment specified at the top of the environment.yml file. If the name is not specified, look inside the file for the name: field to find out what it is.\n\n\nStep 6: Verify the Environment Setup\nTo ensure that the environment has been set up correctly and all the necessary packages have been installed, you can list the installed packages using:\nconda list\nThis command shows all the packages installed in the active conda environment, allowing you to verify the setup.\n\n\n\nKnown Issues and Workarounds for the course environment and TCLab\nWhen working with the course environment and the Temperature Control Lab (TCLab) toolkit, it’s important to be aware of certain issues that can arise due to differences in operating systems. This section outlines some known problems specifically for Windows users and provides instructions on how to address them to ensure a smooth experience with the Course.\n\nOperating System-Specific Package Requirements\nWhile the TCLab environment generally works across different platforms, there might be slight variations in the packages required depending on your operating system (OS). It’s crucial to tailor the environment setup to accommodate these differences to avoid any compatibility issues.\n\n\nAdjustments for Windows Users\nWindows users should take note of the following known differences and apply the recommended changes to the environment.yml file and the installation process to ensure compatibility:\n\nModification of environment.yml File:\n\nThe environment.yml file specifies dependencies required for the course environment. For Windows users, certain dependencies listed in this file may not be compatible or necessary. Therefore, it is recommended to remove the following lines from the environment.yml file:\n\nncurses=6.4\nreadline=8.2\n\n\nRemoving these lines helps prevent potential conflicts or installation errors that might arise due to these specific versions of ncurses and readline not being supported or needed on Windows.\nInstallation of Chardet:\n\nChardet, the Universal Character Encoding Detector, is an additional dependency that Windows users need to install. This package is crucial for handling character encoding, ensuring that text data is correctly processed and displayed within the notebook environment. To install Chardet, use the following pip command:\npython -m pip install chardet\n\nIncluding Chardet enhances compatibility and ensures a smoother user experience by addressing potential issues related to character encoding detection and handling.\n\nBy making these adjustments, Windows users can mitigate known issues related to package compatibility and character encoding, thereby enhancing the stability and usability of the course environment and of the TCLab toolkit on their operating system. It’s always a good practice to review the environment setup and make necessary modifications based on the specific requirements of your OS to avoid common pitfalls and ensure a successful implementation of TCLab in your projects or coursework.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment-without-using-the-environment-file-not-recommended",
    "href": "getting_started_with_python_and_jupyter_notebook.html#installing-the-course-environment-without-using-the-environment-file-not-recommended",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Installing the Course Environment without using the environment file (NOT RECOMMENDED)",
    "text": "Installing the Course Environment without using the environment file (NOT RECOMMENDED)\nPlease note that this is not recommended and it will be removed in future versions of the course.\nInstrutions for the Anaconda Navigator are slightly different and are not covered in this notebook. We assume you use a terminal from hereon.\nIf you decide to use Anaconda, the first thing to do is to create a virtual environment for the course. This makes sure that you do not pollute your main OS python envinronment.\nYou can do this with:\nconda create --name feedback-control python=3.10\nYou only need to run the previous command once.\nYou then just need to activate your environment:\nconda activate feedback-control\ncreate a folder you want to use for this course. You can use your OS GUI or run:\nmkdir feedback-control\nThis creates the folder feedback-control in your current directory. Make sure you are in the correct folder before executing the previous commands.\nTo run the notebooks you need to install the following packages: fastcore pandas matplotlib control sympy numpy\nyou can do this running:\npython -m pip install fastcore pandas matplotlib control sympy numpy notebook\nYou are ready to go!\nRun:\njupyter notebook\nto start your notebook session.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#start-a-jupyter-notebook-session",
    "href": "getting_started_with_python_and_jupyter_notebook.html#start-a-jupyter-notebook-session",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Start a Jupyter Notebook Session",
    "text": "Start a Jupyter Notebook Session\nIf you are using a cloud-based service a Jupyter session will be started when you log on.\nIf you have installed a Jupyter/Python distribution on your laptop then you can open a Jupyter session in one of two different ways:\n\nUse the Anaconda Navigator App, or\nOpen a terminal window on your laptop and execute the following statement at the command line:\n&gt; jupyter notebook\n\nEither way, once you have opened a session you should see a browser window.\nAt this point the browser displays a list of directories and files. You can navigate amoung the directories in the usual way by clicking on directory names or on the ‘breadcrumbs’ located just about the listing.\nJupyter notebooks are simply files in a directory with a .ipynb suffix.",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#simple-calculations-with-python",
    "href": "getting_started_with_python_and_jupyter_notebook.html#simple-calculations-with-python",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Simple Calculations with Python",
    "text": "Simple Calculations with Python\nPython is an elegant and modern language for programming and problem solving that has found increasing use by engineers and scientists. In the next few cells we’ll demonstrate some basic Python functionality.\n\na = 12\nb = 2\n\nprint(a + b)\nprint(a**b)\nprint(a/b)\n\n14\n144\n6.0\n\n\n\nb\n\n2\n\n\n\nPython Libraries\nThe Python language has only very basic operations. Most math functions are in various math libraries. The numpy library is convenient library. This next cell shows how to import numpy with the prefix np, then use it to call a common mathematical function\n\nimport numpy as np\n\n# mathematical constants\nprint(np.pi)\nprint(np.e)\n\n# trignometric functions\nangle = np.pi/4\nprint(np.sin(angle))\nprint(np.cos(angle))\nprint(np.tan(angle))\n\n3.141592653589793\n2.718281828459045\n0.7071067811865475\n0.7071067811865476\n0.9999999999999999\n\n\n\n\nWorking with Lists\nLists are a versatile way of organizing your data in Python.\n\nxList = [1, 2, 3, 4]\nxList\n\n[1, 2, 3, 4]\n\n\nYou can join one list to another or concatentate them\n\n# Concatenation\nx = [1, 2, 3, 4];\ny = [5, 6, 7, 8];\n\nx + y\n\n[1, 2, 3, 4, 5, 6, 7, 8]\n\n\n\nnp.sum(x)\n\n10\n\n\nElement by element operation\n\nprint(np.add(x,y))\nprint(np.multiply(x,y))\nprint(np.dot(x,y))\n\n[ 6  8 10 12]\n[ 5 12 21 32]\n70\n\n\nA for loop is a means for iterating over the elements of a list. The colon marks the start of code that will be executed for each element of a list. Indenting has meaning in Python. In this case, everything in the indented block will be executed on each iteration of the for loop. This example also demonstrates string formatting.\n\nfor x in xList:\n    print(\"sin({0}) = {1:8.5f}\".format(x,np.sin(x)))\n\nsin(1) =  0.84147\nsin(2) =  0.90930\nsin(3) =  0.14112\nsin(4) = -0.75680\n\n\n\n\nNumPy arrays\nNote that while you can do calculations on the lists, NumPy has a special object to represent math vectors or matrices called array.\nThis is NumPy’s main object and it is a homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of non-negative integers. In NumPy dimensions are called axes.\nNumPy arrays are much more powerful.\nCreating an array:\n\na = np.array([2, 3, 4])\n\narray transforms sequences of sequences into two-dimensional arrays, sequences of sequences of sequences into three-dimensional arrays, and so on.\n\nb = np.array([(1.5, 2, 3), (4, 5, 6)])\nprint(b)\n\n[[1.5 2.  3. ]\n [4.  5.  6. ]]\n\n\nThe type of the array can also be explicitly specified at creation time:\n\nc = np.array([[1, 2], [3, 4]], dtype=complex)\nprint(c)\n\n[[1.+0.j 2.+0.j]\n [3.+0.j 4.+0.j]]\n\n\nOften, the elements of an array are originally unknown, but its size is known. Hence, NumPy offers several functions to create arrays with initial placeholder content. These minimize the necessity of growing arrays, an expensive operation.\n\n??np.zeros\n\n\nprint(np.zeros((3, 4)))\n\n\nnp.ones((2, 3, 4), dtype=np.int16)\n\narray([[[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]],\n\n       [[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]]], dtype=int16)\n\n\nArithmetic operators on arrays apply elementwise. A new array is created and filled with the result.\n\nimport numpy as np\n\n\na = np.array([20, 30, 40, 50])\nb = np.arange(4)\nprint(a)\nprint(b)\n\n[20 30 40 50]\n[0 1 2 3]\n\n\n\nc = a - b\nprint(c)\n\n[20 29 38 47]\n\n\n\nb**2\n\narray([0, 1, 4, 9])\n\n\n\n10 * np.sin(a)\n\narray([ 9.12945251, -9.88031624,  7.4511316 , -2.62374854])\n\n\n\na &lt; 35\n\narray([ True,  True, False, False])\n\n\nImportant Unlike in many matrix languages, the product operator * operates elementwise in NumPy arrays. The matrix product can be performed using the @ operator (in python &gt;=3.5) or the dot function or method:\n\nA = np.array([[1, 1],\n              [0, 1]])\n\nB = np.array([[2, 0],\n              [3, 4]])\n\n\nA * B     # elementwise product\n\narray([[2, 0],\n       [0, 4]])\n\n\n\nA @ B     # matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\nA.dot(B)  # another matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\n\nWorking with Dictionaries\nDictionaries are useful for storing and retrieving data as key-value pairs.\n\nmw = {'CH4': 16.04, 'H2O': 18.02, 'O2':32.00, 'CO2': 44.01}\nmw\n\n{'CH4': 16.04, 'H2O': 18.02, 'O2': 32.0, 'CO2': 44.01}\n\n\nWe can retrieve a value from a dictionary:\n\nmw['CH4']\n\n16.04\n\n\nA for loop is a useful means of interating over all key-value pairs of a dictionary.\n\nfor values in mw.keys():\n    print(\"Value {:&lt;s} is {}\".format(values, mw[values]))\n\nValue CH4 is 16.04\nValue H2O is 18.02\nValue O2 is 32.0\nValue CO2 is 44.01\n\n\nDictionaries can be sorted by key or by value\n\nfor values in sorted(mw):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n CO2       44.01\n H2O       18.02\n O2        32.0\n\n\n\nfor values in sorted(mw, key = mw.get):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n H2O       18.02\n O2        32.0\n CO2       44.01\n\n\n\n\nPlotting with Matplotlib\nImporting the matplotlib.pyplot library gives IPython notebooks plotting functionality very similar to Matlab’s. Here are some examples using functions from the\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0,10)\ny = np.sin(x)\nz = np.cos(x)\n\nplt.plot(x,y,'b',x,z,'r')\nplt.xlabel('Radians');\nplt.ylabel('Value');\nplt.title('Plotting Demonstration')\nplt.legend(['Sin','Cos'])\nplt.grid()\n\n\n\n\n\n\n\n\n\nplt.plot(y,z)\nplt.axis('equal')\n\n(-1.09972447591003,\n 1.0979832896606587,\n -1.0992804688576738,\n 1.0999657366122702)\n\n\n\n\n\n\n\n\n\n\nplt.subplot(2,1,1)\nplt.plot(x,y)\nplt.title('Sin(x)')\n\nplt.subplot(2,1,2)\nplt.plot(x,z)\nplt.title('Cos(x)')\n\nText(0.5, 1.0, 'Cos(x)')",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#where-to-learn-more",
    "href": "getting_started_with_python_and_jupyter_notebook.html#where-to-learn-more",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Where to Learn More",
    "text": "Where to Learn More\nPython offers a full range of programming language features, and there is a seemingly endless range of packages for scientific and engineering computations. Here are some suggestions on places you can go for more information on programming for engineering applications in Python.\n\nIntroduction to Python for Science\nThis excellent introduction to python is aimed at undergraduates in science with no programming experience. It is free and available at the following link.\n\nIntroduction to Python for Science\n\n\n\nTutorial Introduction to Python for Science and Engineering\nThe following text is available on Amazon. Resources for this book are available on github.\n\nA Primer on Scientific Programming with Python (Fourth Edition) by Hans Petter Langtangen. Resources for this book are available on github.\n\npycse is a package of python functions, examples, and document prepared by John Kitchin at Carnegie Mellon University.\n\npycse - Python Computations in Science and Engineering by John Kitchin at Carnegie Mellon. This is a link into the the github repository for pycse, click on the Raw button to download the .pdf file.\n\nAnd there is plenty more! Google it!",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "getting_started_with_python_and_jupyter_notebook.html#python-basics",
    "href": "getting_started_with_python_and_jupyter_notebook.html#python-basics",
    "title": "Getting Started with Python and Jupyter Notebooks",
    "section": "Python Basics",
    "text": "Python Basics\nThis second part of the notebook is to describe some more Python concepts that will be used during the class.\n\nVariables\n\n#A variable stores a piece of data and gives it a name\nanswer = 42\n\n#answer contained an integer because we gave it an integer!\n\nis_it_thursday = True\nis_it_wednesday = False\n\n#these both are 'booleans' or true/false values\n\npi_approx = 3.1415\n\n#This will be a floating point number, or a number containing digits after the decimal point\n\nmy_name = \"Andrea\"\n#This is a string datatype, the name coming from a string of characters\n\n#Data doesn't have to be a singular unit\n\n#p.s., we can print all of these with a print command. For Example:\nprint(answer)\nprint(pi_approx)\n\n42\n3.1415\n\n\n\n\nMore Complicated Data Types\n\n#What if we want to store many integers? We need a list!\nprices = [10, 20, 30, 40, 50]\n\n#This is a way to define a list in place. We can also make an empty list and add to it.\ncolors = []\n\ncolors.append(\"Green\")\ncolors.append(\"Blue\")\ncolors.append(\"Red\")\n\nprint(colors)\n\n#We can also add unlike data to a list\nprices.append(\"Sixty\")\n\n#As an exercise, look up lists in python and find out how to add in the middle of a list!\n\nprint(prices)\n#We can access a specific element of a list too:\n\nprint(colors[0])\nprint(colors[2])\n\n#Notice here how the first element of the list is index 0, not 1! \n#Languages like MATLAB are 1 indexed, be careful!\n\n#In addition to lists, there are tuples\n#Tuples behave very similarly to lists except that you can't change them \n# after you make them\n\n#An empty Tuple isn't very useful:\nempty_tuple = ()\n\n#Nor is a tuple with just one value:\none_tuple = (\"first\",)\n\n#But tuples with many values are useful:\nrosa_parks_info = (\"Rosa\", \"Parks\", 1913, \"February\", 4)\n\n#You can access tuples just like lists\nprint(rosa_parks_info[0] + \" \" + rosa_parks_info[1])\n\n# You cannot modify existing tuples, but you can make new tuples that extend \n# the information.\n# I expect Tuples to come up less than lists. So we'll just leave it at that.\n\n['Green', 'Blue', 'Red']\n[10, 20, 30, 40, 50, 'Sixty']\nGreen\nRed\nRosa Parks\n\n\n\n\nUsing variables\n\nfloat1 = 5.75\nfloat2 = 2.25\n#Addition, subtraction, multiplication, division are as you expect\n\nprint(float1 + float2)\nprint(float1 - float2)\nprint(float1 * float2)\nprint(float1 / float2)\n\n#Here's an interesting one that showed up in the first homework in 2017. Modulus: \nprint(5 % 2)\n\n8.0\n3.5\n12.9375\n2.5555555555555554\n1\n\n\n\n\nImporting in Python\n\n#Just about every standard math function on a calculator has a python equivalent pre made.\n#however, they are from the 'math' package in python. Let's add that package!\nimport math\nprint(math.log(float1))\nprint(math.exp(float2))\nprint(math.pow(2,5))\n# There is a quicker way to write exponents if you want:\nprint(2.0**5.0)\n\n#Like in MATLAB, you can expand the math to entire lists\nlist3 = [1, 2, 3, 4, 5]\nprint(2 * list3)\n\n1.749199854809259\n9.487735836358526\n32.0\n32.0\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\n\n# We can plot easily in Python like in matlab, just import the relevant package!\nimport matplotlib.pyplot as plt\n\nx_vals = [-2, -1, 0, 1, 2]\ny_vals = [-4, -2, 0, 2, 4]\nplt.plot(x_vals, y_vals)\n\n\n\n\n\n\n\n\n\n\nLoops\n\n#Repeat code until a conditional statement ends the loop\n\n#Let's try printing a list\nfib = [1, 1, 2, 3, 5, 8]\n\n#While loops are the basic type\ni = 0\nwhile(i &lt; len(fib)):\n    print(fib[i])\n    i = i + 1\n    \n#In matlab, to do the same thing you would have the conditional as: counter &lt; (length(fib) + 1)\n#This is because matlab starts indexing at 1, and python starts at 0.\n    \n#The above type of loop is so common that the 'for' loop is the way to write it faster.\n\nprint(\"Let's try that again\")\n#This is most similar to for loops in matlab\nfor i in range(0, len(fib)) :\n    print(fib[i])\n\nprint(\"One more time:\")\n#Or you can do so even neater\nfor e in fib:\n    print(e)\n\n1\n1\n2\n3\n5\n8\nLet's try that again\n1\n1\n2\n3\n5\n8\nOne more time:\n1\n1\n2\n3\n5\n8\n\n\n\n\nFunctions\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\ndef my_function():\n    print(\"Hello from a function\")\n\nTo call a function, use the function name followed by parenthesis:\n\nmy_function()\n\nHello from a function\n\n\nInformation can be passed into functions as arguments.\nArguments are specified after the function name, inside the parentheses. You can add as many arguments as you want, just separate them with a comma.\nThe following example has a function with one argument (fname). When the function is called, we pass along a first name, which is used inside the function to print the full name:\n\ndef my_function(fname):\n    print(fname + \" Refsnes\")\n\nmy_function(\"Emil\")\nmy_function(\"Tobias\")\nmy_function(\"Linus\")\n\nEmil Refsnes\nTobias Refsnes\nLinus Refsnes\n\n\nYou can send any data types of argument to a function (string, number, list, dictionary etc.), and it will be treated as the same data type inside the function.\nE.g. if you send a List as an argument, it will still be a List when it reaches the function:\n\ndef my_function(food):\n    for x in food:\n        print(x)\n\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nmy_function(fruits)\n\napple\nbanana\ncherry\n\n\nTo let a function return a value, use the return statement:\n\ndef my_function(x):\n    return 5 * x\n\nprint(my_function(3))\nprint(my_function(5))\nprint(my_function(9))\n\n15\n25\n45\n\n\n\n\nClasses\nA class is a user-defined blueprint or prototype from which objects are created. Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by their class) for modifying their state.\nTo understand the need for creating a class let’s consider an example, let’s say you wanted to track the number of dogs that may have different attributes like breed, age. If a list is used, the first element could be the dog’s breed while the second element could represent its age. Let’s suppose there are 100 different dogs, then how would you know which element is supposed to be which? What if you wanted to add other properties to these dogs? This lacks organization and it’s why we need classes.\nClass creates a user-defined data structure, which holds its own data members and member functions, which can be accessed and used by creating an instance of that class. A class is like a blueprint for an object.\nIt’s not hard to define Python class. To do so, you’ll need the class keyword:\nclass ClassName:     # Statement-1     .     .     .     # Statement-N\nFor example\n\nclass Example:    \n    variable = 123\n\nIf you run the above code in a Python environment, you’ll find you can call Example.variable to return an integer value.\n\nExample.variable\n\n123\n\n\nThis is an example of a class for data-only objects, but it’s equally easy to define a class that returns a function object by adding the def keyword to your code:\n\nclass Example:\n    def b(self):\n        return \"this is an example class\"\n\n\nExample.b # we are accessing the function...this is probably not what we want to do..\n\n&lt;function __main__.Example.b(self)&gt;\n\n\nWe need a few more concepts:\n\n\nSome more class concepts\nAn Object is an instance of a Class. A class is like a blueprint while an instance is a copy of the class with actual values. It’s not an idea anymore, it’s an actual dog, like a dog of breed pug who’s seven years old. You can have many dogs to create many different instances, but without the class as a guide, you would be lost, not knowing what information is required. An object consists of :\n\nState: It is represented by the attributes of an object. It also reflects the properties of an object.\nBehavior: It is represented by the methods of an object. It also reflects the response of an object to other objects.\nIdentity: It gives a unique name to an object and enables one object to interact with other objects.\n\n\n\nDeclaring Objects (Also called instantiating a class)\nWhen an object of a class is created, the class is said to be instantiated. All the instances share the attributes and the behavior of the class. But the values of those attributes, i.e. the state are unique for each object. A single class may have any number of instances.\nExample:\n\n\n\n\n\n\nclass Dog:\n     \n    # A simple class\n    # attribute\n    attr1 = \"mammal\"\n    attr2 = \"dog\"\n \n    # A sample method \n    def fun(self):\n        print(\"I'm a\", self.attr1)\n        print(\"I'm a\", self.attr2)\n\n# Object instantiation\nRodger = Dog()\n \n# Accessing class attributes\n# and method through objects\nprint(Rodger.attr1)\nRodger.fun()\n\nmammal\nI'm a mammal\nI'm a dog\n\n\n\n\nSelf\nClass methods must have an extra first parameter in the method definition. We do not give a value for this parameter when we call the method, Python provides it.\nIf we have a method that takes no arguments, then we still have to have one argument.\nWhen we call a method of this object as myobject.method(arg1, arg2), this is automatically converted by Python into MyClass.method(myobject, arg1, arg2).\nNote that this means that inside the function method (in our example) we now have access to the instance of the class! so we can access its variables, etc.\n\n\n__init__ method\nThe init method is similar to constructors in C++, it constructs the object and can be used to initialise the object’s state.\nLike methods, a constructor also contains a collection of statements (i.e. instructions) that are executed when the object is created.\nThe __init__ method runs as soon as an object of a class is instantiated. The method is useful to do any initialization you want to do with your object.\n\n# A Sample class with init method\nclass Person:\n\n    # init method or constructor\n    def __init__(self, name):\n        self.name = name\n\n    # Sample Method\n    def say_hi(self):\n        print('Hello, my name is', self.name)\n\np = Person('Nikhil') # as soon as we do this, the __init__ method is called.\np.say_hi()\n\nHello, my name is Nikhil\n\n\n\n\nClass and Instance Variables\n\nInstance variables are used to store data that is unique to each instance of the class. Instance variables are variables whose value is assigned inside the __init__ method or inside a class method (a method with the argument self)\nClass variables are for attributes and methods shared by all instances of the class. Class variables are variables whose value is assigned directly in the class.\n\n\n# Class for Dog\nclass Dog:\n   \n    # Class Variable\n    animal = 'dog'            \n   \n    # The init method or constructor\n    def __init__(self, breed, color):\n     \n        # Instance Variable    \n        self.breed = breed\n        self.color = color       \n    \n# Objects of Dog class\nRodger = Dog(\"Pug\", \"brown\")\nBuzo = Dog(\"Bulldog\", \"black\")\n \nprint('Rodger details:')  \nprint('Rodger is a', Rodger.animal)\nprint('Breed: ', Rodger.breed)\nprint('Color: ', Rodger.color)\n \nprint('\\nBuzo details:')  \nprint('Buzo is a', Buzo.animal)\nprint('Breed: ', Buzo.breed)\nprint('Color: ', Buzo.color)\n \n# Class variables can be accessed using class\n# name also\nprint(\"\\nAccessing class variable using class name\")\nprint(Dog.animal)\n\nRodger details:\nRodger is a dog\nBreed:  Pug\nColor:  brown\n\nBuzo details:\nBuzo is a dog\nBreed:  Bulldog\nColor:  black\n\nAccessing class variable using class name\ndog\n\n\n\n\nAdditional Resources\n\nCode Academy\nOfficial Python Reference\nReal Python\n\nGoogle Colab - An Introduction to Google Colab, McGraw Center for Teaching and Learning - Getting Started with Google Colab - Colab Walkthrough, Stanford University - Google Colab Tutorial for Data Scientists, Datacamp.com",
    "crumbs": [
      "Getting Started with Python and Jupyter Notebooks"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html",
    "href": "design_of_feedback_control.html",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "",
    "text": "We will take second-order systems as exemplar. However, before diving into the design cycle, it’s crucial to understand that while real-world systems may not always be second-order, mastering the design for such systems is fundamental. This knowledge can be extended to more complex systems. We start with a standard second-order system in a unity-feedback configuration.",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html#analysis",
    "href": "design_of_feedback_control.html#analysis",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "Analysis",
    "text": "Analysis\nDetermine the system’s behavior without any controller:\n\n\n\n\n\n\\[\nG(s) = \\frac{\\omega_n^2}{s(s + 2\\zeta\\omega_n)}\n\\]\nand the closed-loop transfer function \\(Y(s)/R(s)\\) is given by:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\n\\]\nWhere: - $ _n $ is the undamped natural frequency. - $ $ is the damping ratio.\n\nUnderstanding the Damping Ratio (\\(\\zeta\\))\n\nUndamped System (\\(\\zeta = 0\\)): Purely oscillatory behavior.\nUnder-Damped (\\(0 &lt; \\zeta &lt; 1\\)): Oscillatory but decaying response.\nCritically Damped (\\(\\zeta = 1\\)): Fastest return to equilibrium without overshooting.\nOver-Damped (\\(\\zeta &gt; 1\\)): Slow return to equilibrium without oscillations.\n\n\n\nCharacteristic Equation and Roots\nThe characteristic equation is:\n\\[\n\\Delta (s) = s^2 + 2\\zeta\\omega_n s + \\omega_n^2\n\\]\nThe roots of this equation (closed-loop poles or characteristic roots) are critical for system behavior analysis.\nThe characteristic roots of a standard second-order system can be derived from its characteristic equation. For the system represented by the transfer function $ G(s) = $, the characteristic equation is obtained from the denominator of the closed-loop transfer function:\n\\[\n\\Delta s = s^2 + 2\\zeta\\omega_n s + \\omega_n^2 = 0\n\\]\nTo find the roots of this characteristic equation, we solve for $ s $. These roots, which are also known as the poles of the system, dictate the system’s behavior.\nSolving the quadratic equation $ s^2 + 2_n s + _n^2 = 0 $ using the quadratic formula, we get:\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{(2\\zeta\\omega_n)^2 - 4\\omega_n^2}}{2}\n\\]\nSimplifying further:\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{4\\zeta^2\\omega_n^2 - 4\\omega_n^2}}{2}\n\\]\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{4\\omega_n^2(\\zeta^2 - 1)}}{2}\n\\]\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm 2\\omega_n\\sqrt{\\zeta^2 - 1}}{2}\n\\]\n\\[\ns = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1}\n\\]\nSo, the characteristic roots (or poles) are:\n\\[\ns = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1}\n\\]\nDepending on the value of $ $ (the damping ratio), these roots can be real or complex:\n\nFor $ &lt; 1 $ (under-damped): The roots are complex conjugates.\n\\[ s = -\\zeta\\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nFor $ = 1 $ (critically damped): The roots are real and identical.\n\\[ s = -\\omega_n \\]\nFor $ &gt; 1 $ (over-damped): The roots are distinct real numbers.\n\nThese roots are crucial for understanding the system’s transient response, stability, and overall behavior.\n\nCharacteristic Roots Visualization\n\nFor $ = 0 $ (under-damped):\n\\[ s = \\pm j\\omega_n \\]\nFor $ = 1 $ (critically damped): The roots are real and identical.\n\\[ s = -\\omega_n \\]\n\nWe can plot how the roots move in the s-plane.\nLet’s use Python for this running the cell below\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the undamped natural frequency\nomega_n = 1  # You can adjust this as needed\n\n# Create a range of zeta values from 0 to 2\nzeta_values = np.linspace(0, 2, 400)\n\n# Prepare a plot\nplt.figure(figsize=(10, 8))\n\nfor zeta in zeta_values:\n    # Calculate the roots for each zeta\n    if zeta &lt; 1:\n        # Under-damped (Complex conjugate roots)\n        roots = [-zeta * omega_n + 1j * omega_n * np.sqrt(1 - zeta**2),\n                 -zeta * omega_n - 1j * omega_n * np.sqrt(1 - zeta**2)]\n        color = 'blue'\n    elif zeta == 1:\n        # Critically damped (Repeated real roots)\n        roots = [-zeta * omega_n, -zeta * omega_n]\n        color = 'green'\n    else:\n        # Over-damped (Distinct real roots)\n        roots = [-zeta * omega_n + omega_n * np.sqrt(zeta**2 - 1),\n                 -zeta * omega_n - omega_n * np.sqrt(zeta**2 - 1)]\n        color = 'red'\n    \n    # Plot the roots\n    plt.plot([root.real for root in roots], [root.imag for root in roots], 'o', color=color)\n\n# Annotating key points\nplt.annotate('Undamped\\n(Complex Roots)', xy=(0, omega_n), xytext=(0.5, omega_n+0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.annotate('Critically Damped\\n(Repeated Real Roots)', xy=(-omega_n, 0), xytext=(-2, 0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.annotate('Over-Damped\\n(Distinct Real Roots)', xy=(-2*omega_n, 0), xytext=(-2.5, -0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Setting plot features\nplt.title('Root Locus as Damping Ratio (zeta) Varies')\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.axhline(y=0, color='k')  # x-axis\nplt.axvline(x=0, color='k')  # y-axis\nplt.grid(True)\nplt.xlim(-2.5, 0.5)\nplt.ylim(-1.5, 1.5)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nThe quantity \\(\\zeta\\omega_n\\) has a very important role: it is the real part of the complex conjugate pair.\n\n\n\n\n\n\n\n\nDetermining the Damping Angle (\\(\\theta\\))\nGiven the geometry of the root locus diagram above we can determine the angle \\(\\theta\\) (hint: the radius of the circle is \\(\\omega_n\\)):\n\\[\n\\omega_n\\cos\\theta = \\zeta\\omega_n\n\\]\n\\[\n\\cos(\\theta) = \\zeta \\\\\n\\theta = \\cos^{-1}(\\zeta)\n\\]\n\nThe angle \\(\\theta\\) is called the damping angle because it is a function of \\(\\zeta\\) only (and does not depend on \\(\\omega_n\\).\nThe line of constant \\(\\theta\\) (and hence constant \\(\\zeta\\)) is called damping line. Given a specific \\(\\zeta\\) the roots will lie along the associated damping line.\n\nGiven specific \\(\\theta\\), \\(\\omega_n\\) the closed loop poles, the roots of the characteristic equation are:\n\n\n\n\n\nor: \\[ s = -\\zeta\\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nThis means that given specific \\(\\theta\\), \\(\\omega_n\\) we can translate these values into closed loop poles.\nThe design criteria will hence be to force the closed loop poles to the desired location, where we obtain the performance that we want (i.e., satisfy the transient response specification).\n\n\n\nSIDEBAR - Relationship between \\(\\zeta\\), \\(\\omega_n\\), and Closed-Loop Poles\n\nRelationship between \\(\\zeta\\), \\(\\omega_n\\), and Closed-Loop Poles:\n\nIn a standard second-order system, the parameters \\(\\zeta\\) (damping ratio) and \\(\\omega_n\\) (undamped natural frequency) are key determinants of the system’s behavior.\nThe values of \\(\\zeta\\) and \\(\\omega_n\\) directly define the position of the closed-loop poles in the complex plane. For instance, a change in \\(\\zeta\\) and \\(\\omega_n\\) will move these poles, affecting the system’s transient response.\n\nEquivalence of Specifying \\(\\zeta\\), \\(\\omega_n\\), and Closed-Loop Poles:\n\nWhen you specify \\(\\zeta\\) and \\(\\omega_n\\) for a second-order system, it’s equivalent to specifying the desired locations of the closed-loop poles. This is because there’s a direct, calculable relationship between these parameters and the poles.\nThe closed-loop poles, in turn, determine key performance characteristics of the system, like overshoot, settling time, and oscillation frequency.\n\nImportance in Root Locus Design:\n\nThis understanding forms the basis of root locus design, a method used to determine the stability of a control system and design controllers.\nIn root locus design, you typically start with a desired transient response (defined by \\(\\zeta\\) and \\(\\omega_n\\)) and then adjust the controller to move the system’s poles to these predefined locations in the complex plane.\n\nTranslating \\(\\zeta\\) and \\(\\omega_n\\) into Closed-Loop Pole Locations:\n\nBy specifying \\(\\zeta\\) and \\(\\omega_n\\), you essentially set a target for where you want the closed-loop poles to be. The design task then becomes a matter of modifying the system (often through a controller) so that its actual poles align with these target locations.\nAchieving this alignment ensures that the system’s transient response meets the specified performance criteria.\n\n\nIn the context of a standard second-order system, specifying \\(\\zeta\\) and \\(\\omega_n\\) is a way of defining desired performance characteristics. The root locus method then uses these specifications to design a control system that places the closed-loop poles in positions that ensure these performance characteristics are met. This is a fundamental approach in control system design, allowing engineers to tailor systems to meet specific transient response requirements.",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html#transient-response-characteristics",
    "href": "design_of_feedback_control.html#transient-response-characteristics",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "Transient Response Characteristics",
    "text": "Transient Response Characteristics\nLet’s now analyzing the response of an under-damped system to a unit-step input:\n\\[\nR(s) = \\frac{1}{s}\n\\]\nIn this case, the output is:\n\\[\nY(s) = \\frac{\\omega_n^2}{s(s^2 + 2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\nThe response function, obtained as the inverse Laplace transform, is:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\nWhere: - $ _d = _n $ is the damped frequency. - \\(\\theta = \\cos^{-1}(\\zeta)\\) is the damping angle.\nIn this case, the poles are complex conjugate.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the parameters\nzeta = 0.3       # Damping ratio\nomega_n = 1.0    # Natural frequency (rad/s)\nt = np.linspace(0, 10, 1000)  # Time vector\n\n# Calculate the angular frequency and phase angle\nomega_d = omega_n * np.sqrt(1 - zeta**2)\ntheta = np.arctan2(omega_n * np.sqrt(1 - zeta**2), zeta)\n\n# Compute the system response\ny = 1 - (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)) * np.sin(omega_d * t + theta)\n\n# Compute the upper and lower envelope curves\nupper_envelope = 1 + (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2))\nlower_envelope = 1 - (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2))\n\n# Plot the response and envelope curves\nplt.figure(figsize=(8, 6))\nplt.plot(t, y, label='System Response')\nplt.plot(t, upper_envelope, 'r--', label='Upper Envelope')\nplt.plot(t, lower_envelope, 'g--', label='Lower Envelope')\nplt.xlabel('Time (s)')\nplt.ylabel('y(t)')\nplt.title('Second-Order System Response with Envelopes')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nEnvelope Curves and Time Constant\nThe response is bounded by envelope curves:\n\nUpper Envelope: $ 1 + $\nLower Envelope: $ 1 - $\n\nThese curves play a significant role: the faster they decay, the faster the decay of the response.\nThe time constant of the envelope is (hint: it is an exponential function): \\[ \\tau = \\frac{1}{\\zeta\\omega_n} \\]\nThe response is:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\nbut it is more convenient to plot the response with respect to the normalised time \\(\\omega_n t\\). Now we only have \\(\\zeta\\) as parameter:\n\n\n\n\n\nNote that:\n\nfor \\(\\zeta=1\\) the system is critically damped, just about without oscillations.\nfor \\(\\zeta&gt;1\\) the system is over-damped and becomes sluggish. This is typically not desirable in a control system.\n\n\n\nUnderstanding the Design Trade-offs\n\nA lower $ $ (more oscillatory) leads to a shorter rise time but higher overshoot.\nA higher $ $ (less oscillatory) reduces overshoot but increases rise time.\n\n\n\nKey Transient Performance Indicators\n\nRise Time (\\(t_r\\)): Time taken for the response to first reach the final value.\nPeak Time (\\(t_p\\)): Time to first peak of the response.\nMaximum Overshoot (\\(M_p\\)): Maximum deviation from the final value.\n\n\nCalculating \\(t_r\\), \\(t_p\\), and \\(M_p\\)\nWe start from\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\n\n\nRise Time (\\(t_r\\)):\n\\[ t_r :\\;\\; y(t_r) = 1 \\;\\; \\Rightarrow \\frac{e^{-\\zeta\\omega_nt_r}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t_r + \\theta) = 0 \\;\\; \\Rightarrow \\sin(\\omega_d t_r + \\theta) = 0 \\;\\; \\Rightarrow \\omega_d t_r + \\theta = \\pi\\]\n\\[ t_r = \\frac{\\pi - \\theta}{\\omega_d} = \\frac{\\pi - \\cos^{-1}(\\zeta)}{\\omega_n\\sqrt{1-\\zeta^2}} \\]\n\n\nPeak Time (\\(t_p\\)):\nTo determine the time to peak (\\(t_p\\)) for a standard second-order system, we need to analyze the system’s response and find when it reaches its first maximum. This occurs at a point of extremum in the response function, where the first derivative of the response with respect to time (\\(t\\)) equals zero.\nLet’s break down the steps to find \\(t_p\\):\n\nThe Response Function:\nFor an under-damped second-order system (\\(0 &lt; \\zeta &lt; 1\\)), the step response is given by: \\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\] where \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) and \\(\\theta = \\cos^{-1}(\\zeta)\\).\nFinding the Extremum:\nThe extremum occurs where the derivative of \\(y(t)\\) with respect to \\(t\\) is zero. Let’s find this derivative:\n\\[\n\\frac{dy}{dt} = \\zeta\\omega_n \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta) - \\omega_d \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\cos(\\omega_d t + \\theta).\n\\]\nSetting \\(\\frac{dy}{dt} = 0\\) gives us the condition for the peak.\nSimplifying the Equation:\nThe equation \\(\\frac{dy}{dt} = 0\\) simplifies to: \\[\n\\zeta\\sin(\\omega_d t + \\theta) = \\sqrt{1-\\zeta^2}\\cos(\\omega_d t + \\theta).\n\\]\nUsing the identity \\(\\sin(a + b) = \\sin(a)\\cos(b) + \\cos(a)\\sin(b)\\), we get: \\[\n\\zeta[\\sin(\\omega_d t)\\cos(\\theta) + \\cos(\\omega_d t)\\sin(\\theta)] = \\sqrt{1-\\zeta^2}\\cos(\\omega_d t).\n\\]\nSince \\(\\theta = \\cos^{-1}(\\zeta)\\), \\(\\sin(\\theta) = \\sqrt{1-\\zeta^2}\\) and \\(\\cos(\\theta) = \\zeta\\). Substituting these into the equation, we simplify it to: \\[\n\\zeta^2\\sin(\\omega_d t) + \\sqrt{1-\\zeta^2}\\cos(\\omega_d t)\\sin(\\omega_d t) = \\zeta\\cos(\\omega_d t).\n\\]\nFinding \\(t_p\\):\nThe equation simplifies to \\(\\sin(\\omega_d t) = 0\\), indicating that the peak occurs at a multiple of \\(\\pi/\\omega_d\\). The first peak (\\(t_p\\)) occurs at: \\[\nt_p = \\frac{\\pi}{\\omega_d} = \\frac{\\pi}{\\omega_n\\sqrt{1-\\zeta^2}}.\n\\]\n\nThis \\(t_p\\) is the time to peak for the under-damped second-order system’s step response. It’s important to note that this derivation assumes an under-damped system (\\(0 &lt; \\zeta &lt; 1\\)). For critically damped (\\(\\zeta = 1\\)) or over-damped (\\(\\zeta &gt; 1\\)) systems, the approach to finding \\(t_p\\) would be different, as the system response does not exhibit overshoot in these cases.\nNote that the time to first undershoot would be \\(\\omega_d t = 2\\pi\\), the time to second overshoot \\(\\omega_d t = 3\\pi\\) and so on.\n\n\nMaximum Overshoot (\\(M_p\\)):\nTo derive the maximum overshoot value (\\(M_p\\)) for an under-damped second-order system, we need to evaluate the system’s response at the time to peak (\\(t_p\\)), which we previously determined. The maximum overshoot is the amount by which the system’s response exceeds its final value (which is 1 for a unit step input) at the first peak.\n\nRecall the Response Function:\nThe response for an under-damped system (\\(0 &lt; \\zeta &lt; 1\\)) to a unit step input is:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta),\n\\]\nwhere \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) and \\(\\theta = \\cos^{-1}(\\zeta)\\).\nEvaluate the Response at \\(t_p\\):\nWe previously found that \\(t_p = \\frac{\\pi}{\\omega_d}\\). Substituting this into the response function gives:\n\\[\ny(t_p) = 1 - \\frac{e^{-\\zeta\\omega_n(\\pi/\\omega_d)}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d (\\pi/\\omega_d) + \\theta).\n\\]\nSimplify the Expression:\nThe sine term simplifies as \\(\\sin(\\pi + \\theta) = -\\sin(\\theta)\\). Since \\(\\theta = \\cos^{-1}(\\zeta)\\), we have \\(\\sin(\\theta) = \\sqrt{1-\\zeta^2}\\). Therefore:\n\\[\ny(t_p) = 1 + e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n\\]\nCalculate Maximum Overshoot (\\(M_p\\)):\nThe maximum overshoot is the peak value minus the steady-state value (which is 1 for a unit step response), so:\n\\[\nM_p = y(t_p) - 1 = e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n\\]\nSubstitute \\(\\omega_d\\):\nRecall that \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\). Substituting this in \\(M_p\\):\n\\[\nM_p = e^{-\\frac{\\zeta\\omega_n\\pi}{\\omega_n\\sqrt{1-\\zeta^2}}} = e^{-\\frac{\\pi\\zeta}{\\sqrt{1-\\zeta^2}}}.\n\\]\n\nThis final expression gives the maximum overshoot \\(M_p\\) for an under-damped second-order system. It quantifies how much the first peak of the system’s response overshoots the steady-state value in response to a unit step input. The overshoot depends solely on the damping ratio \\(\\zeta\\), and as \\(\\zeta\\) approaches 1 (transition to critical damping), \\(M_p\\) decreases, reflecting less overshoot in the system’s response.\nPop-up Question: What happens to the peak time (\\(t_p\\)) as the damping ratio ($ $) increases?\nAnswer: As $ $ increases, $ _d = _n $ decreases, leading to an increase in peak time (\\(t_p\\)).",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html#transient-performance-specifications",
    "href": "design_of_feedback_control.html#transient-performance-specifications",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "Transient Performance Specifications",
    "text": "Transient Performance Specifications\nLet’s continue our exploration of control engineering, focusing on transient performance specifications. Remember, we’re using a step response, typically a unit step response, as our primary tool for examining the transient response of second-order systems. And interestingly, these specifications apply to higher-order systems too.\n\nRise Time, Peak Overshoot, Time to Peak, and Settling Time\nFirst, let’s recap the key specifications we’re discussing: - Rise Time (t_r): The time it takes for the system’s response to rise from 10% to 90% of its final value. - Peak Overshoot (M_p): The maximum peak value of the response curve as a percentage over the final value. - Time to Peak (t_p): The time taken to reach the first peak overshoot. - Settling Time (t_s): The time taken for the response to reach and stay within a certain percentage (commonly 2% or 5%) of its final value.\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n\ndef find_max_consecutive_index(arr):\n    max_consecutive_index = None\n    consecutive_start = None\n\n    for i in range(len(arr) - 1):\n        if arr[i] + 1 != arr[i + 1]:\n            if consecutive_start is not None:\n                max_consecutive_index = consecutive_start\n            consecutive_start = None\n        elif consecutive_start is None:\n            consecutive_start = i + 1\n\n    # Check if the entire array is consecutive\n    if consecutive_start is not None:\n        max_consecutive_index = consecutive_start\n\n    return max_consecutive_index if max_consecutive_index is not None else len(arr) - 1\n\n\n# Define a function to calculate and plot the system response with performance parameters\ndef plot_response(zeta, omega_n, sim_time):\n    # System parameters: zeta (damping ratio), omega_n (natural frequency)\n    num = [omega_n**2]  # Numerator (assuming unit gain)\n    den = [1, 2 * zeta * omega_n, omega_n**2]  # Denominator\n\n    # Create a transfer function model\n    system = control.tf(num, den)\n\n    # Time parameters\n    t = np.linspace(0, sim_time, int(sim_time*100))  # Time vector\n\n    # Step response\n    t, y = control.step_response(system, t)\n    steady_state_value = y[-1]\n\n    # Rise Time\n    rise_time_indices = np.where(y &gt;= steady_state_value)[0]\n    rise_time = t[rise_time_indices[0]] if rise_time_indices.size else None\n\n    # Peak Overshoot and Peak Time\n    peak_overshoot = np.max(y) - steady_state_value\n    peak_time = t[np.argmax(y)]\n\n    # Settling Time (within 2% of steady-state value). This is found numerically.\n    settling_time_indices = np.where(abs(y - steady_state_value) &lt;= 0.02 * steady_state_value)[0]\n    ts_index = find_max_consecutive_index(settling_time_indices)\n    settling_time = t[settling_time_indices[ts_index]] if settling_time_indices.size else None\n\n    # Plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y, label='System Response')\n    plt.axhline(steady_state_value, color='r', linestyle='--', label='Steady State')\n    # tolerange band (0.02 percent)\n    plt.axhline(steady_state_value * 1.02, color='g', linestyle=':', label='Settling Time Bound')\n    plt.axhline(steady_state_value * 0.98, color='g', linestyle=':')\n\n    if rise_time:\n        plt.axvline(rise_time, color='y', linestyle='-', label=f'Rise Time: {rise_time:.2f}s')\n    plt.axvline(peak_time, color='b', linestyle='-', label=f'Peak Time: {peak_time:.2f}s')\n    plt.scatter(peak_time, np.max(y), color='black', label=f'Peak Overshoot: {peak_overshoot:.2f}')\n    \n    if settling_time:\n        plt.scatter(settling_time, y[settling_time_indices[ts_index]], color='purple')\n        plt.axvline(settling_time, color='purple', linestyle='-', label=f'Settling Time: {settling_time:.2f}s')\n    \n    plt.title('Transient Response with Performance Parameters')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Output')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Interactive sliders\nfrom ipywidgets import interact, FloatSlider\ninteract(plot_response, \n         zeta=FloatSlider(value=0.3, min=0.01, max=1.0, step=0.01), \n         omega_n=FloatSlider(value=2, min=1, max=10, step=0.1), \n         sim_time=FloatSlider(value=10, min=1, max=50, step=1))\n\n\n\n\n&lt;function __main__.plot_response(zeta, omega_n, sim_time)&gt;\n\n\n\n\nSecond-Order System Transfer Function\nFor a standard second-order system, the transfer function is:\n\\[ Y(s) = \\frac{\\omega_n^2}{s(s^2 + 2 \\zeta \\omega_n s + \\omega_n^2)} \\]\nwhere $ _n $ is the natural frequency and $ $ is the damping ratio.\nThis is the response transfor for which \\(R(s) = \\frac{1}{s}.\\)\n\n\nInverse Laplace Transform\nApplying the inverse Laplace transform, we get the time domain response:\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\nwith \\(\\theta = \\cos^{-1}(\\zeta)\\) and \\(\\omega_d = \\omega_n \\sqrt{1 - \\zeta^2}\\), representing the damped natural frequency.\n\n\nRise Time (\\(t_r\\))\nRise time can be expressed as:\n\\[ t_r = \\frac{\\pi - \\cos^{-1}(\\zeta)}{\\omega_n \\sqrt{1 - \\zeta^2}} \\]\nNotice that rise time depends on both $ $ and $ _n $, but the effect of $ $ is relatively small.\n\nAs we discussed, we would like the rise time to be as small as possible. This would mean that the system responds quickly.\n\nTo visualize how rise time varies with $ $ and $ _n $ and to demonstrate that the rise time remains relatively constant as $ $ changes, we can write a Python script using libraries like matplotlib for plotting and numpy for numerical computations.\nIn this script: - We define a range of $ $ values from 0.01 to 0.99. - We select a few values of $ _n $ to illustrate the effect on rise time. - We use the derived formula for rise time and plot it against $ $ for each $ _n $. - The plot will show multiple curves, each representing a different $ _n $, and how the rise time varies with $ $ for these values.\nRunning this code will generate a graph illustrating the relationship between rise time, damping ratio $ $, and natural frequency $ _n $. The graph will demonstrate that while the rise time varies with different $ _n $ values, the effect of $ $ on rise time is relatively small, especially within a typical range of $ $.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a range of zeta and omega_n values\nzeta_values = np.linspace(0.01, 0.99, 100)  # Zeta values from 0.01 to 0.99\nomega_n_values = np.array([1, 2, 5, 10])    # Different omega_n values\n\n# Function to calculate rise time\ndef rise_time(zeta, omega_n):\n    return (np.pi - np.arccos(zeta)) / (omega_n * np.sqrt(1 - zeta**2))\n\ndef normalised_rise_time(zeta):\n    return (np.pi - np.arccos(zeta)) / (np.sqrt(1 - zeta**2))\n    \n# Plotting\nplt.figure(figsize=(10, 6))\nfor omega_n in omega_n_values:\n    rt = rise_time(zeta_values, omega_n)    \n    plt.plot(zeta_values, rt, label=f'ωₙ = {omega_n}')\n\nwnrt = normalised_rise_time(zeta_values)\nplt.plot(zeta_values, wnrt, label=f'ωₙtₙ')\n\n\n# Add vertical lines at zeta = 0.4 and zeta = 0.7\nplt.axvline(x=0.4, color='gray', linestyle='--', linewidth=1.5, label='ζ = 0.4')\nplt.axvline(x=0.7, color='gray', linestyle='--', linewidth=1.5, label='ζ = 0.7')\n\n\nplt.title('Rise Time vs Damping Ratio (ζ) for Different ωₙ')\n\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Rise Time')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPeak Overshoot (\\(M_p\\))\nThe peak overshoot is given by:\n\\[\\Large M_p = e^{-\\frac{\\pi \\zeta}{\\sqrt{1 - \\zeta^2}}} \\]\nHere, $ M_p $ depends solely on the damping ratio $ $.\nWe would like the rise time \\(t_r\\) to be as short as possible, but also that the peak overshoot remains small. A high peak overshoot means that the system is close to instability and even small variations of parameters might make the system unstable.\nTypically, $ M_p $ is acceptable when stays between \\(5\\% - 40\\%\\). A value less than \\(5\\%\\) is also acceptable but typically this means that the rise time will be very high.\nThis means that typically: \\(0.4 &lt; \\zeta &lt; 0.7\\). With reference to the previous figure, in this range, \\(\\omega_n t_r\\) (the normalised rise time) is practically constant and not affected too much by the change in the damping ratio.\nIf this is true we can then say that the rise time is the inverse of the undamped natural frequency:\n\\[ \\omega_n t_r = const \\Rightarrow t_r = \\frac{1}{\\omega_n} const\\]\n\n\nRise time and Bandwidth\nTo optimize the performance of a control system, particularly its speed of response, we often aim to decrease the rise time. The rise time, which indicates how quickly a system responds to changes, is inversely related to the system’s natural frequency, $ _n $. Therefore, to reduce the rise time, a common strategy is to design the system such that $ _n $ is as large as possible.\nHowever, this approach comes with a significant caveat. Increasing $ _n $ also increases the system’s bandwidth. Bandwidth, in simple terms, is the range of frequencies over which the system can effectively operate. A higher bandwidth means that the system becomes more sensitive to a wider range of frequencies, including those in the higher range.\nThe challenge with a large bandwidth is that it allows high-frequency signals, which are often noise, to penetrate the system. These high-frequency signals can adversely affect the system’s performance. In contrast, the useful signals in most control systems are typically of lower frequency. Thus, while a large bandwidth might improve the speed of response, it can compromise the system’s ability to filter out unwanted noise.\nTherefore, when designing for optimal rise time, one must consider the trade-off between speed of response and noise immunity. The goal is not to achieve the smallest theoretical rise time, but to find a practical balance that ensures the system’s reliability and stability. This balance is largely influenced by the bandwidth limitations.\nThe relationship between the speed of response (as measured by the rise time) and the system’s bandwidth is almost direct: a faster response (lower rise time) corresponds to a wider bandwidth. However, an infinite bandwidth is impractical, as it would lead to excessive noise interference. Consequently, a zero rise time, which would require infinite bandwidth, is unachievable.\nThe appropriate balance between rise time and bandwidth is highly dependent on the specific components and characteristics of the system. For instance, if the system employs sensors that do not generate high-frequency noise, it may be feasible to design for a higher bandwidth (and thus a lower rise time) without significantly compromising the system’s performance. Each system requires a tailored approach, considering its unique hardware and operational environment.\n\n\nStability considerations\n\n\n\n\n\nIn the context of control systems, particularly those modeled as second-order systems, the stability and response characteristics are significantly influenced by two parameters: the damping ratio ($ \\() and the natural frequency (\\) _n $). The damping ratio $ $ plays a pivotal role in governing the system’s oscillatory behavior and its ability to reach equilibrium. A higher $ $ results in less oscillation and a more overdamped system, which stabilizes quicker but may have a slower response. Conversely, a lower $ $ leads to a more underdamped system, characterized by more pronounced oscillations, and can risk instability if it becomes too low.\nThe natural frequency $ _n $, representing the system’s intrinsic oscillation rate in the absence of damping, affects the speed of the system’s response. A higher $ _n $ typically allows for faster response times but, coupled with a low damping ratio, can induce rapid oscillations, edging the system towards instability.\nCrucially, the peak overshoot ($ M_p $) is intimately linked with these parameters. $ M_p $, defined as the maximum peak of the response curve as a percentage over the final value, is directly influenced by $ $. Specifically, $ M_p = e^{-} $ illustrates that a higher damping ratio reduces the peak overshoot, moving the system away from instability. This relationship highlights the delicate balance required in control system design: ensuring responsiveness and minimizing overshoot while maintaining stability. Therefore, the selection of $ $ and $ _n $ must be made with a keen understanding of their impact on both the transient response (rise time, overshoot) and the overall stability of the system.\nFor example, a \\(100\\%\\) overshoot means that the poles are on the \\(j\\omega\\) axis and hence the system is marginally stable.\nQualitatively, for second-order systems: - \\(\\zeta\\) is indicative of stability. - \\(\\omega_n\\) is indicative of the speed of response.\n\nIn other words, the stability of a control system depends by two key parameters: the damping ratio $ $ and the natural frequency $ _n $.\n\ndamping ratio $ $: The damping ratio $ $ primarily dictates the system’s ability to mitigate oscillations and return to equilibrium.\n\nA higher $ $ generally indicates a more damped system, which tends to stabilize more quickly but may respond slower to changes.\nIn contrast, a lower $ $ leads to a less damped system that can exhibit more oscillatory behavior, potentially approaching instability if it’s too low.\n\n**natural frequency $ _n $**: The natural frequency $ _n $, on the other hand, is indicative of the system’s inherent tendency to oscillate at a particular rate in the absence of damping.\n\nA higher $ _n $ can contribute to a quicker response time, but when combined with a low damping ratio, it can make the system prone to rapid and potentially unstable oscillations.\n\n\nThe interplay between $ $ and $ _n $ is therefore important: while a higher $ _n $ can enhance system responsiveness, it must be balanced with an appropriate $ $ to ensure the system remains stable and does not oscillate excessively. This balance is key in control system design, ensuring that systems are both responsive and stable.\n\nTo calculate the peak overshoot (\\(M_p\\)) for $ = 0.4 $ and $ = 0.7 $ in Python, we can use the numpy library for numerical calculations.\nThe cell below defines a function peak_overshoot which takes a damping ratio $ $ and computes the peak overshoot using the given formula. The function is then used to calculate the peak overshoot for $ = 0.4 $ and $ = 0.7 $. The results are printed in both decimal and percentage forms.\nHere’s the Python code to do this:\n\nimport numpy as np\n\n# Function to calculate peak overshoot\ndef peak_overshoot(zeta):\n    return np.exp(-np.pi * zeta / np.sqrt(1 - zeta**2))\n\n# Calculate peak overshoot for zeta = 0.4 and zeta = 0.7\nmp_04 = peak_overshoot(0.4)\nmp_07 = peak_overshoot(0.7)\n\nprint(f\"Peak Overshoot for ζ = 0.4: {mp_04:.4f} or {mp_04 * 100:.2f}%\")\nprint(f\"Peak Overshoot for ζ = 0.7: {mp_07:.4f} or {mp_07 * 100:.2f}%\")\n\nPeak Overshoot for ζ = 0.4: 0.2538 or 25.38%\nPeak Overshoot for ζ = 0.7: 0.0460 or 4.60%\n\n\n\n\nPeak time (\\(t_p\\))\nThe peak time \\(t_p\\) is similar to the rise term in terms of qualitative behaviour.\nThe relationship between the peak time (\\(t_p\\))) and the natural frequency (\\(\\omega_n\\))) is also important to understand. The peak time is defined as the time it takes for the system response to reach its first maximum peak. From the theoretical background provided, the peak time is given by the formula:\n\\[ t_p = \\frac{\\pi}{\\omega_n \\sqrt{1 - \\zeta^2}} \\]\nThis equation illustrates that the peak time is inversely proportional to the natural frequency (\\(\\omega_n\\)) of the system, while also being influenced by the damping ratio \\(\\zeta\\)). Specifically, as \\(\\omega_n\\) increases, the peak time \\(t_p\\) decreases, implying that the system reaches its peak response more quickly. This relationship highlights that a system with a higher natural frequency will respond faster, reaching its peak in a shorter amount of time.\nThe presence of \\(\\sqrt{1 - \\zeta^2}\\)) in the denominator also indicates the influence of the damping ratio \\(\\zeta\\)) on the peak time. However, the dominant factor in determining \\(t_p\\) is \\(\\omega_n\\), as the damping ratio’s impact is moderated by the square root and the subtraction from unity.\nIn practical terms, designing a control system with a higher natural frequency \\(\\omega_n\\) can be beneficial for achieving quicker responses. However, this must be carefully balanced with considerations for the system’s stability and overshoot, as influenced by both \\(\\omega_n\\) and \\(\\zeta\\). The peak time thus serves as an essential indicator in the design and analysis of control systems, particularly when quick responses are desirable, but not at the expense of system stability and performance.\n\n\nSettling Time (\\(t_s\\))\nCalculating an analytical expression for the settling time in control systems, particularly for higher-order or complex systems, presents several challenges.\nSettling time is defined as the duration after which the system’s response remains within a specified tolerance band around the steady-state value and does not exit this band thereafter.\nFor second-order systems, this can often be approximated with standard formulas, especially when systems are underdamped. However, for systems that exhibit more complex behavior, such as those with higher-order dynamics, non-linearities, or varying parameters, deriving an exact analytical expression becomes considerably more complicated.\nOne of the key difficulties lies in the system’s response characteristics, which can vary significantly based on factors like damping ratio ($ \\(), natural frequency (\\) _n $), and the presence of non-linear elements or external disturbances. The response might exhibit oscillations, overshoots, or varying rates of decay, which are not straightforward to encapsulate in a single formula. Additionally, the criteria for ‘settling’ within a tolerance band are not always clear-cut in practical scenarios, where noise and external factors can cause the response to fluctuate around the desired value.\nAs a result, numerical methods and simulations become essential tools for accurately determining the settling time. They allow for the detailed modeling of system behavior under various conditions, capturing nuances that analytical methods may miss. The following Python code exemplifies this numerical approach, illustrating how the settling time varies with the damping ratio ($ $) in a second-order system. This numerical analysis provides a more flexible and practical means to understand and predict system behavior in real-world scenarios.\n\n\nSettling Time vs. Damping Ratio\nIn control systems, the relationship between the settling time and the damping ratio (\\(\\zeta\\)) can be effectively illustrated through a graph.\nThis graph is particularly insightful as it reveals the non-linear nature of how the settling time varies with different values of \\(\\zeta\\).\nSpecifically, it highlights a notable characteristic where the settling time experiences a sharp increase at certain values of \\(\\zeta\\).\nThis increase is not linear or gradual but occurs at specific points, reflecting the complex dynamics of how damping affects the time it takes for a system to stabilize within its desired operational parameters. Such a graphical representation is crucial for understanding and designing control systems, especially in fine-tuning damping ratios to achieve optimal performance.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)  # Extended time range for more clarity\n\n# System parameters\nzeta_values = [1, 0.9, 0.7, 0.55, 0.43]\nomega_n = 1  # Natural frequency\n\n# Function for second-order system unit-step response\ndef unit_step_response(t, zeta, omega_n):\n    if zeta &lt; 1:  # Underdamped\n        omega_d = omega_n * np.sqrt(1 - zeta**2)\n        return 1 - np.exp(-zeta * omega_n * t) * (np.cos(omega_d * t) + (zeta/np.sqrt(1-zeta**2)) * np.sin(omega_d * t))\n    elif zeta == 1:  # Critically damped\n        return 1 - np.exp(-omega_n * t) * (1 + omega_n * t)\n\n# Compute settling time\ndef compute_settling_time(t, response, tolerance=0.05):\n    upper_bound = 1 + tolerance\n    lower_bound = 1 - tolerance\n    for i in range(len(response)):\n        if all(response[j] &lt; upper_bound and response[j] &gt; lower_bound for j in range(i, len(response))):\n            return t[i]\n    return np.nan\n\n# Storing settling times\nsettling_times = []\n\n# Plotting responses for different zeta values\nplt.figure(figsize=(10, 6))\nfor zeta in zeta_values:\n    y = unit_step_response(t, zeta, omega_n)\n    settling_time = compute_settling_time(t, y)\n    settling_times.append(settling_time)\n    plt.plot(t, y, label=f'ζ = {zeta}')\n    # Annotate settling time\n    if not np.isnan(settling_time):\n        plt.axvline(x=settling_time, color='gray', linestyle='--', alpha=0.7)\n        settling_point = y[np.argmin(np.abs(t - settling_time))]\n        plt.plot(settling_time, settling_point, 'ro')  # Mark the settling point\n        plt.text(settling_time, settling_point, f' ({settling_time:.2f}s)', verticalalignment='bottom')\n        #plt.text(settling_time, settling_point, f' ({settling_time:.2f}, {settling_point:.2f})', verticalalignment='bottom')\n\n\n# Unit value and tolerance band\nplt.plot(t, np.ones_like(t), 'k--', label='Unit Value')\nplt.fill_between(t, 0.95, 1.05, color='yellow', alpha=0.3, label='5% Tolerance Band')\n\nplt.title('Unit-Step Response of a Second-Order System')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n    \n# Plotting Settling Time vs Zeta\nplt.figure(figsize=(10, 6))\nplt.plot(zeta_values, settling_times, 'o:', label='Settling Time', markersize=12)\nplt.title('Normalised Settling Time (ωₙtₙ) vs Damping Ratio (ζ)')\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Normalised Settling Time (ωₙtₙ)')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe plot shows the typical response of a second-order system to settle to its final value within a \\(5\\%\\) tolerance band (hence between values 0.95-1.05). The plot also shows the response of the system for a critically damped system (\\(\\zeta=1\\)).\nWe can define a better curve varying \\(\\zeta\\):\n\n# Time array\nt = np.linspace(0, 100, 1000)  # Extended time range for more clarity and lower damping ratios\n\nzeta_values = np.linspace(0.2, 1, 500) \nsettling_times =[]\nfor zeta in zeta_values:\n    y = unit_step_response(t, zeta, omega_n)\n    settling_time = compute_settling_time(t, y)\n    settling_times.append(settling_time)\n    \n# Plotting Settling Time vs Zeta\nplt.figure(figsize=(10, 6))\nplt.plot(zeta_values, settling_times, 'o--', label='Settling Time', markersize=5)\nplt.title('Normalised Settling Time (ωₙtₙ) vs Damping Ratio (ζ)')\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Normalised Settling Time (ωₙtₙ)')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nApproximating the Settling Time\nApproximating the settling time of a control system using the envelope of its response is a practical approach, especially in the case of underdamped systems where the response exhibits oscillatory behavior. The envelope provides a clear visual representation of the maximum extent of the system’s response over time, which is particularly useful for identifying when the system’s output stabilizes within a specified tolerance band.\nThis will make it possible to have an approximation of the part where \\(0 &lt; \\zeta &lt; 0.7\\) in the above plot. Remember that typical values for the damping ratio will be in this range. The behaviour for values of \\(\\zeta&gt;0.7\\) is different.\nThe standard form of the response of an underdamped second-order system can be expressed as:\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\nwhere $ $ is the damping ratio, $ _n $ is the natural frequency, and $ _d = _n $ is the damped natural frequency.\nThe envelope of this oscillatory response is given by the decaying exponential term:\n\\[\n1 \\pm \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}}\n\\]\nThis envelope captures the oscillatory nature of the system’s response and its exponential decay.\nTo approximate the settling time, you can set the envelope equal to the tolerance level and solve for time $ t $. For instance, for a 5% tolerance level, the equation becomes:\n\\[ 1 + \\frac{e^{-\\zeta \\omega_n t_s}}{\\sqrt{1 - \\zeta^2}} = 0.05 \\]\nSolving for \\(t\\) gives:\n\\[\n\\zeta\\omega_n t_s = -\\ln(0.05\\sqrt{1-\\zeta^2})\n\\]\nand\n\\[\n\\omega_n t_s = -\\frac{1}{\\zeta}\\ln(0.05\\sqrt{1-\\zeta^2})\n\\]\nand finally:\n\\[\nt_s = -\\frac{1}{\\omega_n\\zeta}\\ln(0.05\\sqrt{1-\\zeta^2})\n\\]\nNote that \\(\\ln(0.05\\sqrt{1-\\zeta^2}) \\in [-3, -3.3]\\), for \\(0 &lt; \\zeta &lt; 0.7\\) (which is what we are analysing).\nWe can obtain a further approximation as:\n\\[\nt_s = \\frac{3}{\\omega_n\\zeta}\n\\]\nLet’s write Python code that plots this envelope for a range of \\(\\zeta\\) values and indicates the associated settling time within a 5% tolerance band. The settling time can be estimated by finding the point at which the envelope first enters the tolerance band and doesn’t exit afterward.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)  # Time range for plotting\n\n# System parameters\nzeta_values = [0.9, 0.7, 0.55, 0.43]  # zeta values - to highlight the difference use [0.2, 0.5, 0.7] \nomega_n = 1  # Natural frequency\ncolors = ['red', 'blue', 'green', 'purple']  # Colors for each zeta value\n\n# Plotting\nplt.figure(figsize=(10, 6))\nfor zeta, color in zip(zeta_values, colors):\n    envelope_upper = 1 + np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)\n    envelope_lower = 1 - np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)\n    \n    # Plot envelope\n    plt.plot(t, envelope_upper, color=color, linestyle='--', alpha=0.5)\n    plt.plot(t, envelope_lower, color=color, linestyle='--', alpha=0.5, label=f'ζ = {zeta}')\n\n    # Settling time estimation\n    settling_time = -np.log(0.05 * np.sqrt(1 - zeta**2)) / (zeta * omega_n)\n    plt.axvline(x=settling_time, color=color, linestyle='-', alpha=0.7)\n    plt.text(settling_time, 1.1, f'{settling_time:.2f}', rotation=90, verticalalignment='bottom', color=color)\n\nplt.title('Envelope and Settling Time for Underdamped Systems')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSettling Time within a 2% Tolerance Band\nIn control system specifications, a 2% tolerance band is commonly utilized. Through detailed computer simulations, it has been observed that the critical damping ratio for achieving a 2% tolerance band is \\(\\zeta = 0.76\\). The behavior of the normalized settling time (\\(\\omega_n t_s\\)) relative to \\(\\zeta\\) in this scenario exhibits a notable pattern:\n\nWhen \\(\\zeta\\) ranges from 1 to 0.76, the normalized settling time decreases.\nAs \\(\\zeta\\) decreases from 0.76 to 0, the normalized settling time increases.\n\nThe challenge in obtaining an analytical expression for the settling time within a 2% tolerance band, as before, lies in its complex non-linear nature. However, an approximation can be made as follows:\n\\[ \\zeta \\omega_n t_s = -\\ln\\left(0.02 \\sqrt{1-\\zeta^2}\\right) \\]\nHere, the logarithmic term \\(\\ln(0.02 \\sqrt{1-\\zeta^2})\\) varies between -3.9 to -4.34 for \\(\\zeta\\) values within the range of 0 to 0.76, reaching its minimum at \\(\\zeta=0.76\\). Rewriting this expression, we get:\n\\[ t_s = -\\frac{1}{\\zeta \\omega_n} \\ln\\left(0.02 \\sqrt{1-\\zeta^2}\\right) \\]\nIn this context, it’s important to note that \\(\\zeta \\omega_n\\) is the reciprocal of the time constant of the envelope curve. Therefore, for a 2% tolerance band, the settling time can be approximated using the time constant of the system’s envelope:\n\\[ t_s = \\frac{4}{\\zeta \\omega_n} \\] (i.e., four times the time constant)\nThis approximation effectively utilizes the time constant of the envelope curve, simplifying the calculation of the settling time within the specified tolerance band.\nThis is the expression for the settling time that we will use most of the time.",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html#understanding-steady-state-error",
    "href": "design_of_feedback_control.html#understanding-steady-state-error",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "Understanding Steady-State Error",
    "text": "Understanding Steady-State Error\nSteady-state error is a key metric in control systems that quantifies the difference between the desired output (the setpoint) and the actual output of the system as time approaches infinity. In simpler terms, it measures how close the system’s output can get to the desired value after transients have died out.\n\nSteady-State Error for Different Inputs\nThe nature of the steady-state error varies significantly based on the type of input signal the system is responding to.\nTypically, three standard types of inputs are considered: step, ramp, and parabolic. When designing a controller for steady state, it is typically important to understand the system behaivour for all these inputs.\nThe steady-state error for each type of input highlights the system’s ability to track different kinds of signals:\n\n1. Step Input\nFor a step input (a sudden change in the desired output), a well-designed second-order system will often have a steady-state error of zero. This is because the system can adjust its output to match the new setpoint after some time.\nThis is clear looking at the unit-step response for \\(t \\rightarrow \\infty\\):\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\n\n\n2. Ramp Input:\nA ramp input (a continuously increasing or decreasing setpoint) introduces a new challenge. The steady-state error for a ramp input is generally non-zero for a standard second-order system. It indicates the system’s inability to keep up with the continuously changing setpoint. The steady-state error in response to a ramp input can be calculated using the final value theorem from Laplace transform theory.\n\\[R(s) = \\frac{1}{s^2}\\]\nand\n\\[Y(s) = \\frac{\\omega_n^2}{s^2(s^2+2\\zeta\\omega_ns+\\omega_n^2)}\\]\nwhose inverse is:\n\\[\ny(t) = t - \\frac{2\\zeta}{\\omega_n} + \\frac{e^{-\\zeta\\omega_nt}}{\\omega_n\\sqrt{1-\\zeta^2}}\\sin(\\omega_dt+2\\theta)\n\\]\nwhere \\(\\theta = \\cos^{-1}\\zeta\\) and \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\)\nTo create a Python sketch of the response to a ramp input, we’ll use the provided response formulas.\nThe code below plots both the response of the system to a ramp input and the ramp input itself. The ramp_response function computes the system’s response using the given formula. The plot will illustrate how the system’s output behaves over time in response to a linearly increasing input. The parameters \\(\\zeta\\) and \\(\\omega_n\\) can be adjusted to see how different system characteristics affect the response.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 500)\n\n# System parameters\nzeta = 0.3  # Example damping ratio\nomega_n = 2  # Example natural frequency\n\n# Calculate omega_s and theta\nomega_s = omega_n * np.sqrt(1 - zeta**2)\ntheta = np.arccos(zeta) # np.arctan(np.sqrt(1 - zeta**2) / zeta)\n\n# Response to ramp input\ndef ramp_response(t, zeta, omega_n, omega_s, theta):\n    return t - (2 * zeta / omega_n) + (np.exp(-zeta * omega_n * t) / (omega_n * np.sqrt(1 - zeta**2))) * np.sin(omega_s * t + 2 * theta)\n\n# Ramp input\nramp_input = t\n\n# Calculating response\nresponse = ramp_response(t, zeta, omega_n, omega_s, theta)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t, response, label='System Response to Ramp Input')\nplt.plot(t, ramp_input, label='Ramp Input', linestyle='--')\nplt.title('Response to a Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nComments\nNote that from a transient perspective, there are no new behaviours. There is oscillations that we captured already analysing the unit-step response. This is the reason why we do not need to analyse the transient to multiple inputs.\nIf however we look at the steady state, we now have a steady state error.\nGiven: \\[\ny(t) = t - \\frac{2\\zeta}{\\omega_n} + \\frac{e^{-\\zeta\\omega_nt}}{\\omega_n\\sqrt{1-\\zeta^2}}\\sin(\\omega_dt+2\\theta)\n\\]\nwhen \\(t \\rightarrow \\infty\\):\n\\[\ny_{ss} = t - \\frac{2\\zeta}{\\omega_n}\n\\]\nThe output follow the ramp input but with a \\(\\frac{2\\zeta}{\\omega_n}\\) steady state error.\nThe steady state error can formally be calculated as:\n\\[\ne_{ss} = r - y_{ss} = t -  \\big(t - \\frac{2\\zeta}{\\omega_n}\\big) = \\frac{2\\zeta}{\\omega_n}\n\\]\n\n\n\n\nAnalytical Calculation\nAnalytically, the steady-state error can be determined using the final value theorem of Laplace transforms.\nIn this case, we are not interested in the transient behaviour which we analyse only through the response to the unit-step input.\nThe theorem states that the steady-state value of a function can be found by taking the limit as \\(s\\) (the Laplace variable) approaches zero of \\(s\\) times the Laplace transform of the function.\nFor example, the steady-state error for a ramp input can be calculated by applying the final value theorem to the error signal \\(E(s)\\), which is the difference between the input signal \\(R(s)\\) and the output signal \\(Y(s)\\). This involves evaluating the limit:\n\\[ e_{ss} = \\lim_{s \\to 0} sE(s) \\]\nwhere \\(E(s) = R(s) - Y(s)\\).\nFor our system:\n\n\n\n\n\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1+G(s)}\n\\]\nFrom which:\n\\[\nE(s) = \\frac{R(s)}{1+G(s)}\n\\]\nApplying the final value theorem:\n\\[ e_{ss} = \\lim_{s \\to 0} s \\frac{R(s)}{1+G(s)} \\]\nRemember the conditions for applycability of the final value theorem: \\(sE(s)\\) has no poles on the imaginary axis or in the RHP.\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1 + \\frac{\\omega_n^2}{s(s+2\\zeta\\omega_n)}} = \\frac{s(s+2\\zeta\\omega_n)}{s^2 +2\\zeta\\omega_ns + \\omega_n^2}\n\\]\ngiven that \\(R(s)=\\frac{1}{s^2}\\) we obtain:\n\\[\nE(s) = \\frac{(s+2\\zeta\\omega_n)}{s(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\n\\[\nsE(s) = \\frac{(s+2\\zeta\\omega_n)}{(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\nThis transfer function has no poles on the imaginary axis or in the right half plane and we can apply the Final Value Theorem. This is important to check!\nand finally:\n\\[ e_{ss} = \\lim_{s \\to 0} s E(s) = \\frac{2\\zeta}{\\omega_n}\\]\n\n3. Parabolic Input:\nThe parabolic input represents an even more challenging scenario, typically resulting in an infinite steady-state error for a standard second-order system. This reflects the system’s inability to track a signal that changes at an accelerating rate.\nApplying the same reasoning: \\[\n   R(s) = \\frac{1}{s^3}\n   \\]\nand\n\\[\n   sE(s) = \\frac{(s+2\\zeta\\omega_n)}{s(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n   \\]\nWe cannot apply the Final Value Theorem because we have one pole on the imaginary axis.\nTo understand the steady state error we can analyse:\n\\[\n   E(s) = \\frac{(s+2\\zeta\\omega_n)}{s^2(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n   \\]\ninvert this expression to obtain \\(e(t)\\) for \\(t\\rightarrow \\infty\\). This function has two poles at the origin, which means that we can interpret this as an unstable system, i.e., the error grows unbounded.\nThe standard second-order system in feedback loop is not able to follow a parabolic input. It means that this system might need to be limited to cases where inputs are steps and ramps only. Alternatively we need a suitable controller.\nTo sum up we can re-run the same code we had in notebook 18_Performance_of_Feedback_Systems. The unbounded growth of the steady state error for the parabolic input is clearly visible.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n# Define system parameters (modify as needed for your example)\nKp = 1.0    # Proportional gain\nomega_n = 1.0  # Natural frequency\nzeta = 0.5  # Damping ratio\nnum = [Kp * omega_n**2]\nden = [1, 2 * zeta * omega_n, omega_n**2]\n\n# Create transfer function\nG = control.tf(num, den)\n\n# Time vector\nt = np.linspace(0, 20, 1000)\n\n# Unit Step Input\nt_step, y_step = control.step_response(G, t)\ne_step = 1 - y_step  # Steady-state error for step input\n\n# Unit Ramp Input\nt_ramp, y_ramp = control.forced_response(G, t, t)\ne_ramp = t - y_ramp  # Steady-state error for ramp input\n\n# Unit Parabola Input\nt_parabola, y_parabola = control.forced_response(G, t, t**2 / 2)\ne_parabola = t**2 / 2 - y_parabola  # Steady-state error for parabola input\n\n# Plotting\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.plot(t_step, y_step, label='Response')\nplt.plot(t_step, np.ones_like(t_step), 'r--', label='Step Input')\nplt.plot(t_step, e_step, 'g:', label='Error')\nplt.title('Response to Unit Step Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(t_ramp, y_ramp, label='Response')\nplt.plot(t_ramp, t_ramp, 'r--', label='Ramp Input')\nplt.plot(t_ramp, e_ramp, 'g:', label='Error')\nplt.title('Response to Unit Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t_parabola, y_parabola, label='Response')\nplt.plot(t_parabola, t_parabola**2 / 2, 'r--', label='Parabola Input')\nplt.plot(t_parabola, e_parabola, 'g:', label='Error')\nplt.title('Response to Unit Parabola Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nPractical Implications\nIn practical terms, understanding and calculating the steady-state error is crucial for system design and tuning. It helps in setting realistic performance expectations and in choosing the right type of controller or compensator to minimize the error for the given type of input. For instance, in systems where following a ramp input is important, designers might opt for different controller settings or add integral action to reduce the steady-state error.\nIn summary, the steady-state error is a vital aspect of control system performance, offering insight into how well a system can maintain its output at or near a desired level in response to various types of inputs. Analyzing and minimizing this error is a key part of control system design and optimization.",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "design_of_feedback_control.html#exercise-and-questions",
    "href": "design_of_feedback_control.html#exercise-and-questions",
    "title": "Design Cycle for a Standard Second-Order System",
    "section": "Exercise and Questions",
    "text": "Exercise and Questions\nNow, let’s reinforce these concepts with some exercises: 1. Compute Peak Overshoot: Given a damping ratio of 0.5, calculate the peak overshoot $ M_p $. 2. Steady-State Error for a Ramp Input: For a system with $ = 0.3 $ and $ _n = 4 $, find the steady-state error for a ramp input. 3. Effect of Bandwidth on Stability: Discuss how increasing the bandwidth affects the system’s stability and its ability to reject noise.",
    "crumbs": [
      "Design Cycle for a Standard Second-Order System"
    ]
  },
  {
    "objectID": "toc.html",
    "href": "toc.html",
    "title": "Table of Contents",
    "section": "",
    "text": "from bin.toc import display_table_of_contents\n\n\n# Call this in your notebook to display the table of contents\ndisplay_table_of_contents(notebook_dir='.', exclude_list=['index.ipynb'], font_size='18px')\n\nNotebooks00_FAQ.ipynb00_Syllabus.ipynb00_TOC.ipynb01_Getting_started_with_Python_and_Jupyter_Notebook.ipynb01_intro.ipynb02_basics_of_feedback_control.ipynb03_introduction_to_control_problem.ipynb04_dynamic_systems.ipynb05_dynamic_response.ipynb06_inverse_laplace_transform.ipynb07_modeling_dynamic_systems.ipynb08_control_system_components.ipynb09_Models_of_Control_Devices_and_Systems.ipynb10_hardware_and_case_studies.ipynb11_AC_hardware_and_case_studies.ipynb12_A_First_Complete_Application.ipynb13_Principles_of_Feedback_Control.ipynb14_Feedback_systems_and_their_effects.ipynb15_Introduction_to_Control_Systems.ipynb16_Stability.ipynb17_Stability_and_Routh_Criterion.ipynb18_Performance_of_Feedback_Systems.ipynb19_Design_of_feedback_control.ipynb20_Design_of_feedback_control_continued.ipynb21_Steady_State_Accuracy_And_Design_Principles.ipynb22_Compensator_Design_Using_Root_Locus.ipynb23_Design_with_the_root_locus.ipynb24_Compensators_and_Root_Locus.ipynb25_Introduction_to_Frequency_Domain_Analysis_in_Control_Systems.ipynb26_Application_of_Nyquist_Stability_Criterion.ipynb27_The_Nyquist_Stability_Criterion_and_Relative_Stability.ipynb28_Bode_Plots.ipynb29_Feedback_system_performance_based_on_frequency_response.ipynb30_TBC.ipynb",
    "crumbs": [
      "Table of Contents"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html",
    "href": "modeling_dynamic_systems.html",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "",
    "text": "Modeling serves as the backbone for understanding and manipulating dynamic systems. These dynamic systems encompass various components:\nThe primary goal? To establish precise equations that define these dynamic systems.\nRecalling our previous discussions, our focus has always been on applying physical laws. By doing so, we can transform the derived differential equations into more digestible forms. Two such forms that we’ll extensively use are:\nThese models offer a structured way to represent systems mathematically, allowing for analysis and design.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#mechanics",
    "href": "modeling_dynamic_systems.html#mechanics",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Mechanics",
    "text": "Mechanics\nWhile this might feel like revisiting old territory, a review of the mechanics of translation is important. This is because the physical models we use in control systems are derived from these very principles.\nUnder the umbrella of mechanics of translation, three fundamental elements emerge:\n\nThe ideal mass \\(M\\)\nThe friction coefficient \\(B\\)\nThe spring constant \\(K\\)\n\n\nMass\nThe component \\(M\\), representing the ideal mass, is a simplification, a lumped parameter idealization of a distributed mass. In real-world scenarios, you wouldn’t encounter a single particle of mass \\(M\\). This is an approximation where we assume that the entire mass is centered at its centre of gravity.\nPop-up Question: Why do we use lumped parameter idealization for the ideal mass \\(M\\) in dynamic systems?\nAnswer: We use lumped parameter idealization to simplify the representation of distributed masses by approximating them as a single point mass concentrated at its centre of gravity. This makes modeling and analysis more tractable.\n\n\nFriction\nThe friction coefficient \\(B\\) presents its own set of challenges. Friction can arise due to various phenomena, hence different models might be necessary.\nFor instance, constant drive friction between surfaces would result in a constant frictional force for all velocities, known as Coulomb friction.\nOn the other hand, when two surfaces slide with a viscous medium in between, the frictional force is typically proportional to velocity, leading to the equation \\(F=Bv\\), where \\(B\\) is the coefficient of viscous friction. This model is prevalent when a solid body interacts with a fluidic medium.\nIt’s essential to acknowledge the presence of other friction types, like Coulomb friction, in devices like DC motors due to brush contact. But since our initial discussions revolve around linear models, we’ll consider all non-linear frictions as disturbances on the system.\n\n\nSprings\nLastly, the spring constant \\(K\\) comes into play when there’s elastic deformation. Here, the force due to the spring effect is given by \\(F=Kx\\), where \\(x\\) is the displacement.\nNote: It’s essential to understand that these models, while incredibly useful, are approximations. They simplify real-world complexities into digestible chunks that can be used for design and analysis.\n\n\nDeriving the Mathematical Model\nLet’s consider a complex mechanical system, in this case, a car’s suspension system, and see how we can approximate it through a simpler mass, spring, damper.\n\n\n\n\n\n\nGiven a physical system, our first step is to derive its mathematical model. This is essential for analysis or design.\nLet’s take, for instance, the load on a system comprising the mass of a power piston, the drive linkage, and wheels. All these components have distributed masses. However, for our model, we’ll simplify this as a single particle of mass \\(M\\).\nIn our case, the distributed mass is the mass of the power piston, the mass of the drive linkage and the mass of the wheels. But we will model all this as a particle mass \\(M\\).\nFrictions in our system arise from various sources, such as the motion of a piston in a viscous medium or the interaction between the drive linkage and its surroundings. We’ll model these frictions using the parameter \\(B\\) and a Viscous Friction.\nThe tires on the road could create a Coulomb Friction, but we will consider this as a disturbance acting on our system.\nFinally, the elastic behaviour of the tires can be modeled through a spring with parameter \\(k\\).\nWith these considerations we can model the cat’s suspension system with:\n\n\n\n\n\n\nThis transformation, while involving various approximations, has proven to be effective for control system design.\nWe saw that depending on the \\(\\zeta\\) parameter we have undamped (\\(\\zeta=0\\)), damped (\\(0&lt;\\zeta&lt;1\\)), critically damped (\\(\\zeta=1\\)) and over damped systems (\\(\\zeta&gt;1\\)).\nIn some situations, we might need to introduce intentional friction to control the system’s damping. This can be achieved using a device called a dashpot, which uses an oil medium to provide resistance against motion.\nThe same symbol (dashpot) we will use for intentional and unintentional friction.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#physical-models-and-approximations",
    "href": "modeling_dynamic_systems.html#physical-models-and-approximations",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Physical models and approximations",
    "text": "Physical models and approximations\nAny physical situation, be it in nature or industry, especially if it pertains to a mechanical system in translational mode, can be modeled using the principles we’ve discussed. This representation will serve as our main model.\nHowever, as we move forward, it’s essential to recognize the complexities and approximations we’ve employed. Every model we derive has its roots in various assumptions and simplifications, which are vital to making the model manageable.\nConsider the parameters \\(M\\) (the ideal mass), \\(K\\) (the spring constant), and \\(B\\) (the dash pot constant or viscous friction constant). In our model, \\(F_\\omega\\) signifies a disturbance force acting on the system. It could be attributed to uncontrolled friction or even environmental factors. We’ve chosen the symbol “\\(\\omega\\)” to represent disturbances.\nThe variables \\(y\\) and \\(v\\) denote displacement and velocity, respectively.\n\n\n\n\n\n\nPop-up Question: Why do we need to model disturbances in our system? Answer: Disturbances can affect the performance and stability of a control system. By modeling them, we can design control strategies to mitigate their effects and ensure the system operates as intended.\nTo transition this physical model into a differential equation model, it’s often useful to sketch a free body diagram.\n\n\n\n\n\n\nThis diagram visualizes the masses as nodes, and the forces acting on them are depicted with arrows. For our current system, we have a single mass, \\(M\\), with an applied force \\(F\\) and a disturbance force \\(F_\\omega\\). Additionally, the spring force \\(Ky\\) and frictional force \\(Bv\\) oppose the motion. We must also consider the inertial force due to the mass \\(M\\) itself, which counteracts the movement.\nA crucial principle in mechanics is the force balance equation, which states that forces promoting motion should equal forces opposing it. Therefore, our equation becomes:\n\\[\nM\\dot{v} + B{v} + Ky = F - F_\\omega\n\\]\nHere, \\(F-F_\\omega\\) is the net force acting to the system.\n\\(\\dot{v}\\) denotes acceleration, and \\(F_\\omega\\) can either assist or counteract (it is an algebric quantity) the applied force \\(F\\) depending on its nature. It’s worth noting that even if \\(F_\\omega\\) assists the motion, it’s still considered a disturbance, as the system wasn’t designed with it in mind.\nWe can convert this to a state variable model:\n\\[\n\\begin{align}\nx_1 &= y\\\\\nx_2 &= v = \\dot{y}\n\\end{align}\n\\]\nand we saw how to do this already. Let’s instead focus on the transfer function model.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#transforming-into-transfer-function-model",
    "href": "modeling_dynamic_systems.html#transforming-into-transfer-function-model",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Transforming into Transfer Function Model",
    "text": "Transforming into Transfer Function Model\nEvery control system can be portrayed in the Laplace domain, making it easier to analyze and design control strategies. For our system, the transfer function is a relation between a single input and output. However, note that the system is a two inputs (\\(F, F_\\omega\\)), one output (\\(y\\)).\nWe can re-write our equation to explicit the output variable:\n\\[\nM\\ddot{y} + B\\dot{y} + Ky = F - F_\\omega\n\\]\nThe Transfer Function is a SISO description and hence, using as a block diagram:\n\n\n\n\n\n\nWe can hence write the transfer function between \\(Y(s)\\) and \\(F(s)\\), and between \\(Y(s)\\) and \\(F_\\omega(s)\\)\nGiven the above representation, we can express the transfer function between \\(Y(s)\\) and \\(F(s)\\) (assuming \\(F_\\omega(s)=0\\)) as:\n\\[\n\\frac{Y(s)}{F(s)} = \\frac{1}{Ms^s+Bs+K}\n\\]\nand this is also the transfer function between \\(Y(s)\\) and \\(F_\\omega(s)\\).\nWe can then call:\n\\[\n\\frac{Y(s)}{F(s)} = \\frac{1}{Ms^s+Bs+K} = G(s)\n\\]\nWith some simplification and standardization, and considering the system’s damping and natural frequency, we get:\n\\[\nG(s)=\\frac{1/K}{\\frac{M}{K}s^s + \\frac{B}{K}s + 1} = \\frac{K_S}{\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 }\n\\]\nWhere I called \\(K_S\\) the system gain to differentiate it from \\(K\\).\nThis function, termed as the quadratic lag, is a second-order lag in contrast to the first-order (or simple) lag we previously discussed.\n\nUnits\nThe importance of understanding these units and parameters cannot be overstated. They form the foundation upon which our mathematical models are built, allowing us to make predictions, design controllers, and understand system behavior.\n\nForce: Newtons, \\(N\\)\nDisplacement \\(y\\): Meters, \\(m\\)\nVelocity \\(v\\): Meters/second, \\(m/s\\)\nAcceleration: Meters/second^2, \\(m/s^2\\)\nMass \\(M\\): kilograms, \\(kg\\), (\\(F=M\\ddot{y}\\)) and hence also \\(N/(m/s^2)\\)\nFriction Coefficient \\(B\\): Newtons/(meters/second), \\(N/(m/s)\\) (\\(F=Bv\\))\nSpring Constant \\(K\\): Newtons/meter, \\(N/m\\) (\\(F=Kx\\))\n\nPop-up Question: What distinguishes a second-order lag (quadratic lag) from a first-order (simple) lag?\nAnswer: A second-order lag has a quadratic term (s^2) in the denominator, while a first-order lag only has a linear term (s). This makes the second-order system more complex, with properties like oscillations and overshoot that aren’t present in a first-order system.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#heat-transfer-through-a-solid-wall",
    "href": "modeling_dynamic_systems.html#heat-transfer-through-a-solid-wall",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Heat Transfer Through a Solid Wall",
    "text": "Heat Transfer Through a Solid Wall\nConsider a wall made of any material with a surface area \\(A\\) (\\(m/s^2\\)) and thickness \\(l\\) (\\(m\\)).\nLet \\(\\theta_1\\) (\\(^oC\\)) and \\(\\theta_2\\) (\\(^oC\\)) be the temperatures on either side of this wall.\n\n\n\n\n\n\nThe heat transfer through this wall can be described by the following equation:\n\\[\nh = \\frac{\\sigma A(\\theta_1−\\theta_2)}{l}\n\\]\nWhere: - \\(h\\) is the heat transfer rate (in Joules per second). - \\(\\sigma\\) is the thermal conductivity of the material.\nFrom an analogous perspective, considering \\(h\\) to be similar to current and the temperature difference \\(\\theta_1−\\theta_2\\) to be similar to voltage, the above equation can be viewed as:\n\\[\nh = \\frac{\\theta_1−\\theta_2}{R}\n\\]\nWhere: - \\(R = \\frac{l}{\\sigma A}\\) is the conductive resistance of the material.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#heat-transfer-at-the-liquid-solid-interface",
    "href": "modeling_dynamic_systems.html#heat-transfer-at-the-liquid-solid-interface",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Heat Transfer at the Liquid-Solid Interface",
    "text": "Heat Transfer at the Liquid-Solid Interface\nConsider a solid-liquid interface, where heat is being transferred. Let \\(U\\) be the film coefficient at this interface, and \\(A\\) be the contact surface area.\nThe heat transfer in this scenario can be described by:\n\\[\nh = UA(\\theta_1−\\theta_2)\n\\]\nWhere: - \\(\\theta_1−\\theta_2\\) is the net gradient across the film\nor\n\\[\nh = \\frac{\\theta_1−\\theta_2}{R}\n\\]\nWhere: - \\(R = \\frac{1}{U A}\\) is the convective heat transfer resistance",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#heat-storage-in-a-solid",
    "href": "modeling_dynamic_systems.html#heat-storage-in-a-solid",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Heat Storage in a Solid",
    "text": "Heat Storage in a Solid\nHeat storage plays an important role in thermal systems. Consider the same wall described earlier.\n\n\n\n\n\n\nThe heat stored within this wall can be represented as:\n\\[\nh=Mc\\frac{d\\theta}{dt}\n\\]\nWhere:\n\n\\(h\\) is the heat flow rate in Joules/second\n\\(M\\) is the mass of the material\n\\(c\\) is the specific heat of the material\n\\(\\theta\\) is the temperature of the material\n\nThe equation can be written as:\n\\[\nh = C\\frac{d\\theta}{dt}\n\\]\nWhere: - \\(C=Mc\\) is the thermal capacitance of the material.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#heat-storage-in-a-solid-1",
    "href": "modeling_dynamic_systems.html#heat-storage-in-a-solid-1",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Heat Storage in a Solid",
    "text": "Heat Storage in a Solid\nHeat storage plays a pivotal role in thermal systems. Consider the same wall described earlier.\n\n\n\n\n\n\nWhere:\n\n\\(M\\) is the mass\n\\(\\theta\\) is the temperature\n\nThe rate of change of the heat stored within this wall can be represented as:\n\\[\nh=Mc\\frac{d\\theta}{dt}\n\\]\nWhere: - \\(h\\) is in Joules/second (rate of change of the heat stored) - \\(c\\) is the specific heat of the material.\nThe equation can be written as:\n\\[\nh=C\\frac{d\\theta}{dt}\n\\]\nWhere:\n\n\\(C=Mc\\) is the thermal capacitance of the material.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "modeling_dynamic_systems.html#heat-storage-in-a-liquid-tank",
    "href": "modeling_dynamic_systems.html#heat-storage-in-a-liquid-tank",
    "title": "Introduction to Modeling of Dynamic Systems",
    "section": "Heat Storage in a Liquid Tank",
    "text": "Heat Storage in a Liquid Tank\nConsider a tank containing a liquid with volume \\(V\\) at temperature \\(\\theta\\).\n\n\n\n\n\n\nThe heat storage within the liquid can be represented as:\n\\[\nh=V\\rho c\\frac{d\\theta}{dt}\n\\]\nWhere:\n\n\\(\\rho\\) is the density of the liquid (\\(Kg/m^3\\)).\n\\(c\\) is the specific heat of the liquid.\n\nThe equation can be written as:\n\\[\nh=C\\frac{d\\theta}{dt}\n\\]\nWhere:\n\n\\(C=V\\rho c\\) is the thermal capacitance of the liquid.\n\nThermal systems have \\(R\\) and \\(C\\) equivalents (and no inductance equivalence).\nPop-up Question: Why do we often use the analogy of electrical circuits when analyzing thermal systems?\nAnswer: Analogizing thermal systems to electrical circuits allows us to apply familiar electrical circuit theory to understand and analyze the behavior of thermal systems. This approach simplifies complex thermal scenarios and provides intuitive insights.",
    "crumbs": [
      "Introduction to Modeling of Dynamic Systems"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_with_the_root_locus_it.html",
    "href": "IT_🇮🇹/design_with_the_root_locus_it.html",
    "title": "Progettare con il luogo delle radici",
    "section": "",
    "text": "Il luogo delle radici è un metodo grafico utilizzato per analizzare come le radici (poli) dell’equazione caratteristica di un sistema cambiano al variare di un parametro, in genere il guadagno del controller (\\(K\\)). Ci aiuta a capire come la stabilità del sistema e la risposta transitoria dipendono dal guadagno di controllo.\nMolti sistemi di controllo industriale sono progettati utilizzando l’approccio del luogo delle radici o l’approccio del dominio della frequenza (basato sui grafici di Bode). Questi metodi garantiscono che il sistema soddisfi i requisiti prestazionali.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettare con il luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_with_the_root_locus_it.html#esempio-di-problema",
    "href": "IT_🇮🇹/design_with_the_root_locus_it.html#esempio-di-problema",
    "title": "Progettare con il luogo delle radici",
    "section": "Esempio di problema",
    "text": "Esempio di problema\nConsideriamo un esempio per applicare il metodo del luogo delle radici. Disponiamo di un impianto con la funzione di trasferimento:\n\\[\nG(s) = \\frac{5}{s(\\frac{1}{6}s+1)(0,5s + 1} = \\frac{60K_A}{s(s+2)(s+6)}\n\\]\nQuesto modello di impianto rappresenta un servosistema motore, dove l’uscita è la posizione e l’ingresso è il segnale manipolato.\n\n\n\n\n\n\n\nCome al solito, la prima cosa che vorremmo capire è se un guadagno del controller può risolvere il nostro problema.\n\nPrecisione in stato stazionario e requisiti transitori\nLa nostra strategia di progettazione consiste nel soddisfare innanzitutto i requisiti di prestazioni transitorie e di precisione in stato stazionario, quindi verificare la robustezza e la reiezione ai disturbi.\nRicordare che i requisiti transitori includono stabilità relativa e velocità di risposta. - La stabilità relativa è correlata al superamento del picco, che può essere specificato utilizzando il rapporto di smorzamento (\\(\\zeta\\)) o il superamento percentuale (\\(M_p\\)). - La velocità di risposta può essere specificata utilizzando il tempo di assestamento (\\(t_s\\)), il tempo di salita (\\(t_r\\)) o la frequenza naturale (\\(\\omega_n\\)).\nNel contesto dei sistemi di secondo ordine, è importante ricordarsi di verificare la ‘condizione di dominanza’. Questa condizione garantisce che le caratteristiche principali di un sistema siano governate dai suoi poli dominanti. Se la condizione di dominanza è soddisfatta, bene! Tuttavia, in caso contrario, dobbiamo affrontare l’influenza degli altri poli, come i terzi poli, sulle prestazioni del sistema. Questo è un aspetto cruciale da considerare quando si affronta un problema di progettazione.\nRequisiti - Precisione a regime: $K_v $ o \\(e_{ss} \\le 0,2\\)\nNella progettazione dei sistemi di controllo, spesso ci concentriamo sulla precisione in condizioni stazionarie. Per un sistema di tipo 1 come il nostro, l’errore di stato stazionario su un ingresso passo è zero. Pertanto, specifichiamo la precisione in stato stazionario in termini di costante di errore di velocità, \\(K_v\\). In questo esempio, vogliamo che \\(K_v\\) sia maggiore o uguale a 5.\nPer soddisfare il requisito di precisione in stato stazionario, dobbiamo selezionare un guadagno appropriato, \\(K_A\\). Dato che vorremmo concentrarci su una pura regolazione del guadagno e disponiamo di un sistema di tipo 1, la costante di accelerazione è sempre \\(K_a=0\\) e l’errore di stato stazionario rispetto agli ingressi parabolici è infinito. Il sistema non sarà in grado di seguire gli input di accelerazione.\nSi noti inoltre che questa discussione significa che per questo sistema qualsiasi requisito di stato stazionario deve essere specificato in termini di precisione per gli ingressi a rampa. È l’unico input che ha senso analizzare. Se ci limitiamo a selezionare un guadagno puro, l’errore al passo è sempre zero; l’errore sulla rampa è sempre infinito.\n\n\nAnalisi del luogo delle radici\nLa prima cosa da fare è mettere la funzione di trasferimento nella forma del luogo delle radici. In questo caso:\n\\[\nG(s) = \\frac{60K_A}{s(s+2)(s+6)} = \\frac{K}{s(s+2)(s+6)}\n\\]\ndove \\(K=60K_A\\) è il guadagno del luogo delle radici.\nIn questo caso, possiamo calcolare \\(K_v\\):\n\\[\nK_v = \\lim_{s\\rightarrow0} s \\frac{60K_A}{s(s+2)(s+6)} = 5K_A\n\\]\ne il nostro requisito è soddisfatto per \\(K_A=1\\), e quindi è soddisfatto per un guadagno del luogo delle radici \\(K=60\\).\n\nPossiamo tracciare un grafico approssimativo del luogo delle radici e localizzare i poli quando \\(K=60\\) applicando la condizione di magnitudo.\n\n\n\n\n\n\n\n\n\nDalla posizione dei poli dell’anello chiuso possiamo determinare l’angolo di smorzamento \\(\\theta\\) e il rapporto di smorzamento \\(\\zeta=\\cos(\\theta) = 0,105\\).\nPossiamo anche ottenere il corrispondente \\(\\omega_n = 2,85\\)\n\n\nTempo di assestamento\nUn parametro chiave per valutare le prestazioni transitorie è il tempo di assestamento (\\(t_s\\)). Il tempo di assestamento rappresenta la velocità con cui il sistema raggiunge uno stato stazionario dopo un disturbo o un cambiamento nell’input. Viene tipicamente definito rispetto ad una fascia di tolleranza del 2% attorno al valore finale.\nLa formula per calcolare il tempo di assestamento è:\n\\[\nt_s = \\frac{4}{\\zeta \\cdot \\omega_n} = 13,36\\;\\;sec\n\\]\ndove \\(\\zeta\\) è il rapporto di smorzamento e \\(\\omega_n\\) è la frequenza naturale. Possiamo calcolare facilmente \\(t_s\\) se conosciamo \\(\\zeta\\) e \\(\\omega_n\\).\n\n\nCondizione di dominanza\nNella progettazione del sistema di controllo, miriamo alla stabilità e alla risposta transitoria soddisfacente. La condizione di dominanza ci aiuta a determinare se possiamo trascurare alcuni poli del sistema.\nLa condizione di dominanza afferma che se i poli complessi coniugati che governano la risposta transitoria sono significativamente più a sinistra sull’asse reale rispetto agli altri poli, possiamo ignorare questi ultimi. Questa semplificazione ci consente di concentrarci sui poli dominanti nell’analisi delle prestazioni transitorie.\nNel nostro caso, le caratteristiche specifiche della risposta transitoria hanno senso solo se abbiamo una coppia di poli dominanti. In questo caso però la condizione di dominanza è certamente verificata. I due anelli chiusi sono con parte reale minore di uno e il terzo polo si allontana da -6 verso \\(-\\infty\\). Se così non fosse, avremmo localizzato il terzo polo utilizzando la condizione di magnitudo e verificato esplicitamente la condizione di dominanza.\nSi noti che la stabilità relativa è piuttosto scarsa, il sistema oscilla ed è molto lento. Con un semplice amplificatore non saremo in grado di soddisfare i requisiti transitori rispettando contemporaneamente la precisione a regime.\n\n\n\nSoddisfare i requisiti temporanei\nConsideriamo un esempio in cui l’utente specifica i requisiti transitori:\n\nRapporto di smorzamento (\\(\\zeta\\)) pari a 0,6\nTempo di assestamento (\\(t_s\\)) inferiore o uguale a 4 secondi\n\n\n1. Trovare i poli dominanti\nPer soddisfare i requisiti transitori, dobbiamo individuare i poli dominanti. Iniziamo impostando \\(\\zeta\\) su 0,6. Ricorda che se ci concentriamo sull’utilizzo di un guadagno semplice, abbiamo solo un grado di libertà e quindi dobbiamo scegliere il parametro specifico con cui vogliamo iniziare.\nPer tentativi ed errori, individuiamo un punto sul diagramma del luogo delle radici che soddisfa sia il criterio dell’angolo che il requisito \\(\\zeta\\). Questo punto rappresenta i poli dominanti.\n\n\n\n\n\n\n\n\n\n2. Valutazione del tempo di assestamento\nTrovati i poli dominanti possiamo calcolare il tempo di assestamento utilizzando la formula citata in precedenza. Per il modello in questione, il tempo di assestamento è di circa 5,3 secondi:\n\\[\nt_s = 5,3\n\\]\nÈ superiore a 4s ma potenzialmente non troppo lontano..\nSe partissimo dai requisiti del tempo di assestamento dovremmo considerare qual è la linea verticale sul diagramma del luogo delle radici che soddisfa i requisiti del tempo di assestamento.\nDato \\(t_s\\) possiamo calcolare il corrispondente \\(\\zeta\\omega_n\\).\nTieni presente che, come al solito con i nostri grafici approssimativi, il punto specifico che scegliamo potrebbe non trovarsi esattamente sul grafico del luogo delle radici e dobbiamo riadattare la trama con tentativi ed errori (muovendoci lungo la linea \\(t_s\\) con i nostri punti di prova ) finché non avremo perfezionato il grafico secondo necessità (il punto soddisfa la condizione dell’angolo) e trovato il punto corretto corrispondente ai poli del circuito chiuso desiderati.\nSi calcola poi il corrispondente \\(\\zeta\\) e si verifica se questo è accettabile rispetto ai requisiti.\n\n\n\n\n\n\n\n\n\n3. Calcolo del guadagno del luogo delle radici \\(K\\)\nDato il punto specifico selezionato, applichiamo la condizione di magnitudo per calcolare il guadagno del luogo delle radici, che in questo caso \\(K=10,5\\), e il corrispondente \\(K_A = 10,5/60\\).\n\n\n4. Precisione allo stato stazionario\nPer garantire che il sistema raggiunga il valore finale desiderato senza errori, utilizziamo la costante di errore di velocità (\\(K_v\\)).\nLa formula per calcolare \\(K_v\\) è:\n\\[\nK_v = \\lim_{s \\to 0} s \\cdot G(s) = \\frac{10,5}{12} = 0,825\n\\]\nCon un errore a regime di \\(e_{ss} = 1,14\\) rad.\nL’errore di stato stazionario è troppo elevato per soddisfare le nostre specifiche.\nPurtroppo un semplice guadagno non può soddisfare le nostre esigenze.\n\n\n\n2.5 Rivalutazione dei requisiti di progettazione\nIl rapporto di smorzamento determina quanto oscillatoria sarà la risposta del sistema. Un \\(\\zeta\\) più basso porta ad una risposta più oscillatoria, mentre un \\(\\zeta\\) più alto porta ad un sistema più smorzato.\nSpesso ci troviamo di fronte a un compromesso nella progettazione del sistema di controllo tra la risposta transitoria (la rapidità con cui il sistema risponde ai cambiamenti) e l’accuratezza dello stato stazionario (la precisione con cui il sistema mantiene il suo output nel tempo).\nConsideratelo come la messa a punto delle sospensioni di un’auto: troppo rigide (ζ alto) e non abbastanza reattive; troppo morbido (ζ basso) e oscilla troppo.\n\n\n\n\n\n\n\nFigura: Per \\(\\zeta = 0,15\\) (K = 60), le radici complesse si trovano in un punto specifico del grafico e si muovono man mano che modifichiamo il guadagno.\n\n\nPresentazione dello zero nel sistema\nCome progettisti di sistemi di controllo, ci troviamo di fronte a un compromesso tra prestazioni transitorie e stazionarie. Introducendo uno zero nel sistema, possiamo regolare il luogo delle radici per soddisfare i requisiti transitori. Tuttavia, ciò potrebbe influire sulla precisione dello stato stazionario. Dobbiamo rivalutare attentamente le esigenze dell’utente e comunicargli i compromessi.\nPer trovare un equilibrio tra prestazioni transitorie e stazionarie, introduciamo uno zero nella funzione di trasferimento del sistema a \\(s = -3\\). Questo zero ha un effetto stabilizzante e influenza il grafico del luogo delle radici.\nIntroducendo uno zero in s = -3 modifichiamo la dinamica del sistema. Ciò può aiutare a bilanciare i nostri requisiti transitori e stazionari.\n\n\n\n\n\n\n\nIl grafico è stato spostato a sinistra e quindi l’aggiunta di uno zero ha stabilizzato il sistema. Il sistema era oscillatorio e aveva proprietà di stabilità relativa molto scarse. L’aggiunta di uno zero migliora la stabilità relativa, è simile ad aumentare lo smorzamento del sistema. L’aggiunta di uno zero può essere pensata come l’aggiunta di un “contrappeso” al nostro sistema che aiuta a regolare la sua risposta dinamica.\nOra disponiamo di un compensatore PD che aggiunge effettivamente uno zero alla funzione di trasferimento del percorso in avanti, migliorando la stabilità e la risposta del sistema.\n\nComprendere l’impatto dell’aggiunta di uno zero\nQuando diciamo “la trama è stata spostata a sinistra”, ci riferiamo alla trama del luogo delle radici del nostro sistema. Questo spostamento a sinistra è significativo perché:\n\nStabilizzazione del sistema: nei sistemi di controllo, spostare i poli di un sistema verso sinistra nel piano s (che è ciò che rappresenta il grafico del luogo delle radici) generalmente significa che il sistema sta diventando più stabile.\nMigliorare la stabilità relativa: originariamente, il nostro sistema era oscillatorio con scarsa stabilità relativa. Pensa alla stabilità relativa come alla capacità del sistema di resistere alle oscillazioni e rimanere stabile in condizioni diverse.\n\n\n\nIl ruolo di un compensatore PD (proporzionale-derivativo).\n\nChe cos’è un compensatore PD?: Un compensatore PD è un tipo di controller utilizzato nei sistemi di controllo per migliorare la stabilità e la risposta. Regola il segnale di controllo in base all’errore corrente (parte proporzionale) e al tasso di variazione dell’errore (parte derivativa).\nEffetto di un compensatore PD: aggiungendo un compensatore PD al nostro sistema, aggiungiamo effettivamente uno zero alla funzione di trasferimento del percorso in avanti. È come aggiungere un contrappeso attentamente calcolato alla nostra barca precedentemente rocciosa, rendendola ora più stabile e reattiva ai cambiamenti.\n\nUn buon modo per illustrare questo concetto è simulare la risposta del sistema con e senza il compensatore PD. Vediamo come diminuiscono le oscillazioni del sistema e migliora la stabilità aggiungendo il compensatore.\nOra scriviamo il codice Python. Simuleremo due sistemi: uno senza compensatore PD e uno con esso.\n\n\n\nCodice Python per confrontare i sistemi\nPer dimostrare come le oscillazioni di un sistema diminuiscono e la sua stabilità migliora quando viene aggiunto un compensatore PD, rispetto ad un controllore proporzionale, utilizzeremo Python. Considereremo due casi: uno con regolatore proporzionale e l’altro con regolatore PD.\nPer prima cosa definiamo il sistema e i controller:\n\nSistema Originale (Controllore Proporzionale): \\[ G(s) = \\frac{K}{s(s+2)(s+6)} \\] Per questo esempio, supponiamo ( K = 60K_A ). Il valore esatto di ( K_A ) non è specificato, quindi sceglieremo un valore che dimostri il comportamento del sistema.\nSistema con controller PD: \\[ G(s) = \\frac{16(s+3)}{s(s+2)(s+6)} \\] Qui, lo zero in ( s = -3 ) rappresenta l’azione derivativa del controller PD.\n\nEntrambi i sistemi saranno in una configurazione con feedback unitario. Utilizzeremo le librerie Python matplotlib per tracciare e “control” per l’analisi del sistema di controllo.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n\n# Define the transfer function of the original system (Proportional Controller)\nK = 60  # Assuming a value for K\nG_proportional = ctl.TransferFunction(K, [1, 8, 12, 0])\n\n# Define the transfer function of the system with PD Controller\nG_PD = ctl.TransferFunction([16, 48], [1, 8, 12, 0])\n\n# Creating unity feedback loop for both systems\nH = ctl.TransferFunction([1], [1])  # Unity feedback\nclosed_loop_proportional = ctl.feedback(G_proportional, H)\nclosed_loop_PD = ctl.feedback(G_PD, H)\n\n# Time vector for simulation\ntime = np.linspace(0, 10, 1000)\n\n# Step response for the Proportional Controller with unity feedback\nt1, y1 = ctl.step_response(closed_loop_proportional, time)\n\n# Step response for the PD Controller with unity feedback\nt2, y2 = ctl.step_response(closed_loop_PD, time)\n\n# Plotting\nplt.figure()\nplt.plot(t1, y1, label='Proportional Controller (Unity Feedback)')\nplt.plot(t2, y2, label='PD Controller (Unity Feedback)')\nplt.title('Step Response Comparison in Unity Feedback Configuration')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nRisultato previsto\nIl grafico generato da questo script mostrerà le risposte al gradino dei due sistemi. Dovresti osservare che:\n\nIl sistema con regolatore proporzionale può presentare più oscillazioni e una risposta più lenta.\nIl sistema con il controller PD dovrebbe mostrare uno smorzamento migliore (meno oscillazioni) e una stabilizzazione più rapida, grazie allo zero aggiunto a $ s = -3 $.\n\nDomanda pop-up: In che modo l’aggiunta di uno zero alla funzione di trasferimento del percorso in avanti di un sistema di controllo influisce sulla sua stabilità?\nRisposta: L’aggiunta di uno zero in genere migliora la stabilità del sistema rendendolo meno oscillatorio e più resistente ai disturbi, in modo simile all’aumento dello smorzamento del sistema.\nConsideriamo ora un requisito \\(\\zeta = 0,6\\) e come al solito inseriamolo nel grafico del luogo delle radici.\n\n\n\n\n\n\n\nLa funzione di trasferimento del percorso in avanti diventa:\n\\[\nG(s) = \\frac{(s+3)}{s(s+2)(s+6)}\n\\]\nPossiamo quindi calcolare il guadagno al quale otteniamo i poli ad anello chiuso desiderati per ottenere:\n\\[K = 16\\]\nE infine il tempo di assestamento:\n\\[\nt_s = \\frac{4}{\\zeta\\omega_n} = 1,96\\;\\;sec\n\\]\ne la costante di velocità:\n\\[\nK_v = \\frac{16\\cdot3}{12} = 4\n\\]\nAvevamo un requisito che \\(K_v \\ge 5\\) quindi non lo abbiamo raggiunto completamente, ma ora con alcuni tentativi ed errori possiamo ottenere le prestazioni che desideriamo.\nCondizione di dominanza: il terzo polo si trova ora nella zona compresa tra -6$ e -3$ e sussiste il rischio che la condizione di dominanza venga violata. Se così fosse bisognerebbe mitigare l’effetto di questo polo. Ad esempio, se la distanza non può essere 5 volte, possiamo provare a realizzarla a una distanza pari a tre o quattro volte la posizione dei poli più a destra. In alternativa, invece di progettare per \\(\\zeta=0,6\\) puoi progettare per qualche altro valore.\nLa simulazione sarà utile per comprenderne tutti gli effetti.\nSi noti inoltre che se il terzo polo si avvicina abbastanza allo zero, il loro effetto combinato in anello chiuso verrà annullato e il sistema si comporterà come un sistema del secondo ordine. La condizione di dominanza è rispettata.\n\nAffrontare il Terzo Polo\nNel nostro sistema abbiamo una situazione in cui il terzo polo si trova nella regione tra -6 e -3. Ciò comporta il rischio che venga violata la condizione di dominanza, per cui questo terzo polo potrebbe influenzare indebitamente il comportamento del sistema.\n\n\nStrategie per mitigare l’effetto del Terzo Polo\n\nConsiderazione sulla distanza: Idealmente, vogliamo che questo terzo polo sia almeno cinque volte più distante dall’asse immaginario dei poli più a destra. Se ciò non è possibile, miriamo a una distanza da tre a quattro volte superiore.\nAdeguamenti di progettazione: Se mantenere la distanza desiderata è impegnativo, potremmo riprogettare il sistema per un diverso rapporto di smorzamento (\\(\\zeta\\)), diverso da 0,6.\nVantaggi della simulazione: simulare la risposta del sistema con queste variazioni fornirà un quadro più chiaro di come questi cambiamenti influiscono sulle prestazioni.\n\n\n\nCancellazione Polo Zero\n\nAvvicinarsi allo zero: se il terzo polo si avvicina sufficientemente allo zero che abbiamo aggiunto, i loro effetti nel sistema a circuito chiuso possono annullarsi a vicenda. Ciò fa sì che il sistema si comporti come un sistema di secondo ordine, rispettando la condizione di dominanza.\nFlessibilità di progettazione: se il terzo polo non è né abbastanza lontano dai poli dominanti né abbastanza vicino allo zero aggiunto, abbiamo ancora una certa flessibilità. Possiamo utilizzare il margine che abbiamo nel tempo di assestamento (il tempo necessario al sistema per stabilizzarsi) per adattare di conseguenza il nostro progetto.\n\nDomanda pop-up: Perché è importante rispettare la condizione di dominanza nella progettazione del sistema di controllo?\nRisposta: Il rispetto della condizione di dominanza garantisce che il sistema si comporti in modo prevedibile e stabile, influenzato principalmente dai poli dominanti, e minimizzi l’impatto di altri poli meno significativi.\n\n\n\nRealizzazione fisica del compensatore\nAbbiamo scelto un controller che lo sia\n\\[ D(s) = s + z_c \\]\ndove $ z_c $ è lo zero del compensatore, e questo viene aggiunto per migliorarne la risposta ai transitori e la stabilità.\nIn pratica, i differenziatori puri vengono evitati a causa della loro sensibilità al rumore ad alta frequenza.\nPertanto, questo tipo di compensatori vengono solitamente implementati con un polo aggiuntivo per attenuare le alte frequenze.\nLa realizzazione pratica di questo compensatore prevede l’aggiunta di un filtro per ridurre l’impatto del rumore ad alta frequenza.\nIl compensatore vero e proprio ha la forma:\n\\[\nD(s) = \\frac{s + z_c}{s + p_c}\n\\]\nQui, $ z_c $ è lo zero e $ p_c $ è un polo introdotto per filtrare il rumore ad alta frequenza.\nLo scopo di questo polo non è quello di aiutare con la parte di compensazione, quindi vogliamo che sia lontano dal resto dei nostri poli e zeri. Nel nostro caso ad esempio potremmo posizionarlo a -10 o più lontano. Potrebbe dipendere dalle esigenze realizzative. L’accuratezza numerica potrebbe porre vincoli specifici su quanto lontano può essere.\nL’aggiunta di un altro polo modifica il luogo delle radici che diventa:\n\n\n\n\n\n\n\nL’aggiunta di un altro polo ha un effetto destabilizzante. È necessario scegliere il polo in modo che il luogo delle radici attorno alle nostre esigenze non venga disturbato. Ad esempio, \\(\\zeta=0.6\\) continua a trovarsi nel luogo delle radici e \\(K_v=4\\) continua a essere soddisfatto (almeno approssimativamente).\nIn questo caso le prestazioni finali sono:\n\\[\n\\zeta = 0,6\n\\]\n\\[\nt_s = 3,33\\;\\; sez\n\\]\n\\[\nK_v = 1,7\n\\]\nLa costante di velocità è ora più scarsa! E quindi abbiamo un errore di stato stazionario più elevato. Potrebbe essere necessario regolare nuovamente il compensatore.\nÈ necessario regolare la coppia zero-polare per ottenere le prestazioni desiderate. Abbiamo un ulteriore grado di libertà.\nNel complesso possiamo cambiare: \\(z_c\\), \\(p_c\\) e \\(K_A\\).\n\n\nCompensazione anticipo fase\nQuesto tipo di controller è chiamato Phase Lead Compensator. Aggiunge un angolo di anticipo. Ciò diventerà più chiaro quando discuteremo della progettazione basata sulla frequenza.\n\n\n\n\n\n\n\nQuesta rete può essere implementata come:\n\n\n\n\n\n\n\ne la sua funzione di trasferimento è:\n\\[\nD(s) = \\frac{-R_F(sR_1C+1)}{sR_1R_2C+R_1R_2}\n\\]\ne possiamo regolare le posizioni del polo e dello zero scegliendo resistori e condensatori in modo appropriato.\nLa funzione di trasferimento di cui sopra può essere riorganizzata per avere la nostra forma tipica come:\n\\[\nD(s) = \\frac{-K_C(\\tau s + 1)}{\\alpha\\tau s + 1}\n\\]\nDove\n\n\\(\\tau = R_1C\\)\n\\(K_C = \\frac{R_F}{R_1+R_2}\\)\n\\(\\alpha = \\frac{R_2}{R_1+R_2}\\)",
    "crumbs": [
      "IT_🇮🇹",
      "Progettare con il luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_with_the_root_locus_it.html#effetti-dellaggiunta-di-un-polo-allorigine",
    "href": "IT_🇮🇹/design_with_the_root_locus_it.html#effetti-dellaggiunta-di-un-polo-allorigine",
    "title": "Progettare con il luogo delle radici",
    "section": "Effetti dell’aggiunta di un polo all’origine",
    "text": "Effetti dell’aggiunta di un polo all’origine\nImpatto sulle dinamiche del sistema\nIl posizionamento di un polo nell’origine influenza in modo significativo sia il comportamento transitorio che quello stazionario del sistema.\n\nPrecisione allo stato stazionario\nQuando viene aggiunto un polo all’origine, il numero del tipo del sistema aumenta, il che a sua volta aumenta il guadagno in stato stazionario $ K_v $ all’infinito per un ingresso a rampa. Ciò migliora la precisione dello stato stazionario.\n\n\nRisposta transitoria\nTuttavia, l’aggiunta di un polo all’origine può influenzare negativamente la risposta transitoria del sistema, potenzialmente destabilizzando il sistema per tutti i valori del guadagno $ K $.\n\n\nVisualizzazione attraverso il luogo delle radici\nPer dimostrarlo possiamo disegnare il luogo delle radici del sistema aggiungendo un polo all’origine.\n\n\n\n\n\n\n\n\n\nAggiunta di uno zero vicino all’origine\nPer recuperare la stabilità dobbiamo tirare il sistema verso sinistra, e per fare questo possiamo aggiungere uno zero vicino all’origine.\nOra il luogo delle radici diventa:\n\n\n\n\n\n\n\nOra stiamo utilizzando un controller del modulo:\n\\[\nD(s) = \\frac{s+z_c}{z} = 1 + \\frac{z_c}{s} = 1 + \\frac{1}{T_is}\n\\]\nche è un controller PI.\n\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\ndef get_closed_loop_system(K, z_c, z=1):\n    # Open-loop transfer function G(s)\n    G = ctl.TransferFunction([K], [1, 8, 12, 0])\n\n    # Compensator D(s)\n    D = ctl.TransferFunction([1, z_c], [z, 0])\n\n    # Combined system\n    open_loop_system = G * D\n\n    # Closing the loop with unity feedback\n    return ctl.feedback(open_loop_system, 1)\n\n\ndef plot_root_locus(K, z_c=1):\n    system = get_closed_loop_system(K, z_c)\n    plt.figure(figsize=(10, 6))\n    ctl.root_locus(system, plot=True)\n    plt.xlabel('Real Axis')\n    plt.ylabel('Imaginary Axis')\n    plt.title(f'Root Locus with Gain K = {K}')\n    plt.grid(True)\n    plt.show()\n\n    \ninteract(plot_root_locus, K=FloatSlider(value=1, min=0, max=100, step=.1, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_root_locus(K, z_c=1)&gt;\n\n\n\n\nApproccio pratico: compensatore del ritardo di fase\nLa progettazione di un compensatore di ritardo di fase prevede un’attenta selezione delle posizioni del polo compensatore e dello zero per bilanciare i requisiti transitori e stazionari.\nSe guardiamo indietro alle nostre specifiche originali, non avevamo un requisito specifico per avere \\(K_v=0\\) (il che avrebbe giustificato il posizionamento di un polo all’origine).\nInvece di posizionare il polo compensatore esattamente all’origine, posizionarlo vicino all’origine può fornire un design più equilibrato. Questo approccio consente flessibilità nel soddisfare i requisiti di precisione sia in stato stazionario che transitorio.\nIl compensatore assume la forma:\n\\[\nD(s) = \\frac{ s + z_c }{ s + p_c }\n\\]\nQuesto controller fornisce un contributo angolare negativo e per questo motivo è chiamato controller Phase-Lag.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettare con il luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_with_the_root_locus_it.html#compensatore-del-ritardo-di-fase-realizzazione-pratica",
    "href": "IT_🇮🇹/design_with_the_root_locus_it.html#compensatore-del-ritardo-di-fase-realizzazione-pratica",
    "title": "Progettare con il luogo delle radici",
    "section": "Compensatore del ritardo di fase: realizzazione pratica",
    "text": "Compensatore del ritardo di fase: realizzazione pratica\nLa realizzazione fisica di un compensatore di ritardo di fase comporta in genere l’utilizzo di resistori e condensatori per creare una rete che imiti la funzione di trasferimento desiderata.\nUn tipico compensatore di ritardo di fase può essere realizzato utilizzando un circuito amplificatore operazionale (Op-Amp). La progettazione prevede la selezione di valori appropriati di resistore e condensatore per ottenere i valori $s + z_c $ e $ s + p_c $ desiderati.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettare con il luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html",
    "title": "Introduzione ai sistemi di controllo",
    "section": "",
    "text": "In questo notebook esploreremo i concetti fondamentali dei sistemi di controllo e le varie modalità di controllo, inclusi il controllo proporzionale, il controllo integrale e il controllo derivativo.\nIn un sistema di controllo, abbiamo una struttura di feedback di base composta da diversi componenti:\nPer semplicità stiamo considerando un sistema a retroazione unitaria, e quindi ci concentriamo direttamente sull’errore di sistema $e$.\nAppunti: - Feedback unitario quindi \\(e = r-y\\), mentre se fosse avvenuto tramite un sensore avremmo avuto \\(\\hat{e}\\).\nStoricamente esistevano limitazioni hardware (i controller dovevano essere idraulici, pneumatici o elettrici).\nCon l’avvento della tecnologia digitale, praticamente qualsiasi funzione può essere realizzata tramite un computer digitale, eliminando le limitazioni dei sistemi di controllo basati su hardware.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-proporzionale-controllo-p",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-proporzionale-controllo-p",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Controllo proporzionale (controllo P)",
    "text": "Controllo proporzionale (controllo P)\nIl controllo proporzionale è una delle modalità di controllo più semplici. Il segnale di controllo $u$ nel controllo proporzionale è dato da:\n\\[\nu = K_c \\cdot e\n\\]\nDove \\(K_c\\) è il guadagno del controller.\nNel dominio di Laplace:\n\\[\nU(s) = K_c \\cdot E(s)\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#proporzionale---controllo-integrale-controllo-pi",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#proporzionale---controllo-integrale-controllo-pi",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Proporzionale - Controllo integrale (controllo PI)",
    "text": "Proporzionale - Controllo integrale (controllo PI)\nIl controllo proporzionale-integrale, spesso noto come controllo PI, introduce un’azione integrale per migliorare le prestazioni del controllo.\nIl segnale di controllo \\(u\\) in controllo integrale è dato da:\n\\[\nu = K_c \\cdot \\big( e + \\frac{1}{T_I} \\int e dt \\big)\n\\]\nÈ composto da due componenti, una proporzionale all’errore e una proporzionale all’integrale dell’errore.\nNel dominio di Laplace:\n\\[\nu = K_c \\cdot \\big( 1 + \\frac{1}{T_I s}\\big)E(s)\n\\]\nA volte scritto anche come:\n\\[\nu = \\big( K_c + \\frac{K_I}{s}\\big)E(s)\n\\]\nDove: - \\(K_I\\) è chiamato guadagno integrale - \\(K_c\\) è chiamato guadagno del controller - \\(T_I\\) è il tempo integrale o tempo di reset.\nEsploreremo i vantaggi del controllo integrale e la sua applicazione nei sistemi di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-proporzionale-derivativo-controllo-pd",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-proporzionale-derivativo-controllo-pd",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Controllo proporzionale-derivativo (controllo PD)",
    "text": "Controllo proporzionale-derivativo (controllo PD)\nIl controllo proporzionale-derivativo, spesso noto come controllo PD, introduce un’azione derivativa nei sistemi di controllo.\nIl segnale di controllo \\(u\\) nel controllo derivato è dato da:\n\\[\nu = K_c \\big(e + T_D \\dot{e}\\big )\n\\]\nNel dominio di Laplace:\n\\[\nU(s) = K_c \\big(1 + T_D s\\big )E(s)\n\\]\nDove \\(T_D\\) è il tempo derivativo o il tempo del tasso.\nA volte scritto anche come:\n\\[\nu = \\big( K_c + K_D s\\big)E(s)\n\\]\nDove \\(K_D\\) è chiamato guadagno derivato.\nEsamineremo il ruolo del controllo derivato e il suo impatto sulle prestazioni del sistema di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-pid",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-pid",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Controllo PID",
    "text": "Controllo PID\nIl controllo PID combina azioni proporzionali, integrali e derivative in un unico controller. Il segnale di controllo \\(u\\) nel controllo PID è dato da:\n\\[\nu = K_c \\cdot (e + \\frac{1}{T_I} \\int e dt + T_D \\cdot \\frac{de}{dt})\n\\]\n\\[\nU(s) = K_c \\big(1+\\frac{1}{T_I s} + T_Ds\\big)E(s)\n\\]\nA volte scritto anche come:\n\\[\nU(s) = \\big(K_c+\\frac{K_I}{s} + K_Ds\\big)E(s)\n\\]\nSpesso utilizzato come primo tentativo prima di tentare metodi diversi se il PID non funziona.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#esempio-sistema-di-controllo-della-temperatura",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#esempio-sistema-di-controllo-della-temperatura",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Esempio: sistema di controllo della temperatura",
    "text": "Esempio: sistema di controllo della temperatura\nConsidera un sistema di controllo della temperatura progettato per mantenere la temperatura di una camera a un livello prescritto. Questo sistema costituisce un eccellente esempio del controllo proporzionale.\n\nDescrizione del sistema: Consideriamo un sistema di controllo della temperatura, ovvero una camera in cui la temperatura deve essere mantenuta a un livello specifico \\(\\theta_r\\). La variabile di disturbo (temperatura ambiente) in questo sistema è indicata come \\(\\theta_a\\) e \\(\\theta\\) rappresenta la temperatura della camera.\nContesto applicativo: questo sistema può essere paragonato a una camera di prova per apparecchiature elettroniche, dove è necessario regolare la temperatura per testare i componenti in diverse condizioni termiche.\n\n\n\n\n\n\nComponenti del sistema: - Temperatura della Camera (\\(\\theta\\)): La variabile primaria da regolare. - Variabile di disturbo (\\(\\theta_a\\)): fattori esterni che influenzano la temperatura della camera, come la temperatura ambiente. - Termocoppia: un sensore utilizzato per misurare la temperatura della camera. - Trasduttore Elettropneumatico: Converte il segnale elettrico in un segnale di pressione. - Posizionatore della valvola: regola una valvola per controllare il flusso di vapore, regolando così la temperatura della camera. - Scambiatore di calore: Facilita il riscaldamento dell’aria all’interno della camera.\nOperazione: -La temperatura desiderata (\\(\\theta_r\\)) viene impostata e confrontata con la temperatura effettiva (θ). - La termocoppia genera un segnale elettrico proporzionale alla differenza di temperatura. - Questo segnale viene amplificato e utilizzato per regolare la posizione della valvola, controllando il flusso di vapore e, di conseguenza, la temperatura.\nRequisiti di controllo\n\nObiettivo: mantenere la temperatura della camera ad un valore regolato, \\(\\theta_r\\).\nRilevamento della temperatura: una termocoppia viene utilizzata come sensore per misurare la temperatura della camera.\nCalcolo dell’errore: l’uscita del sensore, indicata come \\(e_t\\), viene confrontata con un valore di riferimento \\(e_r\\) (proporzionale a \\(\\theta_r\\)) per calcolare il segnale di errore \\(e\\).\n\nController e attuatori\n\nAmplificatore come controller: l’uscita dell’amplificatore, in base al segnale di errore, viene utilizzata per controllare il trasduttore elettropneumatico, che a sua volta genera un segnale di pressione.\nPosizionatore della valvola: questo dispositivo regola la valvola in base al segnale di pressione, controllando il flusso di vapore e quindi la temperatura nella camera.\n\nDisturbi\n\nSorgenti di disturbo: i cambiamenti della temperatura ambientale o le variazioni del segnale di comando sono i disturbi principali.\nRisposta del sistema: il sistema di controllo regola la portata del vapore per ripristinare l’equilibrio in risposta ai disturbi.\n\n\nUtilizzo di un proporzionale proporzionale\nAnalizziamo quanto sia efficace il controllo proporzionale nel mantenere la temperatura desiderata in presenza di disturbi.\n🤔 Domanda popup: Cosa succede al segnale di errore \\(e\\) quando la temperatura della camera \\(\\theta\\) è uguale al setpoint \\(\\theta_r\\)?\nRisposta: Il segnale di errore \\(e\\) diventa zero, indicando che non vi è alcuna discrepanza tra la temperatura desiderata e quella effettiva.\n\n\n\n\n\nNello stato di equilibrio sia il segnale di errore che il segnale di controllo sono nulli. La regolazione iniziale del trasduttore elettropneumatico all’interno del posizionatore della valvola mantiene l’equilibrio termico. Questa regolazione compensa inoltre eventuali perdite di calore nell’ambiente circostante, a condizione che la temperatura ambiente rimanga costante.\nCosa succede se si verificano disordini?\nLe perturbazioni dalla posizione di equilibrio possono essere create da - Cambiamento nell’ambiente - Modifica del segnale di comando\nQuando ciò accade, abbiamo un segnale di errore \\(e\\) e un corrispondente segnale di controllo \\(u\\) che deve riaggiustare la portata del vapore per raggiungere un nuovo equilibrio.\n\n\nModellazione del sistema di controllo della temperatura\n\nModello matematico: Possiamo modellare la camera come un sistema del primo ordine con una funzione di trasferimento\n\n\\[ \\frac{K_p}{\\tau_p s + 1} \\]\ndove \\(K_p\\) è il guadagno del processo e \\(\\tau_p\\) è la costante di tempo.\n\nDisturbo: I cambiamenti nella temperatura ambientale (\\(\\theta_a\\)) possono perturbare il sistema dal suo equilibrio.\n\nPossiamo quindi modellare l’influenza del disturbo come un sistema del primo ordine con una funzione di trasferimento\n\\[ \\frac{1}{\\tau_p s + 1} \\]\nImpostare \\(K\\) come 1 implica che stiamo assumendo un impatto diretto e uno a uno di $ _a $ su $ $ allo stato stazionario. Se una valutazione sperimentale rivela una deviazione da questa ipotesi, è possibile introdurre una costante appropriata per tenere conto della differenza.\nQuando consideriamo i modelli dinamici consideriamo sempre rispetto allo stato stazionario. La temperatura ambiente totale non è \\(\\theta_a\\), che è la perturbazione della temperatura ambiente dal punto di equilibrio.\n\n\n\n\n\n\n\nDiagramma a blocchi\nPossiamo quindi scrivere lo schema a blocchi del sistema di termoregolazione, illustrando la relazione tra il segnale di controllo, l’impianto e l’uscita.\n\n\n\n\n\nNell’esempio del sistema di controllo della temperatura, stiamo osservando un controller proporzionale (P) in cui vengono moltiplicati insieme vari guadagni. Analizziamo questi guadagni e le loro unità per comprendere l’unità complessiva del controller proporzionale in questo contesto.\n\n\nRipartizione dei guadagni e delle loro unità\n\nGuadagno dell’amplificatore (\\(K_A\\)): questo guadagno è generalmente espresso nell’unità volt per volt (V/V), poiché mette in relazione la tensione di uscita con la tensione di ingresso dell’amplificatore.\nGuadagno trasduttore elettropneumatico (\\(K_e\\)): questo guadagno converte il segnale elettrico (tensione) in un segnale pneumatico (pressione).\nGuadagno posizionatore valvola (\\(K_x\\)): Mette in relazione il segnale di pressione pneumatica con la posizione meccanica della valvola. La sua unità potrebbe essere adimensionale e rappresentare il rapporto tra lo spostamento dello stelo della valvola e il segnale di pressione in ingresso (ad esempio mm/psi o mm/bar).\nGuadagno valvola di controllo (\\(K_v\\)): Questo guadagno descrive come la posizione della valvola influisce sulla portata del vapore. L’unità potrebbe essere in termini di portata di vapore per unità di spostamento, ad esempio metri cubi all’ora per millimetro (m³/h/mm).\n\n\n\nCalcolo del guadagno complessivo del controller proporzionale\nQuando questi guadagni vengono moltiplicati insieme, l’unità risultante del guadagno complessivo del controller proporzionale (\\(K\\)) sarà un composto di tutte queste singole unità. Nello scenario indicato, le unità si moltiplicherebbero come segue:\n\\[ K = K_A \\times K_e \\times K_x \\times K_v \\]\nQuindi, ad esempio, l’unità di \\(K\\) sarebbe:\n\\[ \\text{V/V} \\times \\text{psi/V} \\times \\text{(mm/psi)} \\times \\text{(m³/h/mm)} \\]\nSe semplificato, questo ci dà:\n\\[ \\text{m³/h/V} \\]\n\n\nInterpretazione\nL’unità risultante di m³/h/V indica che la produzione del controller, in termini di portata di vapore (m³/h), è proporzionale alla tensione in ingresso al sistema. Ciò riflette l’essenza di un controller proporzionale, in cui l’uscita è direttamente proporzionale al segnale di errore, che, in questo caso, è rappresentato in tensione.\nQuesta conoscenza dettagliata delle unità è fondamentale per la progettazione e la messa a punto dei sistemi di controllo, garantendo che il controller funzioni entro l’intervallo desiderato e gestisca efficacemente l’impianto che sta controllando.\n\n\nComponenti come sistemi di ordine zero\nAbbiamo semplificato il nostro modello trattando tutti questi componenti come sistemi di ordine zero, ignorando le loro dinamiche intrinseche. È importante ricordare che questi componenti possiedono caratteristiche dinamiche.\nCaratterizzarli come sistemi di ordine zero implica l’assunzione di una risposta istantanea, che non è possibile per nessun sistema fisico. Tuttavia questa semplificazione è dovuta al fatto che le costanti di tempo di questi singoli componenti sono notevolmente piccole rispetto alla costante di tempo dell’impianto $ _p $.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#comprendere-limpatto-del-disturbo-theta_a",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#comprendere-limpatto-del-disturbo-theta_a",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Comprendere l’impatto del disturbo (\\(\\theta_a\\))",
    "text": "Comprendere l’impatto del disturbo (\\(\\theta_a\\))\nCon riferimento al disegno fisico sopra riportato, considerare un aumento della temperatura ambiente (\\(\\theta_a\\)). Intuitivamente, se la temperatura esterna aumenta, il flusso di calore in uscita dal sistema diminuirà, portando ad un aumento della temperatura della camera.\nPremesso questo, considereremo positivo l’effetto del disturbo \\(\\theta_a\\) sul sistema \\(\\theta\\) (vedi punto di somma nello schema a blocchi).",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#effetti-del-guadagno-dellamplificatore",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#effetti-del-guadagno-dellamplificatore",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Effetti del guadagno dell’amplificatore",
    "text": "Effetti del guadagno dell’amplificatore\nIl nostro obiettivo è studiare l’effetto del guadagno dell’amplificatore (\\(K_A\\)) su vari parametri prestazionali come errore a regime, risposta ai transitori e sensibilità ai disturbi.\n\nSviluppo dell’equazione del sistema\n\nDescrivere le equazioni\n\nSegnale di errore: L’errore è rappresentato da\n\n\\[e = K_t \\theta_r(s) - K_t \\theta(s)\\]\ndove \\(K_t\\) è la costante della termocoppia, \\(\\theta_r\\) è la temperatura di riferimento e \\(\\theta\\) è la temperatura effettiva.\n\nSegnale di controllo: il segnale di errore viene moltiplicato per il prodotto dei guadagni\n\n\\[K_A K_e K_x K_v\\]\nrisultante nella variabile manipolata.\n\nDinamica complessiva del sistema: Incorporando la dinamica dell’impianto, rappresentata da \\(\\frac{K_p}{\\tau_p s + 1}\\), e il disturbo \\(\\theta_a\\), otteniamo un’equazione completa che descrive il sistema:\n\n\\[\\Big[ (K_t \\theta_r(s) - K_t \\theta(s))K_A K_e K_x K_v \\Big] \\frac{K_p}{\\tau_p s + 1}\\]\n\nIncluso il disturbo:\n\n\\[\\Big[ (K_t \\theta_r(s) - K_t \\theta(s))K_A K_e K_x K_v \\Big] \\frac{K_p}{\\tau_p s + 1} + \\frac{1}{\\tau_p s + 1}\\theta_a(s) = \\theta\\]\n\n\nManipolazione dell’equazione\n\nObiettivo: Esprimere l’uscita del sistema \\(\\theta(s)\\) in termini di ingresso di riferimento \\(\\theta_r(s)\\) e disturbo (_a(s)).\n\n\\[ (\\tau_p s + 1)\\theta(s) + K_tK_A K_e K_x K_vK_p\\theta(s) = (K_tK_A K_e K_x K_vK_p)\\theta_r + \\theta_a \\]\n\nGuadagno del loop (\\(K\\)): Combinando le costanti, definiamo\n\n\\[K = K_t K_A K_e K_x K_v K_p\\]\ndefinito guadagno d’anello.\nQuesto guadagno, in particolare \\(K_A\\) (il guadagno dell’amplificatore), influenza direttamente la risposta del sistema.\n\n\n\nEquazione finale\nUtilizzando il guadagno d’anello \\(K\\) possiamo ora ottenere:\n\\[ (\\tau_p s + 1 + K )\\theta(s) = K \\theta_r(s) + \\theta_a(s) \\]\nInterpretazione: Questa equazione collega la temperatura di uscita \\(\\theta(s)\\) con la temperatura di riferimento \\(\\theta_r(s)\\) e il disturbo della temperatura ambiente \\(\\theta_a(s)\\).\n\n\nPunti chiave da notare\n\nCostante di controllo proporzionale: Il guadagno del circuito \\(K\\) può essere considerato come una costante di controllo proporzionale, che riflette l’efficacia del controllore proporzionale nel mantenere la temperatura desiderata in presenza di disturbi.\nAttenzione ai dettagli: È necessario prestare attenzione nella derivazione di questa equazione. Qualsiasi errore nella manipolazione può portare a conclusioni errate sul comportamento del sistema.\n\nQuindi in questo caso l’equazione finale è:\n\\[ \\theta(s) = \\frac{K}{\\tau_p s + 1 + K} \\theta_r(s) + \\frac{1}{\\tau_p s + 1 + K} \\theta_a(s) \\]\nAbbiamo la relazione tra l’uscita \\(\\theta(s)\\) e il comando \\(\\theta_r(s)\\) e tra l’uscita \\(\\theta(s)\\) e il disturbo \\(\\theta_a(s)\\).\n\nImpatto del feedback sulla costante di tempo\nRiscrivere l’espressione del sistema come\n\\[ \\theta(s) = \\frac{K}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\theta_r(s) + \\frac{1}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\theta_a(s) \\]\nosserviamo che la costante di tempo del sistema retroazionato, $ $, è:\n\\[\\tau = \\frac{\\tau_p}{1 + K} \\]\n\nQui ( _p ) è la costante di tempo originale della pianta senza feedback.\nIl feedback riduce la costante di tempo ($ $) poiché $ K &gt; 0 $.\nImplicazione: una riduzione della costante di tempo implica una risposta più rapida del sistema. I transitori decadono più rapidamente e il sistema raggiunge lo stato stazionario prima dopo un disturbo.\n\n\n\nAnalisi degli errori in stato stazionario\nAnalizziamo ora l’errore a regime. Per questo separiamo l’effetto dell’ingresso \\(\\theta_r\\) e quello del disturbo \\(\\theta_a\\) (possiamo applicare la sovrapposizione dato che parliamo di sistemi lineari).\nPiù nel dettaglio, analizziamo la risposta del sistema ad un ingresso a gradino unitario per determinare il valore di regime:\n\\[\\theta_r = \\frac{1}{s}\\]\ne l’output è:\n\\[ \\theta(s) = \\frac{K}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\frac{1}{s} \\]\nValore di stato stazionario per ingresso passo:\n\\[ \\theta_{ss} = \\lim_{s \\to 0} s \\theta(s) = \\frac{K}{1 + K} \\]\nEsaminiamo ora la risposta del sistema ad un disturbo a gradino unitario.\n\\[\\theta_a = \\frac{1}{s}\\]\nValore di stato stazionario per disturbo:\n\\[ \\theta_{ss} = \\frac{1}{1 + K} \\]\n\n\nCommenti e risultati\nSegnale di comando: - \\(\\theta_r(s)\\) è il segnale di comando. Vogliamo che \\(\\theta_{ss}\\) sia uguale a 1 (stiamo monitorando un input di passo unitario). - All’aumentare di $ K $, $ _{ss} $ si avvicina a 1, riducendo l’errore a regime per segnali di comando costanti. - All’aumentare di $ K $, l’errore a regime in risposta a un segnale di comando diminuisce.\nRifiuto per disturbo: - Valori \\(K\\) più alti migliorano la reiezione del disturbo, spingendo (_{ss}) verso lo zero, e quindi filtrando il disturbo.\n\nMiglioramento con $ K $ elevati: le prestazioni sia in stato transitorio che stazionario migliorano con un $ K $ più elevato.\nScenario ideale: Teoricamente, con $ K $, il sistema avrebbe una risposta immediata e un errore in stato stazionario pari a zero.\n\n\n\nIl compromesso tra prestazioni e stabilità\n\nMiglioramento rispetto alla stabilità:\n\nValori $ K $ più alti migliorano le prestazioni sia transitorie che stazionarie.\nTeoricamente, un $ K $ infinito risulterebbe in un sistema istantaneo con errore stazionario pari a zero.\nTuttavia, ciò porta a un conflitto tra miglioramento delle prestazioni e stabilità del sistema.\n\n\n\n\nConsiderazioni sulle dinamiche di sistema:\n\nRivisitazione delle dinamiche dei componenti:\n\nIl nostro modello iniziale utilizzava approssimazioni di ordine zero per componenti come l’amplificatore e il posizionatore della valvola (le loro costanti di tempo sono trascurabili rispetto alla costante di tempo \\(\\tau_p\\) dell’impianto).\nQuando operiamo in retroazione invece la costante temporale è \\(\\tau=\\frac{\\tau_p}{1+K}\\)\nAll’aumentare di $ K $ e alla diminuzione della costante di tempo effettiva ($ $), queste approssimazioni diventano non valide (le costanti di tempo delle componenti non sono più trascurabili).\n\nImplicazioni di valori $ K$ elevati:\n\nUn $ K $ elevato trasforma il sistema del primo ordine (vedi lo schema a blocchi iniziale sopra) in un sistema di ordine superiore, potenzialmente del quinto ordine (vedi lo schema a blocchi sotto).\nI sistemi di ordine elevato (&gt; terzo ordine) possono diventare instabili con grandi valori di $ K $ (vedremo perché più avanti quando studieremo gli strumenti di analisi della stabilità).\nIl sistema quindi non si comporta come vorremmo.\nQuesta instabilità introduce un compromesso tra le prestazioni del sistema (precisione in stato stazionario) e i suoi requisiti di stabilità.\n\nNon linearità e saturazione: valori elevati di \\(K\\) possono portare i componenti alla saturazione, portando a un comportamento non lineare e potenziale instabilità.\n\n\n\n\n\n\nPer rendere il concetto più chiaro, facciamo un esempio\n\n\n\n\n\nLa funzione di trasferimento ad anello chiuso diventa:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{\\frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1)}}{1+\\ frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1)}} = \\frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1) + K_cK_vK_p}\n\\]\nL’espressione originale per il sistema senza la dinamica del primo ordine dei singoli componenti era:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s + 1 + K}\n\\]\nIn quest’ultimo caso l’equazione caratteristica è:\n\\[\n\\tau_ps + 1 + K = 0\n\\]\ne la sua radice (il polo del sistema ad anello chiuso) è:\n\\[\ns = -\\frac{1+K}{\\tau_p}\n\\]\nNon abbiamo discusso la stabilità nei dettagli, ma intuitivamente (quella delle equazioni differenziali e delle sue soluzioni), se i poli sono nella Mezza Posta Sinistra (LHP) il sistema è stabile.\nNel caso in cui \\(s = -\\frac{1+K}{\\tau_p}\\), per tutti i valori di \\(K\\), \\(s\\) è sempre negativo.\nQuando consideriamo le costanti di tempo per ciascuna componente, l’equazione caratteristica diventa quella di un sistema del terzo ordine:\n\\[ a_1 s^3 + a_2 s^2 + a_3 s + a_4 = 0 \\]\nQuesta equazione ha tre poli nel piano s (tre radici che puoi calcolare come esercizio). Per valori elevati di \\(K\\) alcuni poli vengono spinti verso il semipiano destro (RHP) portando ad un sistema instabile.\nI poli di questo sistema di ordine superiore, influenzato da \\(K\\), ne determinano la stabilità.\n\n\n\nCommenti:\n\nUna volta che il sistema è instabile, tutto il resto non ha importanza! Non ha senso studiare le costanti di tempo, ecc.\nIn circuito aperto, le singole modalità dinamiche sono stabili, ma in circuito chiuso la loro interazione può portare all’instabilità.\nIl circuito di feedback, che contribuisce a migliorare robustezza e sensibilità, crea anche problemi di stabilità.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-integrale-ed-errore-di-stato-stazionario",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#controllo-integrale-ed-errore-di-stato-stazionario",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Controllo integrale ed errore di stato stazionario",
    "text": "Controllo integrale ed errore di stato stazionario\nAffrontare l’errore dello stato stazionario con il controllo integrale\n\nLimitazione del controllo proporzionale: nel controllo proporzionale, è necessario un errore persistente per mantenere l’equilibrio del sistema. Se l’errore è zero, l’azione di controllo è zero (vedere il diagramma seguente).\n\n\n\n\n\n\nNel controllo proporzionale, l’errore fornisce l’energia necessaria per sostenere un nuovo equilibrio. Il nuovo equilibrio si ottiene utilizzando nuova energia disponibile solo se è presente il segnale di errore. Se l’errore è zero, si torna alla posizione di equilibrio originale. Tuttavia ciò non è possibile perché il sistema è costretto alla nuova situazione.\n\nRuolo del controllo integrale: il controller integrale accumula l’errore nel tempo, consentendo all’errore di ridursi a zero pur fornendo l’azione di controllo necessaria.\n\n\n\n\n\n\nIl controllo integrale utilizza l’accumulo di errori passati per raggiungere questo obiettivo, consentendo all’errore di ridursi eventualmente a zero. Questo è sempre possibile per la tipologia di impianti che stiamo considerando.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#rivisitare-il-sistema-di-controllo-della-temperatura",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#rivisitare-il-sistema-di-controllo-della-temperatura",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Rivisitare il sistema di controllo della temperatura",
    "text": "Rivisitare il sistema di controllo della temperatura\nRivisiteremo ora il processo di controllo della temperatura discusso in precedenza, concentrandoci sulle dinamiche del sistema, in particolare sul ruolo del controllo integrale nel miglioramento delle prestazioni del sistema.\n\nPanoramica del sistema\n\n\n\n\n\n\nDescrizione del diagramma a blocchi\n\nTemperatura di riferimento: Indicata come \\(\\theta_r\\), l’impostazione della temperatura desiderata.\nSensore e segnale di errore: Un sensore a termocoppia converte \\(\\theta_r\\) in un segnale di tensione. Questa tensione viene confrontata con la tensione di temperatura effettiva per generare un segnale di errore.\nAmplificatore e Trasduttore: Il segnale di errore viene amplificato (guadagno \\(K_A\\)) e quindi inviato ad un trasduttore elettropneumatico (costante \\(K_e\\)).\nPosizionatore e guadagno della valvola: il segnale del trasduttore controlla un posizionatore della valvola (costante (K_x)) per regolare la portata, influenzato dal guadagno della valvola \\(K_v\\).\nFunzione di trasferimento del processo: Rappresentata come \\(\\frac{K_p}{\\tau_p s + 1}\\).\nEffetto di disturbo: Modellato come \\(\\frac{1}{\\tau_p s + 1}\\), dove \\(\\theta_a\\) è il disturbo della temperatura ambiente.\n\n\n\n\nDinamica e stabilità del sistema\nQuando abbiamo assunto che l’impianto fosse un sistema del primo ordine e che i vari componenti possano essere approssimati come di ordine zero: - Prestazioni transitorie: Il guadagno del circuito più ampio (\\(K\\)) migliora le prestazioni transitorie riducendo la costante di tempo del sistema. - Errore in stato stazionario: \\(K\\) più grandi riducono anche l’errore in stato stazionario. - Limiti sul guadagno: Un guadagno elevato \\(K\\) può portare alla saturazione dei componenti e al comportamento non lineare, limitando l’intervallo di risposta lineare del sistema. Inoltre, la dinamica dei vari componenti non può essere trascurata, portando a una potenziale instabilità.\n\n\nControllo integrale nei sistemi di temperatura\n\nIndirizzamento alle modifiche del segnale di comando\n\nScenario: Considerare l’esigenza di aumentare la temperatura della camera di 10 gradi.\nCambio comando: Ciò richiede un cambiamento in \\(\\theta_r\\) dello stesso importo.\n\n\n\nMeccanismo di controllo integrale\n\nDinamica del segnale di errore: Con il controllo integrale, il sistema può gestire le modifiche nel segnale di comando mantenendo stabilità e prestazioni.\n\nEspressione matematica:\n\\[ u(t) = K_I \\int e(t) \\, dt \\]\nCommenti: - Ruolo nella stabilità del sistema: Il controllo integrale consente al sistema di adattarsi automaticamente a nuovi equilibri senza compromettere la stabilità.\n\nAdattabilità del sistema: Il controller integrale regola l’azione di controllo nel tempo in base all’errore accumulato, portando a un errore stazionario pari a zero anche con modifiche dei comandi.\nAdattabilità del sistema: Il controller integrale regola l’azione di controllo nel tempo in base all’errore accumulato, portando a un errore stazionario pari a zero anche con modifiche dei comandi.\n\nCi sarà un prezzo da pagare: il controllo integrale potrebbe portare all’instabilità ancor più dell’utilizzo di un semplice controllo proporzionale.\n\n\n\nImplementazione del controllo integrale nei sistemi di temperatura\nSostituiamo l’amplificatore \\(K_A\\) con un controller integrale \\(K_I/s\\).\nDinamica del sistema: il sistema ora include il controller integrale, il trasduttore elettropneumatico (\\(K_e\\)), il posizionatore della valvola (\\(K_x\\)) e il guadagno della valvola (\\(K_v\\)).\n\n\n\n\n\nSulla base di questo diagramma a blocchi possiamo quindi scrivere le equazioni matematiche:\n\\[\n(K_t\\theta_r - K_t\\theta)\\cdot \\Big(\\frac{K_I}{s}K_eK_xK_v \\Big) \\Big(\\frac{K_p}{\\tau_ps+1} \\Big) + \\frac{1}{ \\tau_ps+1} \\theta_a = \\theta\n\\]\nPossiamo quindi riorganizzare l’equazione per isolare \\(\\theta(s)\\) da un lato.:\n\\[\n(\\tau_p s + 1)\\theta(s) + \\frac{K}{s} \\theta(s) = \\frac{K}{s} \\theta_r(s) + \\theta_a(s)\n\\]\ndove \\(K = K_tK_IK_eK_xK_vK_p\\).\nE quindi:\n\\[\n\\Big(\\tau_p s + 1 + \\frac{K}{s}\\Big) \\theta(s) = \\frac{K}{s} \\theta_r(s) + \\theta_a(s)\n\\]\no equivalentemente:\n\\[\n\\Big(\\tau_p s^2 + s + K \\Big) \\theta(s) = K \\theta_r(s) + s\\theta_a(s)\n\\]\n\n\nPrestazioni in stato stazionario con controllo integrale\nVorremmo ora calcolare lo stato stazionario per un gradino in ingresso in comando ed in disturbo\n\nRisposta ingresso comando: Per un comando di ingresso passo, l’uscita in stato stazionario \\(\\theta_{ss}\\) è uguale a 1, indipendentemente da \\(K\\), indicando un errore in stato stazionario pari a zero.\n\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s^2 + s + K}\n\\]\nApplicando \\(\\theta_r(s)=\\frac{1}{s}\\), possiamo calcolare \\(\\theta_{ss}\\):\n\\[ \\theta_{ss} = \\lim_{s \\to 0} s \\theta(s) = s \\frac{K}{\\tau_p s^2 + s + K} \\frac{1}{s} = 1 \\]\nCiò è vero per tutti i possibili valori di \\(K\\) e l’errore in stato stazionario è zero.\n\nRisposta al disturbo: In risposta a un disturbo a gradino \\(\\theta_a(s)=\\frac{1}{s}\\), l’uscita in stato stazionario \\(\\theta_{ss}\\) diventa zero, respingendo di fatto il disturbo :\n\n\\[\n\\frac{\\theta(s)}{\\theta_a(s)} = \\frac{s}{\\tau_p s^2 + s + K}\n\\]\n\n\nPrestazioni transitorie con controllo integrale\nTorniamo alla risposta all’input:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s^2 + s + K}\n\\]\n\nCommenti:\n\nL’aggiunta del controllo integrale cambia il sistema dal primo ordine al secondo ordine.\n\nRicordiamo che con un controllore proporzionale il sistema era un sistema del primo ordine con forma \\(\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s + 1 + K}\\)\nPer questo sistema del primo ordine il polo è:\n\\[\ns= \\frac{-(1+K)}{\\tau_p}\n\\]\nQuando aumentiamo \\(K\\) il polo rimane sul piano di sinistra e si sposta da \\(s=\\frac{-1}{\\tau_p}\\) (quando \\(K=0\\)) a sinistra e la sua risposta diventa sempre più rapida .\nPer il sistema del secondo ordine, i poli sono le radici di:\n$$ _p s^2 + s + K = 0 $\nQuando \\(K=0\\), le radici sono \\(s=0\\) e \\(s=\\frac{-1}{\\tau_p}\\).\nSi noti che se all’origine c’è un polo il transitorio non decade mai.\nAumentando il guadagno \\(K\\) i due poli si avvicineranno, finché ad un certo punto diventeranno complessi coniugati.\n\n\nLimitazioni nel miglioramento\n\nLimite sulle prestazioni transitorie: Il controllo integrale impone un limite al miglioramento delle prestazioni transitorie, poiché i poli possono essere guidati solo fino a un certo punto (vedere il grafico del luogo delle radici di seguito).\nRisposta oscillatoria: L’aumento di (K) può portare a un comportamento oscillatorio, una conseguenza diretta del controllo integrale.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom control import tf, root_locus\n\n# System parameters\ntau_p = 1  # For example, let's take tau_p as 1\n\n# Define the characteristic equation of the system with integral control\n# The characteristic equation is tau_p * s^2 + s + K = 0\n\n# For the root locus, we consider the open-loop transfer function G(s)H(s)\n# G(s)H(s) = K / (tau_p * s^2 + s)\n# This is equivalent to a system with a numerator [K] and a denominator [tau_p, 1, 0]\n\nnumerator = [1]  # Coefficient for K\ndenominator = [tau_p, 1, 0]  # Coefficients of s^2, s, and constant term for the denominator\n\n# Create the transfer function for the system\nsystem = tf(numerator, denominator)\n\n# Plot the root locus\nfig, ax = plt.subplots()\nroot_locus_data = root_locus(system, Plot=True, ax=ax)\n\n# Add labels and title for clarity\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Root Locus with Integral Control')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nInfluenza dei Poli sulla risposta del sistema\n\nPoli: Nella teoria del controllo, i poli di un sistema sono le radici della sua equazione caratteristica. Sono cruciali nel determinare il comportamento del sistema nel tempo, in particolare la sua stabilità e la risposta transitoria.\nRappresentazione del piano complesso: i poli sono rappresentati nel piano complesso, dove l’asse orizzontale è l’asse reale e l’asse verticale è l’asse immaginario (asse jω).\nPosizione dei poli: La posizione dei poli nel piano complesso influisce in modo significativo sul modo in cui il sistema risponde agli input.\nProssimità dell’asse reale: i poli più vicini all’asse jω (asse immaginario) hanno una parte reale più piccola. Questa piccola parte reale implica un tasso di decadimento più lento della risposta transitoria del sistema.\nPoli dominanti: i poli più vicini all’asse jω vengono spesso definiti “poli dominanti” perché hanno un effetto più pronunciato sul comportamento transitorio del sistema. Il loro tasso di decadimento più lento fa sì che determinino la risposta complessiva del sistema, soprattutto nella fase transitoria.\n\n\nConsiderazioni sul design\n\nCon riferimento al luogo delle radici sopra, il polo dominante non può essere spostato ulteriormente a sinistra, limitando quindi la risposta dinamica che possiamo ottenere.\nQuando si progettano sistemi di controllo, gli ingegneri spesso mirano a posizionare i poli dominanti in modo da raggiungere l’equilibrio desiderato tra risposta rapida e stabilità. I poli troppo vicini all’asse jω possono comportare tempi di risposta lenti, mentre i poli troppo lontani nel semipiano sinistro possono far sì che il sistema risponda troppo rapidamente, portando potenzialmente a superamento e instabilità.\nRisposta transitoria vs. allo stato stazionario: i poli dominanti influenzano principalmente la risposta transitoria del sistema. Una volta che gli effetti transitori sono decaduti, il comportamento in stato stazionario è determinato da altri fattori, come il guadagno in stato stazionario del sistema e il tipo di controller utilizzato (ad esempio proporzionale, integrale, derivativo).\n\nIn questo caso i poli non si spostano verso destra (diventano instabili). Tuttavia, se una delle costanti di tempo dei nostri componenti inizia ad avere un effetto che potrebbe facilmente portare il sistema all’instabilità (il sistema diventa almeno del terzo ordine e potrebbe avere poli che vanno verso RHP per K elevato).",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#introduzione-al-controllo-dei-derivati",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#introduzione-al-controllo-dei-derivati",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Introduzione al controllo dei derivati",
    "text": "Introduzione al controllo dei derivati\nConsideriamo ora il seguente errore:\n\n\n\n\n\nAi tempi $ t_1 $ e $ t_2 $, un controller proporzionale mostrerebbe azioni di controllo identiche poiché l’entità dell’errore è la stessa in entrambi i casi. Tuttavia, gli scenari con $ t_1 $ e $ t_2 $ sono nettamente diversi: con $ t_1 $ l’errore è in aumento, mentre con $ t_2 $ l’errore ha una tendenza decrescente.\nIntuitivamente, preferiremmo azioni di controllo diversificate in queste situazioni. Nello specifico, a $ t_1 $, potrebbe essere auspicabile un’azione di controllo più aggressiva per evitare che l’errore si aggravi. Considerando il tasso di variazione dell’errore, o la sua pendenza, possiamo distinguere tra questi scenari. Questa pendenza informa efficacemente il controllore sui potenziali errori futuri, consentendo una risposta più predittiva e adattiva.\nQuesto è ciò che fa un controllo derivativo: introduce un segnale che non è solo proporzionale all’entità dell’errore (controllo proporzionale), ma sulla derivata di quel segnale.\n\nConcetto di controllo derivato\n\nNatura predittiva del controllo derivato\n\nPrevisione tramite derivata: Il controllo derivativo predice gli errori futuri (attraverso la pendenza del segnale di errore) e regola di conseguenza l’azione di controllo, fornendo maggiore smorzamento durante i transitori.\n\nEquazione:\n\\[ U(s) = K_c (1 + T_D s) E(s) \\]\n\nEfficacia: il controllo derivato è efficace durante i periodi transitori ma non ha alcun impatto sull’errore stazionario.\n\nSe l’errore stazionario diventa costante, ovvero quando si raggiunge lo stato stazionario, la derivata è zero e l’effetto del controllo derivativo è zero (vedere il grafico dell’errore sopra).\nA regime il controllo derivato perde il suo ruolo e solo il controllo proporzionale ed integrale può supportarlo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_systems_it.html#implementazione-del-controllo-derivato-nei-sistemi-di-controllo",
    "href": "IT_🇮🇹/introduction_to_control_systems_it.html#implementazione-del-controllo-derivato-nei-sistemi-di-controllo",
    "title": "Introduzione ai sistemi di controllo",
    "section": "Implementazione del controllo derivato nei sistemi di controllo",
    "text": "Implementazione del controllo derivato nei sistemi di controllo\nSpostiamo ora la nostra attenzione sugli aspetti pratici dell’implementazione del controllo derivato nei sistemi di controllo. Discuteremo le sfide e le alternative nell’impiego del controllo derivato, in particolare nel contesto di un sistema di controllo della posizione.\nAbbiamo la seguente azione di controllo:\n\\[ U(s) = K_c (1 + T_D s) E(s) \\]\n\nProblema di amplificazione del rumore\n\nDerivato del rumore ad alta frequenza: Il controllo derivato può amplificare i segnali di rumore ad alta frequenza, disturbando potenzialmente le prestazioni del sistema.\nScenario di esempio: Considera un segnale di rumore \\(0,01 \\sin(10^3 t)\\). L’ampiezza di questo segnale è molto piccola ed è ad alta frequenza. Nel controllo proporzionale, molto probabilmente non abbiamo bisogno di considerarlo esplicitamente perché il sistema stesso è un filtro passa basso.\n\nNel controllo derivativo, la derivata di questo segnale è $10^3 (10^3 t) = 10 (10^3 t) $, che amplifica significativamente il rumore.\nL’azione derivativa $ T_D s $ applicata a un segnale di rumore può portare a un segnale di grande ampiezza che può oscurare l’effettivo segnale di errore.\nPer questo motivo il controllo derivato sopra descritto è solo teorico e mai attuato nella pratica. Si applica sempre un filtro passa basso adatto per l’implementazione (lo vedremo più avanti).\nPer lo scopo di questo notebook si presuppone che il rumore ad alta frequenza non sia parte del problema o che sia stato opportunamente filtrato.\n\n\nAlternative al controllo derivato standard\nVediamo quali alternative possiamo avere utilizzando un sistema di controllo della posizione. Per questo rivisiteremo il Position Control System che abbiamo analizzato in un precedente quaderno e riportato di seguito.\nTieni presente che abbiamo apportato alcune semplificazioni: - L’impianto è solo inerziale. - Si trascura l’induttanza.\n\n\n\n\n\nDa ciò possiamo calcolare l’equazione (notare che il segno della coppia di disturbo \\(T_W\\) non è importante):\n\\[\n\\Big[ \\Big(K_p\\theta_r - K_p\\theta\\Big) K_c \\Big(1+T_Ds\\Big)\\frac{K_T}{R_f} + T_W \\big] \\frac{1}{Js^s} = \\theta\n\\]\nche può essere scritto come:\n\\[\nJs^s\\theta + K_pK_C\\frac{K_T}{R_f}\\Big(1+T_Ds\\Big)\\theta = K_pK_C\\frac{K_T}{R_f}\\Big(1+T_Ds\\Big)\\theta_r + T_W\n\\]\npossiamo porre: \\(K = K_pK_C\\frac{K_T}{R_f}\\) e otteniamo:\n\\[\n\\Big(Js^2 + K T_D s + K\\Big)\\theta(s) = K(1+T_Ds)\\theta_r + T_W\n\\]\ne finalmente possiamo scrivere la Funzione di trasferimento:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K (1 + T_D s)}{Js^2 + K T_D s + K}\n\\]\nE i “parametri di personalità” dei sistemi sono:\n\\[\n\\omega_n = \\sqrt{\\frac{K}{J}}\n\\]\n\\[\n2\\zeta\\omega_n = \\frac{KT_D}{J} \\rightarrow \\zeta=\\frac{T_D}{2}\\sqrt{\\frac{K}{J}}\n\\]\nL’effetto del controllo derivativo sul transitorio è visibile attraverso \\(\\zeta\\). È possibile aumentare lo smorzamento aumentando \\(T_D\\).\n\nCommenti aggiuntivi:\nSe osserviamo la funzione di trasferimento notiamo: - Il denominatore è un sistema del secondo ordine - Il numeratore ha uno zero\nQuando viene introdotto un cambio di passo nel segnale di comando (\\(\\theta_r\\)), come \\(\\theta_r = \\frac{1}{s}\\) nel dominio di Laplace, e questo segnale interagisce con un elemento di controllo derivato caratterizzato da $T_Ds $, provoca la generazione di un impulso, o picco. Questo fenomeno si verifica perché differenziando una funzione a gradino, che rimane sostanzialmente costante dopo il cambiamento iniziale, produce un impulso:\n\\[\nT_Ds \\cdot \\frac{1}{s} \\rightarrow T_D \\cdot \\delta(t)\n\\]\nCiò implica che in risposta a un cambiamento di gradino, un controller derivato produce un output iniziale eccezionalmente elevato, comunemente indicato come picco. Questo comportamento può essere interpretato come uno sforzo immediato del sistema di controllo per contrastare un cambiamento improvviso e significativo nell’errore.\nTuttavia, un tale picco nell’output del controller non è sempre auspicabile. Sebbene rappresenti una risposta immediata al cambiamento dell’errore, può essere paragonato all’introduzione di un disturbo nel sistema per poi correggerlo successivamente. Ciò potrebbe potenzialmente portare a problemi quali instabilità del sistema o eccessivo superamento, soprattutto nei sistemi sensibili ai rapidi cambiamenti.\nPer affrontare questo problema, i sistemi di controllo sono spesso dotati di meccanismi di filtraggio aggiuntivi. In alternativa, viene impiegato un approccio modificato al controllo derivato, che non reagisce così intensamente alle componenti ad alta frequenza del segnale di errore. Queste strategie di progettazione aiutano a rendere più fluida la risposta del controller, prevenendo picchi improvvisi e garantendo un comportamento del sistema più stabile.\n\n\n\n\n\nE la presenza della Dinamo Tachimetrica equivale a:\n\n\n\n\n\nInvece di calcolare la derivata del segnale di uscita, è possibile utilizzare una dinamo tachimetrica per generare un segnale di feedback proporzionale alla velocità di variazione dell’uscita.\nQuesto metodo aggira le sfide tipicamente incontrate quando si differenzia il comando di input, in particolare i problemi di amplificazione del rumore e la creazione di picchi quando si verificano cambiamenti improvvisi nel segnale di comando.\nNell’effettiva implementazione di questo sistema non viene effettuata alcuna operazione derivativa. Sebbene il modello includa un termine derivato (\\(sK_t\\)), nella pratica questa differenziazione non avviene.\nÈ importante notare, tuttavia, che questo approccio non è universalmente applicabile. Ad esempio, nei sistemi di controllo della temperatura, non esiste un segnale intrinseco all’interno del sistema che rappresenti direttamente la derivata della variabile controllata.\nNel controllo del movimento ciò è possibile, nel controllo del processo generalmente non è possibile. In questo caso aggiungiamo filtri adeguati per evitare picchi.\nInvece di calcolare direttamente la derivata del segnale di uscita, è possibile utilizzare una dinamo tachimetrica per produrre un segnale di feedback correlato alla velocità di variazione dell’uscita. Questa strategia affronta in modo efficace i problemi tipici associati alla differenziazione diretta del comando di input. Queste problematiche includono l’amplificazione del rumore e la generazione di picchi, soprattutto quando il segnale di comando subisce brusche variazioni.\nNelle implementazioni pratiche di tale sistema, non viene eseguito un calcolo della derivata effettiva. Il modello del sistema potrebbe includere un termine derivato rappresentato come $ sK_t $, ma in realtà questo processo di differenziazione non viene eseguito. La dinamo tachimetrica fornisce intrinsecamente un segnale che riflette la derivata, aggirando così la necessità di una differenziazione esplicita.\nTuttavia, è fondamentale riconoscere che questo metodo non è universalmente applicabile a tutti i tipi di sistemi di controllo. Ad esempio, nei sistemi di controllo della temperatura, in genere non è presente un segnale immediatamente disponibile che rappresenti intrinsecamente la derivata della temperatura. Tali sistemi non hanno un equivalente della dinamo tachimetrica utilizzata nei sistemi di controllo del movimento, dove il feedback derivato è naturalmente integrato.\nIn contesti come il controllo di processo, dove non è possibile ottenere direttamente un segnale derivato, è necessario impiegare strategie alternative. Questi spesso comportano l’aggiunta di filtri adeguati al sistema di controllo. Questi filtri sono progettati per mitigare o eliminare gli effetti indesiderati, come i picchi, che possono verificarsi quando si utilizza il controllo derivato. Questo approccio garantisce prestazioni del sistema più fluide e riduce il rischio di instabilità o di risposta eccessiva ai disturbi ad alta frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html",
    "title": "Modelli di dispositivi controllati",
    "section": "",
    "text": "Dopo essere stati introdotti ai vari modelli di impianti che incontriamo frequentemente in varie applicazioni, siamo ora ben pronti per approfondire il sistema completo di controllo del feedback. Di conseguenza, la nostra attenzione con questo notebook è rivolta ai modelli di dispositivi controllati, nonché ai sistemi completi che costruiremo utilizzando questi dispositivi.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#rivisitazione-dei-modelli-di-impianti",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#rivisitazione-dei-modelli-di-impianti",
    "title": "Modelli di dispositivi controllati",
    "section": "Rivisitazione dei modelli di impianti",
    "text": "Rivisitazione dei modelli di impianti\nPer essere sicuri di avere delle basi chiare, rivediamo lo scenario rispetto ai modelli di impianto che abbiamo modellato attraverso funzioni di trasferimento e diagrammi a blocchi.\n\n\n\n\n\n\nQuesto diagramma incapsula la dinamica dell’impianto attraverso una funzione di trasferimento, \\(G(s)\\). L’input dell’impianto, indicato come \\(R(s)\\), produce un output, \\(Y(s)\\). Questa uscita, chiamata anche variabile controllata del sistema, sarà sempre il risultato della moltiplicazione della funzione di trasferimento \\(G(s)\\) per l’ingresso \\(R(s)\\).\n\\[\nY(s) = G(s)R(s)\n\\]\nQuesta equazione fornisce una rappresentazione matematica nel dominio di trasformazione dell’impianto, che funge da sottosistema nel sistema di controllo generale che esploreremo presto.\nDomanda pop-up: Nell’equazione \\(Y(s) = G(s)R(s)\\), dove \\(Y(s) =\\frac{1}{s+1}\\) e \\(R( s)=1\\), quanto sarebbe \\(Y(s)\\)?\nRisposta: \\(\\frac{1}{s+1}\\)",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#cascata-di-blocchi",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#cascata-di-blocchi",
    "title": "Modelli di dispositivi controllati",
    "section": "Cascata di blocchi",
    "text": "Cascata di blocchi\nSupponiamo ora di avere due blocchi, \\(G_1(s)\\) e \\(G_2(s)\\).\n\n\n\n\n\n\nSe \\(R(s)\\) è l’input del primo blocco e \\(Y(s)\\) è l’output dell’intero setup e \\(X(s)\\) è il segnale tra i due blocchi, possiamo affermare:\n\\[\n\\begin{align}\nX(s) &= G_1(s)R(s)\\\\\nY(s) &= G_2(s)X(s)\\\\\n\\end{align}\n\\]\nCombinando queste equazioni, otteniamo:\n\\[\nY(s) = G_1(s) \\cdot G_2(s) \\cdot R(s)\n\\]\nCiò dimostra che quando due blocchi (o sottosistemi) sono collegati in cascata, le loro funzioni di trasferimento possono essere moltiplicate per accertare la relazione tra l’input e l’output.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#nodi-sommatori-e-punti-di-diramazione",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#nodi-sommatori-e-punti-di-diramazione",
    "title": "Modelli di dispositivi controllati",
    "section": "Nodi sommatori e punti di diramazione",
    "text": "Nodi sommatori e punti di diramazione\nAbbiamo spesso visto cerchi insieme a segni algebrici nei nostri diagrammi a blocchi. Questi denotano rilevatori di errori o giunzioni o nodi sommatori.\n\n\n\n\n\n\nAd esempio, se \\(R(s)\\) e \\(B(s)\\) sono segnali in corrispondenza di un incrocio, il segnale risultante \\(E(s)\\) viene calcolato come:\n\\[E(s)=R(s)−B(s)\\]\no \\(E(s)=R(s)+B(s)\\) se i segnali vengono sommati.\nQuesta rappresentazione simbolica funge da metodo conveniente per rappresentare manipolazioni algebriche di più segnali.\nIn alcuni casi, potremmo voler attingere a un segnale per ottenere feedback. Tali diramazioni (o branch-off) sono stati illustrati nei nostri diagrammi attraverso ramificazioni su una linea di segnale principale. Ciò garantisce che il valore del segnale restituito rimanga coerente.\n\n\n\n\n\n\nPer riassumere, qualsiasi sistema può essere rappresentato in modo completo utilizzando una combinazione di questi quattro elementi fondamentali del diagramma a blocchi: un blocco base, blocchi in cascata, giunzioni sommatrici e punti di diramazione.\n\nSistema di livello del liquido: uno sguardo dettagliato\nPer fornire ulteriore chiarezza, parliamo di un sistema di livello del liquido.\n\n\n\n\n\n\nQuando modelliamo un singolo serbatoio, ci preoccupiamo principalmente della dinamica tra afflusso, deflusso e altezza del liquido. Il modello più comune e semplificato si basa sull’equilibrio del volume del liquido, considerando le velocità di afflusso e deflusso.\nAssunzioni base:\n\nLa sezione trasversale del serbatoio è costante.\nIl liquido nel serbatoio sia ben miscelato e abbia una densità uniforme.\nLa velocità di deflusso dipende dall’altezza del liquido (a causa della pressione gravitazionale).\n\nL’obiettivo principale di questo sistema è controllare l’altezza del liquido all’interno di un serbatoio. Quando modelliamo un serbatoio di questo tipo, spesso deriviamo un modello di sistema del primo ordine, con la dinamica del serbatoio sintetizzata da un guadagno di sistema e da una costante di tempo.\n\\[\n\\frac{H_1(s)}{Q_i(s)} = \\frac{\\frac{R_1}{\\rho g}}{\\tau_1 s+1}\n\\]\nDove:\n\n\\(H(s)\\) è la trasformata di Laplace dell’altezza del liquido \\(h(t)\\).\n\\(Q_i(s)\\) è la trasformata di Laplace del tasso di afflusso \\(q_in(t)\\).\n\\(\\rho\\) è la densità del liquido\n\\(g\\) è l’accelerazione dovuta alla gravità.\n\\(R\\): resistenza al flusso, tipicamente determinata dalla dimensione e dalla forma dell’uscita.\n\nConsideriamo due serbatoi. L’input del secondo serbatoio proviene dall’output del primo serbatoio. Utilizzando i nostri modelli derivati in precedenza e se consideriamo il flusso in ingresso e l’altezza del liquido, possiamo determinare la relazione tra i serbatoi e le rispettive uscite.\n\n\n\n\n\n\nPossiamo modellare il secondo serbatoio come abbiamo fatto per il primo:\n\\[\n\\frac{H_2(s)}{Q_1(s)} = \\frac{\\frac{R_2}{\\rho g}}{\\tau_2 s+1}\n\\]\npossiamo rappresentare questa relazione dinamica con diagrammi a blocchi:\n\n\n\n\n\n\nL’input per il secondo sistema è \\(Q_1(s)\\). Tuttavia:\n\\[\nq_1 = \\frac{p_1}{R_1}\n\\]\ndove \\(p_1\\) è la pressione all’uscita del primo serbatoio, e la pressione totale è \\(\\bar{p_1}+p_1\\), e \\(\\bar{p_1}\\) è la pressione statica.\nPossiamo quindi scrivere:\n\\[\nq_1 = \\frac{p_1}{R_1} = \\frac{\\rho g h_1}{R_1}\n\\]\nEd è così che possiamo mettere in relazione \\(Q_1\\) e \\(H_1\\), ma notiamo che l’output del primo serbatoio, secondo il nostro modello è \\(H_1\\) e non \\(Q_1\\), la seconda funzione di trasferimento è diversa dalla prima.\nPer il secondo sistema, l’input è \\(Q_1\\) (afflusso) e la variabile controllata è \\(H_2\\).\nTuttavia, un punto cruciale da notare è che la dinamica del secondo serbatoio non influenza la dinamica del primo serbatoio. Questa caratteristica implica che il secondo sistema non “carica” ​​il primo. Solo in tali scenari le funzioni di trasferimento dei due sistemi possono essere moltiplicate.\nTuttavia, se i serbatoi fossero collegati in modo diverso, dove la pressione del secondo serbatoio influenza il flusso del primo serbatoio, allora questo effetto di “carico” ci impedirebbe di moltiplicare semplicemente le loro funzioni di trasferimento. Questo effetto di caricamento può alterare drasticamente la dinamica del sistema, persino trasformando un sistema del primo ordine in uno del secondo ordine.\n\n\n\n\n\n\nSe modelliamo questo caso.\nLa velocità di stoccaggio nel serbatoio 1 è:\n\\[\n\\begin{align}\nC_1\\frac{dp_1}{dt} &= q_i - \\frac{p_1-p_2}{R_1}\n\\end{align}\n\\]\ne la velocità di stoccaggio nel secondo serbatoio è:\n\\[\n\\begin{align}\nC_2\\frac{dp_2}{dt} &= q_1 - \\frac{p_2}{R_2}\n\\end{align}\n\\]\ndove \\(p_2\\) è la pressione del secondo serbatoio. Notare come ciò influisce sul flusso del primo serbatoio (termine più a destra nell’equazione (1) sopra), e quindi c’è un effetto di carico del secondo serbatoio sul primo.\nIn questo caso i due sistemi non possono essere scritti come sistemi a cascata! I due sottosistemi non sono indipendenti e non possono essere considerati due blocchi separati.\nPossiamo trovare la funzione di trasferimento complessiva come (ottenuta dalle due equazioni precedenti):\n\\[\n\\frac{H_2(s)}{Q_i(s)} = \\frac{\\frac{R_2}{\\rho g}}{\\tau_1\\tau_2s^2+(\\tau_1 + \\tau_2 + \\frac{R_2}{ R_1})s + 1}\n\\]\nSi noti che mentre nei sistemi liquidi e termici abbiamo tipicamente sistemi del primo ordine, la presenza di un effetto di carico produce un sistema del secondo ordine. Negli ambienti industriali, i singoli serbatoi vengono generalmente modellati utilizzando una costante di tempo e un guadagno di sistema. Quando connesso senza carico, la funzione di trasferimento del sistema rimane di secondo ordine, ma è rappresentata da due costanti di tempo distinte. Al contrario, quando connesso in modalità di caricamento, la funzione di trasferimento del sistema è ancora del secondo ordine, ma caratterizzata da un ritardo quadratico.\nPer ribadire e sottolineare: nelle nostre rappresentazioni del diagramma a blocchi, se rappresentiamo due sistemi, \\(G_1\\) e \\(G_2\\), in cascata, è implicito che \\(G_2\\) non carica \\(G_1\\). Questo è un presupposto cruciale che garantisce l’accuratezza dei nostri modelli e dei calcoli successivi.\nSi possono avere opportuni ammortizzatori (elettrici, idraulici, termici, ecc.) per evitare l’effetto di carico e le due funzioni di trasferimento possono essere considerate indipendentemente. Se ciò non è possibile allora i due sistemi dovranno essere considerati insieme e saranno rappresentati da un’unica funzione di trasferimento.\n\n\nBarra laterale - Modellazione di un singolo serbatoio\nQuando modelliamo un singolo serbatoio, ci preoccupiamo principalmente della dinamica tra afflusso, deflusso e altezza del liquido. Il modello più comune e semplificato si basa sull’equilibrio del volume del liquido, considerando le velocità di afflusso e deflusso.\n\nAssunzioni base:\n\nL’area della sezione trasversale del serbatoio è costante.\nIl liquido nel serbatoio è ben miscelato e ha una densità uniforme.\nLa velocità di deflusso dipende dall’altezza del liquido (a causa della pressione gravitazionale).\n\n\n\nRappresentazione matematica:\nDefiniamo le seguenti variabili:\n\n$ h(t) $: altezza del liquido al tempo $ t $.\n$ A $: area della sezione trasversale del serbatoio.\n$ Q_{in}(t) $: tasso di afflusso al tempo $ t $.\n$ Q_{out}(t) $: tasso di deflusso al tempo $ t $.\n$ $: densità del liquido.\n$ g $: accelerazione dovuta alla gravità.\n$ R $: resistenza al flusso, tipicamente determinata dalla dimensione e dalla forma dell’uscita.\n\nDal principio di conservazione della massa:\n\\[\nA \\frac{dh(t)}{dt} = Q_{in}(t) - Q_{out}(t)\n\\]\nUtilizzando la legge di Torricelli, la portata di deflusso, $ Q_{out}(t) $, dal serbatoio attraverso un orifizio può essere correlata all’altezza del liquido:\n\\[\nQ_{out}(t) = \\frac{\\rho g h(t)}{R}\n\\]\nSostituisci la velocità di deflusso nell’equazione di conservazione della massa:\n\\[\nA \\frac{dh(t)}{dt} = Q_{in}(t) - \\frac{\\rho g h(t)}{R}\n\\]\nQuesta è un’equazione differenziale del primo ordine che rappresenta la dinamica del serbatoio. Mette in relazione la velocità di variazione dell’altezza del liquido con l’afflusso e l’altezza stessa. La soluzione di questa equazione, date le opportune condizioni iniziali, ti darà l’altezza del liquido nel serbatoio in funzione del tempo.\n\n\nModello di funzione di trasferimento:\nNella teoria del controllo, è spesso utile descrivere i sistemi nel dominio della frequenza utilizzando una funzione di trasferimento. La funzione di trasferimento del serbatoio può essere derivata prendendo la trasformata di Laplace dell’equazione differenziale. Assumendo condizioni iniziali pari a zero e denotando la variabile della trasformata di Laplace come $ s $:\n\\[\nA s H(s) = Q_{in}(s) - \\frac{\\rho g}{R} H(s)\n\\]\nDove: - $ H(s) $ è la trasformata di Laplace dell’altezza del liquido $ h(t) $. - $ Q_{in}(s) $ è la trasformata di Laplace della portata di afflusso $ Q_{in}(t) $.\nRiordinare e risolvere la funzione di trasferimento $ G(s) = $:\n\\[\nG(s) = \\frac{A}{As + \\frac{\\rho g}{R}}\n\\]\nQuesta funzione di trasferimento mette in relazione l’altezza del liquido con la velocità di afflusso nel dominio della frequenza.\nRiorganizzare i termini:\n\\[\nA \\frac{dh(t)}{dt} + \\frac{\\rho g h(t)}{R} = Q_{in}(t)\n\\]\nConsideriamo ora la trasformata di Laplace di entrambi i membri. Supponendo condizioni iniziali pari a zero:\n\\[\nA s H(s) + \\frac{\\rho g}{R} H(s) = Q_{in}(s)\n\\]\nFattorizza \\(H(s)\\):\n\\[\nH(s) \\Big( A s + \\frac{\\rho g}{R} \\Big) = Q_{in}(s)\n\\]\nche porta:\n\\[\nG(s) = \\frac{H(s)}{Q_{in}(s)} = \\frac{1}{\\Big( A s + \\frac{\\rho g}{R} \\Big)}\n\\]\nOra, il guadagno di stato stazionario del sistema, quando \\(s=0\\), è:\n\\[\n\\frac{1}{\\frac{\\rho g}{R}} = \\frac{R}{\\rho g}\n\\]\nImpostando \\(A=\\tau\\) - la costante di tempo τ è uguale all’area della sezione trasversale \\(A\\) del serbatoio, otteniamo:\n\\[\n\\frac{H(s)}{Q_{in}(s)} = \\frac{\\frac{R}{\\rho g}}{\\tau s+1}\n\\]\n— FINE DELLA BARRA LATERALE",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#diagramma-a-blocchi-standard-per-la-progettazione-del-feedback",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#diagramma-a-blocchi-standard-per-la-progettazione-del-feedback",
    "title": "Modelli di dispositivi controllati",
    "section": "Diagramma a blocchi standard per la progettazione del feedback",
    "text": "Diagramma a blocchi standard per la progettazione del feedback\nPer facilità di analisi, possiamo riorganizzare lo schema a blocchi.\n\n\n\n\n\n\nIn questo diagramma: - La funzione di trasferimento tra \\(Y\\) e \\(W\\) è \\(G_P(s)\\). - La funzione di trasferimento tra \\(Y\\) e \\(U\\) è \\(G_A(s)G_P(s)\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#un-comodo-diagramma-a-blocchi",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#un-comodo-diagramma-a-blocchi",
    "title": "Modelli di dispositivi controllati",
    "section": "Un comodo diagramma a blocchi",
    "text": "Un comodo diagramma a blocchi\nPossiamo anche manipolare il diagramma per ulteriore comodità.\n\n\n\n\n\n\nIn questo diagramma: - La funzione di trasferimento tra \\(Y\\) e \\(W\\) è \\(N(s)\\). - La funzione di trasferimento tra \\(Y\\) e \\(U\\) è \\(G_A(s)G_P(s)\\).\nImpostando \\(N(s)=G_P(s)\\), entrambi i diagrammi diventano identici. Di conseguenza, la posizione della giunzione di somma diventa irrilevante. Inoltre, i due sottosistemi, \\(G_A(s)\\) e \\(G_P(s)\\) possono essere combinati per formare una funzione di trasferimento unificata rappresentata come \\(G=G_A(s)G_P(s)\\).\nIl diagramma diventa:\n\n\n\n\n\n\nMan mano che avanziamo sempre più nel regno dei sistemi di controllo, la nostra rappresentazione visiva dei sistemi – i diagrammi a blocchi – diventa indispensabile. Questi diagrammi sono rappresentazioni simboliche delle equazioni matematiche che descrivono il nostro sistema. Ma come ogni lingua, esistono molti modi per trasmettere lo stesso messaggio. Pertanto, è spesso necessario manipolare i nostri diagrammi a blocchi per chiarezza o comodità.\nDomanda pop: manipolare il diagramma a blocchi in modo che il blocco \\(A(s)\\) non appaia nel percorso in avanti. - Suggerimento: il segnale \\(\\hat{e}\\) deve essere lo stesso in entrambi i casi.\nRisposta: \\(\\hat{e} = Ay_r - Hy\\). Se dovessimo calcolare il segnale controllato \\(u\\) in questa configurazione, sarebbe:\n\\[ u = GI_r − DHy\\]\nQuesta equazione descrive la relazione tra il segnale di comando (\\(y_r\\)), il segnale controllato (\\(u\\)) e l’uscita (\\(y\\)).\nSe spostiamo il sottosistema \\(A(s)\\) dopo la giunzione di sommatoria:\n\n\n\n\n\n\nIn questa versione modificata, il nostro segnale controllato \\(u\\) può essere espresso come:\n\\[\nu = ADy_r - \\frac{H}{A}ADy\n\\]\nIl confronto di queste due equazioni conferma l’equivalenza di entrambi gli schemi a blocchi. Le trasformazioni che abbiamo applicato per passare dallo schema iniziale a quello semplificato sono puramente simboliche, ma presentano il sistema in una maniera più digeribile. Lo facciamo perché il sistema risultante diventa più conveniente.\nNota: - In quest’ultimo diagramma possiamo dire \\(y_r=r\\) perché non esiste un elemento di riferimento esplicito. Spostando il blocco \\(A\\) all’interno del circuito di feedback, la rappresentazione matematica sarebbe identica e potremmo dire \\(y_r=r\\). Nota che fisicamente potrebbe non avere alcun senso, ma le equazioni matematiche sarebbero le stesse.\n\nSe \\(H=A\\) allora il segnale in uscita dalla giunzione di sommatoria diventa \\(e=y_r-y\\). In tutti gli altri casi è \\(\\hat{e}\\).\n\nDomanda popup: Perchè è fondamentale confermare l’equivalenza dei due schemi a blocchi?\nRisposta: Confermare l’equivalenza garantisce che le nostre semplificazioni o manipolazioni non alterino inavvertitamente il comportamento del sistema. Le prestazioni e la risposta del sistema dovrebbero rimanere invariate indipendentemente dalla sua rappresentazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#sistema-di-feedback-unitario",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#sistema-di-feedback-unitario",
    "title": "Modelli di dispositivi controllati",
    "section": "Sistema di feedback unitario",
    "text": "Sistema di feedback unitario\nUn’ulteriore trasformazione può portarci a quello che viene definito “Unity Feedback System”.\nQuando \\(H(s)\\) corrisponde a \\(A(s)\\) — il che significa che la funzione di trasferimento del sensore si allinea con la funzione di trasferimento di riferimento (uno scenario che potrebbe essere progettato intenzionalmente) — lo schema a blocchi diventa più snello:\n\n\n\n\n\n\nQuesto schema a blocchi è di fondamentale importanza. Spesso possiamo adattare il sistema per allinearlo a questa rappresentazione, rendendolo particolarmente vantaggioso per considerazioni di progettazione. Per via della sua importanza, viene chiamato “sistema di feedback unitario”.\nIl termine “unità” qui non implica necessariamente che la funzione di trasferimento del sensore H(s)H(s) sia unità (o 1). Piuttosto, attraverso un’attenta manipolazione e in determinate condizioni (come \\(H=A\\)), possiamo arrivare a una rappresentazione del diagramma a blocchi che sembra implicare un feedback diretto senza alcuna trasformazione. Ma ricorda, questa è solo una rappresentazione.\nUn malinteso comune è credere che il segnale \\(y\\) venga restituito direttamente alla giunzione di sommatoria senza l’intervento di un sensore, o presupponendo che la funzione di trasferimento del sensore sia sempre 1. Tuttavia, questo non è necessariamente vero. Sebbene la funzione di trasferimento del sensore possa effettivamente essere 1, può anche esserci una funzione di trasferimento del sensore distinta \\(H\\). Selezionando giudiziosamente la funzione di trasferimento del riferimento, è possibile ottenere la struttura di feedback unitario.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#i-disturbi-contano",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#i-disturbi-contano",
    "title": "Modelli di dispositivi controllati",
    "section": "I disturbi contano",
    "text": "I disturbi contano\nInfine, un elemento cruciale da non trascurare mai è il disturbo, che rappresentiamo come \\(w\\).\nL’essenza stessa della teoria del controllo del feedback ruota attorno ai disturbi. Se i nostri sistemi non subissero disturbi, l’intero campo del controllo del feedback potrebbe non esistere. I sistemi a circuito aperto potrebbero gestire perfettamente scenari indisturbati.\n\n\n\n\n\n\nQuesto sarà il diagramma a blocchi di feedback che utilizzeremo principalmente.\nQuesti diagrammi a blocchi servono a rappresentare le relazioni tra i segnali di interesse. Sono costruiti per catturare la relazione dinamica tra tutte le variabili.\nQuando modelli un sistema, sarai sempre in grado di ricondurre il suo modello a uno di questi diagrammi a blocchi standard.\nDomanda popup: Perché i disturbi sono cruciali nei sistemi di controllo del feedback?\nRisposta: i disturbi sono cambiamenti inaspettati o imprevedibili nell’ambiente o negli input di un sistema. I sistemi di controllo del feedback sono progettati per mitigare gli effetti di questi disturbi, garantendo che il sistema funzioni come desiderato nonostante questi cambiamenti imprevisti.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#impostazione-del-disturbo-su-zero",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#impostazione-del-disturbo-su-zero",
    "title": "Modelli di dispositivi controllati",
    "section": "Impostazione del disturbo su zero",
    "text": "Impostazione del disturbo su zero\n\\[\\frac{Y(s)}{R(s)}\\Big|_{w=0}=\\frac{D(s)G(s)}{1+D(s)G(s)H (s)} = M(s)\\]\nÈ importante notare che se il nostro sistema fosse invece un ciclo di feedback positivo, questa equazione vedrebbe un segno meno al denominatore.\nQuesta è chiamata Funzione di trasferimento del riferimento perché mette in relazione il riferimento \\(R\\) con l’output \\(Y\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#impostazione-dellingresso-di-riferimento-su-zero",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#impostazione-dellingresso-di-riferimento-su-zero",
    "title": "Modelli di dispositivi controllati",
    "section": "Impostazione dell’ingresso di riferimento su zero",
    "text": "Impostazione dell’ingresso di riferimento su zero\nA noi interessa ora la funzione di trasferimento tra l’uscita del sistema \\(Y\\) e l’ingresso di disturbo \\(W\\), rappresentata come:\n\n\n\n\n\n\n\\[\n\\frac{Y(s)}{W(s)}\\Grande|_{R(s)=0} = ?\n\\]\nQuesta funzione di trasferimento cattura efficacemente la risposta del sistema ai disturbi. È una misura di come i disturbi esterni vengono filtrati o amplificati dalle dinamiche del sistema prima di influenzare l’output.\nPer rendere il nostro compito più gestibile, possiamo semplificare il nostro diagramma a blocchi combinando gli elementi. Nello specifico, prendendo il segno negativo del rilevatore di errori e consolidandolo con il segno meno esistente, possiamo semplificare la nostra rappresentazione.\n\n\n\n\n\n\nDa questo diagramma modificato si possono ricavare due relazioni fondamentali:\n\n\\(\\hat{E}(s) = -H(s)Y(s)\\)\n\\(Y(i) = D(i)G(i)\\hat{E}(i) + N(i)W(i)\\)\n\nManipolando e combinando queste equazioni, possiamo eliminare \\(\\hat{E}(s)\\) per determinare la relazione tra \\(Y(s)\\) e \\(W(s)\\).\n\\[\nY(s) = -D(s)G(s)H(s)Y(s) + N(s)W(s)\n\\]\nE quindi:\n\\[\n\\frac{Y(s)}{W(s)}\\Big|_{R(s)=0} = \\frac{N(s)}{1+D(s)G(s)H(s) } = M_W(s)\n\\]\nQuesta è chiamata Funzione di trasferimento dei disturbi.\n**Notare che sia nella funzione di trasferimento del riferimento che in quella di trasferimento del disturbo il denominatore è lo stesso: \\(1+D(s)G(s)H(s)\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#la-funzione-di-trasferimento-del-ciclo",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#la-funzione-di-trasferimento-del-ciclo",
    "title": "Modelli di dispositivi controllati",
    "section": "La funzione di trasferimento del ciclo",
    "text": "La funzione di trasferimento del ciclo\nL’espressione:\n\\[\nD(s)G(s)H(s)\n\\]\nè definita “funzione di trasferimento del loop”. Questo nome deriva dal fatto che rappresenta l’effetto combinato di tutte le funzioni di trasferimento presenti all’interno dell’anello di retroazione.\nDomanda popup: Perché il denominatore è lo stesso sia per la funzione di trasferimento del riferimento che per quella del disturbo? Risposta: Il denominatore rappresenta la funzione di trasferimento dell’anello, che è il prodotto di tutte le funzioni di trasferimento nell’anello di feedback. Ciò rimane coerente, indipendentemente dall’input in esame.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#dissezione-di-un-sistema-multi-loop",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#dissezione-di-un-sistema-multi-loop",
    "title": "Modelli di dispositivi controllati",
    "section": "Dissezione di un sistema multi-loop",
    "text": "Dissezione di un sistema multi-loop\nConsidera una configurazione multi-loop, come presentata nel nostro esempio. Il diagramma mostra più loop, di cui il loop primario è quello in cui l’uscita controllata, \\(Y\\), viene restituita all’ingresso di riferimento \\(R\\). Questo ciclo primario è completato da numerosi circuiti di feedback minori, che rendono la struttura del sistema più complessa.\n\n\n\n\n\n\nLa sfida sta nel determinare la relazione tra \\(Y\\) e \\(R\\). Questa è la relazione di cui ho bisogno dal punto di vista del controllo.\nSi noti che se ci fossero state fornite le equazioni differenziali avremmo potuto manipolarle direttamente per ottenere la relazione desiderata. In alternativa, date le equazioni possiamo scrivere lo schema a blocchi equivalente e poi manipolare lo schema a blocchi per ottenere la relazione di cui abbiamo bisogno tra qualsiasi variabile di interesse.\nLa sfida qui è che spesso questi diagrammi non sono immediatamente riducibili a un ciclo di feedback di base. Pertanto, potremmo aver bisogno di riorganizzare le giunzioni di somma, i punti di diramazione o persino spostare i blocchi per creare cicli di feedback di base identificabili.\n\nSoluzione\n\nIdentificazione del ciclo di feedback di base:\n\nIl nostro primo compito è trasformare il sistema multi-loop in cicli di feedback di base. Un ciclo di feedback di base fornisce una relazione diretta tra input e output, facilitando un’analisi più semplice.\n\n\n\n\n\n\nFigura: Ciclo di feedback di base\n\nManipolazione del diagramma a blocchi: Per ora non ci sono cicli di feedback di base nel nostro diagramma.\n\nPer ottenere un ciclo di feedback di base, potrebbe essere necessario spostare le giunzioni di somma o i punti di diramazione. L’obiettivo è identificare e isolare questi circuiti di base, rendendo il sistema più suscettibile di analisi.\n\nApplicazione delle formule di riduzione: Una volta identificati i cicli di feedback di base, applichiamo la formula standard:\n\n\\[\n\\frac{Y(s)}{R(s)}=\\frac{G(s)}{1±G(s)H(s)}\n\\]\nQuesta formula ci consente di ridurre un ciclo di feedback di base in un unico blocco, semplificando l’intero sistema.\n\nRiduzione iterativa: Il processo è iterativo. Continuiamo a identificare i cicli di feedback di base, ad applicare la formula di riduzione e a semplificare il sistema fino a ottenere la relazione desiderata tra \\(Y\\) e \\(R\\).\n\nLa procedura non è unica.\nNel nostro caso possiamo partire da:\n\n\n\n\n\n\n\nSe l’input del blocco \\(H_2\\) continua ad essere \\(X\\) (o l’output del blocco \\(H_2\\) rimane \\(H_2X\\), allora possiamo spostare il punto di diramazione dopo il blocco \\(G_4\\). Questo infatti garantisce che l’input nel resto del diagramma rimane lo stesso.\n\nPossiamo quindi modificare il diagramma precedente in:\n\n\n\n\n\n\no per rendere più espliciti i punti di diramazione:\n\n\n\n\n\n\nQuest’ultimo diagramma facilita l’identificazione del primo ciclo di feedback di base (Notare che si tratta di un ciclo di feedback positivo).\nPossiamo quindi riorganizzare lo schema a blocchi come:\n\n\n\n\n\n\nche, una volta ridotti i blocchi in cascata, possiamo scrivere come:\n\n\n\n\n\n\nE ora è facile vedere i rimanenti cicli di feedback di base. Il primo è evidenziato in rosso.\nInfine otteniamo:\n\n\n\n\n\n\nche possiamo ridurre ancora una volta per ottenere l’equivalente finale a ciclo chiuso:\n\n\n\n\n\n\nDomanda pop-up: due diversi diagrammi a blocchi possono rappresentare le stesse equazioni di sistema? Risposta: Sì, due diversi diagrammi a blocchi possono rappresentare le stesse equazioni di sistema se catturano le stesse relazioni e dinamiche.\n\n\nSoluzione alternativa\nLa sequenza di riduzione non è unica. Approcci diversi potrebbero produrre lo stesso risultato. Ad esempio, lo spostamento delle giunzioni di somma può offrire un metodo alternativo di riduzione.\n\n\n\n\n\n\nPer apportare questa modifica, chiamiamo il segnale che esce dal blocco \\(H_1\\),\\(Z = H_1Y\\). Poiché il segnale \\(Z\\) arriva come input a \\(G_3\\), significa che se spostiamo la somma prima del blocco \\(G_2\\), questo blocco contribuirà ad un ulteriore guadagno di \\(G_2\\). Dobbiamo prenderci cura di questo guadagno per avere una relazione equivalente e dividerlo per \\(G_2\\) nel percorso di feedback.\n\n\n\n\n\n\n\n\n\n\n\n\no anche in modo equivalente\n\n\n\n\n\n\nPossiamo farlo perché i diagrammi a blocchi non rappresentano sistemi fisici, sono una rappresentazione matematica.\nIn conclusione, i diagrammi a blocchi offrono un potente strumento per l’analisi e la progettazione di sistemi per il controllo automatico. Rappresentando visivamente le equazioni del sistema, facilitano la comprensione, soprattutto dei sistemi complessi.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#regole-per-la-manipolazione-del-diagramma-a-blocchi",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#regole-per-la-manipolazione-del-diagramma-a-blocchi",
    "title": "Modelli di dispositivi controllati",
    "section": "Regole per la manipolazione del diagramma a blocchi",
    "text": "Regole per la manipolazione del diagramma a blocchi",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#dai-diagrammi-a-blocchi-ai-grafici-del-flusso-dei-segnali",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#dai-diagrammi-a-blocchi-ai-grafici-del-flusso-dei-segnali",
    "title": "Modelli di dispositivi controllati",
    "section": "Dai diagrammi a blocchi ai grafici del flusso dei segnali",
    "text": "Dai diagrammi a blocchi ai grafici del flusso dei segnali\nPrima di approfondire le complessità della formula del guadagno di Mason, è essenziale capire come convertire un diagramma a blocchi nel corrispondente grafico del flusso del segnale. Questa trasformazione non è solo fondamentale per una migliore visualizzazione, ma facilita anche l’applicazione della formula del guadagno di Mason.\n\nComprensione di nodi e percorsi negli SFG\nIn un grafico del flusso del segnale, il termine “nodo” rappresenta una variabile o un segnale, mentre le frecce o i percorsi tra i nodi rappresentano il guadagno o la trasmittanza del sistema.\nAnalizziamo ulteriori concetti:\n\nNodo di input: un nodo senza segnali in entrata. Il valore di tale nodo è definito esternamente. Ad esempio, il nodo etichettato “R” nei nostri esempi precedenti.\nNodo di Output: Un nodo da cui non ci sono rami in uscita. È essenzialmente il punto finale o il risultato del nostro sistema.\n\n\n\nCostruire il grafico del flusso del segnale\nDato lo schema a blocchi, proviamo a costruire il corrispondente grafico del flusso del segnale:\n\nIdentificare il/i nodo/i di input. Nel nostro esempio, R funge da nodo di input.\nTraccia il percorso dall’input all’output, assicurandoti di attraversare un nodo o un ramo solo una volta. Questo è ciò che definisce un “percorso in avanti”.\nContrassegnare le trasmittanze o i guadagni lungo ciascun ramo. Ad esempio, un ramo con un guadagno di \\(G1\\) dovrebbe essere etichettato come tale.\n\nPrendiamo un blocco base con ingresso \\(R\\) e uscita \\(Y\\), collegati tramite un sistema \\(G\\)\n\n\n\n\n\n\nDove: - \\(R\\) è una variabile - \\(Y\\) è una variabile - \\(G\\) è il guadagno del sistema\nPossiamo costruire il grafico del flusso del segnale equivalente come:\n\n\n\n\n\n\nIn un grafico del flusso del segnale, \\(R\\) e \\(Y\\) diventano nodi e \\(G\\) diventa una trasmittanza di ramo.\nIl concetto chiave nei grafici del flusso del segnale è l’idea di nodi che rappresentano variabili e rami che indicano la relazione (o guadagno) tra questi nodi.\nDa tenere presente che _La somma dei segnali in ingresso a un nodo fornisce il valore del nodo. Il segnale in uscita è il valore della variabile del nodo.\nConsideriamo un circuito di feedback in cui un segnale \\(Y\\) viene restituito attraverso un guadagno \\(H\\).\n\n\n\n\n\n\nPer convertirlo in un diagramma di flusso del segnale:\n\nQuante variabili ci sono? 4: \\(R\\), \\(Y\\), \\(B\\), \\(\\hat{E}\\).\nQuanti guadagni ci sono? 2: \\(G\\), \\(H\\)\n\nPartiamo dalle due variabili di interesse: \\(R\\) e \\(Y\\) e le disegniamo come nodi.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl diagramma precedente può essere rappresentato anche esplicitando il nodo \\(B\\) e separando i contributi \\(H\\) e \\(-1\\). In questo caso è sufficiente la rappresentazione precedente per cogliere la dinamica di cui abbiamo bisogno.\n\n\n\n\n\n\nE infine otteniamo:\n\n\n\n\n\n\nNel grafico del flusso del segnale, il nodo etichettato “R” non ha segnali in entrata. Nella nostra terminologia, un tale nodo senza rami entranti viene definito “nodo di input”.\nQuesto perché il suo valore è definito esternamente, e quindi il valore del nodo “R” dipende da ciò che gli assegniamo.\nIl segnale proveniente da “R” viaggia lungo un ramo, moltiplicandosi per una trasmittanza pari a 1, prima di raggiungere il nodo successivo.\nAllo stesso modo, il segnale “Y” viaggia lungo il suo ramo, moltiplicandosi per una trasmittanza di \\(-H\\), prima di raggiungere il nodo di destinazione. Di conseguenza, il valore in questo nodo è la somma algebrica di questi due segnali.\nNel frattempo, il segnale “\\(\\hat{E}\\)” viaggia lungo un altro ramo, moltiplicandosi per il guadagno “G”, prima di raggiungere la sua destinazione. Di conseguenza, il valore del nodo di output “Y” è dato da $ G $.\nSolo per una migliore visualizzazione, se dovessi introdurre un ramo aggiuntivo (che non è presente nello schema a blocchi originale) e etichettarlo “Y”, questa aggiunta non avrebbe alcun impatto sulle equazioni del nostro sistema. Essenzialmente, questa equazione suggerisce \\(Y=Y\\).\n\n\n\n\n\n\nSebbene ciò possa sembrare ridondante, offre un vantaggio in termini di chiarezza. Ora possiamo definirlo un “nodo di output”. Un nodo di output è caratterizzato dall’assenza di rami in uscita, mentre un nodo di input è privo di rami in entrata. L’introduzione di questo nodo di output aiuta a delineare chiaramente l’attributo di interesse.",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#un-esempio-più-complesso",
    "href": "IT_🇮🇹/models_of_control_devices_and_systems_it.html#un-esempio-più-complesso",
    "title": "Modelli di dispositivi controllati",
    "section": "Un esempio più complesso",
    "text": "Un esempio più complesso",
    "crumbs": [
      "IT_🇮🇹",
      "Modelli di dispositivi controllati"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_it.html",
    "href": "IT_🇮🇹/stability_it.html",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "",
    "text": "Oggi ci imbarchiamo in un’esplorazione del problema della stabilità, un aspetto fondamentale ed essenziale nel campo della progettazione dei sistemi di controllo. Le modifiche ai parametri del controller, fondamentali per qualsiasi processo di progettazione, devono invariabilmente aderire al dominio di stabilità. Il rispetto delle condizioni di stabilità non è solo un requisito, ma una pietra angolare per una progettazione di sistema di successo. Per comprendere questo argomento complesso, attingeremo prima alla nostra comprensione intuitiva della stabilità. Questa conoscenza fondamentale servirà quindi come trampolino di lancio per approfondire metodi più quantitativi e analitici. Intraprendiamo questo viaggio per demistificare i principi di stabilità nei sistemi di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_it.html#stabilità-bibo",
    "href": "IT_🇮🇹/stability_it.html#stabilità-bibo",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Stabilità BIBO",
    "text": "Stabilità BIBO\nLa stabilità BIBO è un concetto critico nello studio dei sistemi di controllo, in particolare per i sistemi lineari tempo-invarianti. Nella stabilità BIBO, consideriamo un sistema inizialmente rilassato, il che significa che al tempo $ t = 0 $, tutte le variabili di stato $ x $ sono a zero e il sistema non ha energia iniziale immagazzinata. Questo scenario fornisce un punto di riferimento per analizzare come il sistema risponde agli input esterni.\nTieni presente che \\(t=0\\) è un orario di riferimento, per i sistemi Linear Time Invariant (LTI) è l’orario iniziale. L’analisi di stabilità per sistemi variabili nel tempo e/o non lineari è più complessa e va oltre lo scopo di questo corso.\nQuesta ipotesi semplifica l’analisi della stabilità poiché possiamo concentrarci sul modello della funzione di trasferimento per analizzare la stabilità. Per un sistema rilassato, l’energia iniziale è zero e questo significa che tutte le variabili di stato non sono eccitate e possiamo tranquillamente trascurarle. Poiché tutte le condizioni iniziali sono zero, possiamo studiare la stabilità solo in termini della sua funzione di trasferimento.\nIl principio chiave qui è che se l’input esterno $ r $ è limitato, anche l’output $ y $ dovrebbe rimanere limitato.\n\nAnalisi quantitativa della stabilità BIBO\nIl metodo quantitativo per stabilire la stabilità BIBO implica garantire che l’output $ y $ rimanga limitato per qualsiasi input limitato $ r $. Questo principio si applica indipendentemente dalla natura dell’input, che si tratti di un comando desiderato o di un disturbo proveniente dall’ambiente. La limitatezza dell’output è un requisito fondamentale affinché un sistema di controllo possa essere considerato stabile secondo i criteri BIBO.\n\nNella stabilità BIBO, ci concentriamo sulla risposta del sistema agli input esterni (comando e disturbo) assumendo zero energia iniziale.\nLa stabilità può essere analizzata utilizzando il modello della funzione di trasferimento, poiché un sistema rilassato può essere completamente descritto da questo modello.\nL’obiettivo è garantire che per ogni input limitato $ r $, l’output $ y $ rimanga limitato.\n\n\n\nEsempio di stabilità BIBO\n\nConsideriamo un sistema con ingresso a gradini. Se il passo in ingresso è limitato, anche la risposta in uscita del sistema dovrebbe mostrare un comportamento limitato, non crescere indefinitamente.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_it.html#stabilità-a-ingresso-zero",
    "href": "IT_🇮🇹/stability_it.html#stabilità-a-ingresso-zero",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Stabilità a ingresso zero",
    "text": "Stabilità a ingresso zero\nIl secondo aspetto del nostro studio sulla stabilità è la stabilità con input zero, dove si presuppone che l’input esterno sia zero.\nTuttavia, lo stato iniziale $ x_0 $ può cambiare a causa di input esterni, influenzando l’accumulo di energia nel sistema.\nIl modello matematico per la stabilità a ingresso zero è rappresentato da:\n\\[\n\\dot{x} = Ax\n\\]\ndove $ x(t = 0) = x_0 $. L’attenzione qui è se lo stato del sistema $ x(t) $ rimane limitato per tutti $ t $ quando varia $ x_0 $. Se è così, il sistema preserva la stabilità a input zero.\n\nRiepilogo\n\nLa stabilità con input zero considera la risposta del sistema quando si presuppone che gli input esterni siano pari a zero.\nL’attenzione si concentra su come le variazioni nello stato iniziale $ x_0 $ influenzano lo stato del sistema $ x(t) $ nel tempo.\nL’obiettivo è garantire che gli stati del sistema rimangano vincolati per tutto il tempo $ t $ con input esterni pari a zero.\n\nChiamiamo un sistema invariante nel tempo in cui l’input è zero, un sistema autonomo. Questo concetto è cruciale per studiare la stabilità a input zero.\nDomanda pop-up: Perché la stabilità a input zero è importante e in cosa differisce dalla stabilità BIBO?\nRisposta: la stabilità a input zero si concentra sul comportamento del sistema in assenza di input esterni, enfatizzando la risposta del sistema in base al suo stato iniziale. Si differenzia dalla stabilità BIBO, che riguarda la risposta del sistema agli input limitati esterni, garantendo che l’output rimanga limitato.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_it.html#combinazione-di-bibo-e-stabilità-a-input-zero",
    "href": "IT_🇮🇹/stability_it.html#combinazione-di-bibo-e-stabilità-a-input-zero",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Combinazione di BIBO e stabilità a input zero",
    "text": "Combinazione di BIBO e stabilità a input zero\n\nPer un sistema lineare, se sono soddisfatte sia le condizioni BIBO che quelle di stabilità con input zero, si può dedurre che per qualsiasi input limitato $ r $ e $ w $, gli stati e l’output del sistema rimarranno limitati.\n\n\nStabilità BIBO e risposta all’impulso\n\nLa risposta all’impulso $ g(t) $ di un sistema fornisce una caratterizzazione completa di un sistema rilassato. L’output del sistema è dato da:\n\n\\[\ny(t) = \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau\n\\]\ndove \\(r(t)\\) è l’input.\nPoiché siamo interessati alla stabilità BIBO, ciò significa che siamo interessati alle ampiezze. In questo caso vale la seguente relazione:\n\\[\n|y(t)| = \\Big| \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau \\Big| \\le \\int_{0}^{\\infty} |g(\\tau)| |r(t-\\tau)| d\\tau\n\\]\nSe l’input è limitato, ovvero \\(|r(t-\\tau)| \\le M\\), con \\(M\\) finito,\n\\[\n|y(t)| = \\Big| \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau \\Big| \\le \\int_{0}^{\\infty} |g(\\tau)| |r(t-\\tau)| d\\tau \\le M \\int_{0}^{\\infty} |g(\\tau)| d\\tau \\le N &lt; \\infty\n\\]\nCiò significa che per la stabilità BIBO, l’integrale del modulo della risposta all’impulso dovrebbe essere finito.\nL’integrale del modulo della risposta all’impulso del sistema caratterizza la stabilità BIBO. Nello specifico, un sistema è BIBO stabile se e solo se:\n\\[\n\\int_{0}^{\\infty} |g(t)| dt &lt; \\infty\n\\]\nQuesta condizione implica che l’area sotto la curva del valore assoluto della risposta all’impulso deve essere finita.\n\nPoli, zeri e analisi delle funzioni di trasferimento\nOra traduciamo la nostra comprensione nei requisiti dei poli e degli zeri, come riflesso nel modello della funzione di trasferimento di un sistema di controllo. Consideriamo la funzione di trasferimento rappresentata come:\n\\[ \\frac{Y(s)}{R(s)} = G(s) = \\frac{b_0 s^m + b_1 s^{m-1} + \\ldots + b_m}{a_0 s^n + a_1 s^{n-1} + \\ldots + a_n} \\]\ndove $ m n $. Questa disuguaglianza garantisce che il sistema sia corretto o strettamente corretto, aspetto cruciale per i sistemi realizzabili.\n\nL’equazione caratteristica, derivata dal denominatore della funzione di trasferimento, è:\n\n\\[ \\Delta(s) = a_0 s^n + a_1 s^{n-1} + \\ldots + a_n = 0 \\]\n\nLe radici di questa equazione, che sono i poli della funzione di trasferimento, determinano la stabilità del sistema.\n\nSe prendiamo l’espansione delle frazioni parziali,\n\nGli zeri (radici del numeratore) influenzano l’entità e la forma della risposta transitoria ma non alterano la stabilità del sistema.\nI poli determinano la stabilità del sistema e il suo comportamento intrinseco.\nAd esempio, un fattore del primo ordine nella funzione di trasferimento risulta in una risposta esponenziale (crescente o decrescente), mentre un fattore del secondo ordine porta a una risposta oscillatoria (crescente o decrescente).\n\n\n\n\nAnalisi nel piano s\nAnalizziamo il piano s per capire come i poli influenzano il comportamento del sistema:\n\nSemipiano sinistro: i poli nella metà sinistra del piano s portano ad una risposta in decomposizione, indicando un sistema stabile. Anche i poli complessi in questa regione danno luogo a risposte oscillatorie ma decadenti.\nSemipiano destro: i poli nella metà destra del piano s provocano una risposta crescente, indicando un sistema instabile. Ciò vale per tutti i poli reali, complessi, ripetuti o distinti in questa regione.\n\nIl paragrafo e il diagramma seguente mostra la risposta all’impulso (\\(R(s)=1\\)) per le possibili posizioni dei poli.\n\n\nPoli e zeri nell’analisi delle funzioni di trasferimento\nNell’analizzare la funzione di trasferimento di un sistema, i poli e gli zeri svolgono un ruolo significativo nel determinare il comportamento del sistema. - I poli, che sono le radici dell’equazione caratteristica del sistema, determinano la stabilità del sistema. - Al contrario, gli zeri influenzano la risposta transitoria ma non influiscono sulla stabilità.\n\nScansione dell’s-Plane per le posizioni dei poli\nEsaminando il piano s, analizziamo la posizione dei poli per determinarne la stabilità. Se un polo si trova nella metà sinistra del piano s, contribuisce al decadimento della risposta all’impulso, indicando stabilità. Al contrario, i poli nella metà destra o sull’asse immaginario possono portare all’instabilità.\n\n\n\n\n\n\n\n\n\n\n\n\nSistemi marginalmente stabili\nNei sistemi di controllo, il concetto di stabilità marginale emerge quando si ha a che fare con i poli dell’asse immaginario, in particolare i poli semplici. Analizziamo più a fondo questo scenario e comprendiamo le sue implicazioni:\n\nMatematica e prospettiva dell’utente:\n\nMatematicamente, i sistemi con poli sull’asse immaginario sono considerati instabili.\nTuttavia, da un punto di vista pratico, tali sistemi potrebbero ancora essere interessanti a determinate condizioni.\n\nAnalisi di una funzione di trasferimento specifica:\n\nConsideriamo una funzione di trasferimento:\n\\[\nG(s) = \\frac{N(s)}{s(s + j\\omega)(s - j\\omega)} = \\frac{Y(s)}{R(s)}\n\\]\nQuesto sistema è matematicamente instabile, ma esaminiamolo dal punto di vista dell’utente.\n\nRisposta limitata per input specifici:\n\nSi osserva che per la maggior parte degli input $ R(s) $, ad eccezione di quelli specifici che corrispondono ai poli sull’asse immaginario, la risposta del sistema rimane limitata - in questo caso, l’input corrisponde ai poli semplici e li rende doppi.\nNel nostro caso specifico sopra, gli input critici da evitare sono $ R(s) = $ o $ R(s) = $. Ad eccezione di questi, il sistema mostra una risposta non crescente (ad esempio, risposta oscillatoria, risposta costante, ecc.).\n\nAccettazione del Sistema in base alla Richiesta:\n\nLa decisione di accettare o rifiutare un tale sistema dipende dalla sua applicazione e dalla sua capacità di gestire le condizioni specifiche in cui la risposta rimane limitata.\n\nConcetto di stabilità marginale:\n\nI sistemi marginalmente stabili sono quelli in cui esistono poli semplici sull’asse immaginario, ma la risposta rimane limitata per input che non corrispondono a questi poli.\nQuesto concetto implica un approccio cauto, in cui i sistemi vengono analizzati in modo più approfondito prima di essere considerati stabili o instabili in base al loro caso d’uso specifico.\nÈ una condizione al contorno che la matematica etichetta come instabile, ma dal punto di vista dell’utente potrebbe dipendere dall’applicazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_it.html#stabilità-a-input-zero-e-variabili-di-stato",
    "href": "IT_🇮🇹/stability_it.html#stabilità-a-input-zero-e-variabili-di-stato",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Stabilità a input zero e variabili di stato",
    "text": "Stabilità a input zero e variabili di stato\nPassiamo ora al concetto di stabilità a input zero, sfruttando la conoscenza che abbiamo delle variabili di stato:\n\nIl sistema autonomo lineare:\n\nConsideriamo un sistema lineare autonomo: \\[ \\dot{x} = Ascia \\] \\[ x(0) = x_0 \\]\n\nTrasformata di Laplace e analisi del sistema:\n\nApplicando la trasformata di Laplace, otteniamo: \\[ sX(s) - x_0 = AX(s) \\]\nDove \\[X(s) = \\begin{bmatrix}\nx_1(i) \\\\\nx_2(s) \\\\\n\\vdots \\\\\nx_n(i)\n\\end{bmatrix}\n\\]\nLa riorganizzazione dà: \\[ X(s) = (sI - A)^{-1}x_0 \\]\nQui, $ X(s) $ rappresenta la trasformata di Laplace del vettore di stato $ x $ e $ A $ è una matrice di coefficienti costanti.\n\nTrasformata inversa per l’analisi della stabilità:\n\nPer analizzare la stabilità, ci concentriamo sulla trasformata inversa di Laplace di $ X(s) $, che coinvolge la matrice $ (sI - A)^{-1} $. Per ogni stato iniziale \\(x_0\\), vogliamo studiare come si comporta \\(x(t)\\).\nQuesta matrice può essere rappresentata come:\n\\[ X(s) = (sI - A)^{-1} = \\frac{(sI - A)_{\\text{aggiunto}}}{\\Delta(s)} x_0 \\]\nDove $ (s) = (sI - A) $ è il determinante della matrice.\n\nPonomio caratteristico e autovalori:\n\nIl polinomio caratteristico \\(\\Delta(s)\\) per una matrice $ n n $ $ A $ è dato da un polinomio di ordine n:\n\\[ \\Delta(s) = \\alpha_0 s^n + \\alpha_1 s^{n-1} + \\ldots + \\alpha_n \\]\nLe radici di $ (s) $ sono gli autovalori di $ A $, che determinano la stabilità del sistema nel caso di input zero.\n\n\nConcentriamoci ora sull’equazione caratteristica derivata dal modello delle variabili di stato del sistema. Questa equazione gioca un ruolo cruciale nella comprensione della dinamica del sistema:\n\nIl modello delle variabili di stato:\n\nPer una matrice $ n n $ $ A $, il determinante di $ sI - A $ risulta in un polinomio di ordine n-esimo, che caratterizza la dinamica del sistema.\nQuesto determinante viene anche chiamato equazione caratteristica quando derivato dal modello delle variabili di stato.\n\n\n\nComprendere le voci della matrice aggiunta\n\nMatrice congiunta di $ sI - A $:\n\nQuando si considera la matrice aggiunta di $ sI - A $, ogni voce è un polinomio di ordine $ n - 1 $.\nIl cofattore di ciascun elemento della matrice contribuisce a queste voci polinomiali.\n\n\n\n\nStabilità e zeri dallo spazio degli stati\n\nAnalisi di stabilità:\n\nLa stabilità del sistema è determinata dalle radici dell’equazione caratteristica, $ (s) = (sI - A) $.\nGli zeri, che provengono dagli elementi aggiunti della matrice, non influiscono sulla stabilità. Pertanto, per l’analisi della stabilità con input zero, ci concentriamo solo sui poli (radici di $ (s) $).\n\nRisposta e stabilità dello Stato:\n\nSe le radici di $ (s) $ giacciono nel semipiano sinistro, il vettore di stato $ x(t) $ rimane limitato, indicando stabilità.\nI poli semplici sull’asse immaginario portano a risposte limitate ma sono considerati marginalmente stabili.\n\n\n\n\nStabilità asintotica\n\nUn sistema è asintoticamente stabile se tutte le radici di $ (s) $ si trovano nel semipiano sinistro, causando il decadimento a zero di tutte le variabili di stato come $ t $.\n\n\\[\n   \\lim_{t \\rightarrow \\infty } x(t) \\rightarrow 0\n   \\]\n\nQuesto concetto è cruciale perché garantisce che la risposta del sistema non solo rimanga limitata ma si avvicini allo zero nel tempo.\n\n\\[\n   x(t) = \\mathcal{L}^{-1}\\Big[\\frac{(sI - A)_{\\text{aggiunta}}}{\\Delta(s)}\\Big] x_0\n   \\]\nNota che \\(x_0\\) è un fattore di scala (in modo simile agli zeri). La dinamica è guidata da \\(\\Delta(s)\\).\n\n\nCondizioni di stabilità, instabilità e stabilità marginale\n\nCondizioni di stabilità:\n\nAsintoticamente stabile: tutti i poli si trovano nel semipiano sinistro.\nInstabile: Almeno un polo nel semipiano destro o più poli sull’asse immaginario.\nMarginalmente stabile: tutti i poli nel semipiano sinistro, ad eccezione dei poli semplici sull’asse immaginario.\n\nStabilità marginale, commenti aggiuntivi\nSi noti che nel caso marginalmente stabile, non stiamo abbinando i poli ora come facevamo prima. È una situazione diversa, \\(x_0\\) è una costante.\n\nUn polo nell’origine dà una risposta costante, moltiplicata per la costante \\(x_0\\), il che significa che \\(x(t)\\) rimane limitato in una regione specifica.\nAllo stesso modo per due poli immaginari. La risposta è oscillatoria, moltiplicata per la costante \\(x_0\\), il che significa che \\(x(t)\\) rimane confinato in una regione specifica.\n\nPer questo motivo, qualsiasi polo semplice sull’asse immaginario fornisce una risposta in uno stato limitato, e questo può essere raggruppato nella condizione di stabilità marginale.\n\n\nRelazione tra stabilità a input zero e stabilità BIBO\n\nEquivalenza dei concetti di stabilità:\n\nSe e solo se $(s)=(sI - A) $ è uguale al denominatore della funzione di trasferimento del sistema $ G(s) $, allora stabilità asintotica (stabilità con input zero ) e la stabilità BIBO sono le stesse.\nIn molti sistemi reali questa condizione è soddisfatta. Questa è chiamata condizione di controllabilità e osservabilità.\n\n\n\n\n\n\nSIDEBAR - concetti di stabilità, concentrandosi in particolare su come la posizione dei poli influisce sulla stabilità di un sistema di controllo e sui casi specifici di poli semplici sull’asse immaginario, che portano alla stabilità marginale.\n\n\nPoli sull’asse immaginario e risposta del sistema\n\nPali semplici sull’asse immaginario:\n\nUn polo semplice sull’asse immaginario (esclusa l’origine) corrisponde ad una componente sinusoidale nella risposta del sistema.\nQuando lo stato del sistema $ x(t) $ è influenzato da un semplice polo sull’asse immaginario, la risposta sarà oscillatoria. L’entità di questa oscillazione è influenzata dalla condizione iniziale $ x_0 $, ma la risposta rimane limitata: non cresce all’infinito né decade a zero.\nQuesto comportamento oscillatorio limitato caratterizza un sistema marginalmente stabile.\n\nPolo all’Origine:\n\nUn polo semplice all’origine del piano s corrisponde ad una componente costante nella risposta del sistema.\nCiò porta a un valore di stato stazionario che dipende dalla condizione iniziale $ x_0 $, risultando in una risposta limitata che non cambia nel tempo.\n\n\n\n\nClassificazioni di stabilità basate sulla posizione dei poli\n\nStabilità asintotica:\n\nUn sistema è asintoticamente stabile se tutti i poli si trovano nel semipiano sinistro. In questo caso, tutte le modalità del sistema decadono nel tempo, portando $ X(t) $ ad avvicinarsi allo zero mentre $ t $ tende all’infinito.\n\nSistemi instabili:\n\nSe almeno un polo si trova nel semipiano destro, o se ci sono più poli sull’asse immaginario, il sistema è instabile. Questo perché tali posizioni polari portano a risposte che crescono illimitate nel tempo.\n\nStabilità marginale:\n\nLa stabilità marginale si verifica quando tutti i poli si trovano nel semipiano sinistro, ad eccezione dei poli semplici sull’asse immaginario. Questi sistemi non mostrano una crescita illimitata in risposta, né si stabilizzano su uno stato stazionario; invece, sostengono le oscillazioni.\n\n\n\n\nEquivalenza tra stabilità asintotica e stabilità BIBO\n\nCondizioni di equivalenza:\n\nLa stabilità asintotica (stabilità con input zero) e la stabilità BIBO (Bounded-Input, Bounded-Output) diventano equivalenti quando il determinante di $ sI - A $ corrisponde al denominatore della funzione di trasferimento del sistema $ G(s) $.\nQuesta condizione è spesso soddisfatta nei sistemi reali, rendendo in molti casi i concetti di stabilità a ingresso zero e stabilità BIBO praticamente sinonimi.\nNella teoria del controllo, questa equivalenza è legata ai concetti di controllabilità e osservabilità.\n\n\n\n\nTermini di stabilità semplificati\n\nClassificazione semplificata:\n\nDate le comprensioni di cui sopra, possiamo semplificare la nostra terminologia:\n\nStabile: tutti i poli sono nel semipiano sinistro.\nInstabile: almeno un polo si trova nel semipiano destro o più poli si trovano sull’asse immaginario.\nMarginalmente stabile: tutti i poli sono nel semipiano sinistro ad eccezione dei poli semplici sull’asse immaginario.\n\n\n\n\n\nConsiderazioni conclusive\nComprendere queste sfumature di stabilità basate sulla posizione dei poli è fondamentale nella progettazione e nell’analisi del sistema di controllo. Aiuta a prevedere il comportamento del sistema in varie condizioni e a garantirne il funzionamento sicuro e affidabile. I sistemi marginalmente stabili, sebbene limitati, richiedono un’attenta considerazione a causa delle loro oscillazioni sostenute, che potrebbero essere indesiderabili in determinate applicazioni.\n\n\n\nBARRA LATERALE - Matrice aggiunta\nPer capire perché ogni elemento della matrice aggiunta di $ sI - A $ è un polinomio di ordine $ n - 1 $, è importante approfondire i concetti di matrici, determinanti e loro aggiunti nel contesto dell’algebra lineare e dei sistemi di controllo .\n\n\nConcetti di base\n\nMatrice aggiunta:\n\nL’aggiunto (o adigato) di una matrice è formato dai cofattori di ciascun elemento della matrice.\nPer una matrice quadrata $ A $, l’aggiunto è indicato come $ (A) $ ed è la trasposta della matrice dei cofattori di $ A $.\n\nCofattore di un elemento:\n\nIl cofattore di un elemento in una matrice si calcola prendendo il determinante della sottomatrice formata eliminando la riga e la colonna di quell’elemento e quindi applicando un segno in base alla posizione dell’elemento.\n\n\n\n\nAggiunto di $ sI - A $\nConsideriamo ora la matrice $ sI - A $ per una matrice $ n n $ $ A $ e una matrice scalare $ s $:\n\n$ sI $ è una matrice diagonale con $ s $ sulla diagonale e zeri altrove.\n$ sI - A $ risulta in una matrice in cui gli elementi diagonali sono $ s - a_{ii} $ (dove $ a_{ii} $ sono gli elementi diagonali di $ A $) e gli elementi fuori diagonale sono gli elementi negati di $ A $.\n\n\n\nOrdine polinomiale negli elementi aggiunti\n\nOrdine polinomiale nei cofattori:\n\nQuando calcoliamo il cofattore di un elemento in $ sI - A $, prendiamo essenzialmente il determinante di una sottomatrice $ (n-1) (n-1) $.\nQuesto determinante sarà un polinomio in $ s $ poiché ogni operazione sul determinante introduce una somma di prodotti di elementi della matrice, che sono lineari in $ s $ dovuti agli elementi diagonali di $ sI - A $.\n\nOrdine del polinomio:\n\nPoiché il determinante di una matrice $ (n-1) (n-1) $ coinvolge una somma di prodotti di $ (n-1) $ elementi, il polinomio risultante in $ s $ sarà dell’ordine $ n - 1$.\nPertanto ogni cofattore della matrice aggiunta, e quindi ogni elemento di $ (sI - A) $, è un polinomio di ordine $ n - 1 $.\n\n\n\n\nConclusione\nIn sintesi, l’aggiunto di $ sI - A $ è costituito da elementi che sono polinomi di ordine $ n - 1 $ perché ogni elemento è derivato dal determinante di una sottomatrice $ (n-1) (n-1) $, che risulta intrinsecamente in un polinomio di $ s $ di ordine $ n - 1 $. Questa comprensione è cruciale nei sistemi di controllo, in particolare quando si analizza la stabilità del sistema attraverso la sua rappresentazione nello spazio degli stati.\n— FINE DELLA BARRA LATERALE",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "",
    "text": "La modellazione funge da spina dorsale per comprendere e manipolare i sistemi dinamici. Questi sistemi dinamici comprendono vari componenti:\nL’obiettivo primario? Stabilire equazioni precise che definiscano questi sistemi dinamici.\nRicordando le nostre discussioni precedenti, il nostro focus è sempre stato sull’applicazione delle leggi fisiche. Così facendo, possiamo trasformare le equazioni differenziali derivate in forme più digeribili. Due di questi moduli che utilizzeremo ampiamente sono:\nQuesti modelli offrono un modo strutturato per rappresentare matematicamente i sistemi, consentendo l’analisi e la progettazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#meccanica",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#meccanica",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Meccanica",
    "text": "Meccanica\nUsando la meccanica della traslazione, emergono tre elementi fondamentali:\n\nLa massa ideale \\(M\\)\nIl coefficiente di attrito \\(B\\)\nLa costante elastica \\(K\\)\n\n\nMassa\nLa componente \\(M\\), che rappresenta la massa ideale, è una semplificazione, un’idealizzazione a parametri concentrati di una massa distribuita. Negli scenari del mondo reale, non si incontra una singola particella (massa concentrata) di massa \\(M\\). E’ un’approssimazione in cui assumiamo che l’intera massa sia centrata nel suo baricentro.\nDomanda pop-up: Perché utilizziamo l’idealizzazione dei parametri concentrati per la massa ideale \\(M\\) nei sistemi dinamici? Risposta: Usiamo l’idealizzazione dei parametri concentrati per semplificare la rappresentazione delle masse distribuite approssimandole come una massa a punto singolo concentrata nel suo centro di gravità. Ciò rende la modellazione e l’analisi più trattabili.\n\n\nAttrito\nIl coefficiente di attrito \\(B\\) presenta una serie di sfide. Possono sorgere attriti a causa di vari fenomeni, quindi potrebbero essere necessari modelli diversi. Ad esempio, un attrito di guida costante tra le superfici si tradurrebbe in una forza di attrito costante per tutte le velocità, nota come attrito di Coulomb. D’altra parte, quando due superfici scivolano con un mezzo viscoso in mezzo, la forza di attrito è tipicamente proporzionale alla velocità, portando all’equazione \\(F=Bv\\), dove \\(B\\) è il coefficiente di attrito viscoso. Questo modello è prevalente quando un corpo solido interagisce con un mezzo fluidico.\nÈ essenziale riconoscere la presenza di altri tipi di attrito, come l’attrito di Coulomb, in dispositivi come i motori CC dovuti al contatto delle spazzole. Ma poiché le nostre discussioni iniziali ruotano attorno a modelli lineari, considereremo tutti gli attriti non lineari come disturbi del sistema.\n\n\nMolle\nInfine, la costante elastica \\(K\\) entra in gioco quando c’è una deformazione elastica. In questo caso la forza dovuta all’effetto molla è data da \\(F=Kx\\), dove \\(x\\) è lo spostamento.\n\nNota: è essenziale comprendere che questi modelli, sebbene incredibilmente utili, sono approssimazioni. Semplificano le complessità del mondo reale in parti digeribili che possono essere utilizzate per la progettazione e l’analisi.\n\n\n\nDerivazione del modello matematico\nConsideriamo un sistema meccanico complesso, in questo caso il sistema di sospensione di un’auto, e vediamo come possiamo approssimarlo attraverso una massa, una molla e un ammortizzatore più semplici.\n\n\n\n\n\n\nDato un sistema fisico, il nostro primo passo è derivarne il modello matematico. Questo è essenziale per l’analisi o la progettazione.\nPrendiamo, ad esempio, il carico su un sistema comprendente la massa di un pistone di potenza, il collegamento di trasmissione e le ruote. Tutti questi componenti hanno masse distribuite. Tuttavia, per il nostro modello, lo semplificheremo come una singola particella di massa \\(M\\).\nNel nostro caso la massa distribuita è la massa del pistone di potenza, la massa del cinematismo e la massa delle ruote. Ma modelleremo tutto questo come una particella con massa \\(M\\).\nGli attriti nel nostro sistema derivano da varie fonti, come il movimento di un pistone in un mezzo viscoso o l’interazione tra il collegamento di trasmissione e l’ambiente circostante. Modelleremo questi attriti utilizzando il parametro \\(B\\) e un attrito viscoso.\nGli pneumatici sulla strada potrebbero creare un attrito di Coulomb, ma lo considereremo come un disturbo che agisce sul nostro sistema.\nInfine, il comportamento elastico dei pneumatici può essere modellato attraverso una molla con parametro \\(k\\).\nCon queste considerazioni possiamo modellare il sistema di sospensione del gatto con:\n\n\n\n\n\n\nQuesta trasformazione, pur comportando varie approssimazioni, si è rivelata efficace per la progettazione del sistema di controllo.\nAbbiamo visto che a seconda del parametro \\(\\zeta\\) abbiamo non smorzato (\\(\\zeta=0\\)), smorzato (\\(0&lt;\\zeta&lt;1\\)), critically damped (\\(\\zeta=1\\)) and over damped systems (\\(\\zeta&gt;1\\)).\nIn alcune situazioni, potrebbe essere necessario introdurre un attrito intenzionale per controllare lo smorzamento del sistema. Ciò può essere ottenuto utilizzando un dispositivo chiamato dashpot, che utilizza un mezzo oleoso per fornire resistenza al movimento.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#modelli-fisici-e-approssimazioni",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#modelli-fisici-e-approssimazioni",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Modelli fisici e approssimazioni",
    "text": "Modelli fisici e approssimazioni\nQualsiasi situazione fisica, sia essa naturale o industriale, soprattutto se riguarda un sistema meccanico in modalità traslazionale, può essere modellata utilizzando i principi di cui abbiamo discusso. Questa rappresentazione servirà come nostro modello principale.\nTuttavia, man mano che andiamo avanti, è essenziale riconoscere le complessità e le approssimazioni che abbiamo impiegato. Ogni modello che deriviamo ha le sue radici in vari presupposti e semplificazioni, che sono vitali per rendere gestibile il modello.\nConsidera i parametri \\(M\\) (la massa ideale), \\(K\\) (la costante della molla) e \\(B\\) (la costante del dash pot o costante di attrito viscoso). Nel nostro modello, \\(F_\\omega\\) indica una forza di disturbo che agisce sul sistema. Potrebbe essere attribuito ad attriti incontrollati o anche a fattori ambientali. Abbiamo scelto il simbolo “\\(\\omega\\)” per rappresentare i disturbi.\nLe variabili \\(y\\) e \\(v\\) denotano rispettivamente spostamento e velocità.\n\n\n\n\n\n\nDomanda pop-up: Perché abbiamo bisogno di modellare i disturbi nel nostro sistema? Risposta: I disturbi possono influenzare le prestazioni e la stabilità di un sistema di controllo. Modellandoli, possiamo progettare strategie di controllo per mitigarne gli effetti e garantire che il sistema funzioni come previsto.\nPer trasformare questo modello fisico in un modello di equazioni differenziali, è spesso utile tracciare un diagramma di corpo libero.\n\n\n\n\n\n\nQuesto diagramma visualizza le masse come nodi e le forze che agiscono su di esse sono rappresentate con frecce. Per il nostro sistema attuale, abbiamo un’unica massa, \\(M\\), con una forza applicata \\(F\\) e una forza di disturbo \\(F_\\omega\\). Inoltre, la forza della molla \\(Ky\\) e la forza di attrito \\(Bv\\) si oppongono al movimento. Bisogna considerare anche la forza d’inerzia dovuta alla massa \\(M\\) stessa, che contrasta il movimento.\nUn principio cruciale in meccanica è l’equazione dell’equilibrio delle forze, che afferma che le forze che promuovono il movimento dovrebbero eguagliare le forze che si oppongono ad esso. Pertanto la nostra equazione diventa:\n\\[\nM\\dot{v} + B{v} + Ky = F - F_\\omega\n\\]\nQui, \\(F-F_\\omega\\) è la forza netta che agisce sul sistema. \\(\\dot{v}\\) denota accelerazione e \\(F_\\omega\\) può assistere o contrastare la forza applicata \\(F\\) a seconda della sua natura. Vale la pena notare che anche se \\(F_\\omega\\) aiuta il movimento, è comunque considerato un disturbo, poiché il sistema non è stato progettato pensando a questo.\nPossiamo convertirlo in un modello con variabili di stato:\n\\[\n\\begin{align}\nx_1 &= y\\\\\nx_2 &= v = \\dot{y}\n\\end{align}\n\\]\ne abbiamo già visto come farlo. Concentriamoci invece sul modello della funzione di trasferimento.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasformazione-nel-modello-della-funzione-di-trasferimento",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasformazione-nel-modello-della-funzione-di-trasferimento",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Trasformazione nel modello della funzione di trasferimento",
    "text": "Trasformazione nel modello della funzione di trasferimento\nOgni sistema di controllo può essere rappresentato nel dominio di Laplace, rendendo più semplice l’analisi e la progettazione di strategie di controllo. Per il nostro sistema, la funzione di trasferimento è una relazione tra un singolo input e output. Tuttavia, si noti che il sistema è composto da due ingressi (\\(F, F_\\omega\\)) e un’uscita (\\(y\\)).\nPossiamo riscrivere la nostra equazione per esplicitare la variabile di output:\n\\[\nM\\ddot{y} + B\\dot{y} + Ky = F - F_\\omega\n\\]\nLa funzione di trasferimento è una descrizione SISO e quindi, utilizzando come diagramma a blocchi:\n\n\n\n\n\n\nPossiamo quindi scrivere la funzione di trasferimento tra \\(Y(s)\\) e \\(F(s)\\), e tra \\(Y(s)\\) e \\(F_\\omega(s)\\)\nData la rappresentazione di cui sopra, possiamo esprimere la funzione di trasferimento tra \\(Y(s)\\) e \\(F(s)\\) (assumendo \\(F_\\omega(s)=0\\)) come:\n\\[\n\\frac{Y(s)}{F(s)} = \\frac{1}{Ms^s+Bs+K}\n\\]\ne questa è anche la funzione di trasferimento tra \\(Y(s)\\) e \\(F_\\omega(s)\\).\nPossiamo quindi chiamare:\n\\[\n\\frac{Y(s)}{F(s)} = \\frac{1}{Ms^s+Bs+K} = Sol(s)\n\\]\nCon un po’ di semplificazione e standardizzazione, e considerando lo smorzamento e la frequenza propria del sistema, otteniamo:\n\\[\nG(s)=\\frac{1}{\\frac{M}{K}s^s + \\frac{B}{K}s + 1} = \\frac{K_S}{\\frac{1}{\\omega_n ^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 }\n\\]\nDove ho chiamato \\(K_S\\) il sistema guadagna per differenziarlo da \\(K\\).\nQuesta funzione, definita ritardo quadratico, è un ritardo di secondo ordine in contrasto con il ritardo di primo ordine (o semplice) di cui abbiamo discusso in precedenza.\n\nUnità\nL’importanza di comprendere queste unità e parametri non può essere sopravvalutata. Costituiscono la base su cui sono costruiti i nostri modelli matematici, consentendoci di fare previsioni, progettare controllori e comprendere il comportamento del sistema.\n\nForza: Newton\nDislocamento \\(y\\): Metri\nVelocità \\(v\\): Metri/secondo\nAccelerazione: metri/secondo^2\nMassa \\(M\\): Chilogrammi\nCoefficiente di attrito \\(B\\): Newton/(metri/secondo)\nCostante della molla \\(K\\): Newton/metro\n\nDomanda pop-up: cosa distingue un ritardo di secondo ordine (ritardo quadratico) da un ritardo di primo ordine (semplice)?\nRisposta: un ritardo di secondo ordine ha un termine quadratico (s^2) al denominatore, mentre un ritardo di primo ordine ha solo un termine lineare (s). Ciò rende il sistema del secondo ordine più complesso, con proprietà come oscillazioni e superamento che non sono presenti in un sistema del primo ordine.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasferimento-di-calore-attraverso-una-parete-solida",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasferimento-di-calore-attraverso-una-parete-solida",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Trasferimento di calore attraverso una parete solida",
    "text": "Trasferimento di calore attraverso una parete solida\nConsideriamo un muro di qualsiasi materiale con superficie \\(A\\) (\\(m/s^2\\)) e spessore \\(l\\) (\\(m\\)). Sia \\(\\theta_1\\) (\\(^oC\\)) e \\(\\theta_2\\) (\\(^oC\\)) le temperature su entrambi i lati di questo muro.\n\n\n\n\n\n\nIl trasferimento di calore attraverso questa parete può essere descritto dalla seguente equazione:\n\\[\nh = \\frac{\\sigma A(\\theta_1−\\theta_2)}{l}\n\\]\nDove: - \\(h\\) è la velocità di trasferimento del calore (in Joule al secondo). - \\(\\sigma\\) è la conducibilità termica del materiale.\nDa una prospettiva analoga, considerando che \\(h\\) è simile alla corrente e la differenza di temperatura \\(\\theta_1−\\theta_2\\) è simile alla tensione, l’equazione di cui sopra può essere vista come:\n\\[\nh = \\frac{\\theta_1−\\theta_2}{R}\n\\]\nDove: - \\(R = \\frac{l}{\\sigma A}\\) è la resistenza di conduzione del materiale.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasferimento-di-calore-allinterfaccia-liquido-solido",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#trasferimento-di-calore-allinterfaccia-liquido-solido",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Trasferimento di calore all’interfaccia liquido-solido",
    "text": "Trasferimento di calore all’interfaccia liquido-solido\nConsidera un’interfaccia solido-liquido, dove viene trasferito il calore. Sia \\(U\\) il coefficiente del film su questa interfaccia e \\(A\\) sia l’area della superficie di contatto.\nIl trasferimento di calore in questo scenario può essere descritto da:\n\\[\nh = UA(\\theta_1−\\theta_2)\n\\]\nDove: - \\(\\theta_1−\\theta_2\\) è il gradiente netto lungo la pellicola\nO\n\\[\nh = \\frac{\\theta_1−\\theta_2}{R}\n\\]\nDove: - \\(R = \\frac{1}{U A}\\) è la resistenza al trasferimento di calore convettivo",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-solido",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-solido",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Accumulo di calore in un solido",
    "text": "Accumulo di calore in un solido\nL’accumulo di calore svolge un ruolo fondamentale nei sistemi termici. Consideriamo lo stesso muro descritto in precedenza. Il calore immagazzinato all’interno di questa parete può essere rappresentato come:\n\\[\nh=Mc\\frac{d\\theta}{dt}\n\\]\nDove:\n\n\\(h\\) è la portata di calore in Joule al secondo\n\\(M\\) è la massa del materiale\n\\(c\\) è il calore specifico del materiale\n\nL’equazione può essere scritta come:\n\\[\nh = C\\frac{d\\theta}{dt}\n\\]\nDove: - \\(C=Mc\\) è la capacità termica del materiale.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-solido-1",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-solido-1",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Accumulo di calore in un solido",
    "text": "Accumulo di calore in un solido\nL’accumulo di calore svolge un ruolo fondamentale nei sistemi termici. Consideriamo lo stesso muro descritto in precedenza.\n\n\n\n\n\n\nDove:\n\n\\(M\\) è la massa\n\\(\\theta\\) è la temperatura\n\nLa velocità di variazione del calore immagazzinato all’interno di questa parete può essere rappresentata come:\n\\[\nh=Mc\\frac{d\\theta}{dt}\n\\]\nDove: - \\(h\\) è in Joule al secondo (velocità di variazione del calore immagazzinato) - \\(c\\) è il calore specifico del materiale.\nL’equazione può essere scritta come:\n\\[\nh=C\\frac{d\\theta}{dt}\n\\]\nDove:\n\n\\(C=Mc\\) è la capacità termica del materiale.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-serbatoio-per-liquidi",
    "href": "IT_🇮🇹/modeling_dynamic_systems_it.html#accumulo-di-calore-in-un-serbatoio-per-liquidi",
    "title": "Introduzione alla modellazione dei sistemi dinamici",
    "section": "Accumulo di calore in un serbatoio per liquidi",
    "text": "Accumulo di calore in un serbatoio per liquidi\nConsideriamo un serbatoio contenente un liquido di volume \\(V\\) alla temperatura \\(\\theta\\).\n\n\n\n\n\n\nL’accumulo di calore all’interno del liquido può essere rappresentato come:\n\\[\nh=V\\rho c\\frac{d\\theta}{dt}\n\\]\nDove:\n\n\\(\\rho\\) è la densità del liquido (\\(Kg/m^3\\)).\n\\(c\\) è il calore specifico del liquido.\n\nL’equazione può essere scritta come:\n\\[\nh=C\\frac{d\\theta}{dt}\n\\]\nDove:\n\n\\(C=V\\rho c\\) è la capacità termica del liquido.\n\nI sistemi termici hanno equivalenti \\(R\\) e \\(C\\).\nDomanda pop-up: Perché usiamo spesso l’analogia dei circuiti elettrici quando analizziamo i sistemi termici?\nRisposta: L’analogia dei sistemi termici con i circuiti elettrici ci consente di applicare la teoria familiare dei circuiti elettrici per comprendere e analizzare il comportamento dei sistemi termici. Questo approccio semplifica scenari termici complessi e fornisce informazioni intuitive.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione alla modellazione dei sistemi dinamici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "",
    "text": "Lo scopo di questo Jupyter Notebook è farti iniziare a utilizzare Python e Jupyter Notebooks per calcoli tecnici di routine. Questa introduzione presuppone che questa sia la prima esperienza con i notebook Python o Jupyter.\nQuesto taccuino contiene informazioni disponibili qui e qui\nIl modo più semplice per utilizzare i notebook Jupyter è utilizzare un servizio basato su cloud come Google Colaboratory. Avrai bisogno di una connettività Internet continua per accedere al tuo lavoro, ma il vantaggio è che non è necessario installare o mantenere alcun software.",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#installazione-di-jupyterpython-sul-tuo-laptop",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#installazione-di-jupyterpython-sul-tuo-laptop",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "Installazione di Jupyter/Python sul tuo laptop",
    "text": "Installazione di Jupyter/Python sul tuo laptop\nPer un uso offline regolare dovresti considerare l’installazione di un ambiente Jupyter Notebook/Python direttamente sul tuo laptop. Ciò ti fornirà un accesso offline affidabile a un ambiente computazionale. Ciò consentirà anche di installare librerie di codici aggiuntive per soddisfare esigenze particolari.\nLa scelta di questa opzione richiederà l’installazione iniziale del software e aggiornamenti di routine. Per questo corso il pacchetto consigliato è Anaconda disponibile da Continuum Analytics. Il download e l’installazione del software sono ben documentati e facili da seguire. Attendi circa 10-30 minuti per l’installazione a seconda della velocità della tua connessione.\nDopo l’installazione assicurati di controllare la presenza di aggiornamenti prima di procedere ulteriormente. Con il pacchetto Anaconda ciò avviene eseguendo i seguenti due comandi in una finestra di terminale:\n&gt; aggiornamento conda conda\n&gt; conda aggiorna anaconda\nAnaconda include un’applicazione ‘Anaconda Navigator’ che semplifica l’avvio dell’ambiente notebook e gestisce il processo di aggiornamento.",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#installazione-dellambiente-del-corso",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#installazione-dellambiente-del-corso",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "Installazione dell’ambiente del corso",
    "text": "Installazione dell’ambiente del corso\nLe istruzioni per Anaconda Navigator sono leggermente diverse e non sono trattate in questo taccuino. Supponiamo che tu utilizzi un terminale da qui in poi.\nSe decidi di utilizzare Anaconda, la prima cosa da fare è creare un ambiente virtuale per il corso. Ciò garantisce di non inquinare l’ambiente Python del sistema operativo principale.\nPuoi farlo con:\nconda create --name feedback-control python=3.10\nÈ necessario eseguire il comando precedente solo una volta.\nQuindi devi solo attivare il tuo ambiente:\nconda attiva il controllo del feedback\ncrea una cartella che desideri utilizzare per questo corso. Puoi utilizzare la GUI del tuo sistema operativo o eseguire:\n“controllo feedback mkdir”.\nQuesto crea la cartella “feedback-control” nella tua directory corrente. Assicurati di essere nella cartella corretta prima di eseguire i comandi precedenti.\nPer eseguire i notebook è necessario installare i seguenti pacchetti: fastcore pandas matplotlib control sympy numpy ffmpeg-python\npuoi farlo eseguendo:\n“python -m pip installa fastcore pandas matplotlib controlla sympy numpy ffmpeg-python notebook”\nSei pronto per andare!\nCorrere:\n“quaderno di Giove”.\nper avviare la sessione del notebook.",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#avvia-una-sessione-di-jupyter-notebook",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#avvia-una-sessione-di-jupyter-notebook",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "1. Avvia una sessione di Jupyter Notebook",
    "text": "1. Avvia una sessione di Jupyter Notebook\nSe stai utilizzando un servizio basato su cloud, al momento dell’accesso verrà avviata una sessione Jupyter.\nSe hai installato una distribuzione Jupyter/Python sul tuo laptop, puoi aprire una sessione Jupyter in due modi diversi:\n\nUtilizzare l’app Anaconda Navigator oppure\nApri una finestra di terminale sul tuo laptop ed esegui la seguente istruzione sulla riga di comando:\n&gt; quaderno di Giove\n\nIn ogni caso, una volta aperta una sessione dovresti vedere una finestra del browser.\nA questo punto il browser visualizza un elenco di directory e file. Puoi navigare tra le directory nel solito modo cliccando sui nomi delle directory o sul ‘breadcrumb’ situato proprio vicino all’elenco.\nI notebook Jupyter sono semplicemente file in una directory con suffisso .ipynb.",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#calcoli-semplici-con-python",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#calcoli-semplici-con-python",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "2. Calcoli semplici con Python",
    "text": "2. Calcoli semplici con Python\nPython è un linguaggio elegante e moderno per la programmazione e la risoluzione di problemi che ha trovato un utilizzo crescente da parte di ingegneri e scienziati. Nelle prossime celle dimostreremo alcune funzionalità di base di Python.\n\na = 12\nb = 2\n\nprint(a + b)\nprint(a**b)\nprint(a/b)\n\n14\n144\n6.0\n\n\n\nb\n\n2\n\n\n\nLibrerie Python\nIl linguaggio Python ha solo operazioni molto basilari. La maggior parte delle funzioni matematiche si trovano in varie librerie matematiche. La libreria Numpy è una libreria conveniente. La cella successiva mostra come importare numpy con il prefisso np, quindi utilizzarlo per chiamare una funzione matematica comune\n\nimport numpy as np\n\n# mathematical constants\nprint(np.pi)\nprint(np.e)\n\n# trignometric functions\nangle = np.pi/4\nprint(np.sin(angle))\nprint(np.cos(angle))\nprint(np.tan(angle))\n\n3.141592653589793\n2.718281828459045\n0.7071067811865475\n0.7071067811865476\n0.9999999999999999\n\n\n\n\nLavorare con gli elenchi\nLe liste sono un modo versatile di organizzare i tuoi dati in Python.\n\nxList = [1, 2, 3, 4]\nxList\n\n[1, 2, 3, 4]\n\n\nPuoi unire un elenco a un altro o concatenarli\n\n# Concatenation\nx = [1, 2, 3, 4];\ny = [5, 6, 7, 8];\n\nx + y\n\n[1, 2, 3, 4, 5, 6, 7, 8]\n\n\n\nnp.sum(x)\n\n10\n\n\nOperazione elemento per elemento\n\nprint(np.add(x,y))\nprint(np.multiply(x,y))\nprint(np.dot(x,y))\n\n[ 6  8 10 12]\n[ 5 12 21 32]\n70\n\n\nUn ciclo for è un mezzo per scorrere gli elementi di una lista. I due punti segnano l’inizio del codice che verrà eseguito per ciascun elemento di una lista. Il rientro ha un significato in Python. In questo caso, tutto nel blocco rientrato verrà eseguito ad ogni iterazione del ciclo for. Questo esempio dimostra anche la formattazione della stringa.\n\nfor x in xList:\n    print(\"sin({0}) = {1:8.5f}\".format(x,np.sin(x)))\n\nsin(1) =  0.84147\nsin(2) =  0.90930\nsin(3) =  0.14112\nsin(4) = -0.75680\n\n\n\n\nArray NumPy\nTieni presente che mentre puoi eseguire calcoli sugli elenchi, NumPy ha un oggetto speciale per rappresentare vettori matematici o matrici chiamato array.\nQuesto è l’oggetto principale di NumPy ed è un array multidimensionale omogeneo. È una tabella di elementi (solitamente numeri), tutti dello stesso tipo, indicizzati da una tupla di numeri interi non negativi. In NumPy le dimensioni sono chiamate assi.\nGli array NumPy sono molto più potenti.\nCreazione di un array:\n\na = np.array([2, 3, 4])\n\narray trasforma sequenze di sequenze in array bidimensionali, sequenze di sequenze di sequenze in array tridimensionali e così via.\n\nb = np.array([(1.5, 2, 3), (4, 5, 6)])\nprint(b)\n\n[[1.5 2.  3. ]\n [4.  5.  6. ]]\n\n\nIl tipo dell’array può anche essere specificato esplicitamente al momento della creazione:\n\nc = np.array([[1, 2], [3, 4]], dtype=complex)\nprint(c)\n\n[[1.+0.j 2.+0.j]\n [3.+0.j 4.+0.j]]\n\n\nSpesso gli elementi di un array sono originariamente sconosciuti, ma la sua dimensione è nota. Pertanto, NumPy offre diverse funzioni per creare array con contenuto segnaposto iniziale. Questi riducono al minimo la necessità di ampliare gli array, un’operazione costosa.\n\nprint(np.zeros((3, 4)))\n\n[[0. 0. 0. 0.]\n [0. 0. 0. 0.]\n [0. 0. 0. 0.]]\n\n\n\nnp.ones((2, 3, 4), dtype=np.int16)\n\narray([[[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]],\n\n       [[1, 1, 1, 1],\n        [1, 1, 1, 1],\n        [1, 1, 1, 1]]], dtype=int16)\n\n\nGli operatori aritmetici sugli array si applicano in base agli elementi. Viene creato un nuovo array e riempito con il risultato.\n\na = np.array([20, 30, 40, 50])\nb = np.arange(4)\nprint(a)\nprint(b)\n\n[20 30 40 50]\n[0 1 2 3]\n\n\n\nc = a - b\nprint(c)\n\n[20 29 38 47]\n\n\n\nb**2\n\narray([0, 1, 4, 9])\n\n\n\n10 * np.sin(a)\n\narray([ 9.12945251, -9.88031624,  7.4511316 , -2.62374854])\n\n\n\na &lt; 35\n\narray([ True,  True, False, False])\n\n\nImportante A differenza di molti linguaggi a matrice, l’operatore prodotto “*” opera in modo elementare negli array NumPy. Il prodotto della matrice può essere eseguito utilizzando l’operatore @ (in Python &gt;=3.5) o la funzione o il metodo dot:\n\nA = np.array([[1, 1],\n              [0, 1]])\n\nB = np.array([[2, 0],\n              [3, 4]])\n\n\nA * B     # elementwise product\n\narray([[2, 0],\n       [0, 4]])\n\n\n\nA @ B     # matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\nA.dot(B)  # another matrix product\n\narray([[5, 4],\n       [3, 4]])\n\n\n\n\nLavorare con i dizionari\nI dizionari sono utili per archiviare e recuperare dati come coppie chiave-valore.\n\nmw = {'CH4': 16.04, 'H2O': 18.02, 'O2':32.00, 'CO2': 44.01}\nmw\n\n{'CH4': 16.04, 'H2O': 18.02, 'O2': 32.0, 'CO2': 44.01}\n\n\nPossiamo recuperare un valore da un dizionario:\n\nmw['CH4']\n\n16.04\n\n\nUn ciclo for è un mezzo utile per eseguire iterazioni su tutte le coppie chiave-valore di un dizionario.\n\nfor values in mw.keys():\n    print(\"Value {:&lt;s} is {}\".format(values, mw[values]))\n\nValue CH4 is 16.04\nValue H2O is 18.02\nValue O2 is 32.0\nValue CO2 is 44.01\n\n\nI dizionari possono essere ordinati per chiave o per valore\n\nfor values in sorted(mw):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n CO2       44.01\n H2O       18.02\n O2        32.0\n\n\n\nfor values in sorted(mw, key = mw.get):\n    print(\" {:&lt;8s}  {}\".format(values, mw[values]))\n\n CH4       16.04\n H2O       18.02\n O2        32.0\n CO2       44.01\n\n\n\n\nStampa con Matplotlib\nL’importazione della libreria matplotlib.pyplot fornisce funzionalità di tracciamento dei notebook IPython molto simili a quelle di Matlab. Ecco alcuni esempi che utilizzano le funzioni di\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(0,10)\ny = np.sin(x)\nz = np.cos(x)\n\nplt.plot(x,y,'b',x,z,'r')\nplt.xlabel('Radians');\nplt.ylabel('Value');\nplt.title('Plotting Demonstration')\nplt.legend(['Sin','Cos'])\nplt.grid()\n\n\n\n\n\n\n\n\n\nplt.plot(y,z)\nplt.axis('equal')\n\n(-1.09972447591003,\n 1.0979832896606587,\n -1.0992804688576738,\n 1.0999657366122702)\n\n\n\n\n\n\n\n\n\n\nplt.subplot(2,1,1)\nplt.plot(x,y)\nplt.title('Sin(x)')\n\nplt.subplot(2,1,2)\nplt.plot(x,z)\nplt.title('Cos(x)')\n\nText(0.5, 1.0, 'Cos(x)')",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#dove-saperne-di-più",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#dove-saperne-di-più",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "Dove saperne di più",
    "text": "Dove saperne di più\nPython offre una gamma completa di funzionalità del linguaggio di programmazione ed esiste una gamma apparentemente infinita di pacchetti per calcoli scientifici e ingegneristici. Ecco alcuni suggerimenti sui luoghi in cui è possibile reperire ulteriori informazioni sulla programmazione per applicazioni di ingegneria in Python.\n\nIntroduzione a Python per la scienza\nQuesta eccellente introduzione a Python è rivolta agli studenti universitari in scienze senza esperienza di programmazione. È gratuito e disponibile al seguente link.\n\nIntroduzione a Python per la scienza\n\n\n\nTutorial Introduzione a Python per la scienza e l’ingegneria\nIl seguente testo è disponibile su Amazon. Le risorse per questo libro sono disponibili su github.\n\nUn’introduzione alla programmazione scientifica con Python (quarta edizione) di Hans Petter Langtangen. Le risorse per questo libro sono disponibili su github.\n\npycse è un pacchetto di funzioni Python, esempi e documenti preparati da John Kitchin presso la Carnegie Mellon University.\n\npycse - Calcoli Python in scienza e ingegneria di John Kitchin alla Carnegie Mellon. Questo è un collegamento al repository github per pycse, fai clic sul pulsante Raw per scaricare il file .pdf.\n\nE c’è molto altro ancora! Cercalo su Google!",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#nozioni-di-base-su-python",
    "href": "IT_🇮🇹/getting_started_with_python_and_jupyter_notebook_it.html#nozioni-di-base-su-python",
    "title": "Guida introduttiva ai notebook Python e Jupyter",
    "section": "Nozioni di base su Python",
    "text": "Nozioni di base su Python\nQuesta seconda parte del quaderno descrive alcuni altri concetti Python che verranno utilizzati durante la lezione.\n\nVariabili\n\n#A variable stores a piece of data and gives it a name\nanswer = 42\n\n#answer contained an integer because we gave it an integer!\n\nis_it_thursday = True\nis_it_wednesday = False\n\n#these both are 'booleans' or true/false values\n\npi_approx = 3.1415\n\n#This will be a floating point number, or a number containing digits after the decimal point\n\nmy_name = \"Andrea\"\n#This is a string datatype, the name coming from a string of characters\n\n#Data doesn't have to be a singular unit\n\n#p.s., we can print all of these with a print command. For Example:\nprint(answer)\nprint(pi_approx)\n\n42\n3.1415\n\n\n\n\nTipi di dati più complicati\n\n#What if we want to store many integers? We need a list!\nprices = [10, 20, 30, 40, 50]\n\n#This is a way to define a list in place. We can also make an empty list and add to it.\ncolors = []\n\ncolors.append(\"Green\")\ncolors.append(\"Blue\")\ncolors.append(\"Red\")\n\nprint(colors)\n\n#We can also add unlike data to a list\nprices.append(\"Sixty\")\n\n#As an exercise, look up lists in python and find out how to add in the middle of a list!\n\nprint(prices)\n#We can access a specific element of a list too:\n\nprint(colors[0])\nprint(colors[2])\n\n#Notice here how the first element of the list is index 0, not 1! \n#Languages like MATLAB are 1 indexed, be careful!\n\n#In addition to lists, there are tuples\n#Tuples behave very similarly to lists except that you can't change them \n# after you make them\n\n#An empty Tuple isn't very useful:\nempty_tuple = ()\n\n#Nor is a tuple with just one value:\none_tuple = (\"first\",)\n\n#But tuples with many values are useful:\nrosa_parks_info = (\"Rosa\", \"Parks\", 1913, \"February\", 4)\n\n#You can access tuples just like lists\nprint(rosa_parks_info[0] + \" \" + rosa_parks_info[1])\n\n# You cannot modify existing tuples, but you can make new tuples that extend \n# the information.\n# I expect Tuples to come up less than lists. So we'll just leave it at that.\n\n['Green', 'Blue', 'Red']\n[10, 20, 30, 40, 50, 'Sixty']\nGreen\nRed\nRosa Parks\n\n\n\n\nUtilizzo delle variabili\n\nfloat1 = 5.75\nfloat2 = 2.25\n#Addition, subtraction, multiplication, division are as you expect\n\nprint(float1 + float2)\nprint(float1 - float2)\nprint(float1 * float2)\nprint(float1 / float2)\n\n#Here's an interesting one that showed up in the first homework in 2017. Modulus: \nprint(5 % 2)\n\n8.0\n3.5\n12.9375\n2.5555555555555554\n1\n\n\n\n\nImportazione in Python\n\n#Just about every standard math function on a calculator has a python equivalent pre made.\n#however, they are from the 'math' package in python. Let's add that package!\nimport math\nprint(math.log(float1))\nprint(math.exp(float2))\nprint(math.pow(2,5))\n# There is a quicker way to write exponents if you want:\nprint(2.0**5.0)\n\n#Like in MATLAB, you can expand the math to entire lists\nlist3 = [1, 2, 3, 4, 5]\nprint(2 * list3)\n\n1.749199854809259\n9.487735836358526\n32.0\n32.0\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\n\n# We can plot easily in Python like in matlab, just import the relevant package!\nimport matplotlib.pyplot as plt\n\nx_vals = [-2, -1, 0, 1, 2]\ny_vals = [-4, -2, 0, 2, 4]\nplt.plot(x_vals, y_vals)\n\n\n\n\n\n\n\n\n\n\nCicli\n\n#Repeat code until a conditional statement ends the loop\n\n#Let's try printing a list\nfib = [1, 1, 2, 3, 5, 8]\n\n#While loops are the basic type\ni = 0\nwhile(i &lt; len(fib)):\n    print(fib[i])\n    i = i + 1\n    \n#In matlab, to do the same thing you would have the conditional as: counter &lt; (length(fib) + 1)\n#This is because matlab starts indexing at 1, and python starts at 0.\n    \n#The above type of loop is so common that the 'for' loop is the way to write it faster.\n\nprint(\"Let's try that again\")\n#This is most similar to for loops in matlab\nfor i in range(0, len(fib)) :\n    print(fib[i])\n\nprint(\"One more time:\")\n#Or you can do so even neater\nfor e in fib:\n    print(e)\n\n1\n1\n2\n3\n5\n8\nLet's try that again\n1\n1\n2\n3\n5\n8\nOne more time:\n1\n1\n2\n3\n5\n8\n\n\n\n\nFunzioni\nUna funzione è un blocco di codice che viene eseguito solo quando viene chiamato.\nÈ possibile passare dati, noti come parametri, in una funzione.\nDi conseguenza, una funzione può restituire dati.\n\ndef my_function():\n    print(\"Hello from a function\")\n\nPer chiamare una funzione, utilizzare il nome della funzione seguito da parentesi:\n\nmy_function()\n\nHello from a function\n\n\nLe informazioni possono essere passate alle funzioni come argomenti.\nGli argomenti vengono specificati dopo il nome della funzione, all’interno delle parentesi. Puoi aggiungere tutti gli argomenti che desideri, separandoli semplicemente con una virgola.\nL’esempio seguente ha una funzione con un argomento (fname). Quando viene chiamata la funzione, passiamo un nome, che viene utilizzato all’interno della funzione per stampare il nome completo:\n\ndef my_function(fname):\n    print(fname + \" Refsnes\")\n\nmy_function(\"Emil\")\nmy_function(\"Tobias\")\nmy_function(\"Linus\")\n\nEmil Refsnes\nTobias Refsnes\nLinus Refsnes\n\n\nPuoi inviare qualsiasi tipo di dato come argomento a una funzione (stringa, numero, lista, dizionario ecc.) e verrà trattato come lo stesso tipo di dato all’interno della funzione.\nPer esempio. se invii una Lista come argomento, sarà ancora una Lista quando raggiunge la funzione:\n\ndef my_function(food):\n    for x in food:\n        print(x)\n\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\n\nmy_function(fruits)\n\napple\nbanana\ncherry\n\n\nPer consentire a una funzione di restituire un valore, utilizzare l’istruzione return:\n\ndef my_function(x):\n    return 5 * x\n\nprint(my_function(3))\nprint(my_function(5))\nprint(my_function(9))\n\n15\n25\n45\n\n\n\n\nClassi\nUna classe è un progetto o un prototipo definito dall’utente da cui vengono creati gli oggetti. Le classi forniscono un mezzo per raggruppare insieme dati e funzionalità. La creazione di una nuova classe crea un nuovo tipo di oggetto, consentendo la creazione di nuove istanze di quel tipo. A ogni istanza di classe possono essere associati attributi per mantenerne lo stato. Le istanze di classe possono anche avere metodi (definiti dalla loro classe) per modificare il loro stato.\nPer comprendere la necessità di creare una classe consideriamo un esempio, supponiamo che tu voglia tenere traccia del numero di cani che possono avere attributi diversi come razza, età. Se viene utilizzata una lista, il primo elemento potrebbe essere la razza del cane mentre il secondo elemento potrebbe rappresentarne l’età. Supponiamo che ci siano 100 cani diversi, quindi come faresti a sapere quale elemento dovrebbe essere quale? E se volessi aggiungere altre proprietà a questi cani? Questo manca di organizzazione ed è per questo che abbiamo bisogno di lezioni.\nLa classe crea una struttura dati definita dall’utente, che contiene i propri membri dati e funzioni membro, a cui è possibile accedere e utilizzare creando un’istanza di quella classe. Una classe è come un progetto per un oggetto.\nNon è difficile definire la classe Python. Per fare ciò, avrai bisogno della parola chiave “class”:\nclass NomeClasse:     # Dichiarazione-1     .     .     .     # Dichiarazione-N\nPer esempio\n\nclass Example:    \n    variable = 123\n\nSe esegui il codice precedente in un ambiente Python, scoprirai che puoi chiamare “Example.variable” per restituire un valore intero.\n\nExample.variable\n\n123\n\n\nQuesto è un esempio di classe per oggetti di soli dati, ma è altrettanto semplice definire una classe che restituisce un oggetto funzione aggiungendo la parola chiave “def” al codice:\n\nclass Example:\n    def b(self):\n        return \"this is an example class\"\n\n\nExample.b # we are accessing the function...this is probably not what we want to do..\n\n&lt;function __main__.Example.b(self)&gt;\n\n\nAbbiamo bisogno di alcuni concetti in più:\n\n\nAltri concetti di classe\nUn Oggetto è un’istanza di una Classe. Una classe è come un progetto mentre un’istanza è una copia della classe con valori effettivi. Non è più un’idea, è un cane vero, come un cane di razza carlino che ha sette anni. Puoi avere molti cani per creare molte istanze diverse, ma senza la classe come guida ti perderesti, non sapendo quali informazioni sono richieste. Un oggetto è composto da:\n\nStato: è rappresentato dagli attributi di un oggetto. Riflette anche le proprietà di un oggetto.\nComportamento: è rappresentato dai metodi di un oggetto. Riflette anche la risposta di un oggetto ad altri oggetti.\nIdentità: dà un nome univoco a un oggetto e consente a un oggetto di interagire con altri oggetti.\n\n\n\nDichiarazione di oggetti (chiamata anche creazione di un’istanza di una classe)\nQuando viene creato un oggetto di una classe, si dice che la classe sia istanziata. Tutte le istanze condividono gli attributi e il comportamento della classe. Ma i valori di tali attributi, ovvero lo stato, sono unici per ciascun oggetto. Una singola classe può avere un numero qualsiasi di istanze.\nEsempio:\n\n\n\n\n\n\nclass Dog:\n     \n    # A simple class\n    # attribute\n    attr1 = \"mammal\"\n    attr2 = \"dog\"\n \n    # A sample method \n    def fun(self):\n        print(\"I'm a\", self.attr1)\n        print(\"I'm a\", self.attr2)\n\n# Object instantiation\nRodger = Dog()\n \n# Accessing class attributes\n# and method through objects\nprint(Rodger.attr1)\nRodger.fun()\n\nmammal\nI'm a mammal\nI'm a dog\n\n\n\n\nSe stesso\nI metodi di classe devono avere un primo parametro aggiuntivo nella definizione del metodo. Non diamo un valore per questo parametro quando chiamiamo il metodo, lo fornisce Python.\nSe abbiamo un metodo che non accetta argomenti, allora dobbiamo avere ancora un argomento.\nQuando chiamiamo un metodo di questo oggetto come myobject.method(arg1, arg2), questo viene automaticamente convertito da Python in MyClass.method(myobject, arg1, arg2).\nNota che questo significa che all’interno della funzione method (nel nostro esempio) ora abbiamo accesso all’istanza della classe! così possiamo accedere alle sue variabili, ecc.\n\n\nMetodo __init__\nIl metodo init è simile ai costruttori in C++, costruisce l’oggetto e può essere utilizzato per inizializzare lo stato dell’oggetto.\nCome i metodi, anche un costruttore contiene una raccolta di istruzioni (ovvero istruzioni) che vengono eseguite quando viene creato l’oggetto.\nIl metodo __init__ viene eseguito non appena viene istanziato un oggetto di una classe. Il metodo è utile per eseguire qualsiasi inizializzazione che desideri eseguire con il tuo oggetto.\n\n# A Sample class with init method\nclass Person:\n\n    # init method or constructor\n    def __init__(self, name):\n        self.name = name\n\n    # Sample Method\n    def say_hi(self):\n        print('Hello, my name is', self.name)\n\np = Person('Nikhil') # as soon as we do this, the __init__ method is called.\np.say_hi()\n\nHello, my name is Nikhil\n\n\n\n\nVariabili di classe e istanza\n\nLe variabili di istanza vengono utilizzate per archiviare dati univoci per ciascuna istanza della classe. Le variabili di istanza sono variabili il cui valore è assegnato all’interno del metodo __init__ o all’interno di un metodo di classe (un metodo con l’argomento self)\nLe variabili di classe riguardano attributi e metodi condivisi da tutte le istanze della classe. Le variabili di classe sono variabili il cui valore viene assegnato direttamente nella classe.\n\n\n# Class for Dog\nclass Dog:\n   \n    # Class Variable\n    animal = 'dog'            \n   \n    # The init method or constructor\n    def __init__(self, breed, color):\n     \n        # Instance Variable    \n        self.breed = breed\n        self.color = color       \n    \n# Objects of Dog class\nRodger = Dog(\"Pug\", \"brown\")\nBuzo = Dog(\"Bulldog\", \"black\")\n \nprint('Rodger details:')  \nprint('Rodger is a', Rodger.animal)\nprint('Breed: ', Rodger.breed)\nprint('Color: ', Rodger.color)\n \nprint('\\nBuzo details:')  \nprint('Buzo is a', Buzo.animal)\nprint('Breed: ', Buzo.breed)\nprint('Color: ', Buzo.color)\n \n# Class variables can be accessed using class\n# name also\nprint(\"\\nAccessing class variable using class name\")\nprint(Dog.animal)\n\nRodger details:\nRodger is a dog\nBreed:  Pug\nColor:  brown\n\nBuzo details:\nBuzo is a dog\nBreed:  Bulldog\nColor:  black\n\nAccessing class variable using class name\ndog\n\n\n\n\nRisorse addizionali\n\nCodice Academy\nRiferimento ufficiale Python\nVero Python\n\nGoogle Colab - Un’introduzione a Google Colab, McGraw Center for Teaching and Learning - Introduzione a Google Colab - Procedura dettagliata di Colab, Università di Stanford - Tutorial di Google Colab per scienziati di dati, Datacamp.com",
    "crumbs": [
      "IT_🇮🇹",
      "Guida introduttiva ai notebook Python e Jupyter"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html",
    "href": "IT_🇮🇹/dynamic_systems_it.html",
    "title": "Modellazione nei sistemi di controllo",
    "section": "",
    "text": "Quando discutiamo di sistemi di controllo, l’importanza della modellazione non può essere sopravvalutata. I modelli sono rappresentazioni matematiche di sistemi e svolgono un ruolo fondamentale nell’analisi e nella progettazione dei sistemi di controllo. Anche se molti di voi potrebbero avere familiarità con alcuni dei modelli di studi precedenti, è sempre una buona idea rivedere e impostare le terminologie e i simboli che utilizzeremo durante il corso.\nDomanda popup: Perché la modellazione è importante nei sistemi di controllo?\nRisposta: La modellazione fornisce una rappresentazione matematica dei sistemi che ne aiuta l’analisi, la progettazione e la comprensione.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#modello-delle-variabili-di-stato",
    "href": "IT_🇮🇹/dynamic_systems_it.html#modello-delle-variabili-di-stato",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Modello delle variabili di stato",
    "text": "Modello delle variabili di stato\nNella nostra ultima discussione, abbiamo introdotto il concetto di modello delle variabili di stato. Questo modello ruota attorno all’idea che lo stato energetico di un sistema può essere definito utilizzando variabili di stato.\nConsideriamo un sistema con variabili di stato \\(x_1, x_2, ... x_n\\).\nLa relazione tra queste variabili e le equazioni differenziali del sistema può essere rappresentata come:\n\\[\n\\begin{aligned}\n\\dot{x_1} &= a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n + b_1r\\\\\n\\dot{x_2} &= a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n + b_2r\\\\\n\\vdots\\\\\n\\dot{x_n} &= a_{n1}x_1 + a_{n2}x_2 + ... + a_{nn}x_n + b_nr\\\\\n\\end{aligned}\n\\]\nDove \\(r\\) è la variabile di input e i coefficienti formano le matrici \\(A\\) e \\(B\\).\nInoltre, l’equazione di output è:\n\\[\ny = c_{1}x_1 + c_{2}x_2 + ... + c_{n}x_n + dr\n\\]\nL’output è un attributo del sistema ed è ottenuto come combinazione algebrica delle variabili di stato.\nIl modello comprende equazioni di stato \\(n\\) e un’equazione di uscita per un sistema SISO (Single Input Single Output).\nQuesto è un sistema di ordini \\(n-esimo\\). L’ordine del sistema è direttamente collegato al numero di variabili di stato.\nNella notazione matriciale, questo sistema può essere rappresentato come:\n\\[\n\\dot{x} = Ax+br\n\\]\ne l’equazione di output:\n\\[\ny=cx+dr\n\\]\nDove: - \\(A\\) è una matrice \\(n \\times n\\) - \\(b\\) è un vettore \\(n \\times 1\\) - \\(c\\) è un vettore \\(1 \\times n\\) - \\(d\\) è una costante scalare.\nNota: nella rappresentazione a variabili di stato, l’ingresso è indicato con \\(u\\) o \\(r\\).\n\nDomanda popup: Cosa rappresenta l’ordine di un sistema? Risposta: L’ordine di un sistema è direttamente collegato al numero di variabili di stato che rappresentano lo stato energetico del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#modellazione-del-circuito-rlc",
    "href": "IT_🇮🇹/dynamic_systems_it.html#modellazione-del-circuito-rlc",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Modellazione del circuito RLC",
    "text": "Modellazione del circuito RLC\nRivisitiamo il circuito che abbiamo visto prima.\nCi sono due elementi che immagazzinano energia in questo circuito, il condensatore e l’induttore. Questo sistema sarà rappresentato da un modello del secondo ordine.\n\n\n\n\n\n\nCome prima, partiamo dalle equazioni differenziali:\nL’equazione del ciclo è data da: \\[\nR i + e + \\frac{Ldi}{dt} = e_i\n\\]\nche possiamo portare sul dominio Laplace come:\n\\[\nRI(s) + E(s) + sLI(s) = E_i(s)\n\\]\nAbbiamo anche una seconda equazione:\n\\[\ni = C\\frac{de}{dt}\n\\]\ne possiamo scrivere:\n\\[\nI(s) = sCE(s)\n\\]\nAbbiamo due equazioni algebriche che possono essere facilmente manipolate per avere la funzione di trasferimento.\n\\[\nG(s) = \\frac{Y(s)}{E_i(s)}\n\\]\ndove \\(Y(s)\\) è l’output che dobbiamo definire.\nAd esempio, \\(y(t)\\) può essere considerato come la tensione ai capi dell’induttore:\n\\[\ny(t) = L\\frac{di}{dt}\n\\]\nche devo trasformare di Laplace:\n\\[\nY(s) = sLI(s)\n\\]\nAbbiamo tre equazioni di cui abbiamo bisogno per avere il modello della funzione di trasferimento.\nRiorganizzando queste equazioni otteniamo:\n\\[\nG(s) = \\frac{Y(s)}{E_i(s)} = \\frac{s^2}{s^2+\\frac{R}{L}s+\\frac{1}{LC}}\n\\]\nche è anch’esso un sistema del secondo ordine.\nSiamo ora pronti a scrivere la forma generica di una funzione di trasferimento:\n\\[\nG(s) = \\frac{b_0 s^m + b_1 s^{m-1} + \\ldots + b_{m-1} s + b_m}{a_0 s^n + a_1 s^{n-1} + \\ldots + a_{n-1} s + a_n}\n\\]\ndove \\(m \\le n\\) (condizione causale/realizzabilità).\nLe funzioni di trasferimento possono essere classificate in base all’ordine dei polinomi del numeratore e del denominatore. Per molti sistemi fisici, l’ordine del polinomio del numeratore è solitamente inferiore all’ordine del denominatore, classificato come funzioni di trasferimento strettamente proprie.\n\nSe \\(m=n\\), la funzione di trasferimento è una vera e propria funzione di trasferimento.\nSe \\(m&lt;n\\), la funzione di trasferimento è una funzione di trasferimento strettamente propria.\n\nUn sistema è realizzabile se \\(m \\le n\\).\nScriveremo anche:\n\\[\nG(s) = \\frac{N(s)}{D(s)}\n\\]\nBarra laterale - Scrivere la forma generale del denominatore\nSebbene il polinomio del denominatore abbia spesso il suo termine di ordine più alto con un coefficiente pari a 1 (rendendolo un polinomio Monic), qui non c’è perdita di generalità. Se c’è un coefficiente diverso da 1, può essere normalizzato. Questa rappresentazione è scelta per comodità, come sarà evidente in seguito.\nDomanda popup: Perché si potrebbe scegliere di rappresentare il termine di ordine più alto del polinomio del denominatore con un coefficiente pari a 1?\nRisposta: questo viene fatto per comodità, poiché semplifica alcune operazioni e rappresentazioni matematiche. Inoltre, qualsiasi funzione di trasferimento può essere riorganizzata per avere questa forma senza perdita di generalità.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#poli-e-zeri",
    "href": "IT_🇮🇹/dynamic_systems_it.html#poli-e-zeri",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Poli e zeri",
    "text": "Poli e zeri\nLe radici del polinomio del numeratore sono chiamate zeri della funzione di trasferimento. Al contrario, le radici del polinomio del denominatore sono chiamate poli della funzione di trasferimento.\nIl comportamento di un sistema, in particolare la sua evoluzione dinamica, è profondamente influenzato dai suoi poli. Questi poli, o radici del polinomio del denominatore, sono così centrali nella dinamica del sistema che sono stati chiamati le radici caratteristiche del sistema. Dettano la natura della risposta del sistema. Gli zeri, invece, influenzano principalmente l’ampiezza della risposta.\nDomanda popup: Perché i poli sono così vitali nel determinare la natura della risposta del sistema?\nRisposta: i poli sono le radici del polinomio del denominatore nella funzione di trasferimento. La posizione e la natura di questi poli determinano la stabilità, il comportamento oscillatorio, lo smorzamento e la risposta ai transitori del sistema. Pertanto, svolgono un ruolo fondamentale nell’analisi del sistema.\nIl polinomio \\(D(s)\\), le cui radici sono i poli della funzione di trasferimento, gioca un ruolo importante nella dinamica del sistema. Per questo motivo \\(D(s)\\) è detto polinomio caratteristico del sistema.\nIl polinomio \\(N(s)\\), il numeratore della funzione di trasferimento, giocherà un ruolo nel determinare l’ampiezza della risposta.\nEspressa in una forma che chiarisce direttamente i poli e gli zeri, la funzione di trasferimento, $ G(s) $, diventa:\n\\[\nG(s) = \\frac{K (s+z_1)(s+z_2)\\ldots(s+z_m)}{(s+p_1)(s+p_2)\\ldots(s+p_n)}\n\\]\nDove: - \\(z_i\\) sono gli zeri - \\(p_i\\) sono i poli - \\(K\\) è la costante di guadagno, pari a $ b_0 $.\nQuesta rappresentazione è spesso chiamata forma polo-zero.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#diagramma-a-blocchi-input-output-utilizzando-il-modello-della-funzione-di-trasferimento",
    "href": "IT_🇮🇹/dynamic_systems_it.html#diagramma-a-blocchi-input-output-utilizzando-il-modello-della-funzione-di-trasferimento",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Diagramma a blocchi input-output utilizzando il modello della funzione di trasferimento",
    "text": "Diagramma a blocchi input-output utilizzando il modello della funzione di trasferimento\nQuando ci viene fornito un modello di funzione di trasferimento, diventa importante comprendere la sua relazione in termini di input e output del sistema. Questa relazione può essere visualizzata in modo efficiente utilizzando diagrammi a blocchi, che offrono una chiara rappresentazione grafica di come interagiscono i vari componenti.\nIl diagramma a blocchi di base\nNella sua forma più semplice, lo schema a blocchi che utilizza un modello di funzione di trasferimento è costituito da:\n\nUn ingresso, \\(R(s)\\), che rappresenta il segnale di ingresso trasformata di Laplace.\nLa funzione di trasferimento, \\(G(s)\\), che mappa l’input sull’output.\nUn’uscita, \\(Y(s)\\), che rappresenta il segnale di uscita trasformata di Laplace.\n\n\n\n\n\n\n\n\nEspansione per includere i disturbi\nAnche se lo schema a blocchi di base fornisce un quadro generale, non incapsula ogni possibile influenza su un sistema. In realtà, spesso i sistemi incontrano disturbi, che possono influenzarne notevolmente le prestazioni.\nPer modellare questo in modo accurato dobbiamo esplicitamente due tipi di input che agiscono sul sistema:\n\nInput manipolato, \\(R(s)\\): questo è l’input su cui abbiamo il controllo. Di solito è l’input che manipoliamo per ottenere il comportamento del sistema desiderato.\nDisturbo, \\(W(s)\\): i disturbi sono input che non sono sotto il nostro controllo. Potrebbe trattarsi di qualsiasi cosa, da cambiamenti ambientali, carichi esterni o qualsiasi cambiamento imprevisto che possa influenzare il sistema. I disturbi sono cruciali poiché determinano la robustezza del nostro sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#disturbi-nei-sistemi",
    "href": "IT_🇮🇹/dynamic_systems_it.html#disturbi-nei-sistemi",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Disturbi nei sistemi",
    "text": "Disturbi nei sistemi\nI disturbi sono perturbazioni inevitabili in qualsiasi sistema. Per definizione, un disturbo è qualcosa che non è sotto il nostro controllo. La natura del disturbo non vi è quindi nota, almeno non completamente. Se si sapesse che si potrebbe facilmente ricavare un controller che ne riduca o ne annulli la presenza.\nI disturbi possono derivare da varie fonti e possono essere di varia natura. Ad esempio, in un sistema elettrico, i carichi elettrici possono costituire disturbi; in un sistema robotico, le variazioni del carico utile possono agire come disturbi. Nei sistemi termici, le temperature ambientali possono disturbare lo stato desiderato del sistema.\nL’obiettivo del controllore sarà quello di filtrare l’effetto dei disturbi.\nI disturbi vengono classificati in due categorie principali:\n\nSegnali irregolari con forme d’onda sconosciute, spesso di natura ad alta frequenza. Questi sono solitamente chiamati Rumore. Questi disturbi richiedono una modellazione stocastica. In questo corso non tratteremo la modellazione stocastica.\nSegnali a variazione lenta, in cui la natura generale della forma d’onda è alquanto prevedibile.\n\nEsempi: - Variazioni del carico utile in un sistema robotico - Variazioni della temperatura ambientale in un sistema di riscaldamento ambientale - Vento che agisce su un aereo - eccetera.\nQuesti disturbi possono essere modellati attraverso modelli deterministici.\nDomanda popup: In un sistema robotico, in che modo le variazioni del carico utile potrebbero agire come un disturbo?\nRisposta: un sistema robotico è spesso progettato per funzionare in modo ottimale con un carico utile specifico. Qualsiasi variazione, sia un aumento che una diminuzione rispetto al carico utile ottimale, può influenzare le prestazioni, l’equilibrio, il consumo di energia e altre dinamiche del robot, agendo quindi come un disturbo.\n\nTipi di disturbi:\n\nDisturbi esterni: derivano dall’ambiente del sistema. Gli esempi includono il vento che agisce su un edificio, i cambiamenti della temperatura ambiente che influenzano il termostato di una stanza o cambiamenti imprevisti di carico nei sistemi elettrici.\nDisturbi interni: si tratta di cambiamenti che si verificano all’interno del sistema ma non fanno parte dell’operazione desiderata. Ad esempio, fluttuazioni di tensione in un circuito elettronico, usura di macchinari o cambiamenti termici interni in un processo.",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_systems_it.html#categorie-di-modelli-di-disturbo",
    "href": "IT_🇮🇹/dynamic_systems_it.html#categorie-di-modelli-di-disturbo",
    "title": "Modellazione nei sistemi di controllo",
    "section": "Categorie di modelli di disturbo",
    "text": "Categorie di modelli di disturbo\nSebbene esista una gamma infinita di disturbi, per motivi di analisi e progettazione, possono essere ampiamente modellati come:\n\nPolso e disturbi dell’impulso:\n\n\nPolso: rappresenta un disturbo costante e di breve durata.\nImpulso: rappresenta un disturbo di breve durata e di elevata magnitudo.\nUtile per situazioni simili a shock improvvisi.\nEsempio: un improvviso picco di tensione in un circuito.\n\nAd esempio, uno shock improvviso su un sistema potrebbe essere approssimato da un impulso, mentre un disturbo di breve durata potrebbe essere approssimato da un impulso.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 4, 600)\n\n# Define a function for the rectangular pulse\ndef rectangular_pulse(t):\n    if 0 &lt;= t &lt;= 2:\n        return 1\n    else:\n        return 0\n\n# Vectorize the function to allow numpy array inputs\nvectorized_pulse = np.vectorize(rectangular_pulse)\n\n# Get the pulse values\npulse_values = vectorized_pulse(t)\n\nplt.figure(figsize=(10, 4))\nplt.plot(t, pulse_values, 'b', linewidth=2)\nplt.title(\"Rectangular Pulse\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 4])\nplt.ylim([-0.2, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n# Create impulse signal\nimpulse = np.where((t &gt; -0.01) & (t &lt; 0.01), 1, 0)\n\nplt.figure(figsize=(10, 4))\nplt.stem(t, impulse, basefmt=\" \") #, use_line_collection=True)\nplt.title(\"Impulse Signal\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([0, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nDisturbo del passo:\n\n\nMagnitudo costante, che imita un cambiamento persistente.\nRilevante per scenari come la variazione del carico elettrico durante le ore serali.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n# Create step signal\nstep = np.where(t &gt;= 0, 1, 0)\n\nplt.figure(figsize=(10, 4))\nplt.plot(t, step, lw=2)\nplt.title(\"Step Signal\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([-0.2, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nDisturbo della rampa:\n\n\nRappresenta un disturbo in continuo aumento o diminuzione nel tempo.\nCattura situazioni in cui una variabile di disturbo va alla deriva.\n\n\nDisturbo parabolico:\n\n\nUna modalità più veloce rispetto alla rampa, che rappresenta una deriva più rapida del disturbo.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n\n# Create ramp signal for t &gt;= 0\nramp = np.where(t &gt;= 0, t, 0)\n\n# Create parabolic signal for t &gt;= 0\nparabola = np.where(t &gt;= 0, t**2, 0)\n\nplt.figure(figsize=(10, 4))\n\n# Plot both signals\nplt.plot(t, ramp, lw=2, label=\"Ramp Signal\")\nplt.plot(t, parabola, lw=2, label=\"Parabolic Signal\")\n\n# Add title, labels, legend, etc.\nplt.title(\"Ramp and Parabolic Signals\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([-0.5, 4.5])\nplt.legend()\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nQueste categorie forniscono un buon spettro di disturbi per l’analisi.\nÈ importante notare che questi modelli, sebbene deterministici, sono approssimazioni dello scenario del mondo reale.\n\n\nModellazione matematica utilizzando le trasformate di Laplace\nIl dominio di Laplace offre un potente strumento per analizzare questi disturbi.\n\nRisposta all’impulso:\n\n\n\\(\\delta(t)\\) (dove \\(\\delta\\) è la funzione delta di Dirac)\nTrasformata di Laplace: \\(1\\)\n\n\nSegnale di passo:\n\n\nDenotato come \\(\\mu(t)\\) (Nota: ci discostiamo dalla solita notazione di utilizzo di \\(u\\) per evitare confusione con i segnali di controllo.)\nTrasformata di Laplace: \\(\\frac{1}{s}\\)\n\n\nSegnale di rampa:\n\n\n\\(f(t)=t\\), per \\(t\\ge0\\) o equivalentemente \\(t\\mu(t)\\)\nTrasformata di Laplace: \\(\\frac{1}{s^2}\\)\n\n\nSegnale parabolico:\n\n\n\\(f(t)=\\frac{t^2}{2}\\mu(t)\\) per \\(t\\ge0\\)\nTrasformata di Laplace: \\(\\frac{1}{s^3}\\)",
    "crumbs": [
      "IT_🇮🇹",
      "Modellazione nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/a_first_complete_application_it.html",
    "href": "IT_🇮🇹/a_first_complete_application_it.html",
    "title": "Un sistema di controllo del feedback",
    "section": "",
    "text": "Nella nostra discussione precedente, abbiamo approfondito il campo delle applicazioni di controllo di processo, con casi specifici che coinvolgono l’uso di motori CC e CC. In questo taccuino rivisiteremo questi concetti fondamentali ed espanderemo ulteriormente la nostra esplorazione con uno sguardo approfondito a un’altra applicazione fondamentale: lo scambiatore di calore.\n\n\nIl controllo del processo può essere caratterizzato dalla regolazione di alcune variabili. Queste variabili includono: - Temperatura - Pressione - Livello del liquido - Composizione\nQueste applicazioni sono spesso influenzate da fattori con costanti di tempo elevate. Pertanto, i dispositivi pneumatici, che possiedono intrinsecamente caratteristiche di risposta più lente, sono particolarmente adatti per queste applicazioni.\n\n\n\n1. Valvola di controllo - Ingresso: segnale elettrico - Uscita: segnale di pressione o alterazione della posizione dell’asta di comando - Scopo: regolare il flusso del fluido al processo\n2. Trasduttore elettropneumatico - Un dispositivo che si interfaccia tra l’attuatore (valvola di controllo) e il controller elettronico (che potrebbe essere basato su Op-Amp o su computer digitale). - Ingresso: segnale elettrico - Uscita: segnale di pressione adatto alla valvola di controllo (attuatore)\nVale la pena notare che mentre ho menzionato che la costruzione del trasduttore elettropneumatico è abbastanza identica in linea di principio a un dispositivo elettroidraulico, ci stiamo concentrando su una descrizione schematica a blocchi per semplicità.\n\n\n\nStoricamente, i controllori erano posizionati in una sala di controllo dedicata, separata dal processo. Ciò richiede la trasmissione del segnale dal processo alla sala di controllo e viceversa.\n\n\n\n\n\nFigura: diagramma che mostra la trasmissione dei segnali tra processo e sala controllo\nPrima degli anni ’50 questa comunicazione veniva facilitata prevalentemente da segnali pneumatici o di pressione dell’aria. Questo metodo può ancora essere osservato nelle industrie più vecchie con estese reti di tubi. Tuttavia, con l’evoluzione della tecnologia, le industrie più nuove hanno gradualmente adottato controller elettronici o digitali, passando dai segnali pneumatici a quelli elettrici per la comunicazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Un sistema di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/a_first_complete_application_it.html#introduzione",
    "href": "IT_🇮🇹/a_first_complete_application_it.html#introduzione",
    "title": "Un sistema di controllo del feedback",
    "section": "",
    "text": "Nella nostra discussione precedente, abbiamo approfondito il campo delle applicazioni di controllo di processo, con casi specifici che coinvolgono l’uso di motori CC e CC. In questo taccuino rivisiteremo questi concetti fondamentali ed espanderemo ulteriormente la nostra esplorazione con uno sguardo approfondito a un’altra applicazione fondamentale: lo scambiatore di calore.\n\n\nIl controllo del processo può essere caratterizzato dalla regolazione di alcune variabili. Queste variabili includono: - Temperatura - Pressione - Livello del liquido - Composizione\nQueste applicazioni sono spesso influenzate da fattori con costanti di tempo elevate. Pertanto, i dispositivi pneumatici, che possiedono intrinsecamente caratteristiche di risposta più lente, sono particolarmente adatti per queste applicazioni.\n\n\n\n1. Valvola di controllo - Ingresso: segnale elettrico - Uscita: segnale di pressione o alterazione della posizione dell’asta di comando - Scopo: regolare il flusso del fluido al processo\n2. Trasduttore elettropneumatico - Un dispositivo che si interfaccia tra l’attuatore (valvola di controllo) e il controller elettronico (che potrebbe essere basato su Op-Amp o su computer digitale). - Ingresso: segnale elettrico - Uscita: segnale di pressione adatto alla valvola di controllo (attuatore)\nVale la pena notare che mentre ho menzionato che la costruzione del trasduttore elettropneumatico è abbastanza identica in linea di principio a un dispositivo elettroidraulico, ci stiamo concentrando su una descrizione schematica a blocchi per semplicità.\n\n\n\nStoricamente, i controllori erano posizionati in una sala di controllo dedicata, separata dal processo. Ciò richiede la trasmissione del segnale dal processo alla sala di controllo e viceversa.\n\n\n\n\n\nFigura: diagramma che mostra la trasmissione dei segnali tra processo e sala controllo\nPrima degli anni ’50 questa comunicazione veniva facilitata prevalentemente da segnali pneumatici o di pressione dell’aria. Questo metodo può ancora essere osservato nelle industrie più vecchie con estese reti di tubi. Tuttavia, con l’evoluzione della tecnologia, le industrie più nuove hanno gradualmente adottato controller elettronici o digitali, passando dai segnali pneumatici a quelli elettrici per la comunicazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Un sistema di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/a_first_complete_application_it.html#evoluzione-degli-standard-di-trasmissione-nel-controllo-di-processo",
    "href": "IT_🇮🇹/a_first_complete_application_it.html#evoluzione-degli-standard-di-trasmissione-nel-controllo-di-processo",
    "title": "Un sistema di controllo del feedback",
    "section": "Evoluzione degli standard di trasmissione nel controllo di processo",
    "text": "Evoluzione degli standard di trasmissione nel controllo di processo\nNell’ambito del controllo di processo, in particolare negli ambienti industriali, la trasmissione di informazioni tra controller, sensori, attuatori e altre apparecchiature è essenziale. Nel corso degli anni, gli standard e i mezzi di questa trasmissione hanno subito una significativa trasformazione.\n\nanni ’50: lo standard industriale prevalente per la trasmissione del segnale era compreso tra 3 e 15 psi (libbre di pressione per pollice quadrato).\nDopo gli anni ’50: sono emersi una miriade di standard di trasmissione, come ±10 volt, da 1 volt a 5 volt, da 1 milliampere a 5 milliampere e così via.\nEra moderna: la standardizzazione ha gravitato in gran parte verso l’intervallo compreso tra 4 milliampere e 20 milliampere per scopi di trasmissione.\n\n\nTrasmissione pneumatica:\n1. Segnali pneumatici (pre-anni ’50): Prima degli anni ’50, la comunicazione tra la sala di controllo e il processo utilizzava spesso segnali pneumatici. Questi sono tipicamente rappresentati in termini di pressione atmosferica.\n\nStandard: lo standard industriale per questi segnali pneumatici era generalmente compreso tra 3 e 15 psi (libbre per pollice quadrato).\nInfrastruttura: I sistemi pneumatici richiedevano tubi per trasmettere questi segnali di pressione tra i dispositivi. Questi tubi sono il motivo per cui, visitando le industrie di processo più vecchie, vedresti una rete di tubi che collegano diverse apparecchiature.\nLimitazioni: I sistemi pneumatici sono generalmente lenti a rispondere a causa della natura fisica dell’aria o del gas compresso o decompresso. Ciò li rende adeguati per sistemi con costanti di tempo elevate ma non per applicazioni a risposta rapida.\n\n\n\nTrasmissione elettronica:\n2. Segnali elettronici (dagli anni ’50 in poi): Con l’evoluzione della tecnologia, i segnali elettronici ed elettrici hanno cominciato a sostituire le trasmissioni pneumatiche.\n\nPrimi standard: Prima che avvenisse una standardizzazione a livello di settore, esistevano diversi standard di segnali elettronici come ±10 volt, da 1 volt a 5 volt e una varietà di segnali di corrente come da 1 milliampere a 5 milliampere.\nStandard 4-20 mA: questo è diventato lo standard dominante per la trasmissione di corrente. È degno di nota perché un segnale da 4 mA può essere utilizzato per indicare lo stato “spento” di un sistema, mentre qualsiasi valore sopra indica uno stato “attivo”. Ciò garantisce che anche se il segnale scende al minimo (4 mA), è comunque rilevabile e distinto da una perdita completa del segnale o da una rottura del cavo.\nVantaggi: I segnali elettronici possono essere trasmessi più velocemente, con una minore perdita di energia e su distanze maggiori rispetto ai segnali pneumatici. I sistemi elettronici sono inoltre meno influenzati dai cambiamenti ambientali.\n\n\n\nTrasmissione digitale:\n3. Segnali digitali (dalla fine del XX secolo in poi): Con l’avvento dei computer e della tecnologia digitale, la segnalazione digitale cominciò ad emergere nel controllo industriale.\n\nController basati su microprocessore: questi controller sono in grado di gestire operazioni complesse, supportare una varietà di protocolli di comunicazione e interagire con la moderna infrastruttura digitale.\nProtocolli: La comunicazione digitale ha introdotto una gamma di protocolli come Modbus, Profibus e, successivamente, standard basati su Ethernet come EtherCAT e PROFINET.\nVantaggi: I segnali digitali sono immuni al rumore e possono trasportare una grande quantità di dati. Possono essere integrati con l’infrastruttura IT, consentendo meccanismi di controllo, monitoraggio e reporting più sofisticati.\n\n\n\nImplicazioni:\nL’evoluzione dalla trasmissione pneumatica a quella elettronica a quella digitale rappresenta non solo un cambiamento nella tecnologia ma anche nella complessità e nella capacità dei sistemi di controllo di processo. I sistemi moderni possono gestire più variabili, integrarsi con altri sistemi IT e offrire una precisione di controllo senza precedenti.\nSebbene la transizione abbia reso possibili sistemi più avanzati e complessi, richiede anche nuove competenze per la manutenzione, l’integrazione e la risoluzione dei problemi. È essenziale che i moderni ingegneri di controllo comprendano non solo gli aspetti tradizionali dei loro processi, ma anche la comunicazione digitale e gli aspetti IT.\n🤔 Domanda pop-up: Perché è stato adottato lo standard 4-20 mA rispetto ad altri standard di segnali elettronici nel settore del controllo di processo?\nRisposta: Lo standard 4-20 mA offre vantaggi distinti: 1. Un segnale da 4 mA può indicare uno stato “spento”, rendendolo distinguibile da una completa perdita di segnale o da una rottura del cavo. 2. Segnali di corrente come questi sono meno influenzati dalla resistenza dei cavi lunghi, garantendo l’integrità del segnale su lunghe distanze. 3. Sono anche meno suscettibili al rumore elettrico rispetto ai segnali di tensione.\n\n\nDiagramma a blocchi della trasmissione del segnale\nImmagina un tipico processo in cui viene misurata una quantità (temperatura, livello del liquido o composizione). Questo segnale, una volta elaborato da un sensore, verrebbe convertito in un segnale elettrico. La maggior parte di queste uscite dei sensori sono segnali di tensione. Ma per la trasmissione, questi segnali di tensione vengono spesso convertiti in segnali di corrente, principalmente perché i segnali di corrente sono meno suscettibili al rumore.\n\n\n\n\n\n\nSarà necessaria la conversione da tensione a corrente nel punto del sensore,\nSarà necessaria la conversione da corrente a tensione sul controller.\n\nCircuito di condizionamento del segnale (o trasmettitore)\nIl condizionamento del segnale è un aspetto fondamentale dell’elettronica e della strumentazione. Si riferisce al processo di modifica di un segnale in modo tale da soddisfare i requisiti della fase o del dispositivo successivo in un sistema. Questo processo può comportare amplificazione, filtraggio, conversione, adattamento della gamma, isolamento e qualsiasi altra funzione che ottimizzi il segnale per un’ulteriore elaborazione.\n\nQuesta unità è composta da componenti di condizionamento del segnale e di guida della linea.\nIl suo ruolo è convertire il segnale elettrico del sensore in un formato compatibile con il controller, adattando al tempo stesso la distanza tra il processo e il controller.\n\n\nNota sulla terminologia\nNel linguaggio del controllo di processo, l’interfaccia tra il processo e il controllore è spesso definita “trasmettitore”. Questa parola è usata in modo intercambiabile con “sensore” in tutta la nostra discussione, ma ricorda che in un contesto più ampio, il trasmettitore può includere anche il componente sensore.\n\n\n\nComponenti e tipi di condizionamento del segnale:\n\nAmplificatori: questi sono i condizionatori di segnale più comuni. Aumentano l’ampiezza di un segnale. Ad esempio, i sensori che producono una tensione di uscita molto bassa (come le termocoppie) spesso necessitano di amplificazione prima che i loro segnali possano essere letti dalla maggior parte dei convertitori analogico-digitali (ADC).\n\nAmplificatori operazionali (Amplificatori operazionali): Ampiamente utilizzati nei circuiti di condizionamento del segnale grazie alla loro versatilità. Possono essere configurati per una gamma di funzioni come circuiti invertenti, non invertenti, differenziali, integratori e differenziatori.\n\nFiltri: i filtri vengono utilizzati per rimuovere le frequenze indesiderate da un segnale.\n\nFiltri passa-basso: Consentono il passaggio dei segnali con una frequenza inferiore a una determinata frequenza di taglio e attenuano le frequenze superiori alla frequenza di taglio.\nFiltri passa-alto: Fanno il contrario, attenuando le frequenze al di sotto della frequenza di taglio e consentendo a quelle al di sopra di passare.\nFiltri passa banda: Consentono il passaggio solo ai segnali entro un determinato intervallo di frequenza.\n\nConvertitori analogico-digitali (ADC): Convertono i segnali analogici in un formato digitale che può essere elaborato da apparecchiature digitali come i computer.\nConvertitori tensione-corrente e corrente-tensione: questi convertitori sono utili per trasmettere segnali su lunghe distanze. Ad esempio, lo standard del loop di corrente da 4-20 mA negli ambienti industriali.\nLinearizzatori: alcuni sensori hanno uscite non lineari, ovvero la relazione tra la quantità fisica misurata e l’uscita del sensore non è una linea retta. I linearizzatori vengono utilizzati per correggere queste uscite.\nIsolatori: sono fondamentali nelle applicazioni in cui è essenziale interrompere il percorso elettrico tra due circuiti, pur continuando a trasferire il segnale. Possono proteggere le apparecchiature sensibili dai picchi di tensione e ridurre i circuiti di terra.\nMultiplexer (MUX): quando è necessario inviare più segnali attraverso un singolo ADC, è possibile utilizzare un multiplexer. Seleziona un segnale alla volta da passare all’ADC.\n\n\n\nImportanza del condizionamento del segnale:\n\nPrecisione: Il condizionamento migliora la precisione dei dati finali garantendo che il segnale sia preparato in modo ottimale per l’elaborazione.\nProtezione: isolando i segnali, le apparecchiature sensibili possono essere protette da potenziali danni dovuti a problemi elettrici come sovratensioni o loop di terra.\nCompatibilità: garantisce che i segnali provenienti da vari sensori e sorgenti possano essere resi compatibili con un’ampia gamma di apparecchiature di elaborazione e visualizzazione.\nPrestazioni migliorate: i filtri possono aiutare a ridurre il rumore, gli amplificatori possono amplificare i segnali deboli e gli ADC possono facilitare l’elaborazione digitale.\nAffidabilità: un condizionamento adeguato può rendere un sistema più robusto e affidabile riducendo al minimo l’impatto di rumore elettrico, interferenze o altri problemi che potrebbero altrimenti distorcere o degradare il segnale.\n\n\n\nApplicazioni:\nI circuiti di condizionamento del segnale sono onnipresenti nei sistemi elettronici. Alcune applicazioni comuni includono:\n\nAutomazione industriale: garantire che i segnali dei sensori siano elaborati correttamente per i sistemi di controllo.\nElettronica medica: miglioramento dei segnali provenienti dai sensori biomedici.\nSistemi di comunicazione: preparazione dei segnali per la trasmissione o la ricezione.\nElettronica di consumo: ad esempio, nell’elaborazione audio nelle radio o nei lettori musicali.\n\nIn sintesi, il condizionamento del segnale consiste nel preparare un segnale affinché sia ​​perfetto per la fase successiva di elaborazione, garantendo che i dati finali siano accurati, affidabili e significativi.",
    "crumbs": [
      "IT_🇮🇹",
      "Un sistema di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/a_first_complete_application_it.html#unapplicazione-completa-sistema-di-controllo-della-temperatura",
    "href": "IT_🇮🇹/a_first_complete_application_it.html#unapplicazione-completa-sistema-di-controllo-della-temperatura",
    "title": "Un sistema di controllo del feedback",
    "section": "Un’applicazione completa: sistema di controllo della temperatura",
    "text": "Un’applicazione completa: sistema di controllo della temperatura\nCon le conoscenze di base, esploriamo un’applicazione reale che coinvolge uno scambiatore di calore.\nAnche se in questo contesto discuteremo solo della variabile temperatura, in un processo industriale reale potrebbe essere necessario controllare più variabili contemporaneamente.\n\nControllo a variabile singola: l’esempio del circuito di controllo della temperatura illustra un sistema di controllo a variabile singola. In questo scenario, il sistema si concentra sul solo controllo della temperatura, presupponendo che le portate siano mantenute da un altro circuito di controllo e che i disturbi siano trascurabili.\nControllo multivariabile: in un ambiente di controllo di processo reale, più variabili (come temperatura, flusso, composizione, valore pH, ecc.) potrebbero richiedere attenzione simultanea. La complessità nasce perché un cambiamento in una variabile potrebbe influenzarne altre. Ad esempio, la portata potrebbe influenzare la temperatura, oppure un cambiamento nella composizione potrebbe influire sul pH.\n\nNel resto della discussione, il presupposto è che potrebbe esserci più di un ciclo di controllo ma che ciascuna variabile possa essere controllata in modo indipendente.\n\nUno sguardo più da vicino allo scambiatore di calore\nCome applicazione, consideriamo un circuito di controllo della temperatura che utilizza uno scambiatore di calore.\nLo scambiatore di calore, come suggerisce il nome, è un dispositivo che permette lo scambio di calore tra due o più fluidi senza consentirne la miscelazione. Il mantenimento di una temperatura ottimale è fondamentale per garantire sia l’efficienza che la sicurezza dei processi in settori che vanno dal petrolchimico alla trasformazione alimentare.\nL’obiettivo di questo segmento è acquisire una comprensione approfondita del circuito di controllo della temperatura di uno scambiatore di calore, dalla configurazione fisica alla modellazione matematica. Inizieremo comprendendo i componenti hardware coinvolti, per poi ricavare una rappresentazione matematica del sistema. Inoltre, attraverso metodi sperimentali, capiremo come accertare i parametri critici che governano il comportamento del sistema.\nSchema dello scambiatore di calore: Lo scambiatore di calore è rappresentato come un insieme di tubi cavi. Attraverso questi tubi circola il fluido di processo (di cui si vuole controllare la temperatura), entrando in un punto specifico ed uscendo da un altro.\n\n\n\n\n\nAd alto livello, uno scambiatore di calore è costituito da tubi cavi attraverso i quali passa un fluido di processo. Questo fluido entra ad una certa temperatura (temperatura di ingresso) ed esce ad un’altra (temperatura di uscita). Il nostro obiettivo principale è controllare la temperatura di questo fluido all’uscita dai tubi.\nTuttavia, ricorda che ci stiamo concentrando esclusivamente sul circuito di controllo della temperatura. In un contesto reale, più variabili potrebbero richiedere il controllo e sarebbero presenti vari cicli di controllo. Ogni circuito può controllare variabili come temperatura, portata, composizione, pH, ecc. Per semplicità e chiarezza, stiamo isolando un circuito di controllo, il circuito di controllo della temperatura, presupponendo un’interferenza minima da parte degli altri circuiti di controllo.\n\nProcedura dettagliata sullo scambiatore di calore\nLo scambiatore di calore in esame è costituito da tubi cavi. Attraverso questi tubi circola il fluido di processo, di cui si vuole controllare la temperatura.\n\n\n\n\n\n\nIl fluido entra con una temperatura di ingresso (indicata come \\(\\theta_i\\), una perturbazione rispetto al valore di stato stazionario desiderato) ed esce ad un’altra temperatura (indicata come \\(\\theta\\)).\nL’obiettivo principale è garantire che il fluido esca ad una specifica temperatura comandata, indipendentemente da eventuali disturbi.\nDal vapore viene tolto calore e fuoriesce condensa. Il vapore, se utilizzato come mezzo di riscaldamento, rilascia calore condensandosi (cambiando la sua fase da vapore a liquido). Quando il vapore cede il calore latente di vaporizzazione, si trasforma nuovamente in acqua, chiamata “condensa”. Il processo di condensazione del vapore rilascia una notevole quantità di calore, che viene utilizzata per scopi di riscaldamento in varie applicazioni.\n\nIndichiamo: - $ $: Perturbazione dal valore di temperatura desiderato in \\(^oC\\). - $ i $: Perturbazione della temperatura in ingresso rispetto al valore di regime - $ q_m $: Perturbazione della portata rispetto al valore a regime. La perturbazione della portata può influenzare la temperatura. - $ q{ms} $: è la perturbazione nel flusso di vapore. Questa è la nostra variabile manipolata che controlleremo utilizzando un controller che agisce sulla valvola per ridurre \\(\\theta\\) a zero.\nNon stiamo considerando come controllare la portata, ma dobbiamo considerarlo perché la perturbazione della portata sarà un disturbo per il nostro sistema.\nSi noti che stiamo discutendo di perturbazioni rispetto allo stato stazionario. Ciò significa che l’obiettivo del controllo sarà quello di ridurre a zero $ $.\n🤔 Domanda pop-up: In quale epoca lo standard industriale per la trasmissione del segnale si spostò da 4 milliampere a 20 milliampere?\n\nAnni ’50\nAnni ’60\nEpoca moderna\nPrima degli anni ’50\n\nRisposta: c) Epoca moderna\n\n\n\n\n\n\nL’attuatore è una valvola di controllo ad azionamento pneumatico. Poiché l’uscita del controller (ad esempio, un computer digitale o un dispositivo elettrico analogico) è necessaria un’interfaccia tra l’uscita del controller e l’attuatore. Ecco perché abbiamo bisogno del trasduttore elettropneumatico.\n\n\n\n\nBarra laterale - Trasduttori elettropneumatici\nUn trasduttore elettropneumatico, spesso indicato come “convertitore I/P” (corrente-pressione) o “convertitore E/P” (elettrico-pneumatico), è un dispositivo che converte un segnale elettrico, solitamente una corrente o tensione, in una corrispondente uscita pneumatica, tipicamente sotto forma di pressione dell’aria.\n\n\n\n\n\nPiù specificamente:\n\nSegnale di ingresso: il segnale di ingresso più comune per i convertitori I/P è il circuito di corrente standard da 4-20 mA, sebbene alcuni modelli accettino segnali di tensione come 0-5 V o 0-10 V.\nSegnale di uscita: l’uscita è in genere un segnale pneumatico compreso tra 3 e 15 psi (libbre per pollice quadrato), sebbene siano possibili anche altri intervalli come 3-27 psi o 6-30 psi, a seconda del dispositivo e applicazione.\nPrincipio di funzionamento: Internamente, il trasduttore elettropneumatico utilizza un solenoide, un meccanismo a cerniera/ugello o altri componenti elettronici per rilevare il segnale elettrico in ingresso. Questo segnale viene quindi utilizzato per controllare un meccanismo di valvola pneumatica che modula la pressione dell’aria in uscita.\nApplicazioni: i trasduttori elettropneumatici sono ampiamente utilizzati nei sistemi di controllo industriale. Consentono ai sistemi di controllo elettronico di interfacciarsi con attuatori pneumatici, valvole e altri dispositivi. Ad esempio, un PLC (controllore logico programmabile) potrebbe utilizzare un convertitore I/P per controllare una valvola pneumatica in un impianto di processo. Inviando diversi valori di corrente al convertitore I/P, il PLC può aprire, chiudere o aprire parzialmente la valvola, a seconda delle condizioni di processo richieste.\nVantaggi:\n\nSicurezza: i sistemi pneumatici sono intrinsecamente più sicuri in determinati ambienti esplosivi o infiammabili. Utilizzando un convertitore I/P, i sistemi di controllo elettronici possono interfacciarsi in modo sicuro con i dispositivi pneumatici in tali aree.\nIntegrazione: Consentono una facile integrazione di sistemi elettronici e pneumatici, consentendo strategie di controllo più versatili e complete.\n\nConsiderazioni: È essenziale garantire che i convertitori I/P siano calibrati correttamente, esenti da vibrazioni esterne e dotati di aria pulita. L’aria contaminata o l’umidità possono comprometterne le prestazioni o provocarne il malfunzionamento.\n\nIn breve, i trasduttori elettropneumatici svolgono un ruolo cruciale nel colmare il divario tra i sistemi di controllo elettronico e l’attuazione pneumatica, consentendo un controllo preciso in una varietà di applicazioni industriali.\n— FINE DELLA BARRA LATERALE\n\n\nDerivazione di un modello matematico: costruzione di una descrizione schematica a blocchi utilizzando metodi sperimentali\nSiamo pronti a formulare il modello matematico completo per il nostro sistema di controllo della temperatura.\nProprio come in precedenza ci si basava sui principi fisici per la derivazione delle equazioni, anche i metodi sperimentali possono essere impiegati per l’identificazione dei modelli. Conducendo esperimenti, possiamo discernere i modelli della funzione di trasferimento di componenti distinti, consentendo così la creazione del modello matematico per l’intero sistema.\n\nIdentificazione dei parametri di processo:\nPartiamo dall’Impianto, dal Processo stesso.\nSupponiamo che il processo possa essere approssimato da un sistema del primo ordine:\n\\[\nG_p(s) = \\frac{K_p}{\\tau_p s +1}\n\\]\n\nSupponiamo che i parametri $ K_p $ e $ _p $ del nostro modello possano essere determinati sperimentalmente.\nSupponiamo che la portata del vapore $ q_{ms} $ sia $ A $ chilogrammi al secondo. Questo sarà considerato come il nostro input:\n\n\\[ q_{ms} = A\\;\\; kg/sec\\]\nRappresentazione della curva di output: Quando viene fornito questo input specifico, l’output ottenuto sperimentalmente può essere tracciato come $ $ rispetto a $ $. La curva risultante potrebbe assomigliare a quella di un tipico processo del primo ordine.\n\n\n\n\n\nDallo stato stazionario di questa curva, possiamo denotare $ _{ss} $ come il valore dello stato stazionario ottenuto sperimentalmente. Possiamo stabilire:\n\\[ K_p = \\frac{\\theta_{ss}}{A} \\]\nIn secondo luogo, considerando la funzione di trasferimento, il nostro obiettivo è determinare la costante di tempo. Analizzando il transitorio della curva di reazione (o curva di risposta) di questo processo, possiamo modellarlo come:\n\\[ \\frac{\\theta(s)}{Q_{ms}(s)} = \\frac{K_p}{\\tau_p s + 1} \\]\nPer un input di passo unitario o per un input di grandezza $ A $:\n\\[ \\theta(s) = \\frac{K_p \\cdot A}{s(\\tau_p s + 1)} \\]\nFacendo la trasformata inversa di Laplace, otteniamo:\n\\[ \\theta(t) = K_p \\cdot A (1 - e^{-\\frac{t}{\\tau_p}}) \\]\nDa cui segue (dato che $ K_p A = _{ss}):\n\\[ \\theta(t) = \\theta_{ss} (1 - e^{-\\frac{t}{\\tau_p}}) \\]\nConsiderando la pendenza a $ t = 0 $, otteniamo:\n\\[ \\frac{d\\theta}{dt} \\Big|_{t=0} = \\frac{\\theta_{ss}}{\\tau_p} \\Big|_{t=0}\\]\nQuesta pendenza ci aiuta a comprendere ulteriormente la curva di reazione del processo.\n\n\n\n\n\nQuesta rappresentazione grafica facilita la determinazione sperimentale di $ _p $. Di conseguenza, possiamo rappresentare la nostra funzione di trasferimento del processo $ G_p(s) $ come:\n\\[ G_p(s) = \\frac{K_p}{\\tau_p s + 1} \\]\ne con un semplice esperimento possiamo identificare \\(K_p\\) e \\(\\tau_p\\).\nUn esempio industriale: Consideriamo un esperimento con uno scambiatore di calore. I parametri identificati erano $ K_p = 50 $ e $ _p = 30 $, dandoci il modello:\n\\[ G_p(s) = \\frac{50}{30s + 1} \\]\nRicordate, questo modello è valido quando la temperatura $ $ è l’output e la portata del vapore è l’input. È essenziale riconoscere che altri input, come i disturbi nel processo, possono influenzare il processo. Per il nostro scambiatore di calore, i disturbi sono \\(q_m\\) (disturbo nella portata del processo) e \\(\\theta_i\\) (disturbo nella temperatura del fluido di processo in ingresso).\nAnche le altre funzioni di trasferimento possono essere determinate sperimentalmente. Ad esempio:\n\\[ \\frac{\\theta(s)}{Q_m(s)}: \\frac{1}{30s + 1} \\]\nCiò significa che il guadagno è di $ 1^oC$ per $ Kg/sec$ di input. La costante di tempo è \\(30\\)sec. Questa in effetti è la costante di tempo del processo quindi è ciò che abbiamo identificato prima.\n\\[ \\frac{\\theta(s)}{\\theta_i(s)}: \\frac{3}{30s + 1} \\]\nCiò rappresenta quando l’input è una variazione di temperatura. Il guadagno è, in questo caso, $ 3^oC$ di output per ogni grado centigrado in input. La costante di tempo è \\(30\\)sec. Questa in effetti è la costante di tempo del processo quindi è ciò che abbiamo identificato prima.\n\n\n\n\n\nIl trasduttore elettropneumatico e la valvola di controllo: Successivamente, esploreremo il trasduttore elettropneumatico combinato con la valvola di controllo. Il trasduttore prende la corrente in ingresso e produce pressione in uscita. Con un intervallo compreso tra 4 e 20 milliampere per la corrente e tra 3 e 15 psi per la pressione, il guadagno del trasduttore è $ $ psi per milliampere (assumendo che il dispositivo sia lineare nell’intervallo in questione):\n\\[\nK_T = \\frac{15-3}{20-4} = \\frac{12}{16}\\;\\; \\text{psi/mA}\n\\]\nConsiderando la valvola di controllo, una pressione compresa tra 3 e 15 psi porta ad un flusso in uscita. Per il nostro sistema, il flusso massimo è di 1,6 chilogrammi al secondo (lo abbiamo determinato, ad esempio, attraverso esperimenti), il che porta ad un guadagno della valvola di controllo di $ $ chilogrammi al secondo per psi.\n\\[\nK_V = \\frac{1.6-0}{15-3} = \\frac{1.6}{12}\\;\\; \\text{kg/sec per psi}\n\\]\nQuando entrambe le unità vengono prese insieme, otteniamo il guadagno combinato $ K_v $ pari a 0,1 chilogrammi al secondo per milliampere.\n\\[K_v = \\frac{12}{16}\\cdot\\frac{1.6}{12} = 0.1\\;\\; \\text{kg/sec per mA}\\]\nSe la costante di tempo del trasduttore elettropneumatico e della valvola di controllo può essere trascurata, questo potrebbe essere il mio intero modello.\nA seconda della dinamica del trasduttore elettropneumatico e della valvola di controllo e della loro relazione con il processo, possiamo rappresentare la loro funzione di trasferimento come:\n\\[ G_v(s) = \\frac{0,1}{3s + 1} \\]\nSi noti che in questo caso, gli esperimenti con il trasduttore elettropneumatico e la valvola di controllo hanno fornito una costante di tempo di 3 sec.\nSe ritieni che 3 secondi siano trascurabili rispetto a 30 secondi, puoi considerare il modello più semplice di solo guadagno.\n\n\n\nIl modello del sensore\nQuando pensiamo al sensore, dovremmo considerare il suo ingresso e uscita. Nel nostro sistema: - Ingresso: Temperatura (\\(^oC\\)) - Uscita: Milliampere (mA)\nQuindi, per il sistema di controllo della temperatura che stiamo progettando, dobbiamo definire l’intervallo di temperatura. Per un’applicazione tipica, questo intervallo è compreso tra 50°C e 150°C. Di conseguenza, l’uscita del sensore varierà da 4 a 20 mA.\n🤔 Domanda pop-up: Cosa pensi che accadrà se la temperatura scenderà sotto i 50°C o sopra i 150°C? Risposta: il sensore potrebbe non fornire letture accurate oppure potrebbe funzionare al di fuori dell’intervallo specificato, causando potenzialmente imprecisioni o addirittura danni.\nCon le informazioni di cui sopra, possiamo determinare il guadagno del sensore osservando la sua linearità nell’intervallo definito. Dato:\n\\[ \\text{Intervallo di uscita} = 20 \\text{mA} - 4 \\text{mA} = 16 \\text{mA} \\]\n\\[ \\text{Intervallo di input} = 150°C - 50°C = 100°C \\]\nIl guadagno del sensore (K) è dato da:\n\\[ K = \\frac{\\text{Intervallo di output}}{\\text{Intervallo di input}} = \\frac{16}{100} = 0,16 \\]\nPertanto, l’unità per il guadagno del sensore è milliampere per grado centigrado (mA/°C).\nTuttavia, considerare semplicemente il guadagno del sensore potrebbe non darci il quadro completo. Spesso, nelle applicazioni reali, la dinamica del sensore non può essere ignorata. Soprattutto in scenari in cui il sensore ha una costante di tempo apprezzabile. Nel nostro caso, ad esempio, il sensore ha una costante di tempo di 10 secondi. Data la costante di tempo del processo di 30 secondi, trascurare la dinamica del sensore sarebbe una scarsa approssimazione.\nÈ essenziale ricordare che considerare solo un modello di ordine zero (solo guadagno) non sarà sufficiente in sistemi con costanti di tempo significative.\nEseguendo un esperimento simile per il nostro sensore, rappresentiamo la sua funzione di trasferimento, H(s), come:\n\\[ H(s) = \\frac{0,16}{10s + 1} \\]\nQuesto rappresenta un fattore di primo ordine per il nostro sensore.\n\n\nModello di sistema completo\nCon le informazioni di cui sopra, possiamo costruire uno schema a blocchi completo per il nostro sistema di controllo della temperatura.\n(Inserisci il diagramma qui)\nNel diagramma Gp(s) è la funzione di trasferimento del processo, data da:\n\\[ Gp(i) = \\frac{50}{30s + 1} \\]\nLe funzioni di trasferimento dei disturbi, che considerano fattori come cambiamenti nella temperatura in ingresso (theta i) e cambiamenti nella portata del fluido in afflusso (q m), sono:\n\\[ \\frac{1}{30s + 1} \\]\n\\[ \\frac{3}{30s + 1} \\]\nOra pensiamo alla valvola di controllo. La sua funzione di trasferimento, come determinato in precedenza, è:\n\\[ \\frac{0.1}{3s + 1} \\]\nIn questo sistema, il nostro obiettivo è far sì che la temperatura in uscita (theta) segua un comando particolare. La sfida sta nel convertire il segnale di comando, espresso in temperatura, in una corrente corrispondente in milliampere per il rilevamento degli errori.\nÈ fondamentale comprendere che per un rilevamento efficace degli errori, il segnale di comando e l’uscita del sensore devono essere nella stessa unità (mA).\nDato che il guadagno in stato stazionario del sensore è 0,16 mA/°C, ha senso scegliere un fattore di scala di 0,16 per il nostro sistema. Ciò garantisce che allo stato stazionario, il valore del segnale comandato (in mA) corrisponda all’uscita del sensore, facilitando un efficace rilevamento degli errori.\n\n\n\n\n\n\n\nWrapping Up\nI valori di cui abbiamo parlato si riferiscono ad un tipico processo industriale. Tuttavia, con la metodologia che abbiamo delineato, è possibile applicarla a qualsiasi situazione. Identificando sperimentalmente varie funzioni di trasferimento, possiamo costruire un modello completo del sistema.\nPer perfezionare ulteriormente il nostro sistema, possiamo introdurre un controllore, \\(D(s)\\), nel ciclo. La progettazione di questo controller è fondamentale per garantire che l’uscita \\(\\theta\\) (temperatura del fluido di processo in uscita) segua il comando (\\(\\theta_r\\)), nonostante eventuali disturbi che agiscono sul processo, \\(\\theta_i\\) (variazione della temperatura di ingresso ) e \\(q_m\\) (variazione della portata del fluido in entrata).\n\n\n\n\n\n🤔 Domanda pop-up: Perché è fondamentale garantire che l’uscita del sensore e il segnale di comando siano nella stessa unità per il rilevamento degli errori? Risposta: Se si trovassero in unità diverse, il confronto non avrebbe senso. È come paragonare le mele alle arance. Averli nella stessa unità garantisce che qualsiasi differenza (errore) tra loro rappresenti accuratamente la deviazione del sistema dal comportamento desiderato.\n\n\nBarra laterale - Fattore di scala nei sistemi di feedback\nIn un sistema di controllo feedback, soprattutto quando si lavora con sensori e attuatori, potrebbero esserci discrepanze tra le unità o le grandezze del segnale di riferimento e il segnale di feedback. Per rendere comparabili i due segnali, a volte è necessario introdurre un fattore di scala.\n\n\nPerché 0.16 come fattore di scala?\nConsiderato il contesto:\n\nComportamento del sensore: il sensore del nostro sistema traduce la temperatura in un segnale di corrente, producendo un’uscita in milliampere (mA). Il guadagno a stato stazionario del sensore, che indica quanto cambia l’uscita per una determinata variazione dell’ingresso, è 0,16 mA/°C. In termini più semplici, per ogni grado Celsius di aumento della temperatura, l’uscita del sensore aumenta di 0,16 mA.\nObiettivo del controllo del feedback: Nel nostro sistema di controllo del feedback, l’obiettivo è fare in modo che l’uscita del processo (temperatura) segua un segnale di riferimento o di comando. Il rilevatore di errore confronta quindi l’uscita del sensore (un valore mA) con questo segnale di riferimento.\nCoerenza dell’unità: il confronto nel rilevatore di errori richiede che i due segnali siano nella stessa unità. Poiché l’uscita del sensore è in mA, il segnale di riferimento (che è una temperatura desiderata) deve essere convertito nel suo equivalente in mA.\nCorrispondenza al comportamento del sensore: per garantire che il segnale di riferimento in mA rappresenti correttamente la temperatura desiderata, è logico utilizzare il guadagno a stato stazionario del sensore come fattore di scala. Quando desideriamo una temperatura particolare come riferimento, moltiplicandola per 0,16 (guadagno del sensore) otteniamo l’esatto valore di corrente che il sensore produrrebbe a quella temperatura.\n\n\n\nUn esempio illustrativo\nSupponiamo di impostare una temperatura di riferimento (\\(\\theta_r\\)) di 100°C. Per convertirlo in una corrente di riferimento per il confronto:\n\\[ \\text{Corrente di riferimento} = \\theta_r \\times \\text{Fattore di scala} \\]\n\\[ \\text{Corrente di riferimento} = 100°C \\times 0,16 \\text{mA/°C} = 16 \\text{mA} \\]\nPertanto, quando il processo raggiunge i 100°C, il sensore idealmente emetterebbe 16 mA. Il rilevatore di errore vedrebbe quindi un errore pari a zero tra la corrente di riferimento (16 mA) e l’uscita del sensore (16 mA), indicando che il sistema sta funzionando nella condizione desiderata.\nIn conclusione, utilizzando il guadagno stazionario del sensore come fattore di scala si garantisce che il rilevatore di errori confronti mele con mele. Ciò è vitale per il corretto funzionamento del sistema di feedback, garantendo che le azioni di controllo siano basate su confronti significativi.\n— FINE DELLA BARRA LATERALE\nNei prossimi quaderni esploreremo le complessità della progettazione del controller e capiremo come adattarlo alle nostre esigenze specifiche. Ciò garantirà che il nostro sistema di controllo della temperatura funzioni in modo ottimale in varie condizioni.",
    "crumbs": [
      "IT_🇮🇹",
      "Un sistema di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html",
    "href": "IT_🇮🇹/bode_plots_it.html",
    "title": "Analisi del diagramma di Bode",
    "section": "",
    "text": "Nel quadro del criterio di stabilità di Nyquist, un aspetto significativo che richiede attenzione è l’applicazione dei grafici di Bode per analizzare il margine di guadagno, il margine di fase e la stabilità complessiva del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#il-diagramma-di-nyquist-e-la-sua-intensità-computazionale",
    "href": "IT_🇮🇹/bode_plots_it.html#il-diagramma-di-nyquist-e-la-sua-intensità-computazionale",
    "title": "Analisi del diagramma di Bode",
    "section": "Il diagramma di Nyquist e la sua intensità computazionale",
    "text": "Il diagramma di Nyquist e la sua intensità computazionale\nIl diagramma di Nyquist, uno strumento essenziale nella teoria del controllo, visualizza graficamente la risposta in frequenza di un sistema\n\\[ G(j\\omega)H(j\\omega) \\]\nche comprende sia l’ampiezza che l’angolo di fase della funzione di trasferimento su un intervallo di frequenze.\nLa costruzione di un diagramma di Nyquist richiede il calcolo di questi componenti per un continuo di frequenze, tipicamente da 0 a infinito. Questo processo, come puoi immaginare, comporta ampi sforzi computazionali.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#metodo-della-semplificazione-di-bode",
    "href": "IT_🇮🇹/bode_plots_it.html#metodo-della-semplificazione-di-bode",
    "title": "Analisi del diagramma di Bode",
    "section": "Metodo della Semplificazione di Bode",
    "text": "Metodo della Semplificazione di Bode\nPer alleviare il carico computazionale associato ai grafici di Nyquist, Hendrik W. Bode ha introdotto un metodo più efficiente. L’approccio di Bode semplifica la visualizzazione dei dati di risposta in frequenza trasformando i grafici complessi in semplici linee asintotiche. Questa trasformazione si ottiene attraverso il ridimensionamento logaritmico dell’ampiezza e della fase della funzione di trasferimento.\nQuesta semplificazione rende possibile eseguire il Fequency Design sui Plot di Bode e non sul Plos di Nyquist.\n\nL’essenza dell’analisi del diagramma di Bode\nPrendiamo una forma generica per una funzione di trasferimento:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{K(1 + j\\omega T_1)...}{j\\omega(1 + j\\omega T_2)...}\n\\]\nQuesto è un sistema di tipo 1 ma possiamo facilmente generalizzarlo all’ennesimo ordine.\nPer analizzare questa funzione utilizzando i grafici di Bode, prendiamo prima il logaritmo di entrambi i membri:\n\\[ \\log_{10}(G(j\\omega)H(j\\omega)) = \\log_{10}K + \\log_{10}(1 + j\\omega T_1) - \\log_{10}j\\ omega - \\log_{10}(1 + j\\omega T_2) ... \\]\nQuesto approccio scompone la funzione di trasferimento in componenti additivi più semplici.\n\nRappresentazione logaritmica: Prendendo il logaritmo delle componenti della funzione di trasferimento, i termini moltiplicativi in ​​$ G(j)H(j) $ diventano additivi. Ciò facilita la creazione di grafici di Bode con calcoli minimi.\nScala logaritmica e linee rette: il metodo di Bode utilizza scale logaritmiche su entrambi gli assi del grafico. Questa scelta fa sì che le singole componenti della funzione di trasferimento, quando tracciate, appaiano come (quasi) linee rette. L’aggiunta di questi segmenti lineari fornisce una visualizzazione chiara e completa della risposta in frequenza del sistema.\n\nNei grafici di Bode l’asse delle frequenze è rappresentato su scala logaritmica, essenziale per l’analisi dei sistemi di controllo. Su tale scala, la nozione di “frequenza zero” non è definita e, pertanto, le frequenze tipicamente vanno da un valore basso (ma diverso da zero) a un valore elevato. Questa caratteristica del diagramma di Bode offre un vantaggio significativo per l’analisi del sistema di controllo.\nI sistemi di controllo spesso funzionano come filtri passa-basso, nel senso che si occupano principalmente dei segnali nella gamma delle basse frequenze. Tuttavia, è altrettanto importante considerare l’impatto del rumore ad alta frequenza. La natura logaritmica dell’asse delle frequenze del diagramma di Bode consente una rappresentazione efficace di entrambi questi aspetti.\nIn una scala di frequenza lineare, come quella utilizzata nei grafici di Nyquist, accogliere un’ampia gamma di frequenze può portare a una rappresentazione compressa della gamma di basse frequenze, dove le caratteristiche prestazionali di un sistema sono più rilevanti. Al contrario, la gamma delle alte frequenze, cruciale per comprendere la reiezione dei disturbi, potrebbe non essere adeguatamente rappresentata a causa delle limitazioni di spazio sul grafico.\nLa scala logaritmica utilizzata nei grafici di Bode risolve elegantemente questi problemi. Allunga la regione delle basse frequenze, consentendo un’analisi più dettagliata del comportamento del sistema in questa gamma cruciale. Allo stesso tempo, adatta efficacemente anche la gamma delle alte frequenze. Questa doppia funzionalità consente una visione completa delle prestazioni del sistema su un ampio spettro di frequenze, il che è particolarmente vantaggioso per l’analisi e la progettazione dei sistemi di controllo.\n\n\nCalcoli di grandezza e fase\n\nGrandezza: Considera il logaritmo della grandezza di ciascun termine.\n\n\\[\n\\left|G(j\\omega)H(j\\omega)\\right| = \\frac{K\\left|1 + j\\omega T_1\\right|...}{\\left|j\\omega\\right|\\left|1 + j\\omega T_2\\right|...}\n\\]\n\\[\nlog_{10} \\left|G(j\\omega)H(j\\omega)\\right| = \\log_{10}K + \\log_{10}\\left|1 + j\\omega T_1\\right| - \\log_{10}{\\left|j\\omega\\right|} - \\log_{10}{\\left|1 + j\\omega T_2\\right|} ...\n\\]\nPossiamo convertirlo in dB (vedi sotto):\n\\[\n20log_{10} \\left|G(j\\omega)H(j\\omega)\\right| = 20\\log_{10}K + 20\\log_{10}\\left|1 + j\\omega T_1\\right| - 20\\log_{10}{\\left|j\\omega\\right|} - 20\\log_{10}{\\left|1 + j\\omega T_2\\right|} ...\n\\]\n\nFase: Somma i contributi di fase di ciascun termine nella funzione di trasferimento.\n\n\\[\n\\angle{G(j\\omega)H(j\\omega)} = \\tan^{-1}{\\omega T_1} - 90^\\circ - \\tan^{-1}{\\omega T_2} ... .\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#barra-laterale---decibel-nei-sistemi-di-controllo",
    "href": "IT_🇮🇹/bode_plots_it.html#barra-laterale---decibel-nei-sistemi-di-controllo",
    "title": "Analisi del diagramma di Bode",
    "section": "BARRA LATERALE - Decibel nei sistemi di controllo",
    "text": "BARRA LATERALE - Decibel nei sistemi di controllo\n\nUnità di grandezza: Nei sistemi di controllo, la grandezza di una funzione di trasferimento è spesso espressa in decibel (dB). La formula per convertire una magnitudo senza unità $ M $ in decibel è $ 20 _{10}(M) $.\nMotivazione per l’utilizzo dei decibel: L’unità decibel, originata dall’ingegneria delle comunicazioni, fornisce una scala standardizzata e pratica per la rappresentazione della magnitudo. Anche se si potrebbe sostenere l’uso del logaritmo naturale o di una scala logaritmica semplice, l’ubiquità dell’unità decibel e la compatibilità con il metodo di Bode ne fanno la scelta preferita.\n\n\n\nDefinizione: Un’unità logaritmica utilizzata per esprimere l’entità di una risposta in frequenza.\nFormula: \\(20 \\log{10}M\\) dB, dove M è la magnitudo.\nSignificato: Fornisce una scala standardizzata per confrontare le grandezze nei sistemi di controllo.\n\n– FINE DELLA BARRA LATERALE",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#la-struttura-dei-grafici-di-bode",
    "href": "IT_🇮🇹/bode_plots_it.html#la-struttura-dei-grafici-di-bode",
    "title": "Analisi del diagramma di Bode",
    "section": "La struttura dei grafici di Bode",
    "text": "La struttura dei grafici di Bode\nI grafici di Bode sono costituiti da due grafici separati: 1. Grafico dell’ampiezza: questo grafico presenta la frequenza (\\(\\omega\\)) sull’asse x e la magnitudo in decibel sull’asse y. Il grafico dell’ampiezza mostra come cambia il guadagno del sistema con la frequenza. 2. Grafico delle fasi: anche questo grafico presenta la frequenza (\\(\\omega\\)) sull’asse x, ma l’angolo di fase (\\(\\phi\\)) sull’asse y. Dimostra come la fase del sistema cambia con la frequenza.\n\n\n\n\n\n\n\n\nIl significato della scala logaritmica\nL’uso di una scala logaritmica per l’asse della frequenza (\\(\\log \\omega\\)) è fondamentale perché converte la complessa risposta in frequenza di ciascun termine in linee rette, al contrario delle linee curve che si vedrebbero su una scala lineare. Questa trasformazione semplifica notevolmente l’analisi.\nSe non avessimo \\(\\log \\omega\\) il grafico di Bode non sarebbe così conveniente.\n\n\nScale lineari e logaritmiche nei grafici di Bode\n\nAsse dell’ampiezza: L’asse della magnitudo in un diagramma di Bode è lineare, poiché l’operazione logaritmica è già incorporata nel calcolo dei decibel.\nAsse della frequenza: L’asse della frequenza è logaritmico, il che semplifica la rappresentazione della risposta in frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#elementi-costitutivi-dei-grafici-di-bode",
    "href": "IT_🇮🇹/bode_plots_it.html#elementi-costitutivi-dei-grafici-di-bode",
    "title": "Analisi del diagramma di Bode",
    "section": "Elementi costitutivi dei grafici di Bode",
    "text": "Elementi costitutivi dei grafici di Bode\nPer costruire un diagramma di Bode, consideriamo i seguenti elementi costitutivi di una funzione di trasferimento:\n\nFattore di guadagno costante $ K $.\nZero o Polo nell’origine $ (j)^{N} $.\nFattori del primo ordine $ (1 jT)^{m} $;\nFattori del secondo ordine $ ( s^2 + s + 1)^{r} $.\nFattore di ritardo $ e^{-j_D} $.\nAltri fattori che rappresentano zeri e poli sia nella metà sinistra che in quella destra del piano s.\n\nSi noti che abbiamo preso la forma della costante di tempo dei fattori.\nSi noti inoltre che il caso 3), comprende:\n$ (1 - jT) $ (zero RHP) e $ $ (polo RHP)\nQuesti elementi vengono combinati per formare il diagramma di Bode completo, dove ciascun fattore contribuisce linearmente alla risposta complessiva.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#diagramma-di-bode",
    "href": "IT_🇮🇹/bode_plots_it.html#diagramma-di-bode",
    "title": "Analisi del diagramma di Bode",
    "section": "Diagramma di Bode",
    "text": "Diagramma di Bode\nIl diagramma di Bode è composto da due grafici:\n\nGrafico dell’ampiezza: questo grafico presenta la frequenza su scala logaritmica (asse x) e l’entità della risposta del sistema in decibel (asse y).\nTracciato delle fasi: anche questo tracciato presenta la frequenza su scala logaritmica (asse x), ma l’asse y rappresenta l’angolo di fase in gradi.\n\n\nIntervallo di frequenze nei grafici di Bode\n\nSpettro di frequenza: i grafici di Bode coprono un’ampia gamma di frequenze, da quelle molto basse (vicine allo zero) a quelle molto alte.\nSignificato: Questa ampia gamma consente un’analisi completa della dinamica del sistema in varie condizioni.\n\nQuesto non era il caso del Nyquist dove la gamma delle basse frequenze era compressa per consentire il tracciamento fino all’infinito.\n\n\nElementi base dei grafici di Bode\nI grafici di Bode vengono costruiti analizzando gli elementi costitutivi di base di una funzione di trasferimento e quindi combinandoli. Cominciamo con l’elemento costitutivo più semplice.\n\nElemento costitutivo 1: Guadagna $ K $\nIl guadagno $ K $ in una funzione di trasferimento può essere rappresentato in un diagramma di Bode come:\n\nMagnitudo: $ 20 (K) $ dB. Questo valore è costante su tutte le frequenze.\nFase: $ 0^$, poiché il guadagno non influisce sulla fase.\n\nGraficamente, su un foglio semi-log, il grafico della magnitudo è una linea orizzontale a $ 20 (K) $ dB, mentre il grafico della fase rimane a $ 0^$.\n\nConsiderazioni sul guadagno $ K $\n\nSe $ K &gt; 1 $, la linea della magnitudo è sopra l’asse degli 0 dB.\nSe $ K &lt; 1 $, the magnitude line is below the 0 dB axis.\n\n\n\n\n\n\n\n\n\n\n\nElemento costitutivo 2: Zero o Polo nell’origine $ (j)^{N} $\nIniziamo a valutare come $ $ influenza il diagramma di Bode e poi generalizziamo il tutto:\n\nGrandezza: $ -20 () $ dB.\nFase: $ -90^$ per tutte le frequenze.\n\n\nAnalisi della magnitudo\nIl grafico della magnitudo è una linea retta con una pendenza di $ -20 $ dB/decade. Questa pendenza è determinata dal fatto che una variazione di frequenza di un fattore 10 (un decennio) comporta una variazione di magnitudo di $ -20 $ dB.\nNota che se prendessi la Magnitudo rispetto a \\(\\omega\\) sarebbe una funzione non lineare (c’è il log).\n\n\nDecennio e dB per decennio\n\nDecennio: un decennio si riferisce ad un aumento di dieci volte della frequenza. Ad esempio, passare da 1 Hz a 10 Hz è un decennio.\ndB per decennio: questo termine descrive come cambia la magnitudo (in decibel) nel corso di un decennio. Una linea con una pendenza di “-20 dB per decade” implica una diminuzione di 20 dB per ogni aumento di dieci volte della frequenza.\n\n\n\nTracciamento dei dB per decade\n\nCostruzione della pendenza: Per illustrare una pendenza di -20 dB per decade, seleziona una frequenza di riferimento e diminuisci l’ampiezza di 20 dB per la decade successiva.\nEsempio: Se inizi a 0,1 Hz, traccia una linea retta che diminuisce di -20 dB a 1 Hz, che rappresenta -20 dB per decade.\n\n\n\n\nEsempio: diagramma per un polo all’origine\nConsidera un intervallo di frequenza compreso tra $ 0,1 $ e $ 10 $ rad/s. Su un grafico semi-logaritmico: - A $ = 0,1 $ rad/s, la magnitudo è $ -20 (0,1) = 20 $ dB. - A $ = 1 $ rad/s, la grandezza è $ -20 (1) = 0 $ dB. - A $ = 10 $ rad/s, la magnitudo è $ -20 (10) = -20 $ dB. - Collega questi punti per formare una linea retta, che rappresenta il grafico della magnitudo.\n\n\n\n\n\n\n\nPossiamo ora generalizzare e considerare $ $:\n\nGrandezza: $ -40 () $ dB (cioè linea retta con pendenza di $ -40 $ dB/decade.\nFase: $ -180^$ per tutte le frequenze.\n\n\n\n\n\n\n\n\n\nVariazione della magnitudo: per ogni termine di ritardo aggiuntivo, la pendenza del grafico della magnitudo raddoppia. Per \\(1/j\\omega^2\\), la pendenza è di -40 dB per decennio.\nTracciamento: Inizia da \\(\\omega\\) = 1 con un livello dB specifico ed estendi la linea con una pendenza di -40 dB per decade.\n\nE se abbiamo uno zero (o più zeri all’origine) la forma è la stessa ma la pendenza diventa positiva.\n\n\nCombinazione di guadagno e polo all’origine \\(\\left( \\frac{K}{s} \\right)\\)\n\\[\nG(s) = \\frac{K}{s}\n\\]\nIl diagramma di Bode si ottiene sommando il diagramma di \\(K\\) e il diagramma di \\(\\frac{1}{s}\\).\n\nEffetti combinati: Quando si combina un fattore di guadagno (\\(K\\)) con un termine (\\(1/j\\omega\\)), il grafico della magnitudo cambia. La fase è -90.\nEquazione della magnitudine: Per \\(G(j\\omega) = \\frac{K}{j\\omega}\\), la grandezza in dB è \\(-20 log(\\omega) + 20 log(K)\\).\n\nQuesta è una linea retta della forma: \\(y = mx + c\\).\n\n\n\n\n\n\n\nDue poli all’origine:\n\\[\nG(s) = \\frac{K}{s^2}\n\\]\nL’equazione della Magnitudo è \\(dB = -40 log(\\omega) + 20 log(K)\\).\n\n\n\n\n\n\n\n\n\nIdentificazione del tipo di sistema dal diagramma di Bode\nNella regione delle basse frequenze, il diagramma di Bode ti dirà il tipo del tuo sistema:\n\nSistema Tipo-0: Caratterizzato da una linea orizzontale nella regione delle basse frequenze, che indica un guadagno costante.\nSistema di tipo 1: Presenta una linea con una pendenza di -20 dB per decade, indicativa di un sistema del primo ordine.\nSistema di tipo 2: Una pendenza di -40 dB per decade nella regione delle basse frequenze segnala un sistema di secondo ordine.\n\n\n\n\n\n\n\n\n\n\n\nElemento fondamentale: ritardo del primo ordine con costante di tempo\n\nPolo semplice o ritardo semplice (1/(1 + jωT))\n\nGrandezza e Fase:\n\nPer \\(G(s) = \\frac{1}{1 + j\\omega T}\\), la grandezza può essere espressa come:\n\\[\n|G(s)| = \\frac{1}{\\sqrt{1 + \\omega^2 T^2}} \\Rightarrow -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\ne la Fase come:\n\\[\n\\angle{G(s)} = -\\tan^{-1}(\\omega T)\n\\]\n\nTracciare il ritardo del primo ordine\nGamma di frequenza: Dividiamo lo spettro di frequenza in due gamme in base al prodotto \\(\\omega T\\): - Caso 1: \\(\\omega T &lt;&lt; 1\\) (Low-frequency range): In this range, the term \\(\\omega^2T^2\\) is negligible, simplifying the equation to \\(dB ≈ 0\\). Thus, the plot remains at 0 dB for low frequencies.\n\nCase 2: \\(\\omega T &gt;&gt; 1\\) (gamma delle alte frequenze): qui \\(1\\) nell’equazione diventa trascurabile, semplificandolo in \\(dB = -20 log(\\omega T)\\). Ciò si traduce in una linea retta con una pendenza di -20 dB per decade.\n\n\n\nFrequenza d’angolo e transizione\n\nFrequenza angolare: La frequenza alla quale \\(\\omega T = 1\\) è nota come frequenza angolare. Rappresenta un punto di transizione critico nel diagramma.\nTracciato della magnitudo: il tracciato passa da una linea piatta (0 dB) alle basse frequenze a una linea con una pendenza di -20 dB per decennio oltre la frequenza d’angolo.\n\nPossiamo quindi tracciare il grafico della magnitudine:\n\n\n\n\n\n\n\nConsideriamo nuovamente l’equazione:\n\\[\n|G(s)| =\\Rightarrow -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\n\nCaso 1: \\(|G(s)| = 0\\)\nCaso 2: \\(|G(s)| = -20\\log(\\omega) - 20\\log(T)\\)\nCaso 3: A \\(\\omega T = 1\\): L’equazione della magnitudo diventa \\(dB = -10 log \\sqrt{2} = -3\\) dB. In questo caso, la fase è \\(tan^{-1}\\left(1\\right) = -45^\\circ\\)\n\nPossiamo verificare la differenza tra la funzione reale e l’approssimazione.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nT = 1  # You can change T as per your requirements\ncorner_frequency = 1 / T\n\n# Frequency range from 0.1 to 100\nomega = np.logspace(-1, 2, 500)  # 500 points between 10^-1 and 10^2\n\n# Calculating dB values for the actual plot\ndB_actual = -10 * np.log10(1 + omega**2 * T**2)\n\n# Asymptotic approximation\ndB_asymptotic = np.zeros_like(omega)\nfor i, w in enumerate(omega):\n    if w &lt; corner_frequency:\n        dB_asymptotic[i] = 0\n    else:\n        dB_asymptotic[i] = -10 * np.log10(w**2 * T**2)  # Slope of -20 dB/decade\n\n# Plotting the Bode plot and its asymptotic approximation\nplt.figure()\nplt.semilogx(omega, dB_actual, label='Actual Plot')\nplt.semilogx(omega, dB_asymptotic, label='Asymptotic Approximation', linestyle='--')\nplt.title('Bode Plot with Asymptotic Approximation')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Magnitude (dB)')\nplt.grid(which='both', axis='both')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nAnalisi degli errori nei grafici di Bode\n\\[\n|G(s)| = -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\nNell’analisi del diagramma di Bode, l’uso di approssimazioni asintotiche semplifica il processo di tracciamento. Tuttavia, questo approccio può introdurre errori, soprattutto in prossimità delle frequenze d’angolo. Per migliorare la precisione del grafico, possiamo aggiungere più punti e calcolare gli errori in questi punti.\n\nCalcoli degli errori: Gli errori nel diagramma di Bode vengono aggiunti algebricamente a frequenze specifiche per creare una rappresentazione più accurata. Ad esempio, alla frequenza d’angolo, l’errore tipico potrebbe essere -3 dB. Inoltre, possiamo calcolare gli errori nei punti un’ottava sopra e sotto la frequenza d’angolo. Un’ottava in questo contesto si riferisce al raddoppio o al dimezzamento della frequenza.\n\nPer una rappresentazione più accurata, possiamo prendere punti aggiuntivi alle frequenze \\(\\omega = \\frac{1}{2T}\\) e \\(\\omega = \\frac{2}{T}\\). Gli errori in questi punti possono essere calcolati come segue:\n\nA \\(\\omega = \\frac{1}{2T}\\):\n\\[\nerr_{dB} = −10\\log(1) - \\left (-10\\log{\\left(1 + \\left(\\frac{1}{2T}\\right)^2 T^2\\right)} \\right) \\approx -1 \\text{ dB}\n\\]\nA \\(\\omega = \\frac{2}{T}\\):\n\\[\nerr_{dB} = -10\\log{\\left(\\left(\\frac{2}{T}\\right)^2 T^2\\right)} - \\left (-10\\log{\\left(1 + \\left(\\frac{2}{T}\\right)^2 T^2\\right)} \\right) \\approx -1 \\text{ dB}\n\\]\n\nQuesti calcoli degli errori aiutano a perfezionare il diagramma di Bode, rendendolo più vicino alla risposta in frequenza effettiva del sistema.\nLa pratica comune prevede la regolazione del grafico a ω = 1/(2T) e ω = 2/T di un certo livello di dB per adattarlo fedelmente al grafico reale.\n\n\nAnalisi del grafico delle fasi\nL’equazione primaria per il diagramma di fase nell’analisi di Bode è data da:\n\\[\n\\angle G(j\\omega) = -\\tan^{-1}(\\omega T)\n\\]\nQuesta equazione implica:\n\nA \\(\\omega = 0\\), \\(\\angle G(j\\omega) = 0^\\circ\\), indicando che la fase inizia a 0 gradi alle basse frequenze.\nCome \\(\\omega \\rightarrow \\infty\\), \\(\\angle G(j\\omega) \\rightarrow -90^\\circ\\), mostrando che la fase si avvicina a -90 gradi alle alte frequenze.\nAlla frequenza specifica \\(\\omega = \\frac{1}{T}\\), \\(\\angle G(j\\omega) = -45^\\circ\\), che è il punto medio della transizione di fase.\n\n\n\n\n\n\n\n\n\n\nCostruzione del diagramma delle fasi\n\nTracciato della fase effettiva: Il tracciato della fase effettiva per un polo semplice passa gradualmente da 0 gradi alle basse frequenze a -90 gradi alle alte frequenze. Mentre alcuni intervalli di frequenza potrebbero consentire approssimazioni di fase costanti, il grafico reale mostra un cambiamento graduale e continuo.\nMetodo di approssimazione: Un’approssimazione pratica per il diagramma di fase utilizza una linea retta che si estende da \\(\\omega = \\frac{1}{10T}\\) a \\(\\omega = \\frac{10}{T}\\). Questa approssimazione semplifica il grafico ma può introdurre un errore fino a circa \\(6^\\circ\\). Un tale errore diventa significativo quando si calcola il margine di fase, dove la precisione è cruciale per valutare la stabilità del sistema.\n\n\n\nVisualizzazione\nI diagrammi di fase, sia approssimati che effettivi, possono essere visualizzati come mostrato di seguito. Le figure illustrano la distinzione tra il comportamento di fase reale e la sua approssimazione asintotica, evidenziando la semplicità e i potenziali errori coinvolti in quest’ultimo approccio.\n\nApprossimazione asintotica: (immagine che mostra l’approssimazione in linea retta da \\(\\frac{1}{10T}\\) a \\(\\frac{10}{T}\\))\n\n\n\n\n\n\n\n\nFigura: l’approssimazione asintotica è rappresentata utilizzando una linea retta per facilitare l’analisi.\n\nTracciato della fase effettiva:\n\nFigura: immagine che rappresenta la transizione graduale da 0 a -90 gradi. Questo è mostrato usando lo script Python qui sotto.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nT = 1  # Time constant, you can change this as needed\n\n# Frequency range from 0.01 to 1000\nomega = np.logspace(-2, 3, 500)  # 500 points between 10^-2 and 10^3\n\n# Calculating the actual phase\nphase_actual = -np.arctan(omega * T) * (180 / np.pi)  # Convert to degrees\n\n# Straight-line approximation\nphase_approx = np.zeros_like(omega)\nfor i, w in enumerate(omega):\n    if w &lt; 1 / (10 * T):\n        phase_approx[i] = 0\n    elif w &gt; 10 / T:\n        phase_approx[i] = -90\n    else:\n        # Linear interpolation between -45 at 1/T and -90 at 10/T\n        phase_approx[i] = np.interp(np.log10(w), [np.log10(1 / (10 * T)), np.log10(10 / T)], [0, -90])\n\n# Plotting the phase plots\nplt.figure()\nplt.semilogx(omega, phase_actual, label='Actual Phase')\nplt.semilogx(omega, phase_approx, label='Straight-line Approximation', linestyle='--')\nplt.title('Phase Plot for a Simple Pole')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Phase (degrees)')\nplt.grid(which='both', axis='both')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nRiepilogo: polo semplice o ritardo semplice (1/(1 + jωT))\n\\[G(s) = \\frac{1}{1 + j\\omega T}\\]\n\n\n\n\n\n\n\n\n\n\n\nZero semplice (1 + jωT)\n\\[\nG(s) = 1+j\\omega T\n\\]\n\nTracciato asintotico: Per uno zero, il tracciato asintotico di Bode inizia con una pendenza crescente di +20 dB per decade alla frequenza d’angolo (1/T).\nRegolazione della precisione: per creare un grafico più accurato, regola il grafico asintotico a frequenze specifiche (come ω = 1/(2T) e ω = 2/T) aggiungendo livelli dB.\n\n\n\n\n\n\n\n\n\n\nDiagramma di Bode per un doppio polo (1/(1 + jωT)²)\n\\[\nG(s) = \\frac{1}{(1+j\\omega T)^2}\n\\]\n\nPendenza della linea: Per un doppio polo, la linea nel diagramma di Bode ha una pendenza di -40 dB per decade, con aggiustamenti per errori intorno a questa frequenza.\nFrequenza angolare: La frequenza angolare, dove ωT = 1, è il punto in cui si verifica il cambiamento di pendenza.\n\n\nAnalisi degli errori nei grafici di Bode\n\nCalcoli degli errori: Gli errori nel diagramma di Bode vengono aggiunti algebricamente a frequenze specifiche per creare una rappresentazione più accurata. Ad esempio, alla frequenza d’angolo, l’errore è di -6 dB, con errori aggiuntivi di -2 dB un’ottava sopra e sotto la frequenza d’angolo.\n\n\n\n\nFattori del secondo ordine\n\\[\nG(s) = \\frac{1}{\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1}\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#margine-di-fase-e-margine-di-guadagno-nei-grafici-di-bode",
    "href": "IT_🇮🇹/bode_plots_it.html#margine-di-fase-e-margine-di-guadagno-nei-grafici-di-bode",
    "title": "Analisi del diagramma di Bode",
    "section": "Margine di fase e margine di guadagno nei grafici di Bode",
    "text": "Margine di fase e margine di guadagno nei grafici di Bode\n\nFrequenza crossover del guadagno: questa è la frequenza alla quale l’ampiezza della risposta del sistema è pari a 1 (o 0 dB). È fondamentale per l’analisi della stabilità.\nMargine di fase: Il margine di fase è lo spostamento di fase aggiuntivo necessario per portare il sistema sull’orlo dell’instabilità. Viene calcolato dal diagramma di fase alla frequenza di crossover del guadagno.\nAnalisi del margine di fase:\n\nIl margine di fase rappresenta l’angolo di fase aggiuntivo che può essere aggiunto al sistema prima che raggiunga un angolo di fase di -180 gradi.\nMargine di fase positivo: se il grafico è al di sopra della linea di -180 gradi in corrispondenza della frequenza di crossover del guadagno, il margine di fase è positivo, indicando un sistema stabile.\nMargine di fase negativo: Al contrario, se il grafico è al di sotto della linea di -180 gradi, si tratta di un margine di fase negativo, suggerendo una potenziale instabilità.\n\nDefinizione della frequenza di crossover di fase: La frequenza di crossover di fase è il punto in cui l’angolo di fase della risposta del sistema diventa -180 gradi. Questa frequenza è fondamentale nel determinare la stabilità del sistema.\n\n\nAnalisi del margine di guadagno\n\nCalcolo del margine di guadagno: Il margine di guadagno è il guadagno aggiuntivo che può essere aggiunto al sistema prima che diventi instabile. Si misura in decibel (dB).\nDeterminazione del margine di guadagno: Per trovare il margine di guadagno, individuare la frequenza di crossover di fase sul grafico della magnitudo. La distanza (in dB) da questo punto alla linea 0 dB rappresenta il margine di guadagno.\n\n\n\n\nCostruzione di grafici di Bode per funzioni di trasferimento specifiche\n\nEsempio:\n\\[\nG(s) = \\frac{k}{s(1 + sT_1)(1 + sT_2)}\n\\]\n\nCostruzione del grafico della magnitudine: Inizia tracciando il grafico a bassa frequenza per K = 10. Quindi, aggiungi grafici per ciascun fattore (1/s, 1 + sT1, 1 + sT2) e regola la pendenza a ciascuna frequenza d’angolo .\nApproccio: Ad ogni frequenza d’angolo, aggiungi o sottrai livelli dB in base al cambiamento netto della pendenza. Ad esempio, a una frequenza d’angolo in cui la pendenza diminuisce, sottrarre i livelli dB per correggere il grafico.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/bode_plots_it.html#controlla-la-tua-comprensione",
    "href": "IT_🇮🇹/bode_plots_it.html#controlla-la-tua-comprensione",
    "title": "Analisi del diagramma di Bode",
    "section": "Controlla la tua comprensione",
    "text": "Controlla la tua comprensione\nDomanda pop-up: Perché i grafici di Bode sono preferiti rispetto ai grafici di Nyquist per alcune analisi nel controllo automatico?\nRisposta: I grafici di Bode semplificano la visualizzazione e l’interpretazione della risposta in frequenza di un sistema convertendo complessi grafici polari in semplici grafici logaritmici. Questa semplificazione è particolarmente utile per comprendere il guadagno e i margini di fase del sistema.\nDomanda pop-up: Perché vengono utilizzati i decibel nell’analisi del diagramma di Bode?\nRisposta: I decibel forniscono una scala logaritmica che semplifica il confronto di diverse grandezze, facilitando l’analisi e la progettazione dei sistemi di controllo.\nDomanda pop-up: Cosa indica un margine di guadagno positivo sulla stabilità di un sistema?\nRisposta: Un margine di guadagno positivo indica che un sistema può sopportare un aumento di guadagno senza diventare instabile.\nDomanda pop-up: Perché vengono utilizzati i decenni nei grafici di Bode?\nRisposta: Vengono utilizzati i decenni perché forniscono una scala logaritmica per la frequenza. Ciò consente di rappresentare in modo compatto un’ampia gamma di frequenze, facilitando l’analisi del comportamento del sistema su diverse bande di frequenza.\nDomanda pop-up: Perché la frequenza d’angolo è importante nei grafici di Bode?\nRisposta: La frequenza d’angolo segna il punto di transizione in cui il comportamento del sistema cambia in modo significativo. È il punto in cui l’approssimazione della risposta in frequenza del sistema si sposta da un regime all’altro, ad esempio da una risposta piatta a una risposta inclinata.\nDomanda pop-up: Qual è il significato del guadagno e dei margini di fase nei sistemi di controllo?\nRisposta: Il guadagno e i margini di fase sono indicatori critici della stabilità del sistema. Un margine di fase positivo e un margine di guadagno sostanziale implicano che il sistema può tollerare un certo livello di aumento di guadagno o spostamento di fase prima di diventare instabile.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi del diagramma di Bode"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html",
    "title": "Sistemi di controllo del movimento CA",
    "section": "",
    "text": "Nei notebook precedenti abbiamo discusso dei sistemi di controllo del movimento utilizzando hardware specifico. Abbiamo accennato all’utilizzo di un motore CC come attuatore, una dinamo tachimetrica CC come sensore di velocità, un potenziometro per il rilevamento della posizione e altro hardware associato. La nostra esplorazione era principalmente radicata nei componenti basati su DC.\nQuesto notebook si concentra su un diverso set di hardware per avere AC Motion Control Systems.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#confronto-tra-sistemi-cc-e-ca",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#confronto-tra-sistemi-cc-e-ca",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Confronto tra sistemi CC e CA",
    "text": "Confronto tra sistemi CC e CA\nPrima di immergerci in profondità, ricordiamo le nostre discussioni precedenti. Nei sistemi di controllo del movimento, abbiamo analizzato due tipologie principali: Sistemi di controllo della posizione e Sistemi di controllo della velocità. Il principio rimane lo stesso, ma l’hardware e talvolta le complessità cambiano quando si passa dai componenti CC a quelli CA.\n\nComponenti del sistema DC:\n\nAttuatore: motore CC\nSensore di velocità: dinamo tachimetrica CC\nSensore di posizione: potenziometro\n\n\n\nComponenti del sistema AC:\n\nAttuatore: servomotore bifase\nSensore di velocità e posizione: Synchro (e altri dispositivi di cui parleremo)",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#il-servomotore-bifase",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#il-servomotore-bifase",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Il servomotore bifase",
    "text": "Il servomotore bifase\nIl nostro primo punto di discussione è il servomotore bifase.\nQuesto attuatore ha il compito di produrre la coppia necessaria per azionare il carico.\n\n\n\n\n\nSi chiama ‘bifase’ perché, come evidente dal nome, funziona utilizzando due fasi. Una fase è denominata “fase di controllo” e la sua importanza diventerà presto evidente. L’altra è denominata “fase di riferimento”. Il rotore trasporta il carico, che può essere direttamente sul rotore o tramite un treno di ingranaggi.\n\nIl motivo principale alla base dell’utilizzo di due fasi (o del concetto di “fase divisa”) in alcuni tipi di motori CA è generare un campo magnetico rotante essenziale per il funzionamento del motore. In un motore CA trifase, le tre fasi creano naturalmente un campo magnetico rotante. In un motore CA monofase, il campo magnetico si alterna semplicemente ma non ruota. Per superare questo problema, i motori bifase utilizzano due avvolgimenti, con una differenza di fase, per simulare il campo rotante.\nRuolo delle due fasi: - Coppia di avviamento: uno dei motivi principali per avere due avvolgimenti (o fasi) è produrre una coppia di avviamento. I motori monofase, senza alcun meccanismo di sfasamento, non hanno intrinsecamente una coppia di avviamento, il che significa che non inizieranno a ruotare da soli. - Campo magnetico rotante: introducendo una differenza di fase tra i due avvolgimenti, solitamente attraverso un condensatore o progettando diversamente gli avvolgimenti, si crea uno sfasamento tra le correnti nei due avvolgimenti. Questa differenza di fase si traduce in un campo magnetico rotante essenziale per il funzionamento del motore.\n\nPer semplificazione, rappresentiamo i parametri di carico come “J” e “B”. Il rotore genera una coppia \\(T_M\\) e affronta una coppia di disturbo \\(T_\\omega\\) che si oppone a \\(T_M\\).\n\nData questa configurazione, il successivo componente di interesse è il condensatore di sfasamento** nella fase di riferimento. Il suo ruolo è fondamentale. Garantisce che possiamo derivare un’alimentazione bifase da una sorgente di tensione monofase. Questo condensatore induce una differenza di fase di 90 gradi tra le due fasi.\n\nLa fase di riferimento riceve un’alimentazione di tensione del tipo \\(E_r\\cos\\omega_{c}t\\), dove \\(\\omega_{c}\\) è denominata frequenza dell’onda portante e \\(E_r\\)è la tensione di riferimento.\n\nLa fase di controllo è collegata ad un Modulatore. L’ingresso al modulatore è la tensione di controllo \\(e_c\\). Si tratta sempre di una tensione a bassa frequenza in un sistema di controllo.\n\n\nCommenti\n\nRicordare che in un sistema di controllo l’obiettivo è rendere zero l’errore. Ad esempio, l’errore potrebbe essere un errore di posizione o di velocità.\nSe il sistema di controllo funziona bene, l’errore sarà un segnale a bassa frequenza e un segnale piccolo.\n\nSe consideriamo \\(e_c\\) come segnale di errore ed entriamo come ingresso per il motore vorrei modulare questo segnale con la frequenza \\(\\omega_c\\), la frequenza portante.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#motori-ac-e-controllo-di-precisione",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#motori-ac-e-controllo-di-precisione",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Motori AC e controllo di precisione",
    "text": "Motori AC e controllo di precisione\nQuesto notebook si concentra sui motori CA bifase utilizzati in applicazioni di controllo di precisione. In questo contesto, il controllo modulato viene implementato per ottenere una caratteristica prestazionale desiderata, in particolare in sistemi come i servoazionamenti. Abbattiamo i componenti:\n\n1. Tensione di fase di controllo (\\(e_c\\)):\nQuesta è essenzialmente la tensione di “ingresso” o di “controllo”. Contiene le informazioni su come vuoi che si comporti il ​​motore. Ad esempio, se vuoi che il motore ruoti ad una certa velocità o si sposti in una certa posizione, questo è codificato in \\(e_c\\). È il tuo modo di dire al motore cosa fare.\n\n\n2. Tensione modulata (\\(e_m\\)):\nQuesta è la tensione di “uscita”, che viene generata dopo aver modulato la tensione di controllo con un riferimento. La modulazione ha molteplici scopi:\n\nPrestazioni migliorate: Modulando con una portante ad alta frequenza, è possibile migliorare le prestazioni del motore. Ad esempio, la modulazione ad alta frequenza può ridurre le ondulazioni di coppia nel motore.\nImmunità al rumore: i segnali ad alta frequenza tendono ad essere meno suscettibili al rumore a bassa frequenza. Ciò è vantaggioso in un ambiente industriale in cui potrebbero essere presenti numerosi disturbi elettrici.\n\nLa tensione di fase di controllo (\\(e_c\\)) codifica il comportamento desiderato del motore. Ciò potrebbe rappresentare la velocità, la coppia o la posizione desiderata. Quando questa tensione di controllo viene combinata (modulata) con la tensione di riferimento ad alta frequenza (\\(E_r\\)), la tensione modulata risultante (\\(e_m\\)) viene applicata al secondo avvolgimento (spesso chiamato fase di controllo o modulazione).\n\n\n3. Tensione di riferimento (\\(E_r\\)):\n\\(E_r\\) è l’onda portante. Si tratta di un segnale ad alta frequenza che non contiene intrinsecamente alcuna informazione sul controllo del motore. Tuttavia, quando \\(e_c\\) (il segnale di controllo a bassa frequenza) viene modulato con \\(E_r\\), il risultato è \\(e_m\\), che ha proprietà sia del segnale di controllo che dell’onda portante.\n\n\nPerché la tensione di riferimento è applicata solo alla fase di riferimento?\nApplicando la tensione di riferimento a una sola fase (spesso chiamata fase di riferimento), la modulazione è più efficace nel creare un controllo differenziale o relativo tra le fasi. Questo differenziale può essere più efficace nel creare la coppia e la velocità desiderate nel motore.\n\nUn motore CA bifase ha due avvolgimenti, generalmente posizionati a 90 gradi l’uno dall’altro. Le correnti attraverso questi avvolgimenti, quando sono fuori fase, producono campi magnetici che si combinano per formare un campo magnetico rotante risultante. Questo campo rotante è ciò che fa girare il rotore.\nL’applicazione della tensione di riferimento, tipicamente un segnale ad alta frequenza, a questa fase stabilisce una linea di base o campo magnetico di “riferimento”.\n\nApplicando la tensione di riferimento solo alla fase di riferimento, la configurazione del motore può creare un campo magnetico differenziale. Questo campo magnetico differenziale, rispetto al riferimento, governa effettivamente il comportamento del motore.\nQuando la tensione di riferimento ad alta frequenza viene applicata alla fase di riferimento e la tensione di controllo modulata viene applicata all’altra fase, l’orientamento e l’ampiezza del campo magnetico risultante dipendono dal segnale modulato. Ciò consente un controllo preciso della posizione o della velocità del motore in base alle caratteristiche del segnale modulato.\nSe la tensione di riferimento fosse applicata ad entrambe le fasi, non produrrebbe un effetto differenziale e non produrrebbe il controllo di precisione desiderato.\nIn sostanza, designando un avvolgimento come “riferimento” e l’altro come “controllo”, e quindi applicando tensioni appropriate a ciascuno, il sistema può creare un campo magnetico rotante con direzione e ampiezza controllabili, che è essenziale per un controllo di precisione in applicazioni come i servosistemi.\n\n\nRuolo dell’alimentazione CA:\nNonostante tutte queste metodologie di controllo, il motore richiede comunque energia per funzionare. L’alimentazione CA fornisce la potenza necessaria per azionare il motore. Tutte le tensioni sopra menzionate (\\(e_c\\), \\(e_m\\), \\(E_r\\)) riguardano il controllo e la modulazione, ma nessuna di esse fornisce direttamente la potenza necessaria per far girare il motore. È qui che entra in gioco l’alimentazione CA.\n\n\nIn sintesi:\nPensa all’intero processo come analogo a una radio FM. Nella trasmissione FM (modulazione di frequenza), si dispone di un segnale di base ad alta frequenza (simile a \\(E_r\\)), che viene modulato da un segnale audio a bassa frequenza (simile a \\(e_c\\)). Il risultato è un segnale modulato ad alta frequenza (come \\(e_m\\)) che può essere trasmesso. La radio demodula quindi questo segnale per estrarre e riprodurre l’audio. Allo stesso modo, nello scenario di controllo del motore, la modulazione viene utilizzata per combinare le informazioni di controllo con una portante ad alta frequenza per migliorare le prestazioni del motore. La potenza effettiva per far funzionare tutto, tuttavia, proviene dall’alimentazione CA principale.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#modulazione-di-ampiezza-am",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#modulazione-di-ampiezza-am",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Modulazione di ampiezza (AM)",
    "text": "Modulazione di ampiezza (AM)\nIn AM, l’ampiezza dell’onda portante ad alta frequenza (\\(E_r\\)) viene variata in base all’ampiezza istantanea del segnale di controllo (\\(e_c\\)).\nPer modulare la portante utilizzando il segnale di errore, prenderemo il prodotto del segnale di errore e del segnale della portante. Ciò si traduce in un segnale modulato in ampiezza (AM).\nL’inviluppo di un segnale modulato in ampiezza (AM) corrisponde all’ampiezza istantanea del segnale, che nel nostro caso è rappresentata dal segnale di errore.\n\nProcesso di modulazione:\n\nOnda portante (\\(E_r\\)):\n\nSi tratta di una forma d’onda sinusoidale ad alta frequenza, che funge da segnale di riferimento. Matematicamente può essere rappresentato come:\n\\[\nE_r(t) = A_c\\sin(2\\pi f_ct)\n\\]\nDove - \\(A_c\\) = Ampiezza dell’onda portante - \\(f_c\\) = frequenza dell’onda portante\n\nSegnale di controllo (\\(e_c\\)): questo è il segnale che vuoi che il motore segua. Potrebbe rappresentare la velocità, la posizione, ecc. desiderate.\nSegnale modulato (\\(e_m\\)): il risultato del processo di modulazione. Al mattino: \\[\ne_m(t) = \\big[ A_c+e_c(t)\\big]\\sin(2\\pi f_ct)\n\\]\n\n\n\nCircuito di modulazione pratico:\nUn circuito comune utilizzato per ottenere la modulazione di ampiezza è il circuito moltiplicatore. Questo circuito moltiplica due segnali di ingresso per produrre un segnale di uscita.\n\nInserisci \\(E_r\\) e \\(e_c\\) nei due input del moltiplicatore\nL’uscita \\(e_m\\) è il prodotto dei due segnali di ingresso\nla sua uscita, che contiene componenti di frequenza sia di \\(E_r\\) che di \\(e_c\\), viene quindi fatta passare attraverso un filtro passa banda per estrarre, se necessario, il segnale modulato desiderato.\n\nAl giorno d’oggi, con i ricetrasmettitori di comunicazione che sono molto digitalizzati, la modulazione viene eseguita principalmente nel dominio digitale utilizzando un blocco di tipo DSP.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time values\nt = np.linspace(0, 10, 1000)\n\n# Define the error signal (decreasing oscillating signal starting from its maximum)\nerror_signal = (1 / (1 + 0.2 * t)) * np.sin(2 * np.pi * .2 * t + np.pi/2)  # Added phase shift of pi/2\n\n# Define the carrier signal\nomega_c = 2 * np.pi * 5  # carrier frequency (for example, 10Hz)\ncarrier_signal = np.cos(omega_c * t)\n\n# Modulate the carrier using the error signal\nmodulated_signal = error_signal * carrier_signal\n\n# Plot\nplt.figure(figsize=(12, 8))\n\n# Plot the error signal\nplt.subplot(3, 1, 1)\nplt.plot(t, error_signal, label=r'Error Signal $e_c$', color='blue')\nplt.title(r'Error Signal $e_c$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the carrier signal\nplt.subplot(3, 1, 2)\nplt.plot(t, carrier_signal, label='Carrier Signal: cos(ωc t)', color='green')\nplt.title('Carrier Signal')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the modulated signal\nplt.subplot(3, 1, 3)\nplt.plot(t, modulated_signal, label='Modulated Signal', color='red')\nplt.title(r'Amplitude Modulated Signal $e_m$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the positive envelope (absolute value of the error signal)\nplt.plot(t, np.abs(error_signal), '--', label='Positive Envelope', color='blue', linewidth=1.5)\n\n# Plot the negative envelope (negative of the absolute value of the error signal)\nplt.plot(t, -np.abs(error_signal), '--', label='Negative Envelope', color='green', linewidth=1.5)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nSi noti che quando cambia il segno di \\(e_c\\), la fase del segnale modulato \\(e_m\\) si inverte (il massimo di \\(e_c\\) è il minimo di \\(e_m\\)).\nA causa di questa inversione di fase si verifica il flusso magnetico e si inverte anche la direzione del motore. Questo è un controllo bidirezionale:\n\nquando \\(e_c&gt;0\\) il motore si muove in una direzione\nquando \\(e_c&lt;0\\) il motore si muove nella direzione opposta\n\n\\(e_m\\) è un’onda modulata con portante alla frequenza \\(\\omega_c\\)\nla tensione di riferimento \\(e_c\\) è alla frequenza \\(\\omega_c\\)\n\nInsomma: Queste due tensioni applicate alle due fasi del motore produrranno una coppia sul motore. La coppia sarà una funzione di \\(e_c\\) (\\(e_r\\) è una tensione fissa) e la sua direzione sarà una funzione del segno di \\(e_c\\).\n\n\nCaratteristiche coppia-velocità del motore CA\nUna vista comparativa con il motore DC mostra che mentre quest’ultimo presenta caratteristiche di coppia-velocità quasi lineari, la curva del motore AC è evidentemente non lineare.\nLa curva coppia-velocità di un tipico motore DC shunt è relativamente semplice rispetto a un motore AC. La coppia dipende in modo più o meno lineare dalla corrente di armatura e, all’aumentare della velocità, la coppia generalmente diminuisce in modo lineare a causa della forza elettromotrice (FEM) del motore che si oppone alla tensione di alimentazione.\nLe caratteristiche lineari dei motori DC sono un vantaggio perché il modello è più semplice.\nSe facessimo un esperimento queste sono le curve tipiche che otterremmo:\n\n\n\n\n\nUna volta determinate sperimentalmente le curve coppia-velocità per i motori, i dati risultanti possono aprire la strada alla formulazione di modelli matematici precisi.\nUna caratteristica così non lineare dei motori CA può rappresentare una sfida, soprattutto se desideriamo farli funzionare su un’ampia gamma. Ma uno degli aspetti positivi dei motori CA è il loro comportamento quasi lineare attorno alla velocità zero, che li rende adatti ai sistemi di controllo della posizione.\nA regime, la velocità è zero e la posizione del carico è uguale alla posizione comandata: il motore non si muove. Intorno a questo punto si ha un comportamento lineare che possiamo utilizzare e modellare.\nPer questo motivo ci concentreremo solo sui modelli lineari dei motori AC, assumendo che il punto di funzionamento sia velocità = 0.\n\n\nEquazione della coppia lineare per motori CA\nDato che per il nostro problema di controllo della posizione possiamo assumere che il punto operativo sia \\(\\text{speed}=0\\), l’equazione della coppia è una funzione della tensione di controllo \\(e_c\\) e della velocità $ $:\n\\[\nT_M = K_1e_c-K_2\\dot{\\theta}\n\\]\nDove: - \\(K_2\\) è il fattore determinante per mettere in relazione coppia e velocità ed è la pendenza dell’approssimazione lineare delle curve Coppia-Velocità nel grafico dei motori CA sopra (quando la velocità \\(\\approx\\) 0). - La tensione di controllo \\(e_c\\) è fondamentale perché fa sì che si sposti da una curva all’altra (nel diagramma sopra \\(e_{c_1}&gt;e_{c_2}&gt;e_{c_3}\\)) - Quando la tensione di controllo aumenta, la coppia aumenta - Quando la velocità aumenta, la coppia diminuisce\nUna volta determinate sperimentalmente le curve, possiamo ottenere i parametri corrispondenti per il nostro modello lineare.\n\nDalle curve Coppia-Velocità nel grafico dei Motori AC sopra possiamo dedurre direttamente la costante \\(K_2\\)\nPer ottenere \\(K_1\\), è possibile tracciare il grafico della tensione di fase di controllo \\(e_c\\) rispetto alla coppia \\(T_m\\) (vedere il grafico sotto). La pendenza della linea risultante in condizioni di velocità costante (diciamo \\(\\omega = 0\\)), fornirà il valore per \\(K_1\\). Questo approccio presuppone un modello di linearità per un dispositivo, che vale per determinati intervalli di funzionamento.\n\n\n\n\n\n\n\n\nEquazione del motore CA\nSiamo ora pronti a scrivere il modello matematico del motore AC:\n\\[\nT_M = K_1e_c-K_2\\dot{\\theta} = J \\ddot{\\theta} + B\\dot{\\theta} + T_W\n\\]\ndove ora abbiamo aggiunto il carico e: - \\(T_M\\) è la Coppia sviluppata dal motore - \\(e_c\\) è la tensione della fase di controllo - \\(\\dot{\\theta}\\) è la velocità del motore - \\(K_1\\) e \\(K_2\\) sono costanti determinate sperimentalmente - \\(J \\ddot{\\theta}\\) è il carico inerziale - \\(B\\dot{\\theta}\\) è lo smorzamento - \\(T_W\\) è la coppia di disturbo sul sistema.\nPossiamo riscrivere l’equazione di cui sopra come:\n\\[\nK_1e_c = J \\ddot{\\theta} + (B+K_2)\\dot{\\theta} + T_W\n\\]\ndove \\(e_c\\) è il mio input.\n\n\nSchema a blocchi del motore CA\nL’intero discorso può essere rappresentato visivamente utilizzando un diagramma a blocchi, evidenziando le relazioni tra \\(e_c\\), \\(\\theta\\), \\(\\omega\\) e altri parametri di sistema.\n\n\n\n\n\nAttraverso lo schema a blocchi che rappresenta il sistema, è possibile ricavare una funzione di trasferimento, che collega \\(e_c\\) (ingresso) e \\(\\omega\\) o \\(\\theta\\) (uscita).\n\nFunzione di trasferimento tra \\(\\omega\\) e \\(e_c\\):\n\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_1}{Js+B+K_2}\n\\]\n\nTieni presente che \\(K_2\\) aumenta lo smorzamento meccanico del sistema, ricordando il comportamento del motore controllato dall’armatura CC.\n\\(K_2\\) aggiunge direttamente allo smorzamento, influenzando la stabilità e la risposta del sistema. Inoltre la costante di tempo del sistema diventa \\[\n\\tau = \\frac{J}{B+K_2}\n\\]\n\nindicando che \\(K_2\\) influenza la velocità con cui il sistema risponde ai cambiamenti.\n🤔 Domanda popup: In che modo l’entità di \\(K_2\\) influisce sullo smorzamento e sulla costante di tempo del sistema?\nRisposta: \\(K_2\\) aumenta direttamente lo smorzamento, influenzando la stabilità e la risposta del sistema. Inoltre, la costante di tempo del sistema diventa \\(\\tau = \\frac{J}{B+K_2}\\) indicando che \\(K_2\\) influenza la velocità con cui il sistema risponde ai cambiamenti.\n\nBarra laterale: un tipico motore a induzione\nLe caratteristiche della velocità di coppia di un normale motore a induzione sono riportate nel grafico sottostante.\n\n\n\n\n\nPossiamo utilizzare questo motore a induzione bifase per applicazioni servo?\nPer rispondere a questa domanda consideriamo la funzione di trasferimento\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_1}{Js+B+K_2}\n\\]\ndove \\(K_2\\) aumenta lo smorzamento.\nSe \\(K_2\\) è negativo, a seconda della sua relazione con \\(B\\) (ricorda che entra in \\(B+K_2\\)), potrebbe portare a instabilità.\nUna curva caratteristica, soprattutto quella che presenta una pendenza negativa, può introdurre uno smorzamento negativo, portando a oscillazioni eccessive e possibilmente culminando in instabilità o oscillazioni eccessive (oscillazioni) nel sistema. \\(B\\) dovrebbe essere estremamente alto per contrastare gli effetti di un \\(K_2\\) negativo.\nPer questo motivo, un normale motore a induzione non viene mai utilizzato per applicazioni servo (sistemi controllati in posizione o velocità).\n🤔 Domanda popup: Perché un normale motore a induzione potrebbe non essere adatto per applicazioni servo?\nRisposta: Un normale motore a induzione potrebbe presentare caratteristiche in cui la pendenza diventa negativa, introducendo la possibilità di smorzamento negativo, che potrebbe portare a instabilità o oscillazioni eccessive nel sistema, soprattutto nel contesto di applicazioni servo dove è importante un controllo preciso .\nRicordiamo che le caratteristiche coppia-velocità dei servomotori AC da noi utilizzati sono riportate nella figura sotto (a sinistra):\n\n\n\n\n\n\nQueste caratteristiche hanno \\(K_2\\) sempre positivo.\n\n\n\nOttenimento di caratteristiche di coppia-velocità con pendenza positiva\n\nQueste caratteristiche sono ottenute direttamente dal motore a induzione, in particolare utilizzando un’elevata resistenza del rotore.\n\nUna maggiore resistenza del rotore garantisce che le caratteristiche di risposta del motore rimangano positive.\nIn sostanza, un servomotore è un motore a induzione con elevata resistenza del rotore. Una tale scelta progettuale garantisce che le caratteristiche del servomotore presentino sempre una pendenza positiva. Tuttavia, questa scelta comporta dei compromessi:\n\nL’elevata resistenza del rotore significa che l’efficienza complessiva del sistema sarà ridotta.\nNonostante la riduzione dell’efficienza, il design è essenziale per applicazioni specifiche come i servosistemi in cui una pendenza negativa potrebbe essere dannosa.\n\n— FINE DELLA BARRA LATERALE\n\n\n\nRitorniamo al modello del motore\nDiamo un’occhiata alla rappresentazione matematica del motore:\nIl modello motorio è dato da:\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_m}{\\tau_m s + 1}\n\\]\nDove: - \\(\\omega\\) è la velocità del motore - \\(e_c\\) rappresenta la tensione di controllo - \\(K_m\\) è il guadagno del motore - \\(\\tau_m\\) è la costante di tempo meccanica del motore.\nQuesto è un sistema del primo ordine tra velocità e tensione di controllo.\n🤔 Domanda popup: Perché l’equazione tra \\(\\theta\\) (posizione) e la tensione di controllo è un sistema del secondo ordine?\nRisposta: L’equazione per \\(\\theta\\) incorpora un ulteriore fattore ‘s’ dovuto alla relazione integrale tra velocità e posizione.\nIl modello motorio compreso tra \\(e_c\\) e \\(\\theta\\) è dato da:\n\\[\n\\frac{\\theta}{e_c} = \\frac{K_m}{s\\big(\\tau_m s + 1\\big)}\n\\]\nE questo è lo stesso del motore DC controllato da armatura (che è un modello di secondo ordine).\n\n\nComprendere la tensione di fase di controllo\n\n\\(e_c\\) o la tensione di fase di controllo è tipicamente un segnale a bassa frequenza.\n\n\n\n\n\n\n\nConsiderare la situazione in cui la tensione di fase di controllo potrebbe essere direttamente un segnale modulato ad alta frequenza.\n\nIn questo caso l’input è \\(e_m\\) e l’output è \\(\\theta\\). Vediamo qual è la funzione di trasferimento tra di loro.\n\n\nBarra laterale: comprensione dell’ingresso del motore CA: segnale modulato dalla portante\nPer comprendere l’input al motore consideriamo un sistema di feedback:\n\n\n\n\n\n\nL’ingresso al motore è la tensione di fase di controllo \\(e_c\\). Ciò tuttavia dipende dal dispositivo (ad esempio un amplificatore) tra la giunzione sommatrice e il motore.\nLa tensione di fase di controllo \\(e_c\\) dipende dal ‘Dispositivo’. Questo dispositivo potrebbe produrre un segnale a bassa frequenza esattamente come abbiamo discusso finora.\nSupponiamo invece che questo dispositivo produca un Segnale Modulato a Portante e questo sia il segnale utilizzato come tensione di fase di controllo \\(e_c\\)\n\nSe il segnale in ingresso è quello riportato di seguito (segnale modulato in ampiezza):\n\nL’effettiva informazione di controllo è incorporata nell’inviluppo del segnale modulato.\nLa frequenza portante (come 50 Hz, 400 Hz, 1000 Hz) è principalmente un aspetto operativo e dipende dalla progettazione del motore. È la frequenza operativa del motore. Dipende da cosa ci ha fornito il produttore.\nLa frequenza operativa (la frequenza portante) può essere selezionata ad esempio in base alla frequenza del rumore. Se sappiamo che il motore funzionerà in un ambiente in cui sono presenti disturbi a bassa frequenza, dovrei scegliere una frequenza portante alta. In ambienti come i sistemi aeronautici, c’è abbondante rumore a bassa frequenza. L’uso di un motore ad alta frequenza come 1000 Hz aiuta a ridurre l’impatto di questo rumore. Per le applicazioni a terra in genere utilizziamo una frequenza più bassa. Dipende dall’applicazione.\n\nIn questo caso il modello matematico del sistema può essere assunto come il rapporto tra la velocità (\\(\\omega\\)) o la posizione (\\(\\theta\\)) - uscita - e l’inviluppo del segnale modulato della portante - ingresso -.\nIn sintesi:\n\nse il segnale di ingresso è direttamente un segnale a bassa frequenza e viene inviato al motore CA tramite un modulatore, quel segnale a bassa frequenza verrà preso come ingresso per il motore\nse il segnale di ingresso al motore è un segnale modulato con portante, allora il nostro ingresso dal punto di vista del controllo è l’inviluppo del segnale modulato. Questo è ciò che trasporta l’informazione, ad esempio rappresenta la differenza tra la posizione comandata e la posizione effettiva.\n\n\nCollegamento al modello matematico\nPer ribadire, il modello matematico che utilizziamo, \\(\\frac{\\omega}{e_c} = \\frac{K_m}{\\tau_m s+ 1}\\), si concentra sulla relazione tra la velocità del motore (\\(\\omega\\)) e l’informazione- che trasporta il segnale \\(e_c\\). La frequenza del segnale portante non è di primaria importanza per le nostre applicazioni di controllo.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time values\nt = np.linspace(0, 10, 1000)\n\n# Define the error signal (decreasing oscillating signal starting from its maximum)\nerror_signal = (1 / (1 + 0.2 * t)) * np.sin(2 * np.pi * .2 * t + np.pi/2)  # Added phase shift of pi/2\n\n# Define the carrier signal\nomega_c = 2 * np.pi * 5  # carrier frequency (for example, 10Hz)\ncarrier_signal = np.cos(omega_c * t)\n\n# Modulate the carrier using the error signal\nmodulated_signal = error_signal * carrier_signal\n\n# Plot\nplt.figure(figsize=(6, 3))\n\n# Plot the modulated signal\nplt.subplot(1, 1, 1)\nplt.plot(t, modulated_signal, label='Modulated Signal', color='red')\nplt.title(r'Amplitude Modulated Signal $e_m$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the positive envelope (absolute value of the error signal)\nplt.plot(t, np.abs(error_signal), '--', label='Positive Envelope', color='blue', linewidth=1.5)\n\n# Plot the negative envelope (negative of the absolute value of the error signal)\nplt.plot(t, -np.abs(error_signal), '--', label='Negative Envelope', color='green', linewidth=1.5)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nSegnale modulato della portante (CMS) - ulteriori commenti\nIl concetto di segnale modulato con portante (CMS) emerge spesso nel contesto dei sistemi di comunicazione e controllo, in particolare quando dobbiamo trasmettere o utilizzare un segnale che, di per sé, non è adatto alla trasmissione diretta o all’applicazione a causa di alcune limitazioni.\nSegnale modulato della portante (CMS): in sostanza, la modulazione comporta la modifica di alcuni aspetti di un’onda portante a frequenza più alta in proporzione al segnale del messaggio a frequenza più bassa che si desidera inviare. L’onda portante, da sola, non trasporta alcuna informazione utile. Sono le modifiche apportate ad esso (modulazione) dal segnale del messaggio che trasmette l’informazione desiderata.\nPerché modulare?: Consideriamo un’analogia. Immagina di voler mandare una barchetta di carta attraverso un grande stagno. Se lo metti semplicemente nell’acqua, potrebbe non andare lontano. Ma se lo posizioni sopra una barca a motore più grande (il trasportatore), può viaggiare efficacemente attraverso lo stagno. In questa analogia, la barchetta di carta è come il segnale a bassa frequenza e la barca più grande è il segnale portante.\nSegnale a bassa frequenza rispetto a CMS: in molte applicazioni pratiche, i segnali a bassa frequenza sono difficili da trasmettere, applicare o rilevare per diversi motivi: - Potrebbero non indurre efficacemente una risposta in alcuni sistemi. - Potrebbero essere più suscettibili alle interferenze o al rumore. Modulando un segnale portante con il segnale a bassa frequenza, possiamo superare queste limitazioni.\nRelazione con i motori: se parli dell’utilizzo del CMS nel contesto del controllo motorio, il concetto può essere visto come simile alla modulazione di larghezza di impulso (PWM). Con PWM, una portante ad alta frequenza (un’onda quadra) viene modulata in modo tale che il suo ciclo di lavoro (la proporzione del tempo in cui è “acceso” rispetto a “spento”) rappresenta il segnale di controllo desiderato, spesso per controllare la velocità o la posizione del motore .\nPer i motori, ciò presenta vantaggi: - Permette un controllo più efficiente e rapido. - La natura ad alta frequenza della portante garantisce un trasferimento efficiente di energia e può ridurre l’usura dei componenti del motore. - La potenza effettiva applicata al motore può essere controllata con precisione semplicemente variando il ciclo di lavoro.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#rilevatore-di-errori-ca-e-trasmettitori-trasformatori-sincroni-per-sistemi-di-controllo-della-posizione",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#rilevatore-di-errori-ca-e-trasmettitori-trasformatori-sincroni-per-sistemi-di-controllo-della-posizione",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Rilevatore di errori CA e trasmettitori-trasformatori sincroni per sistemi di controllo della posizione",
    "text": "Rilevatore di errori CA e trasmettitori-trasformatori sincroni per sistemi di controllo della posizione\nUn componente chiave necessario per comprendere ed eseguire i sistemi di controllo della posizione è il rilevatore di errori CA. Nel discorso presentato, il rilevatore di errore CA viene spiegato attraverso l’introduzione di due dispositivi: il trasmettitore sincronizzato e il trasformatore di controllo sincronizzato.\n\nTrasmettitore sincronizzato\nIl trasmettitore è un dispositivo che trasmette un segnale elettrico corrispondente all’angolo di rotazione del suo albero.\nDall’esterno, un trasmettitore (o ricevitore) sincronizzato assomiglia molto a un normale piccolo motore\n\n\n\n\n\nFigura da APPARECCHIATURA DI CONTROLLO AUTOMATICO USNavy\n\nUn trasmettitore sincronizzato è un trasmettitore CA. È costruito con un rotore a forma di manubrio, attraverso il quale viene fornita una tensione CA tramite anelli collettori. Lo statore ha tre avvolgimenti, mostrati schematicamente come S1, S2 e S3.\nI tre avvolgimenti, con distribuzione spaziale di 120 gradi, permettono di codificare la posizione del rotore in modo rappresentabile attraverso tre diverse tensioni. Non stai cambiando la tensione CA, cambi la posizione del rotore. Quando si modifica la posizione del rotore, le tre tensioni sui tre terminali cambiano di conseguenza.\nLa tensione CA (una tensione fissa) fornita al rotore produce un flusso magnetico che, quando collegato agli avvolgimenti dello statore, induce una forza elettromotrice ai terminali 1, 2 e 3. Le tensioni a questi terminali trasportano l’informazione della posizione del rotore , rappresentato come theta (\\(\\theta\\)).\n\n\n\n\n\n\nRispetto allo schema sopra, prendendo \\(S_2\\) come asse di riferimento: - Quando \\(\\theta=0\\), il flusso massimo (cioè la tensione massima) è su \\(S_2\\) con valore: $ e_{S_2n} = KE_r(_c t) $, dove \\(K\\) è una costante che regola l’ampiezza secondo necessità. - Quando \\(\\theta=0\\), il flusso (cioè la tensione) su \\(S_2\\) vale: \\(0\\)\nIn generale, la relazione matematica tra la posizione del rotore (\\(\\theta\\)) e la tensione (rispetto al neutro \\(n\\)) può essere espressa come:\n\\[\n\\begin{align}\ne_{S_2n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta)\\\\\ne_{S_1n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta -120^o)\\\\\ne_{S_3n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta -240^o)\n\\end{align}\n\\]\npoiché non abbiamo accesso a neutral, abbiamo:\n\\[\n\\begin{align}\ne_{S_1S_2} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta+240^o)\\\\\ne_{S_2S_3} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta+120^o)\\\\\ne_{S_3S_1} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta)\n\\end{align}\n\\]\nPossiamo calcolare l’espressione precedente come:\n\\[\ne_{S_1S_2} = e_{S_1n} + e_{nS_2} = e_{S_1n} - e_{S_2n}\n\\]\nCon riferimento alle equazioni (4-6):\n\nquando \\(\\theta=0\\), \\(e_{S_3S_1} =0\\) e il rotore è nella sua posizione null (posizione di riferimento del rotore).\nquando il rotore è nella posizione nulla, la tensione massima è sull’avvolgimento \\(S_2\\) e la tensione tra \\(S_3\\) e \\(S_1\\), \\(e_{S_3S_1} =0\\)\n\nSi noti inoltre che cambia solo l’ampiezza delle tensioni. Questo è un dispositivo monofase. Le tre tensioni sono in fase.\nUn trasmettitore sincronizzato ha come ingresso la rotazione del suo albero (\\(\\theta\\)) e come uscita le tre tensioni\n\n\nTrasformatore di controllo sincronizzato\nNell’ambito del sistema di controllo della posizione, un altro dispositivo essenziale è il trasformatore di controllo del sincronismo. Questo dispositivo condivide molte somiglianze con il trasmettitore sincronizzato, ad eccezione della costruzione del rotore. Il rotore in questo trasformatore è più cilindrico. Questa costruzione garantisce un’impedenza costante vista da un dispositivo di condizionamento del segnale allegato, garantendo che questa impedenza rimanga inalterata dalla posizione del rotore.\nSe il rotore non è cilindrico, l’impedenza vista dal dispositivo di condizionamento del segnale è funzione della posizione del rotore.\n\n\n\n\n\nSi noti che nulla vieta di utilizzare un rotore cilindrico anche nel trasmettitore Synchro sopra descritto. Tuttavia in quel caso non era un requisito e l’utilizzo di un rotore con bilanciere probabilmente è meno costoso.\nIl dispositivo di condizionamento del segnale elabora l’uscita dal trasformatore di controllo sincronizzato e aziona un motore. Questo motore controlla la posizione del rotore nel trasformatore di controllo sincronizzato. I due avvolgimenti dello statore del trasmettitore sincronizzato e del trasformatore di controllo sincronizzato sono interconnessi, con la posizione del rotore di uno che rappresenta il riferimento e l’altro la posizione controllata.\nNel trasformatore di controllo, l’uscita del dispositivo di condizionamento del segnale va a un motore che controlla la posizione del rotore cilindrico.\nL’ingresso per l’intero sistema, composto sia da un trasmettitore che da un trasformatore, è la differenza dei movimenti dei due alberi \\(\\theta_R\\) e \\(\\theta_C\\), e l’uscita è il segnale all’ingresso del condizionatore , che è proporzionale alla differenza delle due posizioni dell’albero.\n\nRichiamo della coppia di potenziometri\nPotresti ricordare la nostra discussione su una coppia di potenziometri. Illustrare:\n\n\n\n\n\nDal nostro studio, il segnale \\(e\\) può essere rappresentato come:\n\\[\ne = K_p\\big(\\theta_R - \\theta_C\\big)\n\\]\nqui \\(K_p\\) è una costante potenziometrica e l’espressione enfatizza la differenza tra le due posizioni dell’albero.\n\n\n\nMeccanica della coppia sincronizzata\nLa coppia sincronizzata funziona in modo simile, ma gestisce specificamente la corrente alternata e si concentra sui segnali ad alta frequenza.\nContinuiamo a fare riferimento alla nostra coppia Synchro:\n\n\n\n\n\n\n\\(\\theta_R\\) indica la posizione di riferimento.\n\\(\\theta_C\\) simboleggia la posizione controllata.\n\nIl nostro obiettivo finale è sfruttare questo dispositivo come rilevatore di errori, ottenendo un segnale che rappresenti la differenza (o errore) tra \\(\\theta_R\\) e \\(\\theta_C\\).\nSe disponiamo di questo, abbiamo in effetti tutto ciò di cui abbiamo bisogno per completare il nostro ciclo di feedback del controllo della posizione, dove \\(\\theta_R\\) è l’input e \\(\\theta_C\\) è l’output che vogliamo controllare.\n\n\nTrasmettitore sincronizzato funzionante\nConsiderando il trasmettitore sincronizzato, immagina il seguente schema di flusso:\n\n\n\n\n\nIl trasmettitore sincronizzato invia uno schema di flusso specifico in base alla sua posizione. Il trasformatore di controllo sincronizzato riceve uno schema di flusso simile. L’angolo tra il trasmettitore sincronizzato e il trasformatore di controllo sincronizzato è rappresentato dagli angoli θ (per il trasmettitore) e α (per il trasformatore di controllo).\nDato che la forza elettromagnetica indotta a causa di questo modello di flusso è diretta al trasformatore di controllo del sincronismo, possiamo concludere che il modello di flusso in quest’ultimo sarà identico.\nCon una determinata posizione del rotore del trasformatore di controllo del sincronismo, la tensione indotta nel suo rotore può essere rappresentata come \\(e\\).\n🤔 Domanda pop-up: Qual è la tensione indotta nel rotore del trasformatore di controllo quando il trasmettitore sincronizzato è in posizione nulla?\nRisposta: La tensione indotta è zero. Quando il trasmettitore sincronizzato è nella sua posizione nulla o zero, il modello di flusso si allinea in modo tale che non venga indotta alcuna tensione nell’avvolgimento del rotore del trasformatore di controllo sincronizzato.\n\n\nInduzione di tensione al cambio di posizione\nSe il trasmettitore sincronizzato ruota di \\(\\theta\\) e il rotore del trasmettitore di controllo ruota di \\(\\alpha\\), l’angolo netto tra il trasmettitore e l’asse del trasformatore di controllo è \\(90-\\theta-\\alpha\\).\nIn questo caso la tensione indotta \\(e_m\\) è data da:\n\\[\ne_m = K^{'}E_R\\cos(90-\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nQui, quando la differenza angolare tra \\(\\theta\\) e \\(\\alpha\\) è di 90 gradi, chiamiamo lo stato operativo della coppia sincronizzata come “posizione zero elettrico”. In questa posizione la tensione indotta nell’avvolgimento del rotore sarà zero.\nE questo è ciò di cui abbiamo parlato anche prima (vedi equazioni 1-6).\nIn altre parole:\nSe il rotore del trasmettitore sincronizzato ruota di un angolo \\(\\theta\\) e il rotore del trasformatore di controllo sincronizzato ruota di un angolo \\(\\alpha\\), l’angolo netto tra gli assi del trasmettitore e il trasformatore di controllo è dato da $90−+$. La tensione \\(e_m\\) indotta nel trasformatore di controllo in queste condizioni è:\n\\[\ne_m = K^{'}E_R\\cos(90-\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nDove: - \\(K^{'}\\) è una costante. - \\(E_R\\) è la tensione relativa al trasmettitore. - \\(\\omega_c\\) è la frequenza operativa.\nSemplificazione: l’espressione precedente può essere semplificata in:\n\\[\ne_m = K^{'}E_R\\sin(\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nDa questa rappresentazione risulta evidente che la tensione indotta \\(e_m\\) è funzione della differenza degli angoli \\(\\theta\\) e \\(\\alpha\\).\n\n\nPer sistemi di controllo del feedback\nNel contesto di un sistema di controllo feedback, la differenza tra gli angoli \\(\\theta\\) e \\(\\alpha\\) rappresenta l’errore \\(\\phi\\).\nNon appena \\(\\theta - \\alpha = \\phi\\) è diverso da zero, un buon sistema di controllo proverà a riportarlo a zero. Questo perché un buon sistema di controllo cercherà di minimizzare questo errore.\nNel contesto di un sistema di controllo feedback, la differenza tra gli angoli \\(\\theta\\) e \\(\\alpha\\) sarà piccola (designata come \\(\\phi\\)). Questo perché un buon sistema di controllo cercherà di minimizzare questo errore.\nQuando questa differenza è piccola, \\(\\sin(\\theta-\\alpha) \\approx \\phi\\) e l’espressione per \\(e_m\\) possono essere approssimati come:\n\\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t)\n\\]\nCiò semplifica la complessa relazione sinusoidale non lineare trasformandola in lineare, soprattutto se si considera il dispositivo come un rilevatore di errori in un meccanismo di feedback.\nNota che questa è un’approssimazione che vale solo se \\(\\phi\\) è piccolo. In un sistema di controllo che cerca attivamente di ridurre \\(\\phi\\) questo è un presupposto ragionevole. Quando la coppia sincrona non fa parte di un sistema di controllo feedback e \\(\\phi\\) può assumere qualsiasi valore, questa ipotesi non è più valida.\n\n\nDerivazione della funzione di trasferimento\nOra rivolgiamo la nostra attenzione alla configurazione input-output del dispositivo.\nDato il modello:\n\\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t)\n\\]\nL’input per il dispositivo è \\(\\phi(t)\\), che rappresenta l’errore tra le posizioni dell’albero di riferimento e l’albero di feedback o controllato.\nL’uscita è \\(e_m\\), disponibile sui terminali del rotore del trasformatore di controllo.\nTuttavia, derivare una funzione di trasferimento per questo sistema è più complicato. La relazione tra \\(e_m\\) e \\(\\phi\\) include un termine \\(\\sin(\\omega_c t)\\), rendendo complessa la rappresentazione matematica (notare che si tratta di un’operazione di modulazione).\nCome abbiamo discusso in precedenza, qui \\(\\omega_c\\) indica la frequenza operativa del dispositivo, che potrebbe essere valori come 50 Hz, 400 Hz o 1000 Hz. Poiché si tratta della frequenza operativa, non fornisce intrinsecamente informazioni sull’errore del sistema.\n\npossiamo scrivere: \\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t) = e_c(t)\\sin(\\omega_c t)\n\\]\n\nche sarà del formato (uscita del rilevatore di errore di sincronizzazione):\n\n\n\n\n\n\nL’errore \\(\\phi(t)\\) è dato da \\(e_c(t)\\), che è l’inviluppo del segnale sopra. Il corriere non contiene alcuna informazione sull’azione di controllo. Se presente solo perché il dispositivo funziona alla frequenza \\(\\omega_c\\).\n\nQuesta realizzazione implica che per un modello matematico dovremmo preoccuparci principalmente dell’inviluppo \\(e_c\\) e non dell’intero output modulato \\(e_m\\). Pertanto, il modello diventa più semplice, trattando \\(\\phi\\) come input e \\(e_c\\) come output.\nE ora possiamo scrivere la funzione di trasferimento del Synchro Error Detector come:\n\\[\n\\frac{E_c(s)}{\\phi} = K_s\n\\]\nQuesta costante \\(K_s\\), nota come sensibilità del rilevatore di errore di sincronizzazione, svolge un ruolo fondamentale nella comprensione del flusso di informazioni nel sistema. Questa costante non dipende dalla frequenza portante.\nQuesta sensibilità, simile alla costante potenziometrica \\(K_P\\) nella coppia di potenziometri, rimane costante indipendentemente dalla frequenza portante.\nPer ribadire, mentre la frequenza portante, \\(\\omega_c\\), è essenziale per il funzionamento del dispositivo, la nostra attenzione analitica è più sull’inviluppo di errore \\(e_c\\) piuttosto che sul segnale modulato \\(e_m\\). Questa distinzione deriva dalla natura dei sistemi di controllo: è l’errore, non la frequenza portante, a fornire informazioni preziose sulle prestazioni del sistema.\n\n\nRappresentazione simbolica del rilevatore di errore di sincronizzazione",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#trasformatore-differenziale-variabile-lineare-lvdt",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#trasformatore-differenziale-variabile-lineare-lvdt",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Trasformatore differenziale variabile lineare (LVDT)",
    "text": "Trasformatore differenziale variabile lineare (LVDT)\nDopo aver compreso il movimento rotatorio del rilevatore di errore di sincronizzazione, possiamo esplorare ulteriormente un dispositivo lineare che dimostra un’azione simile. Questo dispositivo, chiamato Trasformatore differenziale variabile lineare (LVDT), fornisce un segnale di uscita proporzionale al movimento lineare.\nIMMAGINE\nIl funzionamento dell’LVDT è intuitivo. Quando il nucleo è posizionato centralmente, la tensione netta è zero a causa dell’eguale collegamento delle linee di flusso ad entrambe le bobine secondarie (gli avvolgimenti secondari sono in opposizione di fase). Lo spostamento del nucleo in una direzione collega più linee di flusso a una bobina, risultando in una tensione di una polarità specifica. Il movimento opposto inverte la polarità. La polarità e l’ampiezza della tensione indicano rispettivamente la direzione e l’entità dello spostamento del nucleo.\n\npolarità: ti dà la direzione\nmagnitudine: fornisce l’entità dello spostamento\n\nProprio come il dispositivo sincronizzato fornisce un output relativo al movimento angolare, l’LVDT fornisce un output basato sul movimento lineare. La relazione può essere rappresentata come:\n\\[\ne_m = KE_ry(t)\\sin(\\omega_c t)\n\\]\n\n\\(e_m\\) è l’uscita che è un segnale modulato.\n\nAnalogamente alla discussione precedente, ci concentriamo sulla busta \\(e\\), che è\n\\[e=KE_ry(t)=K_sy(t)\\]\nche è la parte che trasporta le informazioni, per costruire il nostro modello matematico (\\(K_s\\) è la sensibilità del dispositivo).",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#tachimetrica",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#tachimetrica",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Tachimetrica",
    "text": "Tachimetrica\nPrendiamoci un momento per osservare da vicino la dinamo tachimetrica. La dinamo tachimetrica è un dispositivo che traduce la velocità di rotazione in un segnale elettrico, comunemente utilizzato per il feedback nei sistemi di controllo del motore.\n\n\n\n\n\nL’ingresso per la dinamo tachimetrica è indicato come \\(\\dot{\\theta}\\).\nLa dinamo tachimetrica ha un avvolgimento di riferimento e accetta come ingresso \\(E_r\\sin(\\omega_c t)\\).\nL’uscita è un segnale modulato, rappresentato come \\(e_m\\) e dipende dalla frequenza \\(\\omega_c\\) (la portante) e \\(\\dot{\\theta}\\) (l’ingresso meccanico al rotore). L’espressione completa per \\(e_m\\) è:\n\\[\ne_m = KE_r\\omega(t)\\sin(\\omega_c t)\n\\]\nQuesto segnale modulato contrasta con l’uscita di una dinamo tachimetrica CC, che era un segnale diretto a bassa frequenza proporzionale alla velocità. L’uscita della dinamo tachimetrica CC era direttamente proporzionale alla velocità, l’uscita era un segnale CC. Tuttavia, la modellazione matematica fornisce una rappresentazione simile per entrambi.\nLa dinamo tachimetrica DC produce un segnale diretto a bassa frequenza proporzionale alla velocità, mentre la dinamo tachimetrica AC produce un segnale modulato.\nIl segnale di errore, \\(e\\), è rappresentato come:\n\\[\ne= K_t \\omega(t)\n\\]\n(simile al motore DC).\nQui è essenziale capire che l’informazione del segnale viene trasportata dall’inviluppo, non dalla portante. Pertanto, si presume che la demodulazione estragga questo inviluppo.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#il-problema-del-controllo",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#il-problema-del-controllo",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Il problema del controllo",
    "text": "Il problema del controllo\nConsideriamo una situazione in cui abbiamo un teleobiettivo pesante. L’obiettivo è controllare con precisione la posizione di questa telecamera. Per raggiungere questo obiettivo, utilizzeremo un motore CA. Per garantire un movimento fluido e preciso, prenderemo in considerazione anche altri dispositivi e meccanismi per aiutare il motore.\n\n\n\n\n\nIl sistema ha i seguenti componenti:\n\nUn treno di ingranaggi per l’ingrandimento della coppia e la riduzione della velocità. Gli ingranaggi primario e secondario hanno rispettivamente i denti \\(N_1\\) e \\(N_2\\).\nUn disturbo, \\(T_W\\), che agisce sul sistema.\nUn motore CA che genera una coppia etichettata come \\(T_M\\) e ha una posizione di \\(\\theta_M\\). Il motore ha due avvolgimenti, un avvolgimento di riferimento con il condensatore di sfasamento e un avvolgimento di fase di controllo che ha il segnale modulato \\(e_m\\). Il segnale modulato dovrebbe essere proporzionale all’errore tra la posizione comandata e la posizione effettiva \\(\\theta_L\\).\nUn cannocchiale che fornisce un segnale di comando \\(\\theta_R\\).\nL’errore \\(\\theta_R - \\theta_L\\) dovrebbe riflettersi attraverso la tensione \\(e_m\\). Ciò si ottiene utilizzando una coppia sincro, comprendente un trasmettitore sincro e un trasformatore di controllo sincro. Il controllo di sincronizzazione è collegato meccanicamente alla fotocamera per leggere la posizione della fotocamera \\(\\theta_L\\). Il trasmettitore sincronizzato è collegato a un cannocchiale che fornisce l’ingresso di riferimento \\(\\theta_R\\).\n\n🤔 Domanda popup: Come diamo il comando? Risposta: Il telescopio fornisce il segnale di riferimento. Un rilevatore di errore di sincronizzazione che misura la differenza tra la posizione comandata e quella effettiva.\n🤔 Domanda popup: Perché è necessario un treno di ingranaggi nel sistema? Risposta: è necessario un treno di ingranaggi per aumentare la coppia perché il motore da solo non può produrre la coppia sostanziale necessaria per ruotare il pesante teleobiettivo.\n\nComprendere la coppia sincronizzata\nLa coppia sincronizzata, composta da un trasmettitore e un trasformatore di controllo, è fondamentale. Il trasmettitore viene influenzato da \\(\\theta_R\\) e il rotore del trasformatore di controllo da \\(\\theta_L\\). Ciò crea un segnale modulato, che è essenzialmente un mix di una frequenza portante costante e un’ampiezza che dipende dall’errore tra \\(\\theta_R\\) e \\(\\theta_L\\).\n\n\nRuolo dell’amplificatore\nPoiché il segnale modulato potrebbe non avere potenza sufficiente per azionare il motore CA, viene introdotto un amplificatore. Migliora la forza del segnale, garantendo che il motore funzioni in modo efficace.\n\n\nSegnali\nCome detto, i segnali in questo caso non necessitano di modulazione o demodulazione. Questo perché sono intrinsecamente compatibili con i dispositivi con cui interagiscono. L’equazione \\(\\theta_R - \\theta_L\\) coinvolge segnali CC e l’uscita del controllo sincronizzato è un segnale modulato che può essere utilizzato per azionare il motore.\nIl dispositivo sincronizzato funge infatti da modulatore. Accetta un segnale DC (\\(\\theta_R - \\theta_C\\)) ed emette un segnale modulato con frequenza \\(\\omega_c\\). Questo segnale viene quindi amplificato da un amplificatore CA per produrre un altro segnale modulato.\nSi noti che la frequenza di riferimento per questi due dispositivi (sincro e motore) deve essere \\(\\omega_c\\) per compatibilità.\n\n\nMotore AC come demodulatore\nIl ruolo del motore CA può essere paragonato a un demodulatore poiché elabora il segnale modulato per produrre una coppia \\(T_M\\) e una posizione (\\(\\theta_M\\)), entrambi segnali CC. Ciò implica che il dispositivo sincronizzato (modulatore) e il motore CA (demodulatore) funzionano in modo armonioso, garantendo che l’ingresso e l’uscita dell’intero sistema rimangano segnali CC.\n\n\nModello matematico e diagramma a blocchi\nSulla base delle discussioni precedenti, per ricavare un modello matematico, rimuoviamo la frequenza portante.\nPer fare ciò, inizieremo con uno schema a blocchi e poi lo ridurremo ad una opportuna funzione di trasferimento.\n\n\n\n\n\nIn particolare, \\(\\theta R\\) viene confrontato con \\(\\theta_L\\) per produrre un segnale di errore. Il segnale risultante subisce varie trasformazioni che coinvolgono costanti come \\(K_s\\), \\(K_A\\) e \\(K_1\\). E infine possiamo includere segnali di disturbo e meccanismi di feedback:\nIl disturbo \\(T_W\\) agisce indirettamente sul motore attraverso un riduttore, provocando un disturbo riflesso di \\(nT_W\\). Allo stesso modo, parametri come \\(J_L\\) e \\(B_L\\) del teleobiettivo, quando riflessi sull’albero del motore, si trasformano in valori equivalenti \\(J\\) e \\(B\\).\nL’obiettivo principale di questo sistema di controllo è che \\(\\theta_L\\) (posizione del teleobiettivo) imiti perfettamente \\(\\theta_R\\) (posizione del telescopio). È auspicabile che non vi siano transitori in questo movimento e l’errore in stato stazionario dovrebbe essere minimo o pari a zero. Questo delinea il problema di progettazione del controllo.\n\n\nProgettazione del controllo\nSi noti che questo diagramma a blocchi include un controller sotto forma di controller proporzionale. Questo è l’amplificatore puro \\(K_A\\). In futuro potrebbe essere sostituito con un controller più avanzato che potrebbe impiegare azioni di controllo proporzionali, integrali, derivate o anche altre azioni avanzate che terranno conto delle specifiche prestazionali desiderate.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#utilizzo-di-un-motore-cc",
    "href": "IT_🇮🇹/ac_hardware_and_case_studies_it.html#utilizzo-di-un-motore-cc",
    "title": "Sistemi di controllo del movimento CA",
    "section": "Utilizzo di un motore CC",
    "text": "Utilizzo di un motore CC\nConsideriamo un sistema di controllo del feedback in cui vogliamo guidare un carico specifico. Possiamo immaginare questo carico come un componente che deve essere azionato da un’entità esterna, ad esempio un motore.\n\n\n\n\n\nI parametri forniti per questo carico sono:\n\nMomento d’inerzia: \\(J_L\\)\nCoefficiente di smorzamento: \\(B_L\\)\nCoppia di disturbo: \\(T_W\\)\nPosizione: \\(\\theta_L\\)\n\n🤔 Domanda popup: Qual è il significato di ciascuno di questi parametri nel determinare il comportamento del carico?\nRisposta: Il momento d’inerzia (\\(J_L\\)) ci dà un’idea della resistenza del carico alle variazioni di movimento. Il coefficiente di smorzamento (\\(B_L\\)) è una misura della forza resistente quando il carico è in movimento. La coppia di disturbo (\\(T_W\\)) è una forza esterna che influenza il carico. La posizione (\\(\\theta_L\\)) ci dice lo stato attuale o la posizione del carico.\nCi sono stati dati due vincoli per il nostro sistema di controllo: - Dobbiamo utilizzare un motore CC e non un motore CA come attuatore. Il motivo è che i motori CC presentano caratteristiche di coppia-velocità lineari e possono gestire una coppia maggiore per una determinata dimensione rispetto a un motore CA. - Invece di un rilevatore di errore potenziometrico, utilizzeremo un rilevatore di errore sincro. Il rilevatore di errore di sincronismo è preferito per la sua migliore risoluzione, linearità, robustezza e assenza di problemi di contatto comunemente riscontrati nei rilevatori di errore potenziometrici.\nDobbiamo determinare come interfacciare il segnale di uscita del trasformatore di controllo sincronizzato con l’armatura del motore CC, dopo l’amplificazione.\n\nVogliamo utilizzare il motore DC come attuatore e la coppia sincronizzata come rilevatore di errori.\nAssumiamo inoltre che il nostro titolare del trattamento sia un titolare del trattamento PD\n\nNello schema seguente, come colleghiamo insieme i componenti?\n\n\n\n\n\n\nCollegamento della coppia sincrona al motore CC:\nPer interfacciare la coppia sincrona al motore DC:\n\nEstrarre l’inviluppo dell’uscita del trasformatore di controllo del sincronismo utilizzando un demodulatore. Questo è fondamentale perché siamo interessati al segnale informativo sull’errore e non al segnale portante.\nAlimentare la busta estratta ad un circuito PD (Proporzionale Derivativo). Questo circuito produrrà un’uscita proporzionale sia all’errore che alla sua derivata.\n\nNota: l’azione PD dovrebbe agire solo sulle informazioni relative all’errore. Dovremmo evitare di prendere la derivata del segnale portante. Vogliamo solo prendere la derivata dell’inviluppo.\nSi noti inoltre che, se non avessimo utilizzato un controller PD, avremmo potuto utilizzare direttamente un amplificatore CA e un raddrizzatore per ottenere direttamente un segnale CC. Ciò tuttavia funzionerebbe solo se non fosse richiesta un’azione derivativa. Se invece è richiesta una derivata, allora la derivata deve essere presa sul segnale informativo.\n\nAmplificare l’uscita del circuito PD utilizzando un amplificatore con amplificazione \\(K_A\\).\nCollegare il segnale amplificato all’ingresso della tensione di armatura \\(e_a\\) del motore CC, che guiderà quindi il carico attraverso il treno di ingranaggi.\nRicollegare l’albero di uscita del motore al trasformatore di controllo sincronizzato per chiudere il circuito di feedback.\n\n\n\n\n\n\n🤔 Domanda popup: Perché è necessario estrarre l’inviluppo dell’uscita del trasformatore di controllo sincronizzato?\nRisposta: La busta contiene le informazioni sull’errore, fondamentali per il feedback. Estraendo l’inviluppo, eliminiamo i componenti non necessari del segnale portante e ci concentriamo solo sul segnale informativo desiderato.\n\nConsiderazioni importanti:\n\nAmplificatore invertente: quando si deriva la funzione di trasferimento per il controller PD Op-Amp, noterai l’introduzione di un segno negativo. Per risolvere questo problema, utilizzare un amplificatore invertente. Ciò garantirà che la funzione di trasferimento rimanga positiva.\nFunzione di trasferimento del demodulatore: Idealmente, la funzione di trasferimento del demodulatore (che estrae l’inviluppo dal segnale modulato) è l’unità (l’ingresso è l’inviluppo e l’uscita è l’inviluppo).\n\n\n\n\nDiagramma a blocchi\n\n\n\n\n\nEd ecco se esplicitiamo lo schema a blocchi del motore DC:",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di controllo del movimento CA"
    ]
  },
  {
    "objectID": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html",
    "href": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html",
    "title": "Comprensione del sistema standard del secondo ordine: riepilogo",
    "section": "",
    "text": "Per prima cosa riassumiamo la nostra precedente discussione sulle varie misure di risposta transitoria e di risposta allo stato stazionario rispetto a un sistema standard del secondo ordine. Ricordiamo il modello del sistema standard del secondo ordine:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_ns + \\omega_n^2}\n\\]\nQui, $ Y(s) $ è l’output nel dominio di Laplace, e $ _n $ e $ $ rappresentano rispettivamente la frequenza naturale e il rapporto di smorzamento.",
    "crumbs": [
      "IT_🇮🇹",
      "Comprensione del sistema standard del secondo ordine: riepilogo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#specifiche-delle-prestazioni-del-sistema",
    "href": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#specifiche-delle-prestazioni-del-sistema",
    "title": "Comprensione del sistema standard del secondo ordine: riepilogo",
    "section": "Specifiche delle prestazioni del sistema",
    "text": "Specifiche delle prestazioni del sistema\n\nFrequenza naturale alta ($ _n $):\nLa frequenza naturale, $ _n $, gioca un ruolo fondamentale nel determinare la velocità di risposta di un sistema. Un $ _n $ più alto porta ad una migliore velocità di risposta, caratterizzata da un tempo di salita più basso ($ t_r \\() e da un tempo di picco ridotto (\\) t_p $). Inoltre, un $ n $ più elevato contribuisce a una maggiore precisione in stato stazionario, indicato come $ e{ss} $. Tuttavia, è importante notare che il valore di $ _n $ è soggetto a limitazioni imposte dalla larghezza di banda del sistema e dai vincoli hardware. Ad esempio, il raggiungimento di un $ _n $ elevato può richiedere un guadagno dell’amplificatore significativamente elevato, che a sua volta può portare a problemi di saturazione. Ciò evidenzia la necessità di un’attenta progettazione dell’hardware, inclusa l’implementazione di filtri in grado di mitigare i problemi legati al rumore e alle limitazioni hardware.\n\n\nRegolazione del rapporto di smorzamento ($ $):\nIl rapporto di smorzamento, $ $, è l’altro parametro critico da considerare dopo aver deciso $ _n $. $ $ esercita un’influenza significativa sul tempo di salita, sul superamento e sull’errore di stato stazionario del sistema. Un valore inferiore di $ $ si traduce generalmente in un tempo di salita più rapido, anche se l’impatto potrebbe non essere molto pronunciato nell’intervallo di valori generalmente considerati per $ $. Inoltre, un $ $ inferiore porta a un tempo di picco ridotto e migliora l’errore di stato stazionario in risposta agli ingressi di rampa. Tuttavia, è fondamentale riconoscere che un $ $ inferiore si traduce anche in un superamento del picco più elevato e avvicina il sistema all’instabilità.\nLa relazione tra $ $ e il tempo di assestamento normalizzato ($ _n t_s $) è complessa e non lineare. Il minimo $ _n t_s $ viene raggiunto a $ = 0,68 $ per una fascia di tolleranza del 5% e $ = 0,8 $ per una fascia di tolleranza del 2%. Abbiamo osservato che la diminuzione di $ $ può portare ad un aumento del tempo di assestamento. È essenziale comprendere che il tempo di salita da solo non definisce completamente la velocità di risposta; anche il tempo di assestamento è un fattore cruciale. Il compromesso tra questi parametri deve essere risolto in base ai requisiti specifici dell’applicazione. È interessante notare che l’aumento di $ $ oltre 0,68 per una fascia di tolleranza del 5%, o oltre 0,8 per una fascia di tolleranza del 2%, non produce vantaggi, poiché si traduce solo in un sistema più lento con prestazioni ridotte sia nel tempo di assestamento che in quello di salita. tempo. Per un’analisi dettagliata, fare riferimento al grafico ’Tempo di assestamento normalizzato ($ _n t_s \\() vs Rapporto di smorzamento (\\) $)’ nel taccuino intitolato ‘19_Design_of_feedback_control’ e riportato di seguito.\n\n\n\n\n\n\n\nRiepilogo\n\nAlta frequenza naturale (\\(\\omega_n\\)):\n\nPorta a una maggiore velocità di risposta.\nRiduce il tempo di salita (\\(t_r\\)) e il tempo di picco (\\(t_p\\)).\nMigliora la precisione in stato stazionario (\\(e_{ss}\\)).\nLimitato da:\n\nConsiderazioni sulla larghezza di banda.\nFunzionalità hardware.\n\nSfide:\n\nUn \\(\\omega_n\\) elevato potrebbe richiedere un guadagno dell’amplificatore elevato.\nPotenziali problemi: problemi di saturazione.\n\nSoluzioni:\n\nProgettazione hardware adeguata.\nUtilizzo di filtri per mitigare il rumore e le limitazioni hardware.\n\n\nRegolazione del rapporto di smorzamento (\\(\\zeta\\)):\n\nInfluisce sul tempo di salita, sul superamento e sull’errore di stato stazionario.\nUn valore inferiore di \\(\\zeta\\) porta a:\n\nTempo di salita più rapido (sebbene non significativamente oltre i tipici intervalli \\(\\zeta\\)).\nOrario di punta inferiore.\nMiglioramento dell’errore di stato stazionario per gli ingressi di rampa.\nMaggiore superamento del picco e maggiore prossimità all’instabilità.\n\nRelazione complessa con \\(\\omega_n t_s\\) (tempo di assestamento):\n\nMinimo \\(\\omega_n t_s\\) osservato a:\n\n\\(\\zeta = 0,68\\) per la fascia di tolleranza del 5%.\n\\(\\zeta = 0,8\\) per la fascia di tolleranza del 2%.\n\n\nConsiderazioni sui tempi di assestamento:\n\nDiminuendo \\(\\zeta\\) si può aumentare il tempo di assestamento.\nIl tempo di salita non è l’unico fattore determinante della velocità di risposta; anche il tempo di assestamento è cruciale.\n\nRisoluzione dei conflitti specifici dell’applicazione:\n\nScegli \\(\\zeta\\) in base alla necessità dell’applicazione di bilanciare il tempo di salita e il tempo di sedimentazione.\n\nOltre determinati punti (\\(\\zeta &gt; 0,68\\) per tolleranza del 5%, \\(\\zeta &gt; 0,8\\) per tolleranza del 2%):\n\nPorta ad un sistema lento.\nInfluisce negativamente sia sul tempo di assestamento che sul tempo di salita.\nFare riferimento al grafico “Tempo di assestamento normalizzato (\\(\\omega_n t_n\\)) rispetto al rapporto di smorzamento (\\(\\zeta\\))” nel taccuino “19_Design_of_feedback_control” per approfondimenti dettagliati.\n\n\n\n\n\nIntervallo del rapporto di smorzamento (\\(\\zeta\\)) e considerazioni chiave\n\nNorme di settore per $ $:\n\nIntervallo generale: nelle pratiche standard del settore, $ $ è solitamente impostato tra 0,4 e 0,7, in particolare quando l’utente non fornisce criteri di prestazione quantitativi specifici.\n\n\n\nPersonalizzazione per un’elevata precisione statica:\n\nRelazione dell’errore in stato stazionario: Considerando l’equazione $ e_{ss} = $, ottenere un’elevata precisione statica implica:\n\n**Massimizzare $ _n $**: è preferibile un $ _n $ più alto, che potrebbe richiedere l’incorporazione di hardware specializzato per gestire i requisiti di prestazioni più elevate.\nMinimizzare $ $: Si desidera un $ $ più piccolo. In alcune applicazioni specifiche, un valore pari a $ = 0,1 $ può essere considerato accettabile. Sebbene ciò porti a un sistema con oscillazioni elevate e prestazioni transitorie inferiori, offre una maggiore precisione statica. Tuttavia, è fondamentale notare che valori così bassi di $ $ portano il sistema più vicino all’instabilità, rendendolo più sensibile alle variazioni dei parametri e influenzandone la robustezza.\n\n\n\n\nApplicazioni specializzate:\n\nEsempio - Sistemi di controllo di bracci robotici: In applicazioni come bracci robotici, un valore $ $ più alto, vicino a 1, potrebbe essere più adatto. Ciò garantisce un movimento più lento ma più controllato, evitando oscillazioni che potrebbero disturbare il percorso del braccio nel suo ambiente operativo.\n\n\n\nValori $ $ tipici per applicazioni generali:\n\nIntervallo preferito: Per la maggior parte delle applicazioni, il focus rimane all’interno dell’intervallo $ 0,4 &lt; &lt; 0,7 $, sebbene possano esserci lievi deviazioni da questi limiti in base a requisiti specifici.\n\n\n\nConsiderazioni sulla frequenza naturale ($ _n $):\n\nDipendenza dall’hardware del sistema: l’intervallo fattibile per $ _n $ dipende fortemente dall’hardware del sistema e dalla sua configurazione. A differenza di $ $, non esiste un intervallo standard per $ _n $ poiché varia in modo significativo in base alle caratteristiche fisiche e operative del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Comprensione del sistema standard del secondo ordine: riepilogo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#traduzione-delle-specifiche-prestazionali",
    "href": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#traduzione-delle-specifiche-prestazionali",
    "title": "Comprensione del sistema standard del secondo ordine: riepilogo",
    "section": "Traduzione delle specifiche prestazionali",
    "text": "Traduzione delle specifiche prestazionali\nLa traduzione delle specifiche prestazionali in requisiti dei poli a circuito chiuso è un passaggio fondamentale nella progettazione del sistema di controllo. Questo processo implica determinare dove posizionare i poli della funzione di trasferimento ad anello chiuso nel piano complesso per soddisfare i criteri di prestazione desiderati come superamento, tempo di salita, tempo di assestamento ed errore di stato stazionario.\nLa funzione di trasferimento ad anello chiuso per un sistema standard del secondo ordine è data da:\n\\[ T(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\ndove $ $ è il rapporto di smorzamento e $ _n $) è la frequenza naturale.\nI poli di questa funzione di trasferimento sono soluzioni dell’equazione caratteristica:\n\\[ s^2 + 2\\zeta\\omega_n s + \\omega_n^2 = 0 \\]\nquali sono:\n\\[ s_{1,2} = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1} \\]\n\n\n\n\n\nDomanda pop-up: Qual è la regione nel piano s per i poli ad anello chiuso dati i requisiti per \\(\\omega_n\\) e \\(\\zeta\\) che abbiamo specificato?\nRisposta:\nPer determinare la regione ideale nel piano s per i poli a circuito chiuso in base a valori specifici di frequenza naturale ($ _n \\() e rapporto di smorzamento (\\) $), dobbiamo considerare entrambi questi parametri e il modo in cui influenzano il la risposta del sistema. Ecco una ripartizione dell’argomento utilizzando il testo fornito:\n\n1. Stabilire un intervallo per la frequenza naturale ($ _n $):\n\n**Minimo $ _n $**: dovrebbe esserci un valore minimo per $ _n $ per evitare che il tempo di salita diventi troppo grande. Questo può essere visualizzato come un cerchio nel piano s con un raggio pari a questo valore minimo $ _n $, indicato come $ _n^1 $.\n**Massimo $ _n $**: il limite superiore di $ _n $ è limitato dalle capacità hardware e da considerazioni sul rumore. Questo può essere rappresentato da un altro cerchio con un raggio di $ _n^2 $.\n\n\n\n2. Considerando il rapporto di smorzamento ($ $):\n\nIntervallo di $ $: In questo caso, consideriamo i valori di $ $ pari a 0,4 e 0,7. Questi valori determinano l’angolo formato dalla linea dall’origine al polo con l’asse reale negativo. Gli angoli possono essere calcolati come $ ^{-1}(0,4) $ e $ ^{-1}(0,7) $.\n\n\n\n3. Regione ideale per i poli a circuito chiuso:\n\n**Combinazione di $ _n $ e $ $**: la regione ideale per i poli a circuito chiuso è dove queste due considerazioni si intersecano. Nello specifico, i poli dovrebbero trovarsi all’interno di un settore definito dagli angoli corrispondenti a $ = 0,4 $ e $ = 0,7 $ e tra i cerchi che rappresentano i valori minimo e massimo $ _n $.\nSimmetria nel piano S: data la natura simmetrica del piano S, nella metà inferiore del piano esisterebbe un punto corrispondente che riflette la posizione polare.\nCaratteristiche della regione: questa regione, delimitata dalle curve rosse (che rappresentano le considerazioni sulla frequenza naturale) e dalle curve verdi (che rappresentano le considerazioni sullo smorzamento), è dove i poli a circuito chiuso del sistema dovrebbero idealmente essere posizionati per un sistema standard con due poli.\n\nPer riassumere, per applicazioni generali, i poli a circuito chiuso di un sistema dovrebbero idealmente essere posizionati all’interno di una regione specifica nel piano s. Questa regione è definita dai valori minimo e massimo della frequenza naturale ($ _n \\() ed entro i limiti angolari stabiliti dai rapporti di smorzamento specificati (\\) $). Questo posizionamento garantisce una risposta del sistema equilibrata, considerando sia la velocità di risposta (influenzata da $ _n $) sia il livello di superamento e stabilità (influenzato da $ $). Questo è mostrato nella figura qui sotto.",
    "crumbs": [
      "IT_🇮🇹",
      "Comprensione del sistema standard del secondo ordine: riepilogo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#gestione-di-sistemi-non-standard-nellingegneria-dei-controlli",
    "href": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#gestione-di-sistemi-non-standard-nellingegneria-dei-controlli",
    "title": "Comprensione del sistema standard del secondo ordine: riepilogo",
    "section": "Gestione di sistemi non standard nell’ingegneria dei controlli",
    "text": "Gestione di sistemi non standard nell’ingegneria dei controlli\nFinora la nostra discussione si è concentrata su un sistema standard del secondo ordine, rappresentato dalla funzione di trasferimento:\n\\[ Y(s) / R(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nTuttavia, i sistemi del mondo reale spesso si discostano da questo modello standard. Possono avere più di due poli, introdurre zeri o avere altre complessità. La parte successiva del nostro corso esplorerà come gestire queste variazioni.\n\nSistemi di gestione con uno zero\n\n1. Introduzione di uno Zero nel Sistema\n\nIn alcuni sistemi, in particolare quelli che utilizzano il controllo proporzionale-derivativo (PD), nella dinamica del sistema viene introdotto uno zero.\nAd esempio, applicando il controllo PD a un sistema del secondo ordine si aggiunge uno zero alla funzione di trasferimento.\n\n\n\n2. Funzione di trasferimento modificata\n\nLa nuova funzione di trasferimento, in presenza di uno zero, può essere rappresentata come: \\[ \\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2 (s + z)}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\] dove $ s=-z $ è lo zero del sistema.\nVogliamo capire gli effetti dello zero sul transitorio della risposta.\n\n\n\n3. Normalizzazione della funzione di trasferimento\n\nPer facilitare l’analisi, normalizziamo la funzione di trasferimento in modo che il valore in stato stazionario di $ Y $ per un input a gradino diventi 1. Ciò si ottiene moltiplicando la funzione di trasferimento per un fattore di $ 1/z $. Ciò non pregiudica la dinamica che vogliamo studiare.\nLa funzione di trasferimento normalizzata diventa: \\[ \\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{z} \\cdot \\frac{(s + z)}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\npossiamo riscriverlo come: \\[ Y(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}R(s) + \\frac{1}{z} \\cdot \\frac{ s\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}R(s) \\]\nSe scriviamo la funzione di trasferimento in questo modo notiamo:\n\nla parte sinistra è la funzione di trasferimento standard del secondo ordine\nla parte destra è la derivata della funzione di trasferimento del secondo ordine (moltiplicata per un fattore di scala)\n\n\n\n\n4. Effetto sulla risposta transitoria\n\nL’introduzione di uno zero influenza la risposta transitoria del sistema.\nInizialmente, la componente derivativa (dovuta allo zero) è ampia e ha un impatto significativo sulla prima parte della risposta.\nL’effetto complessivo dipende dalla posizione dello zero. Uno zero più vicino all’origine ha un effetto più pronunciato rispetto a uno più lontano nel semipiano sinistro.\n\nPer illustrare l’effetto dell’aggiunta di uno zero sulla risposta transitoria di un sistema di controllo e per confrontarlo con la risposta standard del sistema di secondo ordine, possiamo utilizzare la libreria dei sistemi di controllo di Python. Di seguito è riportato un frammento di codice Python che esegue questa attività. Il codice genera un grafico che mostra la risposta di un sistema standard del secondo ordine e del sistema modificato con uno zero aggiuntivo, entrambi soggetti a un input a gradino unitario.\n\n\"\"\"\n- 'omega_n' and 'zeta' are the natural frequency and damping ratio of the system, respectively.\n- 'zero_position' is the position of the additional zero in the s-plane.\n- 'system_standard' represents the standard second-order system.\n- 'system_zero_added' is the system with an additional zero.\n- The step responses of both systems are computed using ctl.step_response.\n- The responses are then plotted for comparison.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System Parameters\nomega_n = 1  # Natural frequency\nzeta = 0.3   # Damping ratio\n\n# Position of the zero - change this to see the effects of the zero on the response\nzero_position = -0.5  \n\n# Define the standard second-order system\nnum_standard = [omega_n**2]\nden_standard = [1, 2*zeta*omega_n, omega_n**2]\nsystem_standard = ctl.TransferFunction(num_standard, den_standard)\nprint(system_standard)\n\n# Define the system with an additional zero\nnum_zero_added = [1, -zero_position]\nden_zero_added = 1\nsystem_zero_added = 1/(-zero_position)*ctl.TransferFunction(num_zero_added, den_zero_added) * system_standard\nprint(system_zero_added)\n\n# Time range for the response\nt = np.linspace(0, 20, 500)\n\n# Compute the step responses\nt_standard, y_standard = ctl.step_response(system_standard, T=t)\nt_zero_added, y_zero_added = ctl.step_response(system_zero_added, T=t)\n\n# Unit Step Reference (Constant value of 1 across the time range)\nunit_step = np.ones_like(t_standard)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_standard, y_standard, label='Standard Second-Order System')\nplt.plot(t_zero_added, y_zero_added, label='System with Zero Added', linestyle='--')\nplt.plot(t, unit_step, label='Unit Step Input', color='red', linestyle='-', linewidth=3)\n\nplt.title('Comparison of Step Response with Unit Step Input')\n\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n       1\n---------------\ns^2 + 0.6 s + 1\n\n\n    2 s + 1\n---------------\ns^2 + 0.6 s + 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nComprendere la risposta transitoria con l’aggiunta di uno zero:\n\nRisposta del sistema standard di secondo ordine:\n\nLa risposta transitoria di un sistema standard del secondo ordine (senza zero) mostra tipicamente un certo tempo di salita, superamento e tempo di assestamento, a seconda del rapporto di smorzamento ($ \\() e della frequenza naturale (\\) _n $).\n\nEffetto dell’aggiunta di una componente derivativa (Zero):\n\nL’aggiunta di uno zero al sistema aggiunge effettivamente una componente derivativa alla risposta.\nInizialmente, quando la risposta cambia rapidamente, la derivata della risposta (pendenza) è grande. Ciò porta ad un effetto significativo sulla parte iniziale della risposta transitoria dovuta allo zero.\nQuando la risposta inizia a stabilizzarsi e i cambiamenti diventano meno drastici, la derivata (pendenza) diventa più piccola. Pertanto, l’influenza dello zero diminuisce nella parte successiva della risposta.\n\nVisualizzazione dell’effetto dello zero:\n\nLa curva di risposta transitoria del sistema modificato viene “innalzata” o alterata principalmente nella fase iniziale a causa della derivata significativa all’inizio.\nIl fattore di scala $ 1/z $ (dove $ z $ è la posizione dello zero) influenza l’entità di questo effetto. Uno zero più vicino all’origine (piccolo $ z $) ha un impatto più pronunciato, mentre uno zero più nel semipiano sinistro (grande $ z $) ha un effetto trascurabile.\n\nImpatto dello zero sul decadimento della risposta:\n\nIl decadimento della risposta è governato principalmente dalla parte reale dei poli del sistema, in particolare da $ e^{-_n t} $.\nLo zero aggiunto non cambia in modo significativo il tasso di decadimento dettato dai poli ma altera la dinamica della risposta iniziale.\n\n\n\n\nParametri per mostrare l’effetto dello zero:\nPer illustrare meglio l’impatto dell’aggiunta di uno zero, valuta la possibilità di modificare questi parametri nella simulazione di cui sopra:\n\nPosizione dello Zero ($ z $):\n\nVariare la posizione dello zero più vicino o più lontano dall’origine dimostrerà il suo impatto sulla risposta iniziale.\n\nRapporto di smorzamento ($ $):\n\nLa modifica di $ $ può mostrare come lo smorzamento intrinseco del sistema interagisce con gli effetti introdotti dallo zero.\n\n**Frequenza naturale ($ _n $)**:\n\nLa modifica di $ _n $ può aiutare a visualizzare come la velocità di risposta del sistema è influenzata dallo zero.\n\n\nRegolando questi parametri in un ambiente di simulazione, è possibile vedere chiaramente come la presenza di uno zero nella funzione di trasferimento del sistema modifichi la sua risposta transitoria, specialmente nella fase iniziale successiva a un gradino in ingresso. Ciò è essenziale per comprendere le implicazioni progettuali di tali modifiche nei sistemi di controllo.\n\n\nLinee guida sull’influenza di uno zero\n\nPosizione relativa dei poli coniugati zero e complessi:\n\nL’effetto di uno zero sulla risposta transitoria di un sistema di controllo è significativamente correlato alla sua posizione rispetto ai poli coniugati complessi del sistema.\nSe uno zero è circa cinque volte più lontano dall’origine rispetto ai poli complessi coniugati, il suo impatto sulla risposta transitoria è trascurabile.\n\n\n\n\nImplicazioni sulla progettazione\n\nImpatto trascurabile dello zero distante:\n\nQuando lo zero è sufficientemente lontano dai poli coniugati complessi (cinque volte più lontano), è possibile progettare il sistema come se lo zero non esistesse. Ciò significa che è ancora possibile utilizzare le misure di prestazione standard (come tempo di salita, tempo di assestamento, superamento del picco) applicabili a un sistema di secondo ordine senza zero.\n\nRegolazione dei parametri di progettazione:\n\nSe lo zero è più vicino e influenza in modo significativo la risposta, potrebbero essere necessari aggiustamenti nei parametri di progettazione del sistema, in particolare nel rapporto di smorzamento ($ $).\nAd esempio, se un sistema progettato per un rapporto di smorzamento pari a 0,4 sperimenta un aumento del superamento dovuto allo zero, il progettista potrebbe optare per un rapporto di smorzamento leggermente più alto (come 0,5) per compensare questo effetto.\n\nVerifica del progetto tramite simulazione:\n\nL’effettivo impatto dello zero e l’efficacia di eventuali modifiche progettuali compensative dovrebbero essere verificati tramite simulazione.\nLa simulazione confermerà se il rapporto di smorzamento scelto raggiunge le prestazioni desiderate, in particolare in termini di superamento del picco.\n\n\n\n\nRientrare nel ciclo di progettazione\n\nProcesso di progettazione iterativo:\n\nIl processo di progettazione è iterativo. Se il progetto iniziale (con il rapporto di smorzamento modificato) non soddisfa i requisiti, sono necessarie ulteriori modifiche e simulazioni.\nQuesto processo iterativo continua finché il progetto non raggiunge le caratteristiche di risposta transitoria desiderate.\n\nScenario di esempio:\n\nSe un progetto per $ = 0,4 $ porta ad un superamento del 25% a causa della presenza di uno zero, il progettista potrebbe aumentare $ $ a 0,5 per ridurre il superamento. Tuttavia, questa modifica viene quindi testata tramite simulazione per garantire che soddisfi i criteri di prestazione complessivi del sistema.\n\n\nIn sintesi, il testo fornisce una guida pratica per i progettisti di sistemi di controllo su come tenere conto della presenza di uno zero nella funzione di trasferimento del sistema, in particolare quando influisce sulla risposta transitoria. Il punto chiave è valutare l’influenza dello zero in base alla sua posizione relativa rispetto ai poli dominanti e regolare di conseguenza i parametri di progettazione, verificando questi cambiamenti attraverso la simulazione per garantire che soddisfino le prestazioni di sistema desiderate.\n\n\nZeri del semipiano destro e tempi morti del sistema\nDiscutiamo ora le implicazioni di avere uno zero nella metà destra del piano s nella funzione di trasferimento di un sistema di controllo, in particolare in relazione alla stabilità e alla risposta del sistema.\n\nZeri nel semipiano destro\n\nImpatto sulla stabilità:\n\nUno zero nel semipiano destro (RHP) non influisce direttamente sulla stabilità di un sistema. La stabilità è generalmente determinata dai poli del sistema, non dagli zeri. Un sistema rimane stabile finché tutti i suoi poli si trovano nel semipiano sinistro (LHP).\n\nEvento fisico:\n\nNella maggior parte dei sistemi fisici, gli zeri nella RHP sono rari. Tuttavia, possono comparire in determinati scenari, in particolare nei sistemi con tempi morti.\n\n\n\n\nIl tempo morto e la sua rappresentazione\n\nModellazione dei tempi morti:\n\nIl tempo morto in un sistema è un ritardo tra la risposta di ingresso e quella di uscita. È spesso indicato come $ e^{-s_D} $ nel dominio di Laplace, dove $ _D $ è il tempo morto.\nUn’approssimazione comune per i tempi morti è $ e^{-s_D} $. Questa approssimazione introduce uno zero nella destra (in $ s = 2/_D $) e un polo nella sinistra (in $ s = -2/_D $).\n\n\n\n\nEffetti di uno zero nella destra\n\nInfluenza sulla risposta del sistema:\n\nUno zero nell’RHP può alterare significativamente la risposta del sistema. A differenza di uno zero nell’LHP, che tipicamente migliora la capacità del sistema di tracciare rapidi cambiamenti nell’input (a causa dell’effetto di tipo derivato), uno zero RHP può portare a caratteristiche indesiderate nella risposta.\n\nOvershoot ridotto e maggiore lentezza:\n\nLa presenza di uno zero RHP tende a ridurre il superamento del picco nella risposta del sistema. Questo perché l’effetto dello zero contrasta l’azione crescente della risposta del sistema, come se sottraesse la componente derivativa anziché aggiungerla.\nAncora più significativo, uno zero RHP può rendere la risposta del sistema più lenta. Ciò significa tempi di risposta più lenti e prestazioni potenzialmente inferiori nel tracciamento degli input o nel recupero dai disturbi.\n\nConsiderazioni pratiche nel controllo di processo:\n\nNei sistemi di controllo del processo in cui i tempi morti sono comuni, gestire gli effetti di uno zero RHP è una sfida pratica. Gli ingegneri devono progettare controller in grado di compensare il ritardo e la lentezza introdotti dai tempi morti, garantendo che il sistema possa comunque soddisfare i requisiti prestazionali.\n\n\nIn sintesi, mentre uno zero nell’RHP non influisce sulla stabilità di un sistema di controllo, può avere un impatto marcato sulla risposta transitoria del sistema, spesso rendendolo meno reattivo e riducendo l’overshoot. Queste caratteristiche devono essere attentamente considerate e affrontate nella progettazione del sistema di controllo, soprattutto nelle applicazioni di controllo di processo in cui i tempi morti sono un fattore. Comprendere e gestire gli effetti degli zero RHP è fondamentale per garantire che il sistema funzioni in modo efficace nonostante queste sfide intrinseche.\n\n\"\"\"\n- 'omega_n' and 'zeta' are the natural frequency and damping ratio of the system, respectively.\n- 'zero_position' is the position of the additional zero in the s-plane.\n- 'system_standard' represents the standard second-order system.\n- 'system_zero_added' is the system with an additional zero.\n- The step responses of both systems are computed using ctl.step_response.\n- The responses are then plotted for comparison.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System Parameters\nomega_n = 1  # Natural frequency\nzeta = 0.3   # Damping ratio\n\n# Position of the zero - change this to see the effects of the zero on the response\nzero_position = 1  \n\n# Define the standard second-order system\nnum_standard = [omega_n**2]\nden_standard = [1, 2*zeta*omega_n, omega_n**2]\nsystem_standard = ctl.TransferFunction(num_standard, den_standard)\nprint(system_standard)\n\n# Define the system with an additional zero\nnum_zero_added = [1, -zero_position]\nden_zero_added = 1\nsystem_zero_added = 1/(-zero_position)*ctl.TransferFunction(num_zero_added, den_zero_added) * system_standard\nprint(system_zero_added)\n\n# Time range for the response\nt = np.linspace(0, 20, 500)\n\n# Compute the step responses\nt_standard, y_standard = ctl.step_response(system_standard, T=t)\nt_zero_added, y_zero_added = ctl.step_response(system_zero_added, T=t)\n\n# Unit Step Reference (Constant value of 1 across the time range)\nunit_step = np.ones_like(t_standard)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_standard, y_standard, label='Standard Second-Order System')\nplt.plot(t_zero_added, y_zero_added, label='System with Zero Added', linestyle='--')\nplt.plot(t, unit_step, label='Unit Step Input', color='red', linestyle='-', linewidth=3)\n\nplt.title('Comparison of Step Response with Unit Step Input')\n\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n       1\n---------------\ns^2 + 0.6 s + 1\n\n\n    -s + 1\n---------------\ns^2 + 0.6 s + 1",
    "crumbs": [
      "IT_🇮🇹",
      "Comprensione del sistema standard del secondo ordine: riepilogo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#gestire-i-sistemi-di-ordine-superiore",
    "href": "IT_🇮🇹/20_Design_of_feedback_control_continued_it.html#gestire-i-sistemi-di-ordine-superiore",
    "title": "Comprensione del sistema standard del secondo ordine: riepilogo",
    "section": "Gestire i sistemi di ordine superiore",
    "text": "Gestire i sistemi di ordine superiore\nSiamo ora pronti a discutere le complessità implicate nella progettazione di sistemi di controllo di ordine superiore e a introdurre il concetto di “condizione di dominanza”.\nUn modello standard del secondo ordine, sebbene utile, è spesso una semplificazione eccessiva per i sistemi del mondo reale. In pratica, i sistemi sono generalmente di ordine superiore.\nUn sistema standard del secondo ordine può essere rappresentato dalla funzione di trasferimento:\n\\[ Y(s) / R(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nUn sistema reale, di ordine superiore al secondo, potrebbe assomigliare a:\n\\[ Y(s) / R(s) = \\frac{p}{s+p}\\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\ndove \\(p\\) al numeratore normalizza la risposta a 1.\n\nComprendere le modalità del sistema\nIn questo sistema del terzo ordine, la risposta del sistema è dettata da due modalità:\n\nModalità associata al sistema originale del secondo ordine:\n\nQuesta modalità segue la forma $ e^{-_nt} $, caratteristica del sistema originale del secondo ordine.\nAncora una volta, il residuo ai poli del sistema determina l’entità di questa modalità.\n\nModalità associata al palo:\n\nQuesta modalità è rappresentata da $ e^{-pt} $, dove $ p $ è la posizione del polo aggiunto nel sistema (se presente).\nIl residuo su questo polo influenzerà il contributo di questa modalità alla risposta complessiva del sistema.\n\n\n\n\nProgettare un sistema di ordine superiore: condizione di dominanza\nIl concetto di “condizione di dominanza” implica che per un sistema di ordine superiore, la risposta transitoria è influenzata principalmente dai due poli più vicini all’asse immaginario se gli altri poli sono sufficientemente lontani.\nCiò ci consente di utilizzare i principi di progettazione di un sistema del secondo ordine per sistemi di ordine superiore in determinate condizioni.\n\nCondizione di dominanza:\n\nLa condizione di dominanza viene introdotta come un concetto importante per affrontare i sistemi di ordine elevato. Afferma che in un sistema di ordine superiore, se alcuni poli (tipicamente quelli più vicini all’asse immaginario nel piano s) sono dominanti, la risposta transitoria del sistema può essere approssimata considerando solo questi poli dominanti.\nSe gli altri poli sono sufficientemente lontani nel semipiano sinistro (più di cinque volte più lontani dall’origine rispetto ai poli dominanti), il loro contributo alla risposta transitoria può essere considerato trascurabile.\n\nImplicazione della condizione di dominanza:\n\nQuando la condizione di dominanza è soddisfatta, la progettazione e l’analisi del sistema di ordine superiore possono essere semplificate per concentrarsi sui poli dominanti. I parametri $ $ (rapporto di smorzamento) e $ _n $ (frequenza naturale), che sono rilevanti solo per i sistemi del secondo ordine, diventano un guadagno rilevante in questo scenario.\n\n\nIn un sistema di ordine superiore, come un sistema del decimo ordine, il disegno può avere più poli. La condizione di dominanza diventa qui critica:\n\nSe i poli non dominanti sono significativamente lontani dai poli dominanti (diciamo, più di cinque volte la parte reale dei poli dominanti), il loro contributo alla risposta transitoria è minore.\nCiò consente al progettista di concentrarsi sui poli dominanti (tipicamente quelli più vicini all’asse immaginario) per progettare la risposta transitoria del sistema.\nRicordare che \\(\\zeta\\) e \\(\\omega_n\\) non hanno significato a meno che non si tratti di un sistema del secondo ordine. È nostra responsabilità verificare che la condizione di dominanza sia soddisfatta.\nNei casi in cui la condizione di dominanza non è soddisfatta, la progettazione diventa più complessa. Potrebbe essere necessario analizzare e progettare il sistema utilizzando un approccio più dettagliato, considerando gli effetti di tutti i poli e tutti gli zeri. In questo caso, è necessario un processo di progettazione iterativo, inclusa la simulazione, per convalidare le prestazioni del sistema rispetto alle specifiche desiderate. Gli aggiustamenti vengono effettuati in base ai risultati della simulazione fino a quando il sistema non soddisfa i suoi criteri di prestazione (progetto per tentativi ed errori).\n\n\n\nEsempio: Cancellazione Polo Zero\nConsideriamo uno scenario in cui il sistema presenta una configurazione dei poli problematica che determina le prestazioni.\n\n\n\n\n\nPer questo sistema, le prestazioni non sono determinate da \\(\\zeta\\) e \\(\\omega_n\\). Si noti che in questo caso non ci sono poli dominanti e il sistema deve essere valutato come un sistema completo del terzo ordine.\nI requisiti sono ancora espressi in termini di superamento del picco, tempo di salita, ecc., ma non possiamo semplicemente utilizzare l’approccio utilizzato finora.\nUn metodo per minimizzare l’impatto di un polo indesiderato è introdurre uno zero vicino ad esso, annullandone di fatto l’impatto. Questo è noto come metodo di cancellazione del polo zero.\n\nCancellazione polo-zero: se uno zero viene posizionato esattamente nella posizione di un polo, si annulla l’effetto del polo (il residuo su quel polo diventa zero). Possiamo progettare un controller PD che posizioni lo zero dove ne abbiamo bisogno.\nPer un sistema del terzo ordine, se si verifica questa cancellazione, la risposta del sistema potrebbe essere effettivamente dettata dai restanti due poli, semplificando il processo di progettazione.\nIn termini matematici, la cancellazione polo-zero modifica i residui sul polo cancellato, alterando così la risposta del sistema. Ciò può essere particolarmente utile per la gestione di poli complessi o che influiscono negativamente sulle prestazioni del sistema.\nDa notare che non è necessario che si tratti di una cancellazione precisa, posizionando lo zero sufficientemente vicino si riduce l’effetto del polo indesiderato.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Change this to simulate parameter noise in the placement of the zero\n# You can try 0 (no noise), 1e-2, etc.\nDelta = 0 #1e-2\n\n# System parameters\nomega_n = 1  # Natural frequency for complex conjugate poles\nzeta = 0.5   # Damping ratio for complex conjugate poles\nreal_pole = -2  # Location of the real pole\n\n# Transfer function of the original third-order system\n# Two complex conjugate poles and one real pole\nnum_original = [-real_pole*omega_n**2]\n# (s^2 + 2*zeta*omega_n s + omega_n**2)(s+real_pole)\nden_original = [1, \n                -real_pole + 2 * zeta * omega_n, \n                2 * zeta * omega_n * -real_pole + omega_n**2, \n                omega_n**2 * -real_pole] \n\nsystem_original = ctl.TransferFunction(num_original, den_original)\n\n# Add a zero to cancel the real pole\n# The zero is located at the position of the real pole\nnum_modified = [1, -real_pole+Delta]\nsystem_modified = ctl.TransferFunction(num_modified, den_original)\n\n# Standard second-order system\nnum_second_order = [omega_n**2]\nden_second_oder = [1, 2*zeta*omega_n, omega_n**2]\n\nsystem_second_order = ctl.TransferFunction(num_second_order, den_second_oder)\n\n# Time range for the response\nt = np.linspace(0, 10, 500)\n\n# Compute the step responses\nt_original, y_original = ctl.step_response(system_original, T=t)\nt_modified, y_modified = ctl.step_response(system_modified, T=t)\nt_second_order, y_second_order = ctl.step_response(system_second_order, T=t)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_original, y_original, label='Original System (Third-Order)')\nplt.plot(t_modified, y_modified, label='System with Zero Canceling Real Pole', linestyle='--', linewidth=3)\nplt.plot(t_second_order, y_second_order, label='Second-Order System', color='green', linestyle=':', linewidth=3)\nplt.title('Comparison of Step Response: Original vs Modified System vs Second-Order')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusione\nIn conclusione, la transizione da un sistema standard del secondo ordine a sistemi di ordine superiore nella progettazione del controllo implica un’attenta considerazione dei contributi dei poli e degli zeri. Tecniche come la normalizzazione e la cancellazione del polo zero diventano essenziali per gestire in modo efficace la risposta transitoria del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Comprensione del sistema standard del secondo ordine: riepilogo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/performance_of_feedback_systems_it.html",
    "href": "IT_🇮🇹/performance_of_feedback_systems_it.html",
    "title": "Prestazioni dei sistemi di feedback",
    "section": "",
    "text": "In questo notebook approfondiamo gli aspetti quantitativi della performance del sistema di controllo. Ci baseremo sulle nostre precedenti discussioni qualitative, passando da una comprensione generale di ciò che ci aspettiamo da un sistema di controllo a una specifica quantitativa più rigorosa delle prestazioni. Questa transizione è cruciale per progettare sistemi di controllo efficaci.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni dei sistemi di feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/performance_of_feedback_systems_it.html#introduzione-alle-specifiche-quantitative-delle-prestazioni",
    "href": "IT_🇮🇹/performance_of_feedback_systems_it.html#introduzione-alle-specifiche-quantitative-delle-prestazioni",
    "title": "Prestazioni dei sistemi di feedback",
    "section": "",
    "text": "In questo notebook approfondiamo gli aspetti quantitativi della performance del sistema di controllo. Ci baseremo sulle nostre precedenti discussioni qualitative, passando da una comprensione generale di ciò che ci aspettiamo da un sistema di controllo a una specifica quantitativa più rigorosa delle prestazioni. Questa transizione è cruciale per progettare sistemi di controllo efficaci.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni dei sistemi di feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/performance_of_feedback_systems_it.html#rivisitazione-degli-aspetti-qualitativi",
    "href": "IT_🇮🇹/performance_of_feedback_systems_it.html#rivisitazione-degli-aspetti-qualitativi",
    "title": "Prestazioni dei sistemi di feedback",
    "section": "Rivisitazione degli aspetti qualitativi",
    "text": "Rivisitazione degli aspetti qualitativi\nPrima di avanzare, ricapitoliamo brevemente gli aspetti qualitativi di cui abbiamo parlato finora:\n\nStabilità: il requisito principale per qualsiasi sistema di controllo è la stabilità. Un sistema instabile non può svolgere la funzione prevista. La stabilità è la pietra angolare delle prestazioni del sistema di controllo. Un sistema è considerato stabile se, in risposta ad un input limitato, produce un output limitato. In termini pratici, ciò significa che il sistema non mostrerà comportamenti fuori controllo o oscillazioni che crescono indefinitamente nel tempo.\nRisposta transitoria: la risposta transitoria di un sistema di controllo è fondamentale per determinare la rapidità e la precisione con cui raggiunge lo stato desiderato dopo un cambiamento. Il comportamento transitorio ideale è caratterizzato dal rapido raggiungimento del valore target con superamento minimo e oscillazioni ridotte, garantendo prestazioni del sistema efficienti e reattive.\nPrecisione in stato stazionario: nella fase di stato stazionario, in cui gli effetti transitori non sono più significativi, l’attenzione principale è posta sulla precisione con cui l’output del sistema si allinea al valore comandato. L’elevata precisione in stato stazionario è vitale per la maggior parte dei sistemi per garantire errori di tracciamento minimi e prestazioni costanti nel tempo.\nSensibilità e robustezza: un sistema di controllo robusto mantiene l’affidabilità delle prestazioni anche di fronte a variazioni nei parametri del sistema o discrepanze nella modellazione. L’obiettivo è progettare un sistema che funzioni in modo efficace, indipendentemente dal fatto che i parametri effettivi si discostino da quelli inizialmente utilizzati nella progettazione.\nRifiuto dei disturbi: un efficace rifiuto dei disturbi è fondamentale, in particolare nella fase stazionaria del sistema di controllo. Il sistema dovrebbe essere progettato per ridurre al minimo l’impatto di disturbi esterni incontrollati, garantendo che l’uscita rimanga stabile e inalterata, sia durante i transitori che nel funzionamento a regime.\n\nUna volta delineati questi requisiti qualitativi, siamo ora pronti ad approfondire l’analisi quantitativa e la specificazione di questi aspetti.\n\n\n\n\n\n\n#### BARRA LATERALE - Esplorazione dei criteri di prestazione del sistema di controllo\n\n\n### 1. Stabilità\n\n\n#### Definizione e importanza La stabilità è la pietra angolare delle prestazioni del sistema di controllo. Un sistema è considerato stabile se, in risposta ad un input limitato, produce un output limitato. In termini pratici, ciò significa che il sistema non mostrerà comportamenti fuori controllo o oscillazioni che crescono indefinitamente nel tempo.\n\n\n#### Rappresentazione matematica - Stabilità BIBO: un sistema è stabile con input limitato e output limitato (BIBO) se ogni input limitato produce un output limitato. Matematicamente, se $ |x(t)| &lt; M &lt; $ per tutti $ t $, quindi $ |y(t)| &lt; N &lt; $ per tutti $ t $, dove $ x(t) $ è l’input, $ y(t) $ è l’output e $ M, N $ sono costanti. - Criterio di Routh-Hurwitz: questo criterio fornisce un metodo per determinare la stabilità di un sistema esaminando la posizione dei poli della funzione di trasferimento del sistema. Se tutti i poli si trovano nella metà sinistra del piano complesso, il sistema è stabile.\n\n\n#### Considerazioni pratiche - Margini di stabilità: nella progettazione, non si tratta solo di raggiungere la stabilità, ma di garantire un grado di robustezza nella stabilità, noto come margini di stabilità. Questi margini indicano quanto possono variare i parametri di un sistema prima che diventi instabile.\n\n\n### 2. Risposta transitoria\n\n\n#### Caratterizzazione del comportamento transitorio La risposta transitoria si riferisce alla reazione del sistema da uno stato iniziale al raggiungimento del suo stato stazionario. Le caratteristiche chiave includono: - Tempo di salita: tempo impiegato dalla risposta per salire dal 10% al 90% del suo valore finale. - Tempo di assestamento: tempo impiegato dalla risposta per rimanere entro una certa percentuale (comunemente 2% o 5%) del valore finale. - Overshoot: la quantità di cui la risposta supera il valore finale. - Rapporto di smorzamento: una misura delle oscillazioni nella risposta.\n\n\n#### Obiettivi di progettazione - Velocità di risposta: un tempo di salita più rapido è spesso auspicabile, ma può portare a un aumento del superamento. - Controllo dell’oscillazione: riduce al minimo il superamento e garantisce che il sistema si assesti rapidamente senza oscillazioni prolungate.\n\n\n### 3. Precisione allo stato stazionario\n\n\n#### Comprendere lo stato stazionario Una volta che gli effetti transitori sono diminuiti, il sistema entra in uno stato stazionario. In questo caso, l’output dovrebbe idealmente corrispondere il più fedelmente possibile al valore comandato.\n\n\n#### Misure di accuratezza in regime stazionario - Metriche di errore: le misure comuni includono errore in stato stazionario, errore di tracciamento e costanti di errore come costanti di errore di posizione, velocità e accelerazione. - Tipo di sistema ed errore: il tipo di sistema di controllo (Tipo 0, Tipo 1, ecc.) determina la sua capacità di gestire diversi tipi di errori stazionari, in particolare per ingressi a gradino, rampa e parabolici.\n\n\n#### Progettare per la precisione - Controllo del feedback: l’integrazione del feedback riduce efficacemente l’errore in stato stazionario. - Controllo integrale: l’aggiunta di un componente integrale può eliminare l’errore di stato stazionario per determinati tipi di ingressi.\n\n\n### 4. Sensibilità e robustezza\n\n\n#### Resilienza alle variazioni La sensibilità e la robustezza misurano la capacità di un sistema di mantenere le prestazioni nonostante i cambiamenti nei parametri del sistema o nelle condizioni ambientali.\n\n\n#### Analisi quantitativa - Funzione sensibilità: questa funzione quantifica la sensibilità dell’output del sistema alle modifiche di un particolare parametro. - Tecniche di progettazione robusta: metodi come H-infinito e μ-sintesi vengono utilizzati per progettare sistemi che mantengono le prestazioni in una gamma di incertezze.\n\n\n#### Applicazione pratica - Analisi del caso peggiore: valutazione delle prestazioni del sistema in condizioni di variazioni estreme per garantire un funzionamento affidabile.\n\n\n### 5. Rifiuto del disturbo\n\n\n#### Minimizzare l’impatto esterno I sistemi di controllo spesso operano in ambienti con disturbi esterni. Un’efficace reiezione dei disturbi riduce al minimo l’impatto di questi disturbi sull’uscita del sistema.\n\n\n#### Valutazione del rifiuto dei disturbi - Risposta transitoria al disturbo: osservazione della rapidità ed efficacia con cui il sistema mitiga l’impatto di un disturbo. - Errore in stato stazionario dovuto a disturbo: garantire che, in stato stazionario, il disturbo abbia un impatto minimo o nullo sull’uscita.\n\n\n#### Strategie di controllo - Controllo feedforward: Anticipare i disturbi e compensarli prima che incidano sul sistema. - Controllo feedback: regolazione del comportamento del sistema in risposta ai disturbi rilevati nell’uscita.\n\n\n— FINE DELLA BARRA LATERALE\n\n\n## Transizione alle specifiche quantitative\n\n\nNella progettazione del sistema di controllo, spesso iniziamo specificando: - il transitorio desiderato - e precisione in condizioni stazionarie.\n\n\nUna volta progettato un sistema con queste specifiche, ne valutiamo le prestazioni in termini di robustezza e reiezione ai disturbi.\n\n\nNota: la ricerca attuale sulla progettazione dei sistemi di controllo si sta evolvendo verso l’inclusione della sensibilità e della robustezza nella fase di progettazione iniziale stessa. Tuttavia, questa è ancora un’area emergente e non ampiamente incorporata nei programmi di studio standard. Ci concentreremo sul modo classico di progettazione del controllo e questo fornirà la base per comprendere robustezza e sensibilità.\n\n\n### Approccio classico nella progettazione dei sistemi di controllo\n\n\nNella metodologia tradizionale dell’ingegneria dei sistemi di controllo, l’attenzione principale è inizialmente posta sulla precisione transitoria e stazionaria. Questo approccio metodico comprende diversi passaggi chiave:\n\n\n1. Garanzia della stabilità del sistema: questa fase iniziale prevede l’applicazione di strumenti analitici come il criterio di stabilità di Routh. Questi strumenti vengono utilizzati per accertare le condizioni di stabilità del sistema determinando gli intervalli specifici di parametri che garantiscono la stabilità. La stabilità del sistema è un requisito primario. Se questo non regge tutto il resto non ha importanza.\n\n\n2. Ottimizzazione per prestazioni transitorie e stazionarie: il passaggio successivo è l’attenta selezione dei parametri di sistema. Questi parametri vengono scelti all’interno dei domini di stabilità identificati con l’obiettivo di raggiungere i livelli desiderati di accuratezza transitoria e stazionaria. Questo processo di selezione è fondamentale affinché il sistema risponda efficacemente ai cambiamenti e mantenga la precisione nel tempo. Questa è la specifica quantitativa delle prestazioni del sistema.\n\n\n3. Valutazione della robustezza e delle capacità di reiezione ai disturbi: la fase finale prevede una simulazione approfondita del sistema di controllo. Questa simulazione è fondamentale per valutare se il sistema soddisfa gli standard predefiniti di robustezza e la sua capacità di respingere i disturbi. Se questi standard non vengono soddisfatti, si innesca una rivalutazione e una riprogettazione della strategia di controllo. Questa natura iterativa della progettazione riconosce che il raggiungimento di prestazioni ottimali spesso richiede molteplici aggiustamenti e perfezionamenti.\n\n\nSeguendo questi passaggi, l’approccio classico garantisce un processo di sviluppo completo e iterativo, con l’obiettivo di creare un sistema di controllo stabile, accurato, robusto e in grado di respingere efficacemente i disturbi.\n\n\n### Metodologia di progettazione per il sistema di controllo: valutazione di stabilità, accuratezza e robustezza\n\n\n1. Identificazione dei domini di stabilità dei parametri: - Il passo iniziale nella progettazione di un sistema di controllo comporta la determinazione delle condizioni in cui il sistema rimarrà stabile. - Stabilità, nei sistemi di controllo, significa che il sistema non mostrerà un comportamento illimitato o irregolare in risposta a un dato input. - Per trovare queste condizioni, utilizziamo metodi analitici come il criterio di stabilità di Routh. Questo criterio aiuta a identificare i “domini” o intervalli di parametri del sistema (come guadagno, rapporto di smorzamento, ecc.) che garantiscono che il sistema rimanga stabile. - Ad esempio, potremmo risolvere problemi in cui manipoliamo uno o due parametri (come la regolazione del guadagno di un controller) per vedere come questi cambiamenti influiscono sulla stabilità del sistema.\n\n\n2. Garantire la precisione transitoria e stazionaria: - Una volta identificati i domini di stabilità, il passo successivo è affinare i parametri di sistema all’interno di questi domini. - Questo perfezionamento mira a raggiungere obiettivi prestazionali specifici legati al modo in cui il sistema risponde nel tempo (prestazioni transitorie) e alla precisione con cui mantiene il suo output nel lungo termine (prestazioni stazionarie). - L’accuratezza transitoria riguarda la rapidità e l’efficacia con cui il sistema risponde ai cambiamenti, mentre l’accuratezza allo stato stazionario si concentra su quanto l’output del sistema corrisponde all’output desiderato dopo che le fluttuazioni iniziali si sono stabilizzate.\n\n\n3. Valutazione della robustezza e del rifiuto dei disturbi: - Dopo aver soddisfatto i requisiti transitori e stazionari, torniamo alla configurazione originale del sistema. - Qui simuliamo il sistema in varie condizioni per valutarne la robustezza (quanto bene si comporta in diverse condizioni operative o variazioni dei parametri) e la sua capacità di respingere i disturbi (quanto bene mantiene le sue prestazioni in presenza di influenze esterne impreviste). - Se il sistema non riesce a soddisfare i criteri di robustezza o di reiezione ai disturbi, potrebbe essere necessario rivedere il processo di progettazione. Ciò potrebbe comportare la nuova regolazione dei parametri o addirittura la riprogettazione di alcuni aspetti del sistema.\n\n\nSeguendo questo approccio strutturato, garantiamo che il sistema di controllo che progettiamo non solo sia stabile ma soddisfi anche specifici criteri di prestazione sia a breve che a lungo termine e sia resistente ai disturbi esterni e ai cambiamenti dei parametri interni. Questa valutazione globale è fondamentale per creare un sistema di controllo affidabile ed efficiente.\n\n\n## Esplorazione delle specifiche relative alle prestazioni transitorie\n\n\n### Sistemi di feedback unitario\n\n\nPer semplicità, considereremo un sistema con feedback unitario, sebbene i principi si applichino anche ai sistemi con feedback non unitario.\n\n\n\n\n\n- La funzione di trasferimento del sistema è:\n\n\n\\[ Y(s) / R(s) = G(s) / (1 + G(s)) \\]\n\n\n- Qui, $ Y(s) $ è l’output, $ R(s) $ è l’input e $ G(s) $ è la funzione di trasferimento del sistema.\n\n\n### Natura dei segnali di ingresso\n\n\nNei sistemi di controllo pratici, la natura del segnale di ingresso è imprevedibile. Pertanto, utilizziamo segnali di test standard (gradino, rampa, parabola) per progettare e valutare il sistema. Se il sistema funziona bene con questi segnali, dovrebbe funzionare bene con qualsiasi altro segnale.\n\n\nLe prestazioni transitorie dipendono dai poli del sistema ed sono relativamente indipendenti dalla natura del segnale di ingresso.\n\n\nAd esempio, se i poli sono sulla sinistra, il transitorio si estinguerà. Il transitorio dipende quindi dalle caratteristiche del sistema e non dallo specifico ingresso.\n\n\nIn altre parole, nella progettazione del sistema di controllo, è fondamentale valutare come il sistema risponderà ai vari tipi di segnali di ingresso. Poiché non è pratico prevedere ogni possibile input che un sistema potrebbe incontrare nelle operazioni del mondo reale, utilizziamo input di test standard come parametri di riferimento. Questi includono, tra gli altri, segnali a gradino, rampa e parabolici.\n\n\n- Inserimento graduale: si tratta di un cambiamento improvviso, in genere da zero a un valore fisso. È utile per osservare la reazione immediata del sistema e le sue caratteristiche di risposta transitoria.\n\n\n- Ingresso rampa: questo ingresso aumenta linearmente nel tempo, rappresentando un setpoint in continua evoluzione. Aiuta a comprendere come il sistema tiene traccia di un input che varia gradualmente e può essere particolarmente rivelatore per i sistemi in cui il tasso di variazione dell’input è significativo.\n\n\n- Ingresso parabolico: rappresenta uno scenario in cui l’input cambia a un ritmo accelerato, fornendo informazioni su come il sistema gestisce condizioni più complesse e in cambiamento dinamico.\n\n\nLa scelta di questi segnali di test non è arbitraria. Sono selezionati perché stimolano efficacemente diversi aspetti del comportamento del sistema. L’ingresso passo verifica la stabilità di base del sistema e la risposta transitoria. L’ingresso della rampa esamina la capacità del sistema di tenere il passo con un setpoint in continua evoluzione, che è fondamentale per monitorare le prestazioni. L’input parabolico, introducendo un cambiamento accelerato, sfida la reattività del sistema a input più complessi e dinamici.\n\n\nProgettando un sistema di controllo che funzioni in modo soddisfacente con questi input di test standard, possiamo dedurre che probabilmente gestirà un’ampia gamma di input del mondo reale in modo efficace. Questo approccio semplifica il processo di progettazione riducendo l’infinita varietà di possibili input in una serie gestibile di test standard, ciascuno incentrato su un aspetto critico delle prestazioni del sistema.\n\n\n### Utilizzo dell’input passo per l’analisi della risposta transitoria\n\n\n- Nel contesto dell’analisi della risposta transitoria, viene comunemente utilizzato lo step input, rappresentato da una funzione unit-step $ (t) $. - Il ragionamento alla base di questa scelta è che uno step input è particolarmente efficace nello stimolare tutte le modalità del sistema. Questa eccitazione completa consente un’osservazione e un’analisi dettagliate della risposta transitoria del sistema. È importante notare che la stabilità e le caratteristiche transitorie di un sistema di controllo sono determinate principalmente dalla posizione dei suoi poli, che sono proprietà intrinseche del sistema stesso, piuttosto che dalla natura del segnale di ingresso. Pertanto, utilizzando la forma più semplice di input di test, lo step input, possiamo valutare in modo efficiente il comportamento del sistema senza la necessità di forme di input più complesse. Questo approccio semplifica l’analisi fornendo comunque una comprensione approfondita delle dinamiche transitorie del sistema.\n\n\nPer questo motivo, l’input unitario viene utilizzato per specificare quantitativamente le caratteristiche transitorie del sistema. Si noti inoltre che un’ampiezza maggiore non cambia la natura della risposta, cambierà solo l’ampiezza della risposta.\n\n\n\n\n\n🤔Domanda pop-up: Perché preferiamo un input a passi unitari per l’analisi transitoria?\n\n\nRisposta: Un input a passi unitari semplifica l’analisi ed è efficace nell’attivare tutte le modalità del sistema, rendendolo ideale per osservare il comportamento transitorio del sistema.\n\n\n## Specifiche delle prestazioni in stato stazionario\n\n\n### Dipendenza dall’input e caratteristiche del sistema\n\n\nA differenza delle prestazioni transitorie, la risposta allo stato stazionario dipende sia dalle caratteristiche del sistema che dalla natura del segnale di ingresso. Pertanto, un singolo tipo di segnale di ingresso potrebbe non essere sufficiente per caratterizzare completamente le prestazioni in condizioni stazionarie.\n\n\nIdealmente, per caratterizzare a fondo il comportamento in stato stazionario, sarebbe necessario l’input effettivo che il sistema incontrerà nelle operazioni del mondo reale. Tuttavia, negli scenari pratici, questo input specifico potrebbe non essere sempre predeterminato o conosciuto in anticipo. Di conseguenza nasce la necessità di utilizzare segnali di test standardizzati. Questi segnali di test servono come proxy per approssimare una gamma di possibili input del mondo reale, consentendo così una valutazione più solida delle prestazioni stazionarie del sistema in varie condizioni ipotetiche.\n\n\n## Gestione degli input sconosciuti nei sistemi di controllo\n\n\n### Esempi del mondo reale e la sfida degli input imprevedibili\n\n\nQuando progettiamo sistemi di controllo, spesso affrontiamo la sfida di input sconosciuti o variabili. Esploriamolo attraverso alcuni esempi:\n\n\n#### Esempio 1: sistema radar di tracciamento - Scenario: un sistema radar progettato per tracciare i movimenti degli aerei. - Sfida: prevedere l’esatto profilo di movimento dell’aereo è quasi impossibile. Il sistema deve essere adattabile a diverse traiettorie possibili.\n\n\n#### Esempio 2: Controllo Numerico di Macchine Utensili - Situazione: Macchine progettate per tagliare o modellare materiali. - Complessità: alla macchina potrebbe essere richiesto di eseguire una serie di attività, dalla rastremazione al taglio di profili parabolici. Il sistema deve gestire qualsiasi forma gli venga assegnata.\n\n\n#### Esempio 3: Impianto di riscaldamento residenziale - Condizione: variabilità delle temperature ambientali durante le stagioni. - Impatto: Questa variazione modifica sensibilmente i segnali di disturbo che il sistema deve gestire, dall’estate all’inverno.\n\n\nIn ciascuno di questi casi, l’ingresso del sistema di controllo e i segnali di disturbo che incontra non possono essere predeterminati con precisione. Questa incertezza influisce direttamente sulle prestazioni in condizioni stazionarie, che dipendono intrinsecamente dalla natura dell’input.\n\n\n### Affrontare input imprevedibili\n\n\n#### Rappresentazione polinomiale degli input\n\n\nPer superare la sfida degli input imprevedibili, una strategia consiste nel rappresentare l’input effettivo come una somma di funzioni polinomiali. Matematicamente, qualsiasi funzione complessa può essere scomposta in una serie di funzioni polinomiali più semplici. Pertanto, garantire prestazioni soddisfacenti per una serie di input polinomiali può fornire la certezza che il sistema funzionerà bene per vari input del mondo reale.\n\n\n- Rappresentazione della funzione polinomiale:\n\n\nSecondo la discussione precedente possiamo vedere l’input \\(r(t)\\) come una generica funzione polinomiale indicizzata da \\(k\\):\n\n\n\\[ r(t) = \\frac{1}{k!} t^k \\mu(t) \\]\n\n\nQui, $ r(t) $ è una funzione polinomiale del tempo, $ k $ è l’ordine del polinomio e $ (t) $ è la funzione di passo unitario.\n\n\n#### Ingressi polinomiali standard per prestazioni stazionarie\n\n\nPer diversi valori di $ k $, otteniamo vari input di test standard:\n\n\n- $ k = 0 $: $ r(t) = (t)$ diventa una funzione a passo unitario. - $ k = 1 $: $ r(t) = t (t)$ rappresenta una funzione di rampa. - $ k = 2 $: $ r(t) = t^2(t)$ forma una funzione parabolica.\n\n\nAll’aumentare di $ k $, l’input diventa più veloce, ma negli scenari pratici raramente sono necessari valori di $ k $ superiori a 2. Questo perché gli input del sistema del mondo reale generalmente non sono veloci quanto i polinomi di ordine superiore. Pertanto, nella maggior parte dei casi, è sufficiente soddisfare i criteri di prestazione per $ k = 1 $ (funzione rampa) e $ k = 2 $ (funzione parabolica).\n\n\n#### Considerazioni pratiche sulla progettazione dei controlli\n\n\n- Complessità e stabilità: all’aumentare dell’ordine $ k $, la progettazione del sistema di controllo diventa più impegnativa, in particolare per quanto riguarda il mantenimento della stabilità. Per $ k &gt; 3 $ mantenere la stabilità è molto difficile.\n\n\n- Rilevanza industriale: per molte applicazioni industriali, un valore di $ k = 1 $ è spesso sufficiente, in linea con i requisiti pratici.\n\n\nAndando avanti, la nostra analisi si concentrerà su tre input di test fondamentali, ciascuno caratterizzato dal suo comportamento unico e dipendente dal tempo e dalla sua caratteristica natura “unitaria”, derivata dalla proprietà che i suoi derivati ​​sono scalati all’unità:\n\n\n1. Funzione di passo unitario: - Rappresentazione matematica: $ r(t) = (t) $ - Caratteristiche: questa funzione rappresenta un cambiamento improvviso a $ t = 0 $, passando bruscamente da 0 a 1. È chiamata “passo unitario” perché la sua derivata, una funzione delta, raggiunge il picco all’altezza unitaria.\n\n\n2. Funzione Rampa Unità: - Espressione: $ r(t) = t (t) $ - Descrizione: questa funzione crescente linearmente simboleggia un ingresso di rampa che inizia a $ t = 0 $ e aumenta a una velocità costante. La designazione “unità” è dovuta al fatto che la sua derivata è costante (unità) nel tempo.\n\n\n3. Funzione Unità-Parabola: - Formulazione: $ r(t) = t^2 (t) $ - Spiegazione: questa funzione rappresenta una curva parabolica, che inizia da $ t = 0 $ e aumenta quadraticamente nel tempo. Il fattore \\(\\frac{1}{2}\\) garantisce che la derivata di questa funzione, $ t (t) $, si allinei con la funzione rampa unitaria, da qui il termine ‘parabola unitaria’.\n\n\nCiascuno di questi input funge da segnale di test standard nell’analisi dei sistemi di controllo, fornendo una base per esaminare le risposte del sistema in diversi tipi di scenari di input.\n\n\n## Specifiche delle prestazioni transitorie\n\n\n### Approccio basato sul settore\n\n\nInvece di fare affidamento esclusivamente su modelli matematici, un approccio basato sull’industria prevede l’esame dei sistemi di controllo del mondo reale. Eccitando questi sistemi con un ingresso a gradino standard e osservando la loro risposta, possiamo ricavare specifiche pratiche sulle prestazioni transitorie.\n\n\n### Osservazioni e indici di performance transitoria\n\n\n- Risposta tipica: la risposta transitoria di un sistema di controllo pratico spesso presenta oscillazioni smorzate prima di raggiungere lo stato stazionario.\n\n\n\n\n\n- Accettabilità delle oscillazioni: alcuni superamenti sono generalmente accettabili in scenari pratici.\n\n\n### Indici chiave di prestazione\n\n\n1. Tempo di salita ($ t_r $): è la durata necessaria affinché la risposta del sistema raggiunga inizialmente il valore finale (o il livello di stato stazionario) al 100% per la prima volta. Fornisce informazioni sulla velocità di risposta del sistema in seguito a una modifica.\n\n\n2. Peak Overshoot ($ M_p $): questo parametro misura il livello massimo di cui la risposta del sistema supera il suo valore finale. Se il superamento del picco rientra nei limiti accettabili, si presume generalmente che anche eventuali successive fluttuazioni di magnitudo saranno accettabili, poiché sono generalmente inferiori.\n\n\n3. Peak Time ($ t_p $): si riferisce al tempo trascorso dall’inizio della risposta fino al raggiungimento del suo massimo superamento. Indica la velocità con cui il sistema raggiunge il picco di risposta in seguito ad un disturbo o ad un cambiamento.\n\n\n4. Tempo di assestamento: è il tempo necessario affinché la risposta del sistema rimanga costantemente entro un intervallo di tolleranza specifico attorno al valore finale. L’intervallo di tolleranza, spesso fissato al 2% o al 5% del valore finale, varia in base ai requisiti di precisione dell’applicazione. Questa metrica è fondamentale per determinare la velocità con cui il sistema si stabilizza dopo fluttuazioni transitorie.\n\n\n#### Nota aggiuntiva sulla caratterizzazione matematica del tempo di assestamento:\n\n\nConsideriamo una funzione della forma \\(e^{-t/\\tau}\\), che rappresenta un decadimento esponenziale.\n\n\nMatematicamente, tale funzione si stabilizza completamente solo quando \\(t\\) si avvicina all’infinito (\\(t \\rightarrow \\infty\\)).\n\n\nIn altre parole, il suo tempo di assestamento teorico è infinito. Tuttavia, nell’analisi e nella progettazione pratica del sistema di controllo, definiamo un tempo di assestamento all’interno di una fascia di accettabilità pratica per riflettere condizioni operative realistiche. Questo approccio riconosce che, in pratica, un sistema è considerato “stabilizzato” quando la sua risposta è sufficientemente vicina al valore di stato stazionario, anche se non lo ha raggiunto esattamente.\n\n\nInfine, vale la pena notare che affronteremo separatamente la precisione stazionaria-stazionaria perché non è specificata solo per un passo unitario ma anche per gli ingressi a rampa e parabolici.\n\n\nDati questi quattro parametri, possiamo quasi ricostruire la risposta al gradino.\n\n\n### Esplorazione delle dinamiche transitorie nei sistemi del secondo ordine: una simulazione interattiva\n\n\nPossiamo vedere l’effetto della modifica di questi parametri utilizzando il seguente codice Python.\n\n\n#### Istruzioni per l’uso:\n\n\n1. Slider Zeta: regolare questo cursore per modificare il rapporto di smorzamento del sistema. Un valore più basso significa meno smorzamento (più risposta oscillatoria), mentre un valore più alto significa più smorzamento (meno risposta oscillatoria). 2. Slider Omega_n: questo slider modifica la frequenza naturale del sistema. Una frequenza naturale più elevata generalmente porta ad una risposta più rapida.\n\n\n3. Slider del tempo della simulazione: questo cursore modifica il tempo della simulazione.\n\n\nCon questi cursori è possibile osservare come la variazione del rapporto di smorzamento e della frequenza naturale influenzi la risposta ai transitori di un sistema stabile del secondo ordine.\n\n\n::: {#8ee42504 .cell} ``` {.python .cell-code} # Import necessary libraries import numpy as np import matplotlib.pyplot as plt import control\n\n\ndef find_max_consecutive_index(arr): max_consecutive_index = None consecutive_start = None\n\n\nfor i in range(len(arr) - 1): if arr[i] + 1 != arr[i + 1]: if consecutive_start is not None: max_consecutive_index = consecutive_start consecutive_start = None elif consecutive_start is None: consecutive_start = i + 1\n\n\n# Check if the entire array is consecutive if consecutive_start is not None: max_consecutive_index = consecutive_start\n\n\nreturn max_consecutive_index if max_consecutive_index is not None else len(arr) - 1\n\n\n# Define a function to calculate and plot the system response with performance parameters def plot_response(zeta, omega_n, sim_time): # System parameters: zeta (damping ratio), omega_n (natural frequency) num = [omega_n**2] # Numerator (assuming unit gain) den = [1, 2 * zeta * omega_n, omega_n**2] # Denominator\n\n\n# Create a transfer function model system = control.tf(num, den)\n\n\n# Time parameters t = np.linspace(0, sim_time, int(sim_time*100)) # Time vector\n\n\n# Step response t, y = control.step_response(system, t) steady_state_value = y[-1]\n\n\n# Rise Time rise_time_indices = np.where(y &gt;= steady_state_value)[0] rise_time = t[rise_time_indices[0]] if rise_time_indices.size else None\n\n\n# Peak Overshoot and Peak Time peak_overshoot = np.max(y) - steady_state_value peak_time = t[np.argmax(y)]\n\n\n# Settling Time (within 2% of steady-state value). This is found numerically. settling_time_indices = np.where(abs(y - steady_state_value) &lt;= 0.02 * steady_state_value)[0] ts_index = find_max_consecutive_index(settling_time_indices) settling_time = t[settling_time_indices[ts_index]] if settling_time_indices.size else None\n\n\n# Plot plt.figure(figsize=(10, 6)) plt.plot(t, y, label=‘System Response’) plt.axhline(steady_state_value, color=‘r’, linestyle=‘–’, label=‘Steady State’) # tolerange band (0.02 percent) plt.axhline(steady_state_value * 1.02, color=‘g’, linestyle=‘:’, label=‘Settling Time Bound’) plt.axhline(steady_state_value * 0.98, color=‘g’, linestyle=‘:’)\n\n\nif rise_time: plt.axvline(rise_time, color=‘y’, linestyle=‘-’, label=f’Rise Time: {rise_time:.2f}s’) plt.axvline(peak_time, color=‘b’, linestyle=‘-’, label=f’Peak Time: {peak_time:.2f}s’) plt.scatter(peak_time, np.max(y), color=‘black’, label=f’Peak Overshoot: {peak_overshoot:.2f}’)\n\n\nif settling_time: plt.scatter(settling_time, y[settling_time_indices[ts_index]], color=‘purple’) plt.axvline(settling_time, color=‘purple’, linestyle=‘-’, label=f’Settling Time: {settling_time:.2f}s’)\n\n\nplt.title(‘Transient Response with Performance Parameters’) plt.xlabel(‘Time (seconds)’) plt.ylabel(‘Output’) plt.legend() plt.grid(True) plt.show()\n\n\n# Interactive sliders from ipywidgets import interact, FloatSlider interact(plot_response, zeta=FloatSlider(value=0.3, min=0.01, max=1.0, step=0.01), omega_n=FloatSlider(value=2, min=1, max=10, step=0.1), sim_time=FloatSlider(value=10, min=1, max=50, step=1)) ```\n\n\n::: {.cell-output .cell-output-display}\n\n\n{=html} &lt;script type=\"application/vnd.jupyter.widget-view+json\"&gt; {\"model_id\":\"b6369e0b55f2465e86c0dd63e6c6496c\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"} &lt;/script&gt;\n\n\n:::\n\n\n::: {.cell-output .cell-output-display}",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni dei sistemi di feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/performance_of_feedback_systems_it.html#sfide-di-progettazione-e-prestazioni-in-regime-stazionario-nei-sistemi-di-controllo",
    "href": "IT_🇮🇹/performance_of_feedback_systems_it.html#sfide-di-progettazione-e-prestazioni-in-regime-stazionario-nei-sistemi-di-controllo",
    "title": "Prestazioni dei sistemi di feedback",
    "section": "Sfide di progettazione e prestazioni in regime stazionario nei sistemi di controllo",
    "text": "Sfide di progettazione e prestazioni in regime stazionario nei sistemi di controllo\nMan mano che approfondiamo l’ambito della progettazione dei sistemi di controllo, incontriamo un aspetto cruciale che ha un impatto significativo sull’efficacia di un sistema: il conflitto intrinseco tra i parametri di progettazione. Questa sezione esplora questo conflitto e le sue implicazioni sulle prestazioni del sistema.\n\nComprendere il conflitto\nNei sistemi di controllo, alcune qualità desiderabili sono intrinsecamente in contrasto tra loro. Per esempio:\n\nRise Time ($ t_r $): Idealmente, vogliamo che $ t_r $ sia il più piccolo possibile. Un $ t_r $ più piccolo implica una risposta del sistema più rapida, evitando un comportamento lento. Tuttavia, la riduzione di $ t_r $ spesso ha un costo.\nTempo di picco ($ t_p $): Desideriamo anche che $ t_p $ sia piccolo affinché il sistema raggiunga rapidamente il suo picco e poi si stabilizzi. Allo stesso modo, un piccolo $ t_p $ può avere effetti negativi su altri parametri del sistema.\nTempo di assestamento ($ t_s \\()** e **Peak Overshoot (\\) M_p $): Entrambi questi parametri dovrebbero idealmente essere piccoli. Tuttavia, gli sforzi per minimizzarne uno spesso si traducono nell’aumento dell’altro.\n\nQuesto conflitto nasce perché le caratteristiche dinamiche del sistema sono interconnesse. La regolazione di un parametro per migliorare un determinato aspetto delle prestazioni del sistema può inavvertitamente peggiorare un altro aspetto.\n\nEsempio: compromesso nel design\nConsidera uno scenario in cui la riduzione del tempo di salita si traduce in un superamento del picco maggiore. Questo è un compromesso comune nei sistemi di controllo. Un sistema che risponde rapidamente (piccolo $ t_r $) potrebbe superare il suo obiettivo in modo significativo (grande $ M_p $), portando potenzialmente a instabilità o inefficienze.\n\n\n\nSpecifiche delle prestazioni in stato stazionario\nPassando alle prestazioni in regime stazionario, consideriamo il sistema a retroazione unitaria con la funzione di errore $ e(t) $ definita come $ r(t) - y(t) \\(. L'errore a regime (\\) e_{ss} $) è dato da:\n\\[ e_{ss} = \\lim_{t \\to \\infty} [r(t) - y(t)] \\]\n\n\n\n\n\n\n\nSpecifiche degli errori in stato stazionario per vari ingressi\nNei sistemi di controllo, l’errore stazionario ($ e_{ss} $) è una metrica chiave per valutare quanto bene il sistema mantiene il suo output in linea con l’input desiderato nel tempo. L’errore a regime varia a seconda del tipo di segnale di ingresso applicato al sistema. I tipi di input comunemente considerati includono:\n\nIngresso unitario: Quando viene applicata una funzione di incremento unitario $ r(t) = (t) $, l’errore di stato stazionario $ e_{ss} $ valuta quanto l’output del sistema corrisponde a una costante valore dopo che i transitori iniziali si sono estinti. È una misura della capacità del sistema di mantenere un output stabile in risposta a un cambiamento improvviso e fisso nell’input.\nIngresso rampa unitaria: Per un ingresso rampa $ r(t) = t (t) $, che aumenta linearmente nel tempo, l’errore di stato stazionario $ e_{ss} $ valuta la capacità del sistema di tenere traccia di un input in continua evoluzione. Un input a rampa mette alla prova la capacità del sistema di adattare il proprio output a un ritmo corrispondente al tasso di variazione dell’input.\nIngresso parabola unitario: Con un ingresso parabolico $ r(t) = t^2 (t) $, che rappresenta un ingresso che cambia a un ritmo accelerato, l’ingresso costante -state error $ e_{ss} $ indica le prestazioni del sistema nel tracciare un input con accelerazione crescente.\n\n\n\nIl significato di “E/O” nelle specifiche\nLe specifiche dello stato stazionario sono generalmente definite come: \\(e_{ss}|_{\\mu(t}\\) e/o \\(e_{ss}|_{t\\mu(t)}\\) e/o \\(e_{ss}| _{.5t^2\\mu(t)}\\).\nIl termine “e/o” nel contesto di queste specifiche implica flessibilità nei requisiti di sistema. Non tutti i sistemi devono eccellere nel rispondere a ogni tipo di input. A seconda delle esigenze dell’applicazione, i criteri di progettazione possono essere personalizzati:\n\nRequisiti meno rigorosi: se l’applicazione non richiede un’elevata precisione per diversi tipi di input, specificare $ e_{ss} $ solo per un input di passo unitario potrebbe essere adeguato. Questo scenario semplifica il processo di progettazione, poiché il sistema deve essere ottimizzato solo per un input costante dopo il periodo transitorio iniziale.\nRequisiti rigorosi e diversificati: al contrario, se un’applicazione richiede il monitoraggio preciso degli input che cambiano nel tempo (come ingressi a rampa o parabolici), allora il sistema deve soddisfare anche $ e_{ss} $ per questi tipi di input . Questo requisito rende il processo di progettazione più complesso. Il sistema deve essere sufficientemente versatile da gestire non solo un input costante ma anche input che cambiano linearmente o quadraticamente nel tempo.\n\n🤔 Domanda pop-up: Perché specificare $ e_{ss} $ per più tipi di input complica il processo di progettazione?\nRisposta: Specificare $ e_{ss} $ per vari tipi di input come gradino, rampa e parabola impone più vincoli al sistema. Ciascun tipo di input verifica aspetti diversi del comportamento del sistema e la progettazione di un sistema che funzioni bene per tutti questi input richiede una regolazione più complessa dei parametri di sistema.\n\n\nAnalisi della risposta del sistema agli input di passo unitario, rampa unitaria e parabola unitaria\nPer ottenere informazioni più approfondite su questo aspetto, esploriamo il comportamento di un sistema quando sottoposto a segnali di input come passo unitario, rampa unitaria e parabola unitaria. Il codice seguente illustra questa analisi.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n# Define system parameters (modify as needed for your example)\nKp = 1.0    # Proportional gain\nomega_n = 1.0  # Natural frequency\nzeta = 0.5  # Damping ratio\nnum = [Kp * omega_n**2]\nden = [1, 2 * zeta * omega_n, omega_n**2]\n\n# Create transfer function\nG = control.tf(num, den)\n\n# Time vector\nt = np.linspace(0, 20, 1000)\n\n# Unit Step Input\nt_step, y_step = control.step_response(G, t)\ne_step = 1 - y_step  # Steady-state error for step input\n\n# Unit Ramp Input\nt_ramp, y_ramp = control.forced_response(G, t, t)\ne_ramp = t - y_ramp  # Steady-state error for ramp input\n\n# Unit Parabola Input\nt_parabola, y_parabola = control.forced_response(G, t, t**2 / 2)\ne_parabola = t**2 / 2 - y_parabola  # Steady-state error for parabola input\n\n# Plotting\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.plot(t_step, y_step, label='Response')\nplt.plot(t_step, np.ones_like(t_step), 'r--', label='Step Input')\nplt.plot(t_step, e_step, 'g:', label='Error')\nplt.title('Response to Unit Step Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(t_ramp, y_ramp, label='Response')\nplt.plot(t_ramp, t_ramp, 'r--', label='Ramp Input')\nplt.plot(t_ramp, e_ramp, 'g:', label='Error')\nplt.title('Response to Unit Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t_parabola, y_parabola, label='Response')\nplt.plot(t_parabola, t_parabola**2 / 2, 'r--', label='Parabola Input')\nplt.plot(t_parabola, e_parabola, 'g:', label='Error')\nplt.title('Response to Unit Parabola Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni dei sistemi di feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/performance_of_feedback_systems_it.html#la-robustezza-del-design",
    "href": "IT_🇮🇹/performance_of_feedback_systems_it.html#la-robustezza-del-design",
    "title": "Prestazioni dei sistemi di feedback",
    "section": "La robustezza del design",
    "text": "La robustezza del design\nUn aspetto critico della progettazione del sistema di controllo è garantire la robustezza. La robustezza si riferisce alla capacità del sistema di mantenere prestazioni soddisfacenti in una serie di condizioni, in particolare quando i parametri effettivi del sistema variano dai valori nominali utilizzati nella progettazione.\n\nLa simulazione come strumento chiave nella convalida del progetto\n\nVariazione dei parametri del modello: quando si progetta un sistema di controllo, inizialmente si lavora con un modello matematico che rappresenta il sistema fisico. Tuttavia, questo modello si basa su alcune ipotesi e parametri nominali. In realtà, il sistema fisico reale può presentare variazioni in questi parametri a causa di tolleranze di produzione, cambiamenti ambientali, invecchiamento o altri fattori.\nColmare il divario tra modello e realtà: per garantire che la progettazione del sistema di controllo sia solida ed efficace nelle condizioni del mondo reale, è necessario tenere conto delle possibili deviazioni dal modello nominale. È qui che la simulazione gioca un ruolo cruciale. Variando i parametri del modello entro un intervallo ragionevole, è possibile simulare il comportamento del sistema reale in scenari diversi.\nApproccio di simulazione:\n\nRegolare vari parametri del modello di sistema, come valori di guadagno, costanti di tempo, rapporti di smorzamento, ecc., entro gli intervalli di variazione previsti.\nSi eseguono quindi simulazioni per osservare come questi cambiamenti influiscono sulle prestazioni del sistema di controllo. Questo approccio aiuta a identificare potenziali punti deboli o punti di errore nella progettazione.\n\nValutazione della robustezza del progetto: l’obiettivo è garantire che il sistema di controllo soddisfi ancora i criteri di prestazione desiderati (come stabilità, risposta transitoria, errore a regime) in queste diverse condizioni. Se il sistema funziona in modo soddisfacente in un’ampia gamma di variazioni dei parametri, ciò indica una progettazione robusta.\nFase finale della progettazione: questo processo è fondamentale prima di finalizzare un progetto. Se il progetto regge bene in queste simulazioni, dà la certezza che funzionerà in modo affidabile una volta implementato nel sistema fisico reale. In sostanza, questo passaggio riguarda lo stress test del progetto rispetto alle incertezze e alle variabilità delle applicazioni del mondo reale.\n\n\n\nPerché la simulazione è essenziale\n\nColmare teoria e pratica: le simulazioni colmano il divario tra modelli teorici e applicazioni pratiche. Forniscono un ambiente controllato per testare come il sistema potrebbe rispondere all’imprevedibilità del mondo reale.\nTest economici e sicuri: consente test approfonditi senza i costi e i rischi associati alla sperimentazione su sistemi fisici, soprattutto laddove i guasti possono essere costosi o pericolosi.\nMiglioramento iterativo: le informazioni acquisite dagli studi di simulazione possono portare a miglioramenti iterativi nella progettazione, migliorando le prestazioni e l’affidabilità del sistema.\n\nIn sintesi, la simulazione è un passaggio indispensabile nella progettazione del sistema di controllo, poiché fornisce una piattaforma per testare e perfezionare il sistema in una varietà di condizioni, garantendo che il progetto finale non sia solo teoricamente valido ma anche praticabile e robusto.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni dei sistemi di feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "",
    "text": "Continuiamo il nostro viaggio nel mondo dei sistemi di controllo approfondendo l’analisi di stabilità. Costruiamo sulle conclusioni a cui siamo arrivati ​​l’ultima volta.\nConsideriamo un sistema ad anello chiuso caratterizzato dalla sua funzione di trasferimento. Per semplicità, assumiamo un sistema a feedback unitario in cui $ G(s) $ è la funzione di trasferimento ad anello aperto, $ R $ è l’input e $ Y $ è l’output.\nLa funzione di trasferimento ad anello chiuso è data da:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)}\n\\]\nL’equazione caratteristica del nostro sistema è $ 1 + G(s) = 0 $. Le radici di questa equazione, note anche come poli a circuito chiuso, determinano la stabilità del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html#determinazione-della-stabilità",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html#determinazione-della-stabilità",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Determinazione della stabilità",
    "text": "Determinazione della stabilità\nProcediamo ora per determinare la stabilità. L’equazione caratteristica può generalmente essere rappresentata come un polinomio di ordine ennesimo:\n\\[\n\\Delta(s) = a_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\n\nQuesta equazione deriva da $ 1 + G(s) = 0 $ e rappresenta i poli del nostro sistema a circuito chiuso.\nVorremmo sapere se gli zeri di queste equazioni caratteristiche sono stabili oppure no.\n\nNota: gli zeri del sistema a circuito chiuso non vengono considerati nell’analisi di stabilità, poiché influiscono solo sull’entità, non sulla modalità, della risposta.\n\nControllabilità, osservabilità e zeri\nUn presupposto cruciale nella nostra analisi è che gli zeri non annullano i poli, una condizione tipicamente riscontrata nei sistemi controllabili e osservabili. Se uno zero annulla un polo instabile può portare a valutazioni errate di stabilità.\nQuesto è il punto di convergenza sia per la stabilità asintotica che per la stabilità BIBO (Bounded Input Bounded Output). Negli scenari in cui queste condizioni non sono soddisfatte, i due tipi di stabilità divergono nelle loro interpretazioni. Nello specifico, nella stabilità BIBO, l’annullamento di un polo da parte di uno zero non si manifesta nel comportamento del sistema. Tuttavia, quando si considera la stabilità interna, che viene analizzata utilizzando un modello delle variabili di stato, l’impatto di tale polo annullato diventa evidente sulla stabilità complessiva del sistema.\nLa presunzione che un sistema sia sia controllabile che osservabile generalmente vale per la maggior parte dei sistemi del mondo reale.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html#criterio-di-stabilità-di-routh",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html#criterio-di-stabilità-di-routh",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Criterio di stabilità di Routh",
    "text": "Criterio di stabilità di Routh\nRivolgiamo ora la nostra attenzione al criterio di stabilità di Routh, un metodo prezioso nel campo dell’analisi di stabilità. Mentre i moderni strumenti numerici possono calcolare senza sforzo le radici di un’equazione, il criterio di Routh aiuta oltre questi metodi numerici, specialmente in contesti orientati alla progettazione. Ci consente sia di valutare la stabilità che di identificare i parametri di progettazione che garantiscono una configurazione stabile del sistema.\nConsidera la nostra equazione caratteristica: \\(a_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\\). I coefficienti di questa equazione sono intrinsecamente legati agli attributi fisici del sistema. Un’indagine comune potrebbe comportare la determinazione degli intervalli consentiti per questi coefficienti che garantiscono la stabilità del sistema. In questi casi, fare affidamento esclusivamente su strumenti numerici può rivelarsi inadeguato, poiché in genere richiedono valori numerici predefiniti per i coefficienti, cosa non sempre fattibile negli scenari di progettazione. Il criterio di stabilità Routh affronta questa lacuna, fornendo informazioni sulle implicazioni di stabilità dei diversi parametri del sistema.\n\nCostruire l’array Routh\nIniziamo con la nostra equazione caratteristica:\n\\[\na_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\n\nAssicurarsi che $ a_n $ per evitare radici banali in $ s = 0 \\(.\n-\\)a_0 &gt; 0$. Se $ a_0 $ non è positivo possiamo semplicemente moltiplicare per \\(-1\\) e questo non cambia l’analisi.\n\n🤔 Domanda pop-up: Perché è importante che il coefficiente principale $ a_0 $ sia positivo nell’analisi di stabilità di Routh?\nRisposta: Un $ a_0 $ positivo garantisce che l’array Routh inizi con un valore positivo, che è fondamentale per determinare correttamente il numero di cambi di segno e, di conseguenza, la stabilità del sistema.\n\n\nCondizioni necessarie\n\nTutti i coefficienti devono essere positivi: affinché un sistema sia stabile, ogni coefficiente nel polinomio caratteristico deve essere positivo e diverso da zero. Un coefficiente zero o negativo è una bandiera rossa, che indica potenziale instabilità. Nota che se non avessimo $ a_0 &gt; 0 $ allora questa condizione diventa: tutti i coefficienti devono avere lo stesso segno.\n\n\n\nCondizioni sufficienti: costruzione del Routh Array\nData l’equazione caratteristica:\n\\[\na_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\nOra costruiamo l’array di Routh, un metodo strutturato per analizzare la stabilità di un’equazione polinomiale. L’array Routh viene costruito riga per riga, utilizzando i coefficienti del polinomio caratteristico.\n\nPrime due righe: le prime due righe derivano direttamente dal polinomio. Per un polinomio di grado $ n $, la prima riga contiene i coefficienti delle potenze pari di $ s $ (ad esempio, $ a_0, a_2, a_4, $), mentre la seconda riga contiene i coefficienti delle potenze dispari di $ s $ ( ad esempio, $ a_1, a_3, a_5, $).\nRighe successive: ciascun elemento delle righe successive viene calcolato utilizzando una formula specifica. Per la terza riga (corrispondente a $ s^{n-2} $), ciascun elemento viene calcolato come segue:\n\nIl primo elemento della terza riga è dato da $ $.\nIl secondo elemento è $ $, e così via.\n\nNota: Se manca un coefficiente (ovvero, la potenza di $ s $ non appare nel polinomio), trattalo come zero in questi calcoli.\nIndicizzazione delle righe: L’indicizzazione delle righe (ad esempio, $ s^{n-1}, s^{n-2}, $) serve come guida ma non corrisponde alle potenze di $ s $ nel polinomio originale dopo le prime due righe.\n\nEcco un esempio di come apparirebbe la struttura della tabella Routh per un generico polinomio di ordine $ n $ -esimo:\n\n\n\n\n\n\n\n\n\n\n\nOrder of \\(s\\)\nColumn 1\nColumn 2\nColumn 3\n…\nColumn \\(\\frac{n}{2}+1\\)\n\n\n\n\n\\(s^n\\)\n\\(a_0\\)\n\\(a_2\\)\n\\(a_4\\)\n…\n\\(a_{2k}\\) or 0\n\n\n\\(s^{n-1}\\)\n\\(a_1\\)\n\\(a_3\\)\n\\(a_5\\)\n…\n\\(a_{2k+1}\\) or 0\n\n\n\\(s^{n-2}\\)\n\\(b_1 = \\frac{a_1 a_2 - a_0 a_3}{a_1}\\)\n\\(b_2 = \\frac{a_1 a_4 - a_0 a_5}{a_1}\\)\n\n…\n\n\n\n\\(s^{n-3}\\)\n\n\n\n…\n\n\n\n…\n\n\n\n…\n\n\n\n\\(s^1\\)\n\n\n\n…\n\n\n\n\\(s^0\\)\n\n\n\n…\n\n\n\n\n\n$ k $ è la parte intera di $ $.\nUn coefficiente mancante è 0.\n\n\n\nEsempio illustrativo\nIllustriamolo con uno specifico polinomio del 4° ordine:\n\\[\ns^4 + 8 s^3 + 18 s^2 + 16 s + 5 = 0\n\\]\n\nPrime due righe:\n\nRiga per $ s^4 $: $ 1 $ (coefficiente di $ s^4 $), $ 18 $ (coefficiente di $ s^2 $), $ 5 $ (termine costante).\nRiga per $ s^3 $: $ 8 $ (coefficiente di $ s^3 $), $ 16 $ (coefficiente di $ s^1 $), $ 0 $ (poiché non esiste $ s^{-1} termine $).\n\nRiga per $ s^2 $:\n\nPrimo elemento: $ = = 16 $.\nSecondo elemento: $ = = 5 $.\nIl terzo elemento è zero (poiché non ci sono più elementi da utilizzare nel calcolo).\n\nRiga per $ s^1 $:\n\nPrimo elemento: $ = = 13,5 $.\nIl secondo elemento è zero (poiché gli elementi corrispondenti sopra sono zero o non esistono).\n\nRiga per $ s^0 $:\n\nÈ necessario solo il primo elemento, che è uguale al secondo elemento della riga precedente: $ 5 $.\n\n\nEcco l’array Routh corretto:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n1\n18\n5\n\n\n$ s^3 $\n8\n16\n0\n\n\n$ s^2 $\n16\n5\n0\n\n\n$ s^1 $\n13.5\n0\n\n\n\n$ s^0 $\n5\n\n\n\n\n\nPoiché non ci sono cambiamenti di segno nella prima colonna dell’array Routh, questo sistema è stabile. Il criterio di stabilità di Routh ci dice che tutte le radici dell’equazione caratteristica si trovano nella metà sinistra del piano complesso, indicando stabilità.\n\n\nAnalisi della stabilità con la tabella di Routh\nDopo aver costruito l’array Routh, esaminiamo i segni della prima colonna per trarre conclusioni sulla stabilità del sistema.\n\nSe non ci sono cambiamenti di segno nella prima colonna dell’array Routh, il sistema è stabile.\nSe ci sono cambiamenti di segno, il sistema non è stabile e il numero di radici nella destra è uguale al numero di cambiamenti di segno. I criteri quindi forniscono informazioni sul numero di radici instabili, ma non danno la posizione delle radici.\n\n\nimport numpy as np\n\ndef routh_array(coefficients):\n    n = len(coefficients)\n    routh = []\n\n    # First two rows\n    r1 = [coefficients[i] for i in range(0, n, 2)]\n    r2 = [coefficients[i] for i in range(1, n, 2)]\n    \n    routh.append(r1)\n    routh.append(r2 + [0] * (len(r1) - len(r2)))  # Padding zeros\n\n    # Other rows\n    for i in range(2, n):\n        row = []\n        for j in range(len(r1) - 1):\n            # Calculate element\n            first = routh[i-1][0]\n            upper = routh[i-2][j+1]\n            left = routh[i-1][j+1] if j+1 &lt; len(routh[i-1]) else 0\n            element = ((upper * first) - left * routh[i-2][0]) / first\n            row.append(element)\n        routh.append(row + [0] * (len(r1) - len(row)))  # Padding zeros\n\n        # Check for row of zeros\n        if all(r == 0 for r in row):\n            print(\"Row of zeros detected. Special procedure needed.\")\n            return routh\n\n    return routh\n\n# Example usage\ncoeffs = [1, 8, 18, 16, 5]\nrouth = routh_array(coeffs)\n\n# Printing the Routh array\nfor row in routh:\n    print(row)\n\n[1, 18, 5]\n[8, 16, 0]\n[16.0, 5.0, 0]\n[13.5, 0.0, 0]\n[5.0, 0.0, 0]\n\n\n\n\nEsempio illustrativo 2\nPer calcolare l’array Routh per il polinomio $ 3s^4 + 10s^3 + 5s^2 + 5s + 2 = 0 $, possiamo usare lo stesso metodo di prima.\nEseguiamo i calcoli passo dopo passo:\n\nPrime due righe:\n\nRiga per $ s^4 $: $ 3 $ (coefficiente di $ s^4 $), $ 5 $ (coefficiente di $ s^2 $), $ 2 $ (termine costante).\nRiga per $ s^3 $: $ 10 $ (coefficiente di $ s^3 $), $ 5 $ (coefficiente di $ s^1 $), $ 0 $ (poiché non esiste $ s^{-1} termine $).\n\nRiga per $ s^2 $:\n\nPrimo elemento: $ = = 3,5 $.\nSecondo elemento: $ = = 2 $.\nIl terzo elemento è zero (poiché non ci sono più elementi da utilizzare nel calcolo).\n\nRiga per $ s^1 $:\n\nPrimo elemento: $ = = -0.71 $.\nIl secondo elemento è zero (poiché gli elementi corrispondenti sopra sono zero o non esistono).\n\nRiga per $ s^0 $:\n\nÈ necessario solo il primo elemento, che è uguale al primo elemento della riga precedente: $ 2 $.\n\n\nEcco l’array Routh completato:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n3\n5\n2\n\n\n$ s^3 $\n10\n5\n0\n\n\n$ s^2 $\n3.5\n2\n0\n\n\n$ s^1 $\n-0.71\n0\n\n\n\n$ s^0 $\n2\n\n\n\n\n\nPoiché ci sono due cambiamenti di segno nella prima colonna dell’array Routh (da positivo a negativo tra $ s^2 $ e $ s^1 $ e uno da negativo a positivo tra $ s^1 $ e $ s^0 $ ) , questo sistema è instabile.\nIl criterio di stabilità di Routh indica che ci sono due radici dell’equazione caratteristica nella metà destra del piano complesso, portando alla conclusione di instabilità.\nNota che in questo caso, dato che la seconda riga è divisibile per 5, avremmo potuto scrivere anche la seguente tabella:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n3\n5\n2\n\n\n$ s^3 $\n2\n1\n0\n\n\n$ s^2 $\n3.5\n2\n0\n\n\n$ s^1 $\n\\(-\\frac{1}{7}\\)\n0\n\n\n\n$ s^0 $\n2\n\n\n\n\n\nE finalmente possiamo provare la nostra funzione routh_array:\n\nrouth_array([3, 10, 5, 5, 2])\n\n[[3, 5, 2],\n [10, 5, 0],\n [3.5, 2.0, 0],\n [-0.7142857142857143, 0.0, 0],\n [2.0, 0.0, 0]]",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html#criterio-di-stabilità-di-routh-gestire-le-radici-sullasse-immaginario",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html#criterio-di-stabilità-di-routh-gestire-le-radici-sullasse-immaginario",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Criterio di stabilità di Routh: gestire le radici sull’asse immaginario",
    "text": "Criterio di stabilità di Routh: gestire le radici sull’asse immaginario\nCi addentriamo in scenari più complessi in cui le radici dell’equazione caratteristica possono trovarsi sull’asse immaginario (asse jω). Questa discussione ci condurrà attraverso il processo di gestione di questi casi speciali.\n\nEsempio illustrativo 3\nConsideriamo un sistema rappresentato dall’equazione caratteristica\n\\[\n\\Delta(i) = s^5 + s^4 + 4s^3 + 24s^2 + 3s + 63 = 0\n\\]\nQuando applichiamo il criterio di stabilità di Routh a questo sistema, ci troviamo di fronte ad una situazione unica. In questo caso, una riga completa nell’array Routh potrebbe risultare composta da tutti zeri, indicando la possibilità di radici sull’asse jω. Questo è un indicatore significativo, poiché implica che il sistema potrebbe mostrare stabilità o instabilità marginale.\n\n\n\n\n\n\n\n\n\nOrdine di $ s $\nColonna 1\nColonna 2\nColonna 3\n\n\n\n\n$ s^5 $\n1\n4\n3\n\n\n$ s^4 $\n1\n24\n63\n\n\n$ s^3 $\n\\(\\cancel{-20} \\rightarrow -1\\)\n\\(\\cancel{-60} \\rightarrow -3\\)\n\n\n\n$ s^2 $\n\\(\\cancel{21} \\rightarrow 1\\)\n$ $\n0\n\n\n$ s^1 $\n\\(0\\)\n0\n\n\n\n$ s^0 $\n\n\n\n\n\n\n\n\nComprendere la riga Tutto-Zero\n\nSe incontriamo una riga tutta zero in qualsiasi passaggio, il coefficiente della riga successiva non è definito e dobbiamo costruire un polinomio ausiliario dalla riga immediatamente sopra la riga tutta zero e utilizzare la sua derivata per continuare la costruzione dell’array Routh.\nCiò indica la potenziale presenza di radici sull’asse jω.\nImplicazione di righe tutte zero: quando si incontra una riga tutta zero nell’array Routh, ciò suggerisce che l’equazione caratteristica potrebbe avere radici simmetriche attorno all’asse immaginario. Ciò potrebbe significare una coppia di radici che giacciono esattamente sull’asse jω o coppie coniugate complesse simmetriche lungo questo asse.\nIncertezza sulla stabilità: la presenza di una riga tutta zero non classifica immediatamente il sistema come stabile o instabile. Invece, indica che sono necessarie ulteriori analisi per determinare la stabilità del sistema.\n\n\n\n\n\n\n\nQuando una riga è tutta zeri, non possiamo trarre conclusioni sulla stabilità del sistema e sono necessarie ulteriori indagini.\nTieni presente che il sistema non può essere stabile.\nA causa della simmetria, una riga tutta zero sarà sempre associata a una potenza dispari di s.\n\n\nCostruire il polinomio ausiliario\n\nPer affrontare la riga tutta zero, costruiamo un polinomio ausiliario dai coefficienti della riga appena sopra la riga tutta zero. Ad esempio, se la riga con tutti zero è su $ s^2 $, esamineremo la riga $ s^3 $ per questi coefficienti, se la riga con tutti zero è su $ s^1 $ (come nel nostro caso precedente ), esaminiamo $ s^2 $.\n\nCon riferimento al nostro esempio sopra, il polinomio ausiliario è:\n\\[ A(s) = s^2 + 3 \\]\n\nNota che \\(s^2\\) proviene dall’ordine della riga appena sopra la riga composta da tutti zero (nel nostro caso \\(s^2\\)).\nIl polinomio ausiliario è un fattore dell’equazione caratteristica originale \\(\\Delta(s)\\).\nPoiché in questo caso le radici del polinomio ausiliario sono immaginarie, possiamo concludere che anche le radici dell’equazione caratteristica si trovano sull’asse immaginario (e siamo nel caso medio sopra), e il sistema è marginalmente stabile o instabile nel caso abbiamo più poli immaginari. Infatti per trarre conclusioni sulla stabilità bisogna trarre conclusioni anche sulle restanti radici dell’equazione caratteristica (quelle del polinomio ausiliario sono un sottoinsieme).\n\n\n\nConclusione sulla stabilità\nUna volta ottenuto il polinomio ausiliario ci sono due modi per trarre conclusioni sulla stabilità:\n\nDividiamo l’equazione caratteristica totale per il polinomio ausiliario, otteniamo il resto e applichiamo il criterio di Routh al polinomio resto\nPrendiamo la derivata del polinomio ausiliario \\(\\frac{dA}{ds}\\) e sostituiamo la riga tutta zero con i coefficienti di questa derivata. Questa modifica ci permette di continuare con la costruzione dell’array Routh.\n\nNel nostro caso:\n\\[\\frac{dA}{ds} = 2s + 0\\]\ne possiamo completare l’array Routh:\n\n\n\n\n\n\n\n\n\nOrdine di $ s $\nColonna 1\nColonna 2\nColonna 3\n\n\n\n\n$ s^5 $\n1\n4\n3\n\n\n$ s^4 $\n1\n24\n63\n\n\n$ s^3 $\n\\(\\cancel{-20} \\rightarrow -1\\)\n\\(\\cancel{-60} \\rightarrow -3\\)\n\n\n\n$ s^2 $\n\\(\\cancel{21} \\rightarrow 1\\)\n$ $\n0\n\n\n$ s^1 $\n2\n0\n\n\n\n$ s^0 $\n3\n\n\n\n\n\n\nDopo aver sostituito la riga composta da tutti zero e aver completato l’array Routh, rivalutiamo la prima colonna per i cambiamenti di segno. Il numero di cambiamenti di segno ora ci dà informazioni sulla stabilità del sistema, considerando le radici sull’asse immaginario.\nNel nostro caso ci sono due cambi di segno. Concludiamo che il polinomio originale ha:\n\ndue radici nella RHP (dall’array Routh)\ndue radici sull’asse immaginario (dal polinomio ausiliario)\nuna radice nella sinistra sinistra (quella rimanente)\n\n\nIl sistema è instabile.\n\n\nCaso speciale in cui la riga \\(s_0\\) è tutta zeri?\n\nInfattibilità di una riga tutta zero \\(s_0\\): una riga tutta zero al livello \\(s_0\\) (l’ultima riga dell’array Routh) non è praticamente fattibile. Se dovesse verificarsi, implicherebbe una singola radice all’origine, il che contraddice la situazione di righe tutte zero poiché una singola radice non crea questo scenario.\nConsiderazione sulla simmetria: La simmetria coinvolta nella distribuzione della radice dell’equazione caratteristica implica che una riga tutta zero corrisponderà a una potenza pari di \\(s_0\\). Pertanto, le radici associate ad una riga tutta zero avranno sempre una certa simmetria rispetto all’asse immaginario.\n\n\nIl criterio di stabilità di Routh è uno strumento analitico fondamentale utilizzato nell’ingegneria di controllo per valutare la stabilità dei sistemi lineari. Ecco un riepilogo dei punti chiave che abbiamo visto finora:\n\nScopo: il criterio di Routh viene utilizzato per determinare se un sistema è stabile, instabile o marginalmente stabile senza calcolare esplicitamente le radici della sua equazione caratteristica.\nEquazione caratteristica: la stabilità viene analizzata in base all’equazione caratteristica della funzione di trasferimento del sistema, tipicamente rappresentata come un polinomio in $ s $ (la variabile di Laplace).\nCostruzione dell’array Routh: il criterio prevede la costruzione di un array tabulare, noto come array Routh, utilizzando i coefficienti dell’equazione caratteristica. L’array è formato riga per riga, con le prime due righe riempite con i coefficienti del polinomio, alternando potenze pari e dispari di $ s $.\nAnalisi di stabilità:\n\nSe tutti gli elementi nella prima colonna dell’array Routh sono positivi, il sistema è stabile (nessun polo nella metà destra del piano s).\nLa presenza di cambiamenti di segno nella prima colonna indica instabilità. Il numero di cambiamenti di segno corrisponde al numero di poli nella metà destra del piano s.\nSe una riga è composta interamente da zeri, indica radici simmetriche rispetto all’asse immaginario e richiede un’ulteriore analisi.\n\nGestione di casi speciali:\n\nRiga tutta zero: quando una riga nell’array Routh è tutta zero, suggerisce radici simmetriche attorno all’asse immaginario. Un polinomio ausiliario viene formato dalla riga sopra la riga composta da tutti zero e la sua derivata viene utilizzata per continuare la costruzione dell’array Routh.\nStabilità marginale: una riga tutta zero può indicare stabilità marginale, dove le radici si trovano sull’asse immaginario. Tuttavia, sono necessarie ulteriori indagini per confermarlo.\n\nPolinomio ausiliario: questo polinomio deriva dalla riga sopra la riga di tutti zero. La derivata del polinomio ausiliario viene utilizzata per sostituire la riga tutta zero e continuare la costruzione dell’array Routh.\nLimitazioni: Sebbene il criterio Routh possa indicare il numero e la posizione (metà piano sinistro o semipiano destro) delle radici, non fornisce i valori esatti di queste radici.\n\n\n\n\nEsempio illustrativo 3\nConsideriamo il sistema caratterizzato dal polinomio\n\\[\ns^6 + 2s^5 + 8s^4 + 12s^3 + 20s^2 + 16s + 16 = 0\n\\]\nMentre costruiamo l’array Routh, incontriamo una riga tutta zero in $ s^3 $.\n\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\nColumn 4\n\n\n\n\n$ s^6 $\n1\n8\n20\n16\n\n\n$ s^5 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^4 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^3 $\n0\n0\n\n\n\n\n$ s^2 $\n…\n…\n\n\n\n\n$ s^1 $\n…\n\n\n\n\n\n$ s^0 $\n…\n\n\n\n\n\n\nL’array Routh deve essere completato con ulteriori calcoli a partire dalla riga $ s^3 $ modificata. Questo processo fornirà le informazioni necessarie per valutare la stabilità del sistema.\nIn questo caso, formiamo un polinomio ausiliario dalla riga $ s^4 $, che risulta essere:\n\\[ A(s) = s^4 + 6s^2 + 8 \\]\nIl passo successivo consiste nel ricavare la derivata di questo polinomio ausiliario:\n\\[ \\frac{dA}{ds} = 4s^3 + 12s + 0 \\]\n\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\nColumn 4\n\n\n\n\n$ s^6 $\n1\n8\n20\n16\n\n\n$ s^5 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^4 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^3 $\n$ $\n\\(\\cancel{12} \\rightarrow 3\\)\n\n\n\n\n$ s^2 $\n3\n8\n\n\n\n\n$ s^1 $\n\\(\\frac{1}{3}\\)\n\n\n\n\n\n$ s^0 $\n8\n\n\n\n\n\n\nConclusioni\n\nLa prima colonna dell’array Routh è tutta positiva (nessun cambiamento di segno). Ciò significa che il polinomio \\(\\frac{\\Delta(s)}{A(s)}\\) non ha radici nella RHP.\nQuando guardiamo il polinomio ausiliario: $ A(s) = s^4 + 6s^2 + 8 $, possiamo risolvere le sue radici:\n\nimposta $s^2=z A(s) = z^2 + 6z + 8 $ con radici: \\(s=\\pm j\\sqrt{2};\\;\\;\\;s=\\pm j2\\)\nil polinomio ausiliario ha solo radici immaginarie (caso centrale nel diagramma che abbiamo disegnato sopra)\n\nIl sistema è quindi marginalmente stabile, oscillando a una frequenza \\(\\sqrt{2}\\;\\;rad/s\\) e a \\(2\\;\\;rad/s\\) (l’uscita rimane limitata). Utilizzeremo questo punto durante la fase di progettazione.\n\n\n\nUno zero in una riga\nUna situazione speciale si verifica quando solo l’elemento pivot (il primo elemento) di una riga nell’array Routh è zero, mentre almeno uno degli elementi successivi nella stessa riga è diverso da zero. Questo scenario richiede un approccio distinto per la continuazione della costruzione dell’array Routh. Ecco i dettagli:\n\nL’elemento pivot in un array Routh si riferisce al primo elemento di qualsiasi riga. Un elemento pivot zero con almeno un elemento diverso da zero nella stessa riga presenta un caso unico nella formulazione dell’array.\nUn elemento pivot pari a zero rende impossibile l’utilizzo della formula matriciale Routh standard per la riga successiva, poiché comporta la divisione per l’elemento pivot.\nLa presenza di un elemento pivot zero non suggerisce immediatamente radici simmetriche o radici sull’asse immaginario, a differenza di una riga tutta zero. Rappresenta invece una condizione numerica risultante dai coefficienti specifici dell’equazione caratteristica.\n\n\nGestire l’elemento pivot zero\n\nApproccio: per continuare la costruzione dell’array Routh, in genere sostituiamo l’elemento pivot zero con un piccolo numero positivo, indicato come $ $. Questa sostituzione consente al calcolo di procedere senza l’indeterminatezza causata dalla divisione per zero.\nSignificato di $ $: Il valore di $ $ è considerato infinitesimo, tendente di fatto allo zero. Questa sostituzione è una tecnica matematica per superare l’ostacolo computazionale e non cambia la natura fondamentale del sistema analizzato.\n\n🤔 Domanda pop-up: Cosa rappresenta la sostituzione di $ $ al posto di un elemento pivot zero nell’array Routh?\nRisposta: La sostituzione di $ $ rappresenta un metodo per aggirare il problema computazionale della divisione per zero. Consente la continuazione della costruzione dell’array Routh e aiuta a trarre conclusioni sulla stabilità del sistema.\nAnalizziamo questo scenario attraverso un esempio:\nConsideriamo il sistema caratterizzato dal polinomio\n\\[\ns^5 + 3s^4 + 2s^3 + 6s^2 + 6s + 9 = 0\n\\]\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^5 $\n1\n2\n6\n\n\n$ s^4 $\n3\n6\n9\n\n\n$ s^3 $\n0\n3\n\n\n\n$ s^2 $\n\n\n\n\n\n$ s^1 $\n\n\n\n\n\n$ s^0 $\n\n\n\n\n\n\nNon possiamo fare alcuna valutazione di stabilità. La presenza di uno 0 come elemento cardine rappresenta una condizione numerica risultante dai coefficienti specifici dell’equazione caratteristica.\nIn questo caso, sostituiamo il pivot zero nella riga con \\(\\epsilon\\) e continuiamo a costruire l’array. Ciò corrisponde a perturbare i coefficienti del polinomio.\n\n\n\nPerturbazione dei coefficienti dell’equazione caratteristica\n\nStabilità delle radici: è improbabile che le radici di un polinomio nel semipiano sinistro o destro “saltino” da un lato all’altro del piano complesso con una piccola perturbazione nei coefficienti. Questa stabilità delle posizioni delle radici nel piano complesso costituisce la base di questo approccio.\nEffetto di piccoli cambiamenti: Se i coefficienti del polinomio caratteristico sono leggermente alterati (diciamo dell’1% o meno), si prevede che le posizioni fisiche delle radici nel piano complesso cambino solo leggermente. Ciò implica che le radici originariamente nel semipiano sinistro probabilmente rimarranno lì, e allo stesso modo per quelle nel semipiano destro.\nPreoccupazione con le radici sull’asse immaginario: il rischio in questo metodo di perturbazione sorge se l’equazione caratteristica originale ha radici esattamente sull’asse immaginario (asse jω). Una piccola variazione nei coefficienti potrebbe spostare queste radici nel semipiano destro o sinistro, alterando la conclusione sulla stabilità. Se così fosse, non sapresti se queste radici immaginarie si sono spostate a sinistra o a destra.\nAssunzione dell’assenza di radici sull’asse immaginario: se si sa in anticipo che non ci sono radici sull’asse immaginario, perturbare leggermente i coefficienti non dovrebbe influenzare in modo significativo le conclusioni sulla stabilità complessiva del sistema.\n\nNota che una riga tutta zero indicherà se potrebbero esserci radici sull’asse immaginario\n\nGestione di uno Zero Pivot nell’array Routh: In pratica, se una riga nell’array Routh ha un elemento pivot zero, questo problema può spesso essere risolto sostituendo lo zero con un piccolo numero positivo, $ $. Questo approccio equivale effettivamente ad una piccola perturbazione dei coefficienti dell’equazione caratteristica.\nImportanza della riga tutta zero: se c’è una riga tutta zero nell’array Routh, di solito indica le radici sull’asse immaginario. Pertanto, nei casi senza una riga composta da tutti zero, possiamo essere più sicuri che la perturbazione dei coefficienti (come con la sostituzione $ $) non porterà a conclusioni errate riguardo alla stabilità.\nApplicazione pratica: questa tecnica è particolarmente utile nei calcoli automatizzati o negli algoritmi in cui gestire un elemento pivot zero è computazionalmente problematico. Introducendo $ $, è possibile completare l’array Routh e valutarne la stabilità.\nValutazione del rischio: il punto chiave qui è la valutazione del rischio quando si applica questa perturbazione. Se esiste la possibilità che le radici si trovino sull’asse immaginario, è necessario essere cauti, poiché la perturbazione potrebbe portare a conclusioni errate sulla stabilità.\n\nPer ora supporremo che non vi siano radici sull’asse immaginario e perturberemo i coefficienti del polinomio.\nIn questo caso, sostituiamo il pivot zero nella riga con \\(\\epsilon\\) e continuiamo a costruire l’array.\nDopo aver sostituito il pivot zero con \\(\\epsilon\\), rivalutiamo la prima colonna per i cambiamenti di segno. Le conclusioni tratte da questo array Routh modificato aiutano a valutare la stabilità del sistema.\nConsiderazione di ( ) nell’analisi limite: È importante notare che l’uso di $ $ nel contesto di un processo limitante, dove tende allo zero, rende il suo segno (positivo o negativo ) irrilevante. Questo perché, nei casi in cui l’equazione caratteristica del sistema non ha radici sull’asse immaginario, il segno specifico della piccola perturbazione introdotta da $ $ non incide in modo significativo sull’analisi di stabilità.\n\n\n\n\n\nCompletiamo quindi l’array Routh:\n\n\n\n\n\nConclusioni sulla stabilità: Possiamo ora trarre conclusioni sulla stabilità. Dato che abbiamo scelto $ &gt; 0 $ allora abbiamo due cambi di segno, il che significa che il sistema ha due radici sulla destra, e quindi il sistema è instabile.\nSignificato di una riga tutta zero: se, nel processo di lasciare che $ $ si avvicini allo zero, incontriamo una riga che diventa interamente zero, ciò suggerisce la potenziale esistenza di radici sull’asse immaginario. In tali scenari, qualsiasi conclusione sulla stabilità derivata sulla base del limite $ $ dovrebbe essere affrontata con cautela, poiché potrebbe non riflettere accuratamente il comportamento del sistema. In questo contesto è fondamentale considerare la direzione da cui $ $) si avvicina allo zero (sia dal lato positivo che negativo). Il segno di $ $ diventa importante perché, a seconda che $ $ tenda a zero dalla direzione positiva o negativa, può influenzare l’analisi delle radici che giacciono vicine all’asse immaginario. Questa sensibilità al segno di $ $ è particolarmente rilevante quando si ha a che fare con radici che possono attraversare l’asse immaginario a causa di perturbazioni così piccole, alterando così le caratteristiche di stabilità del sistema. Pertanto, nei casi con una riga tutta zero, la valutazione della stabilità dovrebbe includere un attento esame di come questi piccoli cambiamenti in $ $ influenzano la posizione delle radici rispetto all’asse immaginario.\nIn questi casi, formuliamo un polinomio ausiliario utilizzando la riga immediatamente sopra la riga tutta zero. Questo polinomio ausiliario aiuta ad analizzare ulteriormente il comportamento del sistema.\nIl passo successivo prevede la divisione del polinomio caratteristico originale per questo polinomio ausiliario per isolare le radici rimanenti. Il criterio di stabilità di Routh viene quindi riapplicato a questo polinomio del resto.\n\n\nEsempio illustrativo\nConsideriamo il polinomio:\n\\[\n\\Delta(i) = s^6 + s^5 +3s^4 + 3s^3 + 3s^2 + 2s+ 1\n\\]\n\n\n\n\n\nQuando $ $ si avvicina a zero, gli elementi nella riga $ s^1 $ dell’array Routh convergono a zero. Questa situazione suggerisce una potenziale presenza di radici sull’asse immaginario nel piano s. Per risolvere questo problema è necessario un esame più attento del polinomio ausiliario. Nei casi in cui non si trovano radici sull’asse immaginario, tipicamente si procede sostituendo la riga tutta zero con i coefficienti derivati ​​dalla derivata del polinomio ausiliario. Tuttavia, se le radici sull’asse immaginario sono effettivamente presenti, adottiamo un approccio diverso: il polinomio caratteristico originale viene diviso per il polinomio ausiliario e il criterio di stabilità di Routh viene quindi applicato a questo polinomio del resto risultante.\nNell’esempio specifico analizzato, quando si considera il limite di $ $ che si avvicina allo zero nella riga $ s^2 $, il polinomio ausiliario è formulato come $ A(s) = s^2 + 1 = 0 $.\n\nRadici del polinomio ausiliario:\n\nIl polinomio ausiliario $ A(s) = s^2 + 1 = 0 $ ha radici in $ s = j $, indicando la presenza di radici sull’asse immaginario nel piano s. Queste radici sono posizionate simmetricamente rispetto all’asse reale.\n\nDivisione del polinomio originale:\n\nData la presenza di radici dell’asse immaginario, il polinomio caratteristico originale deve essere diviso per il polinomio ausiliario. Questa divisione isola la restante parte del polinomio, che esclude le radici già individuate dal polinomio ausiliario. Questa divisione produrrà un nuovo polinomio che rappresenta la parte del sistema non considerata dal polinomio ausiliario.\n\n\\[\n\\frac{\\Delta(s)}{A(s)} = s^4 + s^3 + 2s^2 + 2s + 1\n\\]\nApplicazione del criterio di stabilità di Routh al polinomio del resto:\n\nUna volta diviso il polinomio originale per $ A(s) = s^2 + 1 $, il polinomio risultante è soggetto al criterio di stabilità di Routh. Questa analisi rivelerà la stabilità del sistema per quanto riguarda le radici che non si trovano sull’asse immaginario.\n\n\n\n\n\n\n\n\nInterpretare i risultati:\n\nSe tutti gli elementi nella prima colonna del nuovo array Routh sono positivi, ciò indica che le restanti radici (escluse quelle sull’asse immaginario) si trovano nel semipiano sinistro, suggerendo stabilità per questa parte del sistema.\nSe nella prima colonna ci sono cambiamenti di segno, indica instabilità dovuta al fatto che le radici si trovano nel semipiano destro.\n\n\nIn questo caso, quando \\(\\epsilon \\rightarrow 0\\), ci sono due cambi di segno nella prima colonna dell’array. Ci sono quindi due radici nella RHP.\nIl polinomio originale \\(\\Delta(s)\\) ha quindi due radici nella RHP e due radici nell’asse immaginario.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html#estendere-il-criterio-di-routh-oltre-la-stabilità-assoluta",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html#estendere-il-criterio-di-routh-oltre-la-stabilità-assoluta",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Estendere il criterio di Routh oltre la stabilità assoluta",
    "text": "Estendere il criterio di Routh oltre la stabilità assoluta\n\nStabilità relativa\nIl criterio di stabilità di Routh viene utilizzato per confermare la stabilità assoluta di un sistema, verificando che tutte le radici della sua equazione caratteristica siano localizzate nella metà sinistra del piano s. Dopo aver stabilito che un sistema è assolutamente stabile, con tutte le sue radici caratteristiche nel semipiano sinistro, il passo successivo è valutarne la stabilità relativa. La stabilità relativa si concentra sulla comprensione delle caratteristiche della risposta transitoria del sistema.\nIn altre parole, la stabilità relativa si riferisce al grado di stabilità del sistema, indicando quanto velocemente la risposta di un sistema si stabilizza al suo stato stazionario o quanto è resiliente alle oscillazioni e alle perturbazioni.\n\nSignificato delle posizioni delle radici: Nel piano s, la posizione dei poli del sistema (radici dell’equazione caratteristica) determina la sua stabilità relativa. I poli più a sinistra nel piano s indicano un decadimento più rapido dei transitori, il che implica una maggiore stabilità relativa.\nCostante di tempo e risposta: la risposta transitoria di una modalità in un sistema può essere rappresentata come $ e^{-pt} $, dove $ p $ è il polo e $ t $ è il tempo. Questo può essere riscritto come $ e^{-} $, dove $ $, la costante di tempo, è l’inverso della parte reale del polo. Un $ $ più piccolo significa una risposta più rapida.\nUtilizzo del criterio di stabilità di Routh: il criterio di stabilità di Routh può essere esteso per valutare la stabilità relativa esaminando quanto vicine sono le radici all’asse immaginario. Il criterio può accertare se le radici si trovano a sinistra di una linea verticale specificata nel piano s (ad esempio, $ s = -$), che rappresenta un limite dello smorzamento desiderato (vedi diagramma sotto). Saprai se i tuoi poli sono più veloci di $ e^{-t} $\n\n\n\n\n\n\n🤔 Domanda pop-up: In che modo la posizione dei poli nel piano s è correlata alla stabilità relativa?\nRisposta: Più a sinistra si trovano i poli nel piano s, più velocemente decade la risposta transitoria del sistema, indicando una maggiore stabilità relativa. I poli più vicini all’asse immaginario suggeriscono un decadimento più lento dei transitori, implicando una stabilità relativa inferiore.\n\n\nEsempio illustrativo 4\nConsideriamo il polinomio:\n\\[\ns^3 + 7s^2 + 25s + 39 = 0\n\\]\n\nEstensione del criterio di Routh per la stabilità relativa:\n\nPer analizzare la stabilità relativa, possiamo modificare il criterio di Routh per valutare se i poli si trovano a sinistra di una linea specifica nel piano s, ad esempio $ s = -$.\nSostituendo $ s = - $ nell’equazione caratteristica, spostiamo l’analisi su un nuovo piano ($ $-piano). Qui, $ $ è un valore predefinito che rappresenta il livello desiderato di smorzamento o velocità di risposta.\n\n\nAd esempio, per \\(\\sigma=1\\), possiamo cambiare la coordinata in $ s = - 1 $ e riscrivere l’equazione caratteristica come:\n\\[\n\\hat{s}^3 + 4\\hat{s}^2 + 14\\hat{s} + 20 = 0\n\\]\ne applichiamo il criterio di Routh a questo nuovo polinomio.\nPossiamo quindi verificare che, in questo caso, non ci sono cambiamenti di segno nella prima colonna dell’array Routh. Ciò significa che il polinomio originale non ha radici a destra della linea \\(s=-1\\).\n\nL’array Routh stabilisce se il nuovo polinomio non ha radici a destra di \\(\\hat{s}=0\\).\nSe imposti \\(\\hat{s}=0\\) in $ s = - 1 $, questo ci darà: \\(s=-1\\)\n\n🤔 Domanda pop-up: In che modo la scelta di $ $ influisce sull’analisi della stabilità relativa?\nRisposta: La scelta di $ $ stabilisce un punto di riferimento per la velocità di risposta o smorzamento desiderata nel sistema. Analizzando le posizioni delle radici relative a $ s = -$, possiamo determinare se la risposta del sistema è più veloce o più lenta rispetto a questo benchmark, valutando così la sua relativa stabilità.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/stability_and_routh_criterion_it.html#analisi-della-sensibilità-e-della-stabilità-dei-parametri",
    "href": "IT_🇮🇹/stability_and_routh_criterion_it.html#analisi-della-sensibilità-e-della-stabilità-dei-parametri",
    "title": "Analisi di stabilità nei sistemi di controllo",
    "section": "Analisi della sensibilità e della stabilità dei parametri",
    "text": "Analisi della sensibilità e della stabilità dei parametri\nNella nostra continua esplorazione dei sistemi di controllo, approfondiamo un aspetto importante: la sensibilità della stabilità del sistema alle variazioni dei parametri. Ci concentreremo su un sistema di feedback caratterizzato da un parametro $ K $. Il nostro obiettivo è determinare l’intervallo di $ K $ che garantisce la stabilità del sistema.\n\nL’equazione caratteristica e l’array Routh\nConsideriamo un sistema di feedback in cui:\n\\[ G(s) = \\frac{K}{s(s^2+s+1)(s+4)} \\]\ne $ K $ è il nostro parametro di progettazione e vorremmo sceglierlo in modo tale che il sistema rimanga stabile.\nLa stabilità del sistema è governata dall’equazione caratteristica $ 1 + G(s) = 0 $. Per questo sistema, l’equazione caratteristica diventa una funzione di $ K $:\n\\[\ns^4 + 5s^3 + 5s^2 + 4s + K = 0\n\\]\nCostruiamo l’array Routh per questo sistema, tenendo presente che sarà una funzione di $ K $:\n\\[\\begin{array}{c|ccc}\ns^4 & 1 & 5 & K\\\\\ns^3 & 5 & 4 & \\\\\ns^2 & \\frac{21}{5} & K & \\\\\ns^1 & \\frac{84/5 - 5K}{\\frac{21}{5}} & 0 \\\\\ns^0 & K & \\\\\n\\end{array}\\]\n\nVincoli di stabilità sul parametro $K $\nL’analisi dell’array di Routh rivela i vincoli su $K $.\nPer garantire la stabilità:\n\n$K $ deve essere maggiore di zero. Ciò si allinea con i sistemi fisici in cui, in genere, il guadagno dell’amplificatore (\\(K\\)) è positivo.\nUlteriori vincoli derivano dall’array Routh. Ad esempio, il primo elemento della colonna corrispondente a $s^1 $ dovrebbe essere positivo, producendo la condizione $K &lt; $.\n\nPertanto, per la stabilità del sistema, $K $ deve trovarsi all’interno dell’intervallo $0 &lt; K &lt; $.\n\n\nImplicazioni sulla progettazione\n\nIntervallo di stabilità: Nell’intervallo $0 &lt; K &lt; $ becomes critical in system design. Any performance specifications must be met within this range to avoid instability.\nPole Movement with Varying $K $: As $K $ increases within this range, the closed-loop poles drift towards the right half-plane. A $K $ value of $ $ brings the poles to the \\(j\\omega\\) axis, indicating a marginally stable system. In the case where \\(K = \\frac{84}{25}\\) we would obtain an all-zero row in the Routh array. The corresponding roots would be on the \\(j\\omega\\) axis (more specifically they would be \\(\\pm j \\omega_0\\)).\nSystem Behavior Beyond the Stability Range: For $K &gt; $, il sistema diventa instabile, oscillando con una frequenza di \\(\\omega_0\\) radianti al secondo.\n\n🤔 Domanda pop-up: Cosa succede alla stabilità di un sistema quando il parametro \\(K\\) supera il suo limite superiore di stabilità?\nRisposta: Quando $K $ supera il suo limite superiore di stabilità (in questo caso, $ $), il sistema passa da uno stato marginalmente stabile a uno stato instabile, caratterizzato da oscillazioni ad uno specifico frequenza determinata dai poli del sistema.\n\n\nEstendere l’analisi: considerare gli elementi di ritardo\nInfine estendiamo la nostra analisi ad un sistema più complesso dove:\n\\[G(s) = \\frac{K}{s(s+1)} \\]\ne \\[H(s) = e^{-s\\tau_D} \\]\ndove stiamo introducendo un elemento di ritardo $_D $.\n\n\n\n\n\nL’equazione caratteristica è:\n\\[\n1+G(s)H(s) = 1 + \\frac{Ke^{-s\\tau_D}}{s(s+1)} = 0\n\\]\n\nLa presenza di ritardo rende l’equazione caratteristica non polinomiale.\nTuttavia, approssimando il termine di ritardo $e^{-s_D} $ utilizzando l’approssimazione del primo ordine di Padé, possiamo tornare alla forma polinomiale, consentendo l’applicazione del criterio di Routh.\nPiù specificamente, un’approssimazione approssimativa di \\(e^{-s\\tau_D}\\) è:\n\n\\[\ne^{-s\\tau_D} \\approx 1 - s\\tau_D\n\\]\no uno migliore:\n\\[\ne^{-s\\tau_D} \\approx \\frac{1 - s\\frac{\\tau_D}{2}}{1 + s\\frac{\\tau_D}{2}} = \\frac{1 - sT}{1 +st}\n\\]\nOra abbiamo due parametri sconosciuti: \\(K\\) e \\(T\\).\nEsercizio: applica il criterio di stabilità di Routh all’equazione caratteristica approssimata che coinvolge $K $ e \\(T\\). Determinare l’intervallo di stabilità per questi parametri.\n\\[\nTs^3 + (1+T)s^2 + (1-KT)s + K = 0\n\\]\n\\[\\begin{array}{c|cc}\ns^3 & T & 1-KT \\\\\ns^2 & 1+T & K \\\\\ns^1 & \\frac{1+T-2KT-KT^2}{1+T} & 0 \\\\\ns^0 & K & \\\\\n\\end{array}\\]\nPerché il sistema sia stabile:\n\n\\(T&gt;0\\) (fisicamente ha senso) -\\(K&gt;0\\)\n\\(\\frac{1+T-2KT-KT^2}{1+T} &gt;0\\) \\(\\Rightarrow\\) \\(1+T-KT(T+2)&gt;0\\) \\(\\Rightarrow\\) \\(KT = \\frac{ T+2}{T+1}\\) (caso marginale).\n\nPossiamo tracciare questo:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the range of T, avoiding T = 0 and T = -1 to prevent division by zero\nT = np.linspace(0, 1, 400)\nT = T[np.logical_and(T != 0, T != -1)]\n\n# Calculate K as a function of T\nK = (T + 2) / (T * (T + 1))\n\n# Plotting\nplt.plot(T, K, label='K(T) = (T + 2) / (T * (T + 1))')\nplt.fill_between(T, 1, K, color='lightblue', alpha=0.5, label='Stable Range (below curve)')\n\nplt.xlabel('T')\nplt.ylabel('K')\nplt.title('Plot of K(T) = (T + 2) / (T * (T + 1))')\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNota su ritardo e stabilità: - Questo esempio illustra come l’aumento del ritardo (\\(\\tau_D\\)) riduca il margine di stabilità, evidenziando l’effetto destabilizzante del ritardo nei sistemi di controllo. - Il sistema sarà stabile per un valore inferiore a \\(K\\). - I tempi morti causano instabilità nel sistema e dovrebbero essere ridotti il ​​più possibile. - Qualsiasi coppia \\((K, T)\\) deve trovarsi nell’intervallo stabile.",
    "crumbs": [
      "IT_🇮🇹",
      "Analisi di stabilità nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html",
    "href": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html",
    "title": "Il criterio di stabilità di Nyquist e la stabilità relativa",
    "section": "",
    "text": "La stabilità relativa si riferisce al grado in cui un sistema tollera i cambiamenti nei suoi parametri prima di diventare instabile. A differenza della stabilità assoluta, che ci dice semplicemente se un sistema è stabile o meno, la stabilità relativa fornisce una misura di quanto il sistema è vicino al confine dell’instabilità.\nConsideriamo un grafico che rappresenta i poli del circuito chiuso sul piano σ-jω. Supponiamo di avere due poli dominanti in questo sistema. Se questi poli sono più vicini all’asse jω, la risposta transitoria del sistema decade più velocemente.\nQuesto posizionamento dei poli rispetto all’asse jω indica la relativa stabilità del sistema.\nLa parte reale guida l’inviluppo della risposta oscillante.\n\n\n\n\n\n\n\n\n\n\nI poli dominanti sono quelli che hanno l’effetto più significativo sul comportamento del sistema.\nPiù questi poli sono vicini all’asse jω, più lentamente decade la risposta ai transitori, indicando una stabilità relativa più scarsa.\n\n\n\n\nOra interpretiamo questi concetti nel dominio della frequenza utilizzando il diagramma di Nyquist.\nI grafici corrispondenti al precedente esempio del piano s potrebbero essere i seguenti (nota che questo è solo un esempio):\n\n\n\n\n\n\n\n\n\nInserisci qui due grafici di Nyquist: 1. Un grafico che mostra una risposta più vicina al punto (-1, j0), indicando un sistema più vicino all’instabilità. 2. Un altro grafico che mostra una risposta più lontana dal punto (-1, j0), indicando un sistema più stabile.\n\n\n\n\nLa vicinanza del grafico di Nyquist al punto (-1, j0) ci dà un’indicazione della relativa stabilità del sistema.\n\n\n\nRacchiudere il punto (-1, j0) indica stabilità assoluta.\nPiù il tracciato è vicino a questo punto, maggiore è il rischio di instabilità.\n\n\n\n\n\nIl diagramma polare è una rappresentazione grafica della risposta in frequenza di un sistema, che va da ω = 0 a ω = ∞.\nLa vicinanza del diagramma polare al punto critico (-1, j0) è indicativa del potenziale di oscillazioni o instabilità sostenute del sistema.\nAumentando il guadagno del sistema si tende a spostare il diagramma polare più vicino al punto critico (-1, j0).\nSe questo grafico circonda il punto (-1, j0), è un segnale che il sistema si sta muovendo verso l’instabilità.\n\n\n\n\n\n\n\n\n\n\n\n\nLa chiave per comprendere la stabilità relativa di un sistema sta nel misurare la distanza del diagramma polare (o di Nyquist) dal punto (-1, j0).\nDeterminare questa “distanza relativa” implica misurare quanto il grafico è vicino a (-1, j0), che a sua volta riflette la suscettibilità del sistema all’instabilità.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon solo l’intersezione con l’asse reale negativo ma anche l’angolo di fase del grafico è fondamentale per valutare la stabilità relativa.\nPer misurarlo vengono spesso utilizzati due indici: il punto di intersezione sull’asse reale e l’angolo di fase nel punto in cui la grandezza è unitaria.\n\n\n\n\n\n\n\n\n\n\n\n\nMagnitudo all’intersezione: viene misurata nel punto in cui il diagramma di Nyquist interseca l’asse reale negativo. Quanto più bassa è questa grandezza, tanto più stabile è considerato il sistema.\nAngolo di fase: viene considerato un cerchio unitario centrato in (-1, j0). L’angolo al quale questo cerchio interseca il diagramma di Nyquist fornisce una misura della stabilità relativa.\n\nSi può anche dire che questi due indici non sono necessariamente sufficienti. Tuttavia, forniscono un semplice algoritmo per quantificare la stabilità relativa.\n\n\n\n\n\n\nAnalizziamo lo scenario in cui il guadagno del sistema, indicato come \\(K\\), viene progressivamente aumentato. Con questo incremento di guadagno, aumenta anche la grandezza complessiva del diagramma di Nyquist. Ad un valore di guadagno specifico, il grafico interseca il punto critico di (-1, j0).\nPer determinare l’esatto incremento di guadagno richiesto affinché il grafico si intersechi (-1, j0), utilizziamo il fattore \\(\\frac{1}{a}\\). Qui, \\(a\\) rappresenta la distanza dell’intersezione del grafico dall’asse reale nel suo stato originale (prima dell’aumento del guadagno).\nApplicando un guadagno di \\(\\frac{1}{a}\\) al tuo diagramma polare, allinei la sua intersezione con l’asse reale esattamente nel punto -1.\nIl margine di guadagno (GM) è matematicamente espresso come \\[GM = \\frac{1}{a}.\\] Questo valore rappresenta la soglia prima che il sistema raggiunga uno stato di stabilità o instabilità marginale.\nIl margine di guadagno considera il fattore di amplificazione al quale un sistema diventa instabile.\nLa seguente illustrazione illustra visivamente questo concetto:\n\n\n\n\n\n\n\n\n\n\nPer chiarire ulteriormente questo concetto, esaminiamo un esempio specifico:\nConsideriamo la funzione di trasferimento:\n\\[\nG(s) = K_1\\frac{1 + sT_1}{s(1 + sT_2)}\n\\]\nIn questo caso, il numero di poli ad anello aperto nel semipiano destro, indicato come \\(P\\), è uguale a 0. Questo scenario corrisponde al diagramma di Nyquist mostrato di seguito:\n\n\n\n\n\n\n\nConcentrandosi sul margine di fase, indicato come \\(\\phi\\), analizziamo il suo significato nella stabilità del sistema:\n\nIl margine di fase \\(\\phi\\) rappresenta lo sfasamento aggiuntivo che può essere introdotto nel sistema senza farlo intersecare con il punto critico (-1, j0).\nIn sostanza, quantifica la capacità del sistema di gestire gli sfasamenti senza cadere nell’instabilità.\n\nQuando si considera il margine di fase, un valore positivo di \\(\\phi\\) è indicativo della robustezza del sistema.\nQuesto margine di fase positivo è la soglia di ulteriore ritardo di fase che, se incorporato nel sistema, lo porterebbe al limite estremo dell’instabilità, senza però passare in uno stato instabile.\nLa presenza di un margine di fase positivo funge da salvaguardia contro l’instabilità, dimostrando la capacità del sistema di resistere a determinati livelli di alterazioni di fase.",
    "crumbs": [
      "IT_🇮🇹",
      "Il criterio di stabilità di Nyquist e la stabilità relativa"
    ]
  },
  {
    "objectID": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#introduzione-alla-stabilità-relativa",
    "href": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#introduzione-alla-stabilità-relativa",
    "title": "Il criterio di stabilità di Nyquist e la stabilità relativa",
    "section": "",
    "text": "La stabilità relativa si riferisce al grado in cui un sistema tollera i cambiamenti nei suoi parametri prima di diventare instabile. A differenza della stabilità assoluta, che ci dice semplicemente se un sistema è stabile o meno, la stabilità relativa fornisce una misura di quanto il sistema è vicino al confine dell’instabilità.\nConsideriamo un grafico che rappresenta i poli del circuito chiuso sul piano σ-jω. Supponiamo di avere due poli dominanti in questo sistema. Se questi poli sono più vicini all’asse jω, la risposta transitoria del sistema decade più velocemente.\nQuesto posizionamento dei poli rispetto all’asse jω indica la relativa stabilità del sistema.\nLa parte reale guida l’inviluppo della risposta oscillante.\n\n\n\n\n\n\n\n\n\n\nI poli dominanti sono quelli che hanno l’effetto più significativo sul comportamento del sistema.\nPiù questi poli sono vicini all’asse jω, più lentamente decade la risposta ai transitori, indicando una stabilità relativa più scarsa.\n\n\n\n\nOra interpretiamo questi concetti nel dominio della frequenza utilizzando il diagramma di Nyquist.\nI grafici corrispondenti al precedente esempio del piano s potrebbero essere i seguenti (nota che questo è solo un esempio):\n\n\n\n\n\n\n\n\n\nInserisci qui due grafici di Nyquist: 1. Un grafico che mostra una risposta più vicina al punto (-1, j0), indicando un sistema più vicino all’instabilità. 2. Un altro grafico che mostra una risposta più lontana dal punto (-1, j0), indicando un sistema più stabile.\n\n\n\n\nLa vicinanza del grafico di Nyquist al punto (-1, j0) ci dà un’indicazione della relativa stabilità del sistema.\n\n\n\nRacchiudere il punto (-1, j0) indica stabilità assoluta.\nPiù il tracciato è vicino a questo punto, maggiore è il rischio di instabilità.\n\n\n\n\n\nIl diagramma polare è una rappresentazione grafica della risposta in frequenza di un sistema, che va da ω = 0 a ω = ∞.\nLa vicinanza del diagramma polare al punto critico (-1, j0) è indicativa del potenziale di oscillazioni o instabilità sostenute del sistema.\nAumentando il guadagno del sistema si tende a spostare il diagramma polare più vicino al punto critico (-1, j0).\nSe questo grafico circonda il punto (-1, j0), è un segnale che il sistema si sta muovendo verso l’instabilità.\n\n\n\n\n\n\n\n\n\n\n\n\nLa chiave per comprendere la stabilità relativa di un sistema sta nel misurare la distanza del diagramma polare (o di Nyquist) dal punto (-1, j0).\nDeterminare questa “distanza relativa” implica misurare quanto il grafico è vicino a (-1, j0), che a sua volta riflette la suscettibilità del sistema all’instabilità.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNon solo l’intersezione con l’asse reale negativo ma anche l’angolo di fase del grafico è fondamentale per valutare la stabilità relativa.\nPer misurarlo vengono spesso utilizzati due indici: il punto di intersezione sull’asse reale e l’angolo di fase nel punto in cui la grandezza è unitaria.\n\n\n\n\n\n\n\n\n\n\n\n\nMagnitudo all’intersezione: viene misurata nel punto in cui il diagramma di Nyquist interseca l’asse reale negativo. Quanto più bassa è questa grandezza, tanto più stabile è considerato il sistema.\nAngolo di fase: viene considerato un cerchio unitario centrato in (-1, j0). L’angolo al quale questo cerchio interseca il diagramma di Nyquist fornisce una misura della stabilità relativa.\n\nSi può anche dire che questi due indici non sono necessariamente sufficienti. Tuttavia, forniscono un semplice algoritmo per quantificare la stabilità relativa.\n\n\n\n\n\n\nAnalizziamo lo scenario in cui il guadagno del sistema, indicato come \\(K\\), viene progressivamente aumentato. Con questo incremento di guadagno, aumenta anche la grandezza complessiva del diagramma di Nyquist. Ad un valore di guadagno specifico, il grafico interseca il punto critico di (-1, j0).\nPer determinare l’esatto incremento di guadagno richiesto affinché il grafico si intersechi (-1, j0), utilizziamo il fattore \\(\\frac{1}{a}\\). Qui, \\(a\\) rappresenta la distanza dell’intersezione del grafico dall’asse reale nel suo stato originale (prima dell’aumento del guadagno).\nApplicando un guadagno di \\(\\frac{1}{a}\\) al tuo diagramma polare, allinei la sua intersezione con l’asse reale esattamente nel punto -1.\nIl margine di guadagno (GM) è matematicamente espresso come \\[GM = \\frac{1}{a}.\\] Questo valore rappresenta la soglia prima che il sistema raggiunga uno stato di stabilità o instabilità marginale.\nIl margine di guadagno considera il fattore di amplificazione al quale un sistema diventa instabile.\nLa seguente illustrazione illustra visivamente questo concetto:\n\n\n\n\n\n\n\n\n\n\nPer chiarire ulteriormente questo concetto, esaminiamo un esempio specifico:\nConsideriamo la funzione di trasferimento:\n\\[\nG(s) = K_1\\frac{1 + sT_1}{s(1 + sT_2)}\n\\]\nIn questo caso, il numero di poli ad anello aperto nel semipiano destro, indicato come \\(P\\), è uguale a 0. Questo scenario corrisponde al diagramma di Nyquist mostrato di seguito:\n\n\n\n\n\n\n\nConcentrandosi sul margine di fase, indicato come \\(\\phi\\), analizziamo il suo significato nella stabilità del sistema:\n\nIl margine di fase \\(\\phi\\) rappresenta lo sfasamento aggiuntivo che può essere introdotto nel sistema senza farlo intersecare con il punto critico (-1, j0).\nIn sostanza, quantifica la capacità del sistema di gestire gli sfasamenti senza cadere nell’instabilità.\n\nQuando si considera il margine di fase, un valore positivo di \\(\\phi\\) è indicativo della robustezza del sistema.\nQuesto margine di fase positivo è la soglia di ulteriore ritardo di fase che, se incorporato nel sistema, lo porterebbe al limite estremo dell’instabilità, senza però passare in uno stato instabile.\nLa presenza di un margine di fase positivo funge da salvaguardia contro l’instabilità, dimostrando la capacità del sistema di resistere a determinati livelli di alterazioni di fase.",
    "crumbs": [
      "IT_🇮🇹",
      "Il criterio di stabilità di Nyquist e la stabilità relativa"
    ]
  },
  {
    "objectID": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#margine-di-guadagno-infinito",
    "href": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#margine-di-guadagno-infinito",
    "title": "Il criterio di stabilità di Nyquist e la stabilità relativa",
    "section": "Margine di guadagno infinito",
    "text": "Margine di guadagno infinito\nConsidera un sistema in cui il diagramma di Nyquist diventa asintotico rispetto a una linea ma non si interseca mai. In questi casi, il margine di guadagno è considerato infinito.\nConsideriamo la funzione di trasferimento:\n\\[\nG(s) = \\frac{K}{s(1 + sT)}\n\\]\nQuesta funzione ha il seguente diagramma polare, che non interseca mai il punto -1. Si avvicina asintoticamente all’asse reale per \\(K\\) in aumento.\n\n\n\n\n\n\n\n\n\n\nCoinvolgimento:\nSebbene possa sembrare ideale, un margine di guadagno infinito spesso indica altri fattori di stabilità da considerare, principalmente il margine di fase. Il margine di fase in questo caso è più adatto per misurare la distanza dal punto -1 e si riduce quando aumentiamo \\(K\\).\n\nComprendere il guadagno e i margini di fase nei sistemi stabili a circuito aperto\nÈ importante riconoscere che i sistemi instabili ad anello aperto non rientrano nell’ambito delle definizioni convenzionali di guadagno e margini di fase.\nQuesti margini sono specificamente progettati e applicabili per i sistemi che mostrano stabilità nella loro configurazione a circuito aperto.\nDi conseguenza, le valutazioni del guadagno e dei margini di fase sono principalmente rilevanti e significative quando si ha a che fare con sistemi stabili ad anello aperto. Nei casi in cui il sistema è instabile a circuito aperto, queste definizioni non sono direttamente applicabili e dovrebbero essere considerati metodi alternativi di analisi della stabilità.\nSebbene la maggior parte degli impianti industriali e dei sistemi di controllo siano intrinsecamente stabili a circuito aperto, è fondamentale prestare particolare attenzione quando si incontra un sistema instabile a circuito aperto. Questo scenario, sebbene meno comune, richiede un approccio più articolato per garantire un funzionamento efficace e sicuro dell’impianto. Comprendere e affrontare le sfide uniche poste dai sistemi instabili a circuito aperto è essenziale per mantenere la stabilità e l’affidabilità del sistema.\n\n\nSistemi di tipo 0\nEsploriamo un esempio specifico di un sistema di tipo 0, in cui i gradi del numeratore e del denominatore della funzione di trasferimento sono uguali.\n\nFunzione di trasferimento:\n\n\\[\nG(s)H(s) = \\frac{1 + sT_1}{1 + sT_2}\n\\]\nQuesto è un sistema di tipo 0 con il seguente diagramma di Nyquist:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{1 + j\\omega T_1}{1 + j\\omega T_2}\n\\]\n\nAnalisi di stabilità: Il sistema è stabile per tutti i \\(T_1\\) e \\(T_2\\). Ciò rende le definizioni tradizionali di guadagno e margine di fase meno significative.\n\nPossiamo mostrarlo usando Python:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nimport matplotlib.cm as cm\n\n# Define the ranges for T1 and T2 values\nT1_values = np.linspace(0.2, 1, 5)  # Adjust the number of values as needed\nT2_values = np.linspace(0.5, 1.5, 5)  # Adjust the number of values as needed\n\n# Prepare a colormap\nnum_plots = len(T1_values) * len(T2_values)\ncolors = cm.viridis(np.linspace(0, 1, num_plots))  # Use 'viridis' colormap\n\n# Prepare the plot\nplt.figure(figsize=(10, 8))\nplt.title('Nyquist Plots for Different T1 and T2 Values')\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\n\n# Iterate over combinations of T1 and T2\ncolor_idx = 0\nfor T1 in T1_values:\n    for T2 in T2_values:\n        num = [1, T1]\n        den = [1, T2]\n        G = ctl.TransferFunction(num, den)\n\n        # Extract real and imaginary parts\n        _, contour = ctl.nyquist(G, omega=np.logspace(-2, 1, 1000), return_contour=True)\n        real, imag = np.real(G(contour)), np.imag(G(contour))\n\n        # Plot each curve with a label and the same color for mirror image\n        color = colors[color_idx]\n        plt.plot(real, imag, label=f'T1 = {T1:.1f}, T2 = {T2:.1f}', color=color)\n        plt.plot(real, -imag, color=color)  # Nyquist plot is symmetric\n        color_idx += 1\n\n# Add legend, grid, and axis lines\nplt.legend()\nplt.grid(True)\nplt.axhline(y=0, color='k')  # Add x-axis\nplt.axvline(x=0, color='k')  # Add y-axis\nplt.xlim([-2, 2])  # Adjust x-axis limits as needed\nplt.ylim([-2, 2])  # Adjust y-axis limits as needed\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Il criterio di stabilità di Nyquist e la stabilità relativa"
    ]
  },
  {
    "objectID": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#affrontare-i-sistemi-instabili-ad-anello-aperto",
    "href": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#affrontare-i-sistemi-instabili-ad-anello-aperto",
    "title": "Il criterio di stabilità di Nyquist e la stabilità relativa",
    "section": "Affrontare i sistemi instabili ad anello aperto",
    "text": "Affrontare i sistemi instabili ad anello aperto\nQuando si parla di margine di guadagno e margine di fase, la loro applicazione nel contesto di sistemi instabili ad anello aperto richiede particolare attenzione.\n\nGestione dei sistemi instabili ad anello aperto\n\nCaratteristiche: Si tratta di sistemi in cui uno o più poli ad anello aperto si trovano nella metà destra del piano s.\nRilevanza per i margini di stabilità: In tali sistemi, le interpretazioni convenzionali di guadagno e margine di fase non sono direttamente applicabili. Un aspetto chiave di questi sistemi è che il loro diagramma polare deve circondare il punto critico (-1+j0) un numero specifico di volte per ottenere la stabilità a circuito chiuso.\n\n\n\nUn esempio illustrativo\n\nFunzione di trasferimento: \\[\nG(s)H(s) = \\frac{s + \\frac{1}{2}}{s(s + 1)(s - 1)}\n\\] In questo caso, il grafico di Nyquist deve girare attorno al punto (-1+j0) una volta per garantire la stabilità.\nNote aggiuntive: Per i sistemi instabili a ciclo aperto, vengono generalmente utilizzati grafici Nyquist completi o tecniche alternative come l’analisi del luogo delle radici. I margini di stabilità convenzionali di guadagno e fase non vengono generalmente utilizzati per valutare la robustezza di questi sistemi, poiché potrebbero non fornire informazioni chiare. In ogni caso, è necessario un approccio su misura per tenere conto degli specifici accerchiamenti nel diagramma di Nyquist.\n\nDi seguito è riportato uno script Python per visualizzare il suo diagramma di Nyquist.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the numerator and denominator of the transfer function\n# G(s)H(s) = (s + 0.5) / (s*(s + 1)*(s - 1))  \nnum = [1, 0.5]\nden = [1, 0, -1, 0]\n\n# Create the transfer function\nG = ctl.TransferFunction(num, den)\n\n# Compute and plot the Nyquist plot\nctl.nyquist_plot(G)\nplt.title('Nyquist Plot of G(s)H(s)')\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.grid(True)\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Il criterio di stabilità di Nyquist e la stabilità relativa"
    ]
  },
  {
    "objectID": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#comprendere-le-frequenze-crossover",
    "href": "IT_🇮🇹/the_nyquist_stability_criterion_and_relative_stability_it.html#comprendere-le-frequenze-crossover",
    "title": "Il criterio di stabilità di Nyquist e la stabilità relativa",
    "section": "Comprendere le frequenze crossover",
    "text": "Comprendere le frequenze crossover\nNei sistemi di controllo, due frequenze critiche sono la frequenza di crossover del guadagno (\\(\\omega_{gc}\\)) e la frequenza di crossover della fase (\\(\\omega_{pc}\\)).\nQueste frequenze sono importanti per determinare la stabilità e le prestazioni di un sistema.\n\nGuadagno frequenza di crossover (\\(\\omega_{gc}\\))\n\nDefinizione: La frequenza alla quale l’ampiezza della funzione di trasferimento ad anello aperto G(jω)H(jω) è 1 (0 dB).\nImportanza: È la frequenza alla quale il guadagno del sistema è uguale all’unità.\nCalcolo: Determina \\(\\omega_{gc}\\) dal grafico Nyquist o polare dove |G(jω)H(jω)| = 1.\n\n\n\nFrequenza di incrocio di fase (\\(\\omega_{pc}\\))\n\nDefinizione: La frequenza alla quale l’angolo di fase di G(jω)H(jω) raggiunge -180°.\nImportanza: Indica la frequenza con cui lo sfasamento del sistema potrebbe portare all’instabilità.\nCalcolo: Determinare \\(\\omega_{pc}\\) dal grafico Nyquist o polare in cui l’angolo di fase di G(jω)H(jω) è -180°.er (\\(\\omega_{PC}\\)): ** Questa è la frequenza alla quale l’angolo di fase del sistema raggiunge -180 gradi.\n\n\n\n\n\n\n\n\n\n\nChiarimento del guadagno e dei margini di fase nei sistemi di controllo\nIl margine di guadagno, indicato come $ $, è un parametro critico nella valutazione della stabilità di un sistema. È importante capire che questo margine non è direttamente il guadagno del sistema stesso. Diventa invece un guadagno solo nel contesto di un sistema la cui trama originaria è basata sul guadagno unitario. In altri casi, il margine di guadagno rappresenta il fattore mediante il quale è possibile modificare il guadagno originale del sistema.\n\nUlteriori commenti sul margine di guadagno\n\nIpotizzando un sistema stabile ad anello aperto (\\(P=0\\))\nPer un sistema stabile, il margine di guadagno è sempre maggiore di 1.\nPer un sistema instabile, il margine di guadagno è inferiore a 1.\nSe il margine di guadagno è inferiore a 1, ciò implica che il guadagno del sistema è stato aumentato a un livello tale da introdurre instabilità. Per riportare il sistema ad uno stato stabile, il guadagno deve essere ridotto di questo fattore di margine.\n\n\n\nUlteriori commenti sul margine di fase\n\nIl margine di fase viene determinato misurando un angolo specifico sul diagramma di Nyquist. Questo angolo rappresenta la quantità di cui è possibile aumentare la fase senza provocare instabilità.\nNei sistemi stabili a circuito aperto, un margine di fase positivo indica un cuscinetto contro l’instabilità, mentre un margine di fase negativo è un segno di potenziale instabilità.\nIpotizzare di misurare l’angolo di margine di fase rispetto all’asse reale negativo.",
    "crumbs": [
      "IT_🇮🇹",
      "Il criterio di stabilità di Nyquist e la stabilità relativa"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "",
    "text": "Nella nostra fase finale di discussione, approfondiremo gli aspetti di progettazione dei sistemi di controllo nel dominio della frequenza. Il nostro obiettivo è capire come un sistema può essere rappresentato e caratterizzato in questo dominio. Le prossime lezioni illustreranno gli algoritmi di progettazione essenziali per l’analisi nel dominio della frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#rappresentazione-e-caratterizzazione-di-un-sistema-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#rappresentazione-e-caratterizzazione-di-un-sistema-nel-dominio-della-frequenza",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Rappresentazione e caratterizzazione di un sistema nel dominio della frequenza",
    "text": "Rappresentazione e caratterizzazione di un sistema nel dominio della frequenza\nPer cominciare, è importante capire cosa intendiamo con “dominio della frequenza”. A differenza del dominio del tempo, in cui analizziamo i sistemi in base alla loro risposta nel tempo, il dominio della frequenza si concentra su come i sistemi rispondono a frequenze diverse. Ciò è importante nei sistemi di controllo, soprattutto per analizzare come si comportano i sistemi sotto vari ingressi sinusoidali.\nConsideriamo un sistema di feedback con una funzione di trasferimento ad anello aperto nel percorso in avanti, indicata come \\(G(s)\\), e una funzione di trasferimento del sensore o del percorso di feedback, \\(H(s)\\). La funzione di trasferimento ad anello chiuso \\(M(s)\\) è data da:\n\\[ M(s) = \\frac{G(s)}{1 + G(s)H(s)} \\]\n\n\n\n\n\n\n\nPer analizzare queste funzioni di trasferimento nel dominio della frequenza, sostituiamo la variabile di Laplace $ s $ con $ j$. Pertanto, la nostra funzione di trasferimento ad anello chiuso nel dominio della frequenza diventa:\n\\[ M(j\\omega) = \\frac{G(j\\omega)}{1 + G(j\\omega)H(j\\omega)} \\]\nPoiché la frequenza varia da 0 a infinito, per comprendere il comportamento del sistema a circuito chiuso è necessario valutare l’ampiezza e l’angolo di fase di \\(M(j\\omega)\\).\nIn altre parole, conosco il comportamento del sistema ad anello chiuso se sono in grado di valutare il modulo e l’angolo di fase di \\(M(j\\omega)\\).\n\nRisposta in frequenza\nQuando si analizzano i sistemi di controllo, un concetto chiave è la risposta in frequenza ad anello aperto \\(G(j\\omega)H(j\\omega)\\), che appare nella funzione di trasferimento ad anello chiuso. Questa risposta è particolarmente importante poiché fornisce informazioni fondamentali sul comportamento del sistema senza l’influenza di un ciclo di feedback.\nAnalizziamolo:\n\nRisposta in frequenza ad anello aperto: si riferisce al modo in cui il sistema, costituito dal sensore e dall’impianto, risponde a frequenze diverse quando non viene applicato alcun feedback. Essenzialmente, è il comportamento naturale del sistema in risposta agli input.\nImportanza: il motivo per cui ci concentriamo sulla risposta in frequenza ad anello aperto è perché offre preziose informazioni sulle caratteristiche intrinseche del sistema. Comprendendo la risposta del sistema in uno stato a circuito aperto, possiamo fare previsioni informate su come si comporterà una volta introdotto un ciclo di feedback (cioè in una configurazione a circuito chiuso).\n\nPer riassumere, la risposta in frequenza ad anello aperto, che include l’effetto combinato del sensore e della pianta (indicato come $ GH $), è un’informazione fondamentale. Può essere derivato da un modello teorico del sensore e dell’impianto o attraverso metodi sperimentali per misurare come il sistema risponde a varie frequenze in uno stato a circuito aperto.\n\n\nDall’anello aperto all’anello chiuso\nEsploriamo un aspetto critico dei sistemi di controllo: determinare il comportamento a circuito chiuso dai dati di risposta in frequenza a circuito aperto. Questo compito, anche se apparentemente semplice, in realtà pone una questione complessa che necessita di un’attenta analisi.\nEcco il processo suddiviso:\n\nAnalisi del comportamento a circuito chiuso: il nostro obiettivo è capire come si comporta il sistema quando viene applicato il feedback. Questo è noto come comportamento a circuito chiuso.\nUtilizzo dei dati a circuito aperto: iniziamo con ciò che sappiamo: la risposta in frequenza a circuito aperto. Questa è la risposta del sistema senza feedback, come discusso in precedenza.\nTransizione all’anello chiuso: per analizzare il comportamento ad anello chiuso, applichiamo i dati della risposta in frequenza ad anello aperto nella formula della funzione di trasferimento ad anello chiuso. Si tratta di un approccio matematico che integra i dati a circuito aperto in un quadro che considera il feedback.\nComprensione del risultato: applicando i dati ad anello aperto alla formula ad anello chiuso, possiamo calcolare aspetti importanti come l’ampiezza e l’angolo di fase della funzione di trasferimento ad anello chiuso, indicata come $ M $. Questi calcoli ci danno un quadro chiaro di come il feedback altera la risposta del sistema.\n\nIn sintesi, per comprendere il comportamento a ciclo chiuso, dobbiamo tradurre in modo efficace la nostra comprensione del sistema a ciclo aperto (il sistema senza feedback) nel contesto a ciclo chiuso (il sistema con feedback). Questa traduzione viene eseguita tramite la formula della funzione di trasferimento ad anello chiuso, utilizzando i dati della risposta in frequenza ad anello aperto come punto di partenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#caratteristiche-ideali-del-filtro-passa-basso-nei-sistemi-di-controllo",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#caratteristiche-ideali-del-filtro-passa-basso-nei-sistemi-di-controllo",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Caratteristiche ideali del filtro passa-basso nei sistemi di controllo",
    "text": "Caratteristiche ideali del filtro passa-basso nei sistemi di controllo\nNei sistemi di controllo, il concetto di filtro passa-basso è essenziale. Analizziamo questa idea per comprenderne meglio il ruolo e la funzionalità.\n\nChe cos’è un filtro passa-basso?\n\nUn filtro passa-basso è un tipo di sistema che consente ai segnali con frequenze inferiori a una determinata soglia (nota come frequenza di taglio) di attraversarlo senza attenuazione.\nI segnali con frequenze superiori a questa frequenza di taglio vengono notevolmente indeboliti o attenuati.\nQuesta caratteristica rende i filtri passa-basso ideali per bloccare il rumore ad alta frequenza indesiderato consentendo al contempo il passaggio dei segnali a frequenza più bassa.\n\nCapire la frequenza di taglio (\\(\\omega_c\\))\n\nLa frequenza di taglio, indicata come \\(\\omega_c\\), è un punto critico in un filtro passa-basso. Determina la soglia tra le frequenze che possono passare e quelle che vengono attenuate.\nFino a questa frequenza, il filtro mantiene un guadagno costante, che spesso consideriamo come unitario (o nessuna variazione dell’intensità del segnale).\nOltre \\(\\omega_c\\), il filtro riduce drasticamente il guadagno, filtrando efficacemente le frequenze più alte.\n\nCaratteristiche ideali di un filtro passa-basso\n\nIn un filtro passa-basso ideale, questa transizione dal guadagno unitario al guadagno zero alla frequenza di taglio è brusca e distinta.\nQuesto comportamento ideale è molto ricercato in molti sistemi di controllo, soprattutto negli scenari in cui il filtraggio del rumore ad alta frequenza è fondamentale mantenendo l’integrità dei segnali a frequenza più bassa.\n\nApplicazione nei sistemi di controllo\n\nIl filtro passa-basso trova la sua utilità in vari sistemi di controllo dove è essenziale preservare i segnali a bassa frequenza (come ingressi o comandi del sistema reale) eliminando al contempo i disturbi ad alta frequenza (come rumore elettronico o fluttuazioni rapide irrilevanti)\n\n\n\n\n\n\n\n\n\nÈ importante comprendere il ruolo dei filtri passa-basso nei sistemi di controllo. Approfondiamo perché le caratteristiche passa-basso sono particolarmente adatte per i sistemi di controllo.\n\nCaratteristiche del filtro passa-basso nei sistemi di controllo\n\nFiltro passa-basso ideale: la caratteristica ideale di un filtro passa-basso è l’adattamento perfetto per molti sistemi di controllo. Questa caratteristica implica consentire ai segnali a bassa frequenza di passare inalterati bloccando o attenuando i segnali ad alta frequenza.\nRilevanza per i sistemi di controllo: i sistemi di controllo spesso trattano segnali nella gamma a bassa frequenza, che sono i segnali di interesse primario, come comandi di controllo o input di sistema.\nFiltraggio del rumore: i componenti ad alta frequenza nel segnale rappresentano solitamente rumore o disturbi indesiderati. La capacità di un filtro passa-basso di filtrare questi componenti ad alta frequenza è fondamentale per mantenere l’integrità e le prestazioni del sistema di controllo.\n\nApplicazione pratica nei sistemi di controllo\n\nScenario del mondo reale: in pratica, i sistemi di controllo spesso mostrano un comportamento di filtro passa-basso, sebbene potrebbero non corrispondere perfettamente alle caratteristiche ideali di un filtro passa-basso ideale.\nFunzionalità: questi sistemi sono progettati per lasciar passare i segnali a bassa frequenza (la parte utile del segnale) riducendo al contempo l’impatto del rumore ad alta frequenza. Ciò garantisce che il sistema di controllo risponda principalmente agli input di controllo effettivi anziché essere disturbato dal rumore.\n\nProgettazione di sistemi di controllo con caratteristiche passa-basso\n\nQuando si progetta un sistema di controllo nel dominio della frequenza, uno degli obiettivi chiave è dotarlo di caratteristiche passa-basso. Ciò garantisce che il sistema funzioni in modo efficace concentrandosi sui segnali della gamma a bassa frequenza e filtrando il rumore ad alta frequenza.\n\n\nIn sintesi, i filtri passa-basso sono un concetto integrale nei sistemi di controllo, in linea con l’obiettivo primario di questi sistemi di rispondere ai segnali a bassa frequenza rilevanti filtrando al contempo il rumore indesiderato ad alta frequenza.\nI sistemi di controllo spesso presentano caratteristiche di filtro passa-basso, che filtrano il rumore ad alta frequenza preservando i segnali a bassa frequenza di interesse.\nIdealmente, un filtro passa-basso avrebbe un guadagno piatto fino ad una certa frequenza di taglio \\(\\omega_c\\), oltre la quale il guadagno scende bruscamente fino a zero. Tuttavia, una tale caratteristica ideale non è realizzabile nella pratica.\n\nRisposta in frequenza tipica di un sistema di controllo in feedback\nIn pratica, un filtro passa-basso ideale non è realizzabile. I sistemi di controllo tendono ad avere un declino più graduale del guadagno oltre la frequenza di taglio.\n\n\n\n\n\n\n\nFigura: una caratteristica del filtro passa-basso più realistica che mostra un graduale calo del guadagno.\n\nCurva caratteristica di un sistema retroazionato\n\nFrequenza di risonanza e picco:\n\nIn un pratico sistema di controllo del feedback, la curva di risposta in frequenza presenta una caratteristica unica nota come frequenza di risonanza. Questa è la frequenza alla quale la risposta (o guadagno) del sistema raggiunge il suo massimo.\nAd accompagnare la frequenza di risonanza c’è il picco di risonanza, che è l’effettiva grandezza di questa risposta massima. Questo picco è indicativo della risposta più pronunciata del sistema ad una particolare frequenza.\n\nGraduale declino oltre la frequenza di risonanza:\n\nA differenza di un filtro passa-basso ideale con un taglio netto, i sistemi di controllo del mondo reale mostrano tipicamente un declino più graduale del guadagno oltre la frequenza di risonanza.\nCiò significa che invece di un improvviso calo del guadagno fino a zero oltre una certa frequenza, i sistemi pratici attenuano lentamente il segnale man mano che la frequenza aumenta oltre il punto di risonanza.\n\n\n\n\n\nComprendere la larghezza di banda nei sistemi di controllo\n\nLarghezza di banda definita:\n\nLa larghezza di banda ($ _b $) si riferisce all’intervallo di frequenze su cui un sistema di controllo mantiene un guadagno costante, vicino al suo valore massimo.\nQuesta gamma è fondamentale perché determina le frequenze alle quali il sistema funziona in modo più efficace.\n\nImpostazione della frequenza di taglio:\n\nDeterminare il punto esatto per la frequenza di taglio può essere difficile (vedere la figura sopra). Tuttavia, nei sistemi di controllo, spesso definiamo la larghezza di banda come l’intervallo di frequenza in cui il guadagno del sistema rimane vicino all’unità.\nLa frequenza di taglio, in questo caso, è dove il guadagno scende a $ $ del valore unitario. Questo punto segna la transizione dal raggio operativo effettivo del sistema al punto in cui inizia ad attenuare il segnale.\nSelezioniamo il valore unitario e non il picco, perché un valore unitario a tutte le frequenze sarebbe il valore ideale. Corrisponderebbe al tracciamento perfetto di qualsiasi input.\n\nSignificato della larghezza di banda:\n\nAll’interno della larghezza di banda, il sistema funziona in modo ottimale, elaborando i segnali con un’attenuazione minima. Questa è la gamma di frequenza in cui il guadagno del sistema è quasi piatto, il che significa una gestione del segnale stabile ed efficace.\nOltre la larghezza di banda, il guadagno del sistema inizia a diminuire, indicando l’inizio dell’attenuazione del segnale. Questa caratteristica è fondamentale per filtrare i segnali ad alta frequenza indesiderati mantenendo la fedeltà dei segnali all’interno della larghezza di banda.\n\nApplicazione pratica:\n\nNegli scenari del mondo reale, i sistemi di controllo sono progettati per avere una larghezza di banda specifica che si allinea con la gamma di frequenza dei segnali che intendono gestire o controllare.\nComprendendo e impostando la larghezza di banda appropriata, gli ingegneri possono garantire che il sistema risponda accuratamente alle frequenze rilevanti filtrando rumori o disturbi indesiderati.\n\n\nLa larghezza di banda ($ _b $) nei sistemi di controllo è un parametro critico che definisce la gamma di frequenze su cui il sistema può elaborare efficacemente segnali con guadagno vicino all’unità. Oltre questo intervallo, l’efficienza del sistema nella gestione dei segnali diminuisce, rendendo la larghezza di banda un fattore vitale nella progettazione del sistema e nell’analisi delle prestazioni.\n\nLarghezza di banda e prestazioni del sistema\nNon esiste una frequenza di taglio chiara e per questo motivo,\n\nDefinizione della larghezza di banda (\\(\\omega_b\\)):\n\nLa larghezza di banda è un concetto critico nei sistemi di controllo. È definito in base all’intervallo di frequenza su cui il sistema mantiene un guadagno vicino all’unità, elaborando efficacemente i segnali.\nTecnicamente, la larghezza di banda (\\(\\omega_b\\)) è la frequenza alla quale il guadagno del sistema scende a \\(\\frac{1}{\\sqrt{2}}\\) del guadagno massimo (o unitario). Questo punto è cruciale perché segna l’inizio della fase di attenuazione del sistema per le frequenze più alte.\n\nImplicazioni pratiche:\n\nLa larghezza di banda aiuta a comprendere l’ampiezza della gamma di frequenze che il sistema può gestire in modo efficace. All’interno di questo intervallo, il sistema funziona in modo ottimale, mantenendo un guadagno costante.\nAl di là della larghezza di banda, la capacità del sistema di elaborare i segnali diminuisce, il che è vitale per la progettazione di sistemi di controllo che devono filtrare segnali ad alta frequenza indesiderati.\n\n\nIn sintesi, la risposta in frequenza di un tipico sistema di controllo feedback è caratterizzata dalla frequenza di risonanza e dal picco, seguiti da una graduale riduzione del guadagno oltre questo punto. La larghezza di banda del sistema, un indicatore chiave delle prestazioni, definisce la gamma di frequenze su cui il sistema mantiene effettive capacità di controllo ed elaborazione del segnale.\n\n\n\nQuantificazione delle prestazioni del sistema\n\n**Ampia larghezza di banda ($ _b $)**: desiderabile per buone prestazioni di tracciamento e tempi di salita ridotti. Ciò significa che il guadagno del sistema è il più ampio possibile per una gamma di frequenze, migliorando le prestazioni di tracciamento e la velocità di risposta.\nPicco risonante ($ M_r $): non dovrebbe essere troppo alto per garantire che venga soddisfatto il requisito di guadagno piatto.\nLimitazioni: fattori come le caratteristiche del rumore e il rischio di saturazione limitano la larghezza di banda ottenibile. Una larghezza di banda elevata significa che il rumore potrebbe entrare nel circuito. Conoscere le caratteristiche del sensore significa conoscere la larghezza di banda massima che possiamo supportare, anche se ciò potrebbe significare compromettere la precisione del tracciamento. Una larghezza di banda ampia significa anche grandi guadagni e quindi possibilmente saturazione. Con riferimento all’equazione seguente, \\(M(j\\omega)=1\\) (larga larghezza di banda in un ampio intervallo di frequenze) solo quando \\(G(j\\omega) \\rightarrow \\infty\\):\n\n\\[ M(j\\omega) = \\frac{G(j\\omega)}{1 + G(j\\omega)H(j\\omega)} = 1 \\Rightarrow G(j\\omega) \\rightarrow \\infty \\]\n\n\nQuantificazione del comportamento del sistema di controllo\n\nCaratteristiche della risposta in frequenza:\n\nPer comprendere appieno il comportamento di un sistema di controllo, esaminiamo la sua risposta in frequenza. Ciò implica comprendere come il sistema reagisce attraverso una gamma di frequenze.\n\nRisposta in frequenza ad anello chiuso e ad anello aperto:\n\nÈ importante notare che la risposta in frequenza a cui ci riferiamo qui è la risposta a circuito chiuso, sebbene inizialmente abbiamo accesso ai dati di frequenza a circuito aperto. Ciò significa che per costruire un grafico della risposta in frequenza ad anello chiuso, dobbiamo elaborare di conseguenza i dati ad anello aperto.\n\n\n\nParametri caratterizzanti della risposta in frequenza\n\nFrequenza di risonanza (\\(\\omega_r\\)):\n\nQuesta è la frequenza alla quale la risposta del sistema raggiunge il suo massimo. È un punto critico per comprendere il comportamento del sistema.\n\nPicco risonante (M_r):\n\n$ M_r $ è l’entità della risposta del sistema alla frequenza di risonanza. Idealmente non dovrebbe essere troppo alto per garantire una risposta stabile del sistema.\n\nLarghezza di banda (\\(\\omega_b\\)):\n\nLa larghezza di banda è definita come l’intervallo di frequenza in cui la risposta (o guadagno) del sistema è vicina al massimo. Oltre questo intervallo, il sistema inizia ad attenuare i segnali.\n\nTempo di salita e larghezza di banda:\n\nSia \\(\\omega_r\\) che \\(\\omega_b\\) sono legati al tempo di salita del sistema. Un tempo di salita più breve richiede valori più grandi di \\(\\omega_r\\) e \\(\\omega_b\\).\n\n\n\n\nIndici aggiuntivi per la caratterizzazione del sistema\n\nMargine di fase e margine di guadagno:\n\nQuesti derivano dalla risposta in frequenza ad anello aperto e sono indicativi della relativa stabilità del sistema ad anello chiuso.\nIl margine di fase (\\(\\phi\\)) viene misurato rispetto all’asse reale negativo, e un margine di fase positivo suggerisce stabilità.\nAnche il margine di guadagno, calcolato come \\(\\frac{1}{a}\\), fornisce un’indicazione della stabilità del sistema.\n\n\n\n\n\n\n\n\n\n\n\nCaratterizzazione completa del sistema\n\nDominio del tempo e dominio della frequenza:\n\nAnche se possiamo caratterizzare un sistema nel dominio della frequenza utilizzando indici come \\(\\omega_r\\), \\(M_r\\), \\(\\omega_b\\), margine di guadagno e margine di fase, è anche fondamentale comprenderne l’impatto nel dominio del tempo.\nLa prospettiva del dominio temporale ci fornisce informazioni su come il sistema risponde a input come i cambiamenti di passo e su come gestisce gli errori transitori.\n\nCollegamento nel dominio del tempo e nel dominio della frequenza:\n\nLa vera sfida nella progettazione del sistema è correlare questi due domini. Questa correlazione è fondamentale per sfruttare la semplicità della progettazione nel dominio della frequenza e la comprensione intuitiva del dominio del tempo.\nSebbene in teoria il comportamento nel dominio del tempo e quello della frequenza siano collegati tramite la trasformata di Fourier, in pratica questa trasformazione può essere complessa. Pertanto, spesso ci affidiamo a simulazioni e approssimazioni per rendere questa correlazione più gestibile.\n\n\n\n\n\n\n\n\n\n\n\nIndici chiave di prestazione\nIl comportamento di un sistema di controllo nel dominio della frequenza può essere caratterizzato da diversi indici:\n\nPicco risonante (\\(M_r\\))\nFrequenza di risonanza (\\(\\omega_r\\))\nLarghezza di banda (\\(\\omega_b\\))\nMargine di guadagno (GM)\nMargine di fase (PM)\nErrore nello stato stazionario (\\(e_{ss}\\))\nCostanti di sistema (\\(K_p, K_v, K_a\\))\n\nQueste specifiche guidano il processo di progettazione e aiutano a mettere a punto il sistema per ottenere le prestazioni desiderate sia nel dominio della frequenza che in quello del tempo.\nQuesti parametri derivano dai dati della risposta in frequenza ad anello aperto ma riflettono il comportamento ad anello chiuso. Offrono spunti sulla stabilità relativa del sistema.\n\n\n\nVisualizzazione del comportamento del sistema nel dominio del tempo\nComprendere la relazione tra frequenza e tempo è fondamentale per analizzare e progettare sistemi di controllo efficaci.\n\nVisualizzazione nel dominio del tempo:\n\nIl dominio del tempo è particolarmente utile per visualizzare come si comporta un sistema in risposta a determinati input, come un input di passaggio.\nAd esempio, nel dominio del tempo, possiamo facilmente vedere quanto bene un sistema traccia un input e identificare gli errori transitori (la differenza iniziale tra la risposta desiderata e quella effettiva).\nIl comportamento dinamico di un sistema, come la sua risposta ai cambiamenti nel tempo, è spesso compreso in modo più intuitivo nel dominio del tempo.\n\n\n\n\nSemplificazione con la progettazione nel dominio della frequenza\n\nVantaggi del dominio della frequenza:\n\nLa progettazione nel dominio della frequenza è generalmente più semplice e diretta.\nTuttavia, per sfruttare appieno i suoi vantaggi, dobbiamo stabilire una connessione tra le caratteristiche del dominio del tempo e del dominio della frequenza.\n\nCollegamento dei domini di tempo e frequenza:\n\nQuesto collegamento implica la correlazione di parametri come il picco di risonanza \\(M_r\\), la frequenza di risonanza \\(\\omega_r\\), la larghezza di banda \\(\\omega_b\\), il margine di fase e il margine di guadagno tra i due domini.\nComprendendo queste relazioni, possiamo apprezzare come le decisioni nel dominio della frequenza influenzeranno il comportamento nel dominio del tempo.\n\n\n\nApproccio pratico\n\nLimitazioni della trasformata di Fourier:\n\nIn teoria, la trasformata di Fourier può essere utilizzata per derivare la risposta temporale dai dati della risposta in frequenza. Tuttavia, in pratica, questo può essere complesso e poco pratico.\n\nUtilizzo di strumenti computazionali:\n\nCon l’avvento dei computer, un approccio più pratico consiste nell’utilizzare la funzione di trasferimento derivata dai dati nel dominio della frequenza e simularla nel dominio del tempo.\nQuesto metodo ci consente di approssimare come i parametri del dominio della frequenza si manifesteranno nel dominio del tempo, aggirando le complessità delle trasformate di Fourier.\n\nRapporti approssimativi:\n\nIl nostro obiettivo è valutare rapidamente se i parametri del dominio della frequenza scelti hanno senso quando convertiti in comportamento nel dominio del tempo.\nUna rappresentazione completa e accurata del comportamento nel dominio del tempo può essere ottenuta attraverso una simulazione approfondita.\nCiò significa che accetteremo approssimazioni e verificheremo se le ipotesi e le approssimazioni fatte sono corrette attraverso simulazioni approfondite. Questo è simile a quello che abbiamo fatto quando abbiamo utilizzato la condizione di dominanza per identificare due poli a circuito chiuso che erano dominanti nella risposta del sistema. Questa approssimazione viene utilizzata per la progettazione iniziale e quindi, se si verificano discrepanze nelle simulazioni, vengono apportate le modifiche di conseguenza.\n\n\n\n\n\nApprossimazione chiave nella progettazione di sistemi a circuito chiuso nel dominio della frequenza\n\nAssumendo un comportamento del sistema di secondo ordine:\n\nUna semplificazione significativa nel processo di progettazione consiste nell’approssimare il comportamento del sistema a circuito chiuso come simile a un sistema del secondo ordine. Ciò significa che presupponiamo che il sistema abbia una coppia dominante di radici che influenzano prevalentemente la sua risposta.\n\nImplicazioni per la visualizzazione nel dominio del tempo:\n\nCon questa approssimazione diventa più semplice prevedere e visualizzare il comportamento del sistema nel dominio del tempo. Ad esempio, capire come il sistema risponde a determinati input o il suo comportamento dinamico complessivo diventa più intuitivo.\n\nGestione delle limitazioni di approssimazione:\n\nÈ importante riconoscere che si tratta di un’approssimazione. Se il sistema reale si discosta in modo significativo da un comportamento di secondo ordine, potrebbe esserci una notevole discrepanza tra le nostre previsioni e le prestazioni effettive osservate nelle simulazioni.\nPer risolvere tali discrepanze, spesso facciamo affidamento su un approccio per tentativi ed errori. Ciò comporta l’adeguamento della progettazione in base ai risultati della simulazione per corrispondere meglio al comportamento previsto.\n\n\n\n\nIl ruolo della simulazione nel perfezionamento del design\n\nColmare il divario con la simulazione:\n\nLe simulazioni sono cruciali per verificare e perfezionare le nostre approssimazioni di progettazione. Forniscono una visione pratica di come si comporterà il sistema, permettendoci di apportare le modifiche necessarie.\n\nApproccio iterativo alla progettazione:\n\nLa progettazione del sistema nel dominio della frequenza richiede spesso un processo iterativo, che si sposta avanti e indietro tra progettazione, simulazione e messa a punto in base ai risultati della simulazione. Questo processo iterativo aiuta a garantire che il progetto finale si allinei bene alle specifiche prestazionali desiderate.\n\n\nIn sostanza, mentre l’approssimazione del sistema a circuito chiuso come sistema di secondo ordine semplifica il processo di progettazione, è importante convalidare e adattare questa approssimazione attraverso la simulazione per ottenere un progetto che funzioni efficacemente in condizioni reali.\nPrima di andare avanti è opportuno ribadire l’uso dell’approssimazione del secondo ordine che faremo.\n\n\nChiarimento sull’uso dell’approssimazione\n\nAmbito dell’approssimazione:\n\nL’approssimazione di trattare il sistema a circuito chiuso come un sistema di secondo ordine viene utilizzata principalmente per una rapida visualizzazione e comprensione. È importante sottolineare che si tratta di uno strumento di concettualizzazione piuttosto che di un elemento diretto nel processo di progettazione vero e proprio.\n\nApplicazione nella visualizzazione:\n\nLo scopo principale di questa approssimazione è fornire un modo più semplice per tradurre e comprendere il comportamento del sistema dal dominio della frequenza al dominio del tempo. È un metodo per valutare rapidamente come il sistema potrebbe comportarsi durante il funzionamento in tempo reale in base alle sue caratteristiche nel dominio della frequenza.\n\nNon utilizzato direttamente nella progettazione:\n\nQuando si tratta della progettazione effettiva del sistema nel dominio della frequenza, questa approssimazione non influenza direttamente le decisioni o i calcoli di progettazione. Non viene reinserito nel processo di progettazione.\n\nAttenzione nel processo di progettazione:\n\nI progettisti dovrebbero prestare attenzione e non fare eccessivo affidamento su questa approssimazione per effettuare scelte progettuali. Sebbene sia utile per una comprensione iniziale, la progettazione vera e propria dovrebbe basarsi su analisi e simulazioni più precise che tengano conto delle caratteristiche specifiche del sistema.\n\n\n\n\nImportanza della precisione nella progettazione\n\nPrecisione del progetto:\n\nUna progettazione accurata ed efficace nel dominio della frequenza richiede di considerare tutte le caratteristiche di dettaglio del sistema, al di là delle semplificazioni offerte dall’approssimazione.\n\nRuolo delle simulazioni:\n\nLe simulazioni svolgono un ruolo fondamentale nella validazione del progetto, offrendo un quadro più accurato di come si comporterà il sistema in vari scenari, che potrebbe differire dall’approssimazione semplificata.\n\n\nL’approssimazione di un sistema a circuito chiuso come sistema del secondo ordine è uno strumento utile per la visualizzazione e la comprensione iniziale e non dovrebbe essere utilizzato direttamente nel processo di progettazione. Una progettazione accurata richiede un’analisi dettagliata e simulazioni su misura per il sistema specifico in fase di sviluppo.\n\nDomanda pop-up: Perché è importante comprendere i comportamenti sia nel dominio del tempo che in quello della frequenza nei sistemi di controllo?\nRisposta: la comprensione di entrambi gli ambiti consente una visione completa delle prestazioni del sistema. Il dominio del tempo offre informazioni sulla risposta del sistema agli input nel mondo reale, mentre il dominio della frequenza semplifica il processo di progettazione e analisi, in particolare negli aspetti di filtraggio e stabilità.\nDomanda pop-up: Perché è utile collegare le analisi nel dominio del tempo e della frequenza?\nRisposta: Il collegamento di questi domini consente di sfruttare la semplicità della progettazione del dominio della frequenza apprezzando e verificando al contempo le prestazioni del sistema nel dominio del tempo più intuitivo.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#approssimazione-del-comportamento-del-sistema-del-secondo-ordine",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#approssimazione-del-comportamento-del-sistema-del-secondo-ordine",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Approssimazione del comportamento del sistema del secondo ordine",
    "text": "Approssimazione del comportamento del sistema del secondo ordine\nUn’approssimazione comune nell’analisi del sistema di controllo presuppone che il sistema si comporti come un sistema del secondo ordine con due poli dominanti. Questa semplificazione è spesso valida, soprattutto quando il progetto finale presenta due poli dominanti, e i poli non dominanti hanno un effetto minimo.\nComportamento tipico del sistema: - Un sistema standard del secondo ordine è rappresentato dalla funzione di trasferimento\n\\[\\frac{\\omega_n^2}{ s(s + 2 \\zeta \\omega_n) }\\]\ne dal seguente ciclo di feedback:\n\n\n\n\n\n\n\n\nIn molti progetti tali sistemi presentano due poli dominanti, che influenzano significativamente il comportamento del sistema.\n\n\nDerivazione della frequenza di risonanza e del picco in un sistema del secondo ordine\nIniziamo a determinare la frequenza di risonanza (\\(\\omega_r\\)) e il picco di risonanza (\\(M_r\\)). Analizziamo questo processo passo dopo passo per chiarezza.\n\n\nFunzione di trasferimento ad anello chiuso di un sistema del secondo ordine\nConsideriamo la seguente funzione di trasferimento:\n\\[\nM(s) = \\frac{\\omega_n^2}{s^2 + 2 \\zeta \\omega_n s + \\omega_n^2}\n\\]\nQuesta equazione rappresenta la funzione di trasferimento ad anello chiuso per un sistema del secondo ordine, dove \\(\\omega_n\\) è la frequenza naturale e \\(\\zeta\\) è il rapporto di smorzamento.\n\n\nEspressione della funzione di trasferimento con frequenza complessa\nPer analizzare il comportamento del sistema a diverse frequenze, esprimiamo \\(M(s)\\) utilizzando una frequenza complessa \\(j\\omega\\):\n\\[\nM(j\\omega) = \\frac{\\omega_n^2}{- \\omega^2 + j 2 \\zeta \\omega_n \\omega + \\omega_n^2}\n\\]\n\n\nUtilizzo della frequenza normalizzata\n\nDefinizione della frequenza normalizzata:\n\nIntroduciamo una frequenza normalizzata $ u = $. Ciò semplifica i nostri calcoli e aiuta a confrontare sistemi con frequenze naturali diverse.\n\nFunzione di trasferimento modificata:\n\nCon questa frequenza normalizzata la nostra funzione di trasferimento diventa:\n\n\\[\nM(ju) = \\frac{1}{1 - u^2 + j 2 \\zeta u}\n\\]\n\n\n\nDeterminazione della frequenza di risonanza e del picco\n\nCalcolo della frequenza di risonanza (\\(\\omega_r\\)):\n\nPer trovare la frequenza di risonanza, dobbiamo determinare il punto in cui la grandezza di $ M(ju) $ raggiunge il suo massimo. Ciò implica differenziare la grandezza rispetto a $ u $ e impostare la derivata a zero ($ = 0 $).\n\nEntità di $ M(ju) $:\n\nLa grandezza di $ M(ju) $ è data da:\n\n\\[\n\\left|M(ju)\\right| = \\frac{1}{\\sqrt{(1 - u^2)^2 + (2 \\zeta u)^2}}\n\\]\nTrovare $ u_r $ e $ M_r(u_r) $:\n\nPonendo $ = 0 $, troviamo $ u_r $, la frequenza normalizzata alla quale si verifica il picco di risonanza.\nSostituendo nuovamente questo valore nell’equazione della magnitudo otteniamo $ M_r(u_r) $, il picco di risonanza.\n\nCalcolo della frequenza di risonanza e del picco:\n\n\\[ u_r = \\sqrt{1 - 2\\zeta^2} \\] \\[ \\omega_r = \\omega_n\\sqrt{1 - 2\\zeta^2} \\] \\[ M_r = \\frac{1}{2\\zeta\\sqrt{1 - \\zeta^2}} \\]\n\nRelazione tra rapporto di smorzamento e picco risonante\nL’indice del dominio della frequenza, \\(\\omega_r\\) (frequenza di risonanza) e \\(M_r\\) (picco di risonanza), sono direttamente correlati al parametro del dominio del tempo, il rapporto di smorzamento (\\(\\zeta\\)). Questa relazione lega il superamento del picco nel dominio del tempo, che è una funzione di \\(\\zeta\\), alle caratteristiche del dominio della frequenza.\n\\[ M_r = \\frac{1}{2\\zeta\\sqrt{1 - \\zeta^2}} \\quad \\text{for} \\quad 0 &lt; \\zeta &lt; 0.707 \\]\nThe equation illustrates a direct relationship between the resonant peak (\\(M_r\\)) in the frequency domain and the peak overshoot in the time domain (which is obtained through \\(\\zeta\\)).\nWe can make the following plot of \\(M_r\\) as \\(\\zeta\\) varies:\n\n\n\n\n\n\n\nL’equazione è valida per $ 0 &lt; &lt; 0.707 $. When $ &gt; 0.707 $ il sistema si comporta molto vicino ad un sistema smorzato in modo critico e in pratica non vi è alcun picco di overshoot (l’overshoot sarà compreso tra il 2% e il 5%). Siamo più interessati a catturare comportamenti importanti che possono influenzare la stabilità del sistema, mentre possiamo catturare comportamenti dettagliati attraverso simulazioni.\nIn altre parole, l’equazione del picco risonante è definita per \\(0 &lt; \\zeta &lt; 0.707\\). For \\(\\zeta &gt; 0.707\\), il sistema si avvicina ad una risposta smorzata in modo critico, senza alcun superamento significativo. Ciò implica che per valori maggiori di \\(\\zeta\\), il comportamento del sistema è simile a non avere alcun picco di risonanza, portando ad una risposta in frequenza più piatta.\n\n\nInterpretazione di \\(\\omega_r\\) e \\(\\omega_b\\)\nI valori di \\(\\omega_r\\) e \\(\\omega_b\\) (larghezza di banda) possono fornire informazioni sul tempo di salita e sul tempo di assestamento del sistema. Dato un rapporto di smorzamento specifico (\\(\\zeta\\)), \\(\\omega_r\\) aiuta a determinare la frequenza naturale (\\(\\omega_n\\)) e, di conseguenza, il tempo di salita e il tempo di assestamento.\n\\(\\omega_r\\) dipende da \\(\\zeta\\) e \\(\\omega_n\\) e quindi rappresenta il tempo di salita o di sedimentazione.\nDati \\(\\omega_r\\) e \\(M_r\\) possiamo ottenere \\(\\zeta\\) e \\(\\omega_n\\) e quindi il comportamento transitorio del sistema in termini di tempo di assestamento, tempo di salita, superamento del picco, ecc.\nL’unica avvertenza è che il sistema deve essere approssimato da un sistema del secondo ordine. In caso contrario, in questo corso ci affideremo solo alle simulazioni.\n\n\nCalcolo della larghezza di banda per i sistemi del secondo ordine\nPer calcolare la larghezza di banda, torniamo alla nostra equazione di magnitudo:\n\\[\n   \\left|M(ju)\\right| = \\frac{1}{\\sqrt{(1 - u^2)^2 + (2 \\zeta u)^2}}\n\\]\ne impostare \\(\\left|M(ju)\\right| = 0,707\\) per trovare \\[u_b=\\frac{\\omega_b}{\\omega_n}\\]\ne infine può essere calcolato per un sistema del secondo ordine come segue:\n\\[ \\text{Larghezza di banda, } \\omega_b = \\omega_n \\left[ (1 - 2\\zeta^2) + \\sqrt{4\\zeta^4-4\\zeta^2 +2} \\right]^{\\frac {1}{2}} \\]\nNel dominio del tempo, \\(\\omega_b\\) è correlato al tempo di salita e di assestamento del sistema. Nel dominio della frequenza, \\(\\omega_b\\) è correlato alle caratteristiche di filtraggio del rumore.\n\n\n\nCoerenza nelle specifiche del sistema\nNella progettazione dei sistemi di controllo, soprattutto nel dominio della frequenza, dobbiamo garantire che le specifiche che scegliamo siano coerenti e compatibili tra loro.\nEsploriamo ulteriormente questo concetto e comprendiamo come si applica alla selezione di specifiche come il picco di risonanza (\\(M_r\\)), la frequenza di risonanza (\\(\\omega_r\\)) e la larghezza di banda (\\(\\omega_b\\)).\n\nNatura correlata delle specifiche del dominio della frequenza:\n\nNel dominio della frequenza, parametri chiave come la frequenza di risonanza (\\(\\omega_r\\)), il picco di risonanza (\\(M_r\\)) e la larghezza di banda (\\(\\omega_b\\)) sono strettamente correlati. Non possono essere impostati indipendentemente l’uno dall’altro poiché i loro valori si influenzano a vicenda.\nData questa interdipendenza, queste specifiche devono essere coerenti tra loro. Ad esempio, un cambiamento nel picco di risonanza (\\(M_r\\)) potrebbe richiedere aggiustamenti nella larghezza di banda (\\(\\omega_b\\)) o nella frequenza di risonanza (\\(\\omega_r\\)) per mantenere la coerenza del sistema.\nNegli scenari in cui sono coinvolte più di due specifiche, in genere uno di questi parametri sarà il risultato degli altri due. Ciò significa che se si specificano due parametri, il terzo dovrebbe logicamente seguire o essere derivato in base a tali scelte.\n\nSelezione delle specifiche compatibili:\n\nQuando vengono fornite più specifiche per il comportamento di un sistema, queste devono allinearsi tra loro. Ad esempio, se imposti una determinata frequenza di risonanza (\\(\\omega_r\\)), dovrebbe essere in armonia con altri parametri come il picco di risonanza (\\(M_r\\)) e la larghezza di banda (\\(\\omega_b\\)).\n\n\n\n\nScegliere specifiche efficaci\n\nPicco risonante (\\(M_r\\)) e larghezza di banda (\\(\\omega_b\\)):\n\nUn approccio pratico nella progettazione nel dominio della frequenza consiste nell’utilizzare principalmente \\(M_r\\) e \\(\\omega_b\\) come specifiche chiave.\n\\(M_r\\) rappresenta effettivamente le caratteristiche di smorzamento, mentre \\(\\omega_b\\) si riferisce sia alle caratteristiche di filtraggio del rumore che, in termini di dominio temporale, al tempo di salita o di assestamento del sistema.\n\nImplementazione negli algoritmi di progettazione:\n\nQueste specifiche, \\(M_r\\) e \\(\\omega_b\\), possono essere integrate nell’algoritmo di progettazione. Ciò consente un approccio mirato e coerente alla progettazione del sistema.\nÈ possibile verificare la compatibilità di specifiche aggiuntive, come \\(\\omega_r\\), dopo il processo di progettazione iniziale.\n\nSemplificazione attraverso metodi specifici:\n\nAvere un metodo chiaro per specificare le prestazioni del sistema può semplificare il processo di progettazione. Concentrandoci su parametri chiave come \\(M_r\\) e \\(\\omega_b\\), possiamo controllare efficacemente aspetti importanti del comportamento del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#come-ottenere-una-risposta-in-frequenza-ad-anello-chiuso-da-dati-ad-anello-aperto",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#come-ottenere-una-risposta-in-frequenza-ad-anello-chiuso-da-dati-ad-anello-aperto",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Come ottenere una risposta in frequenza ad anello chiuso da dati ad anello aperto",
    "text": "Come ottenere una risposta in frequenza ad anello chiuso da dati ad anello aperto\n\nÈ importante comprendere che gli indici critici per caratterizzare un sistema di controllo — come la frequenza di risonanza (\\(\\omega_r\\)), il picco risonante (\\(M_r\\)), la larghezza di banda (\\(\\omega_b\\)) — derivano esclusivamente dalla struttura chiusa del sistema risposta in frequenza dell’anello.\nUn compito significativo nell’analisi del sistema di controllo è determinare la risposta in frequenza ad anello chiuso sulla base dei dati della risposta in frequenza ad anello aperto. La risposta a circuito aperto ci fornisce informazioni sul comportamento intrinseco del sistema senza feedback, ma è la risposta a circuito chiuso che ci mostra come funzionerà il sistema nelle condizioni operative effettive con feedback.\nNel contesto moderno, dove gli strumenti computazionali sono prontamente disponibili, questa transizione diventa molto più gestibile. Con l’aiuto dei computer, possiamo elaborare in modo efficiente i dati a circuito aperto per generare la risposta in frequenza a circuito chiuso.\n\n\nUtilizzo di dati a circuito aperto per la caratterizzazione a circuito chiuso\n\nIl nostro obiettivo è trovare metodi efficienti per caratterizzare la risposta in frequenza ad anello chiuso di un sistema. A questo scopo sono utili gli indici come picco di risonanza (\\(M_r\\)), frequenza di risonanza (\\(\\omega_r\\)) e larghezza di banda (\\(\\omega_b\\)).\nLa sfida è ottenere rapidamente questi parametri, soprattutto quando di solito disponiamo solo di dati sulla risposta in frequenza ad anello aperto.\nVedremo come caratterizzare il comportamento del sistema ad anello chiuso utilizzando direttamente i dati della risposta in frequenza ad anello aperto.\nAbbiamo già visto un metodo: il criterio di stabilità di Nyquist. Questo criterio ci consente di dedurre il comportamento a circuito chiuso del sistema utilizzando i dati della risposta in frequenza a circuito aperto. Vedremo come il criterio di Nyquist e il diagramma di Bode ci aiutano a comprendere aspetti chiave come il margine di guadagno e il margine di fase direttamente dai dati a ciclo aperto, colmando il divario tra l’analisi a ciclo aperto e quella a ciclo chiuso.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#comprensione-del-margine-di-guadagno-e-del-margine-di-fase-e-applicazione-ai-sistemi-del-secondo-ordine",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#comprensione-del-margine-di-guadagno-e-del-margine-di-fase-e-applicazione-ai-sistemi-del-secondo-ordine",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Comprensione del margine di guadagno e del margine di fase e applicazione ai sistemi del secondo ordine",
    "text": "Comprensione del margine di guadagno e del margine di fase e applicazione ai sistemi del secondo ordine\n\nIl margine di guadagno e il margine di fase sono parametri critici nella valutazione della stabilità di un sistema di controllo.\nIl margine di guadagno indica di quanto è possibile aumentare il guadagno del sistema prima che diventi instabile, calcolato come \\(1/a\\) dove \\(A\\) è il guadagno alla frequenza di crossover di fase.\nIl margine di fase \\(\\phi\\) è l’ulteriore spostamento di fase che porterebbe il sistema al limite dell’instabilità, offrendo informazioni su quanto il sistema sia lontano da un potenziale stato oscillatorio o instabile.\n\n\nApplicazione ai sistemi del secondo ordine\nPer un sistema standard del secondo ordine, questi parametri di stabilità diventano particolarmente significativi. Possiamo mettere in relazione il margine di guadagno e il margine di fase del sistema con il suo comportamento caratteristico, fornendo un quadro chiaro della sua stabilità in circuito chiuso.\nPer un sistema standard del secondo ordine, rappresentato dalla funzione di trasferimento\n\\[G(s) = \\frac{\\omega_n^2}{s(s + 2 \\zeta \\omega_n)}\\]\nla sua risposta in frequenza ad anello aperto presenta caratteristiche uniche.\nEsploriamo come analizzare questo sistema direttamente dai dati di risposta in frequenza ad anello aperto.\n\n\nCaratteristiche del diagramma polare\nIl diagramma polare di un sistema standard del secondo ordine non incrocia l’asse immaginario ma è asintotico rispetto ad esso. Questo comportamento è una caratteristica chiave di un sistema di tipo 1, di secondo ordine.\n\nCalcolo del margine di fase per un sistema del secondo ordine\n\nFrequenza di crossover del guadagno (\\(\\omega_{gc}\\)): Questa è la frequenza alla quale il guadagno del sistema è uguale all’unità. È importante per determinare il margine di fase del sistema.\nCalcolo del margine di fase: il margine di fase viene calcolato alla frequenza di crossover del guadagno. È l’angolo misurato positivo rispetto all’asse reale negativo in \\(\\omega_{gc}\\).\nMargine di guadagno: Il margine di guadagno è infinito per un sistema standard di secondo ordine.\n\n\n\n\n\n\n\n\nFigura: diagramma polare della risposta in frequenza ad anello aperto per un sistema standard del secondo ordine.\nPossiamo tracciarlo usando Python come mostrato di seguito.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the parameters for the second-order system\nomega_n = 1.0  # Natural frequency\nzeta = 0.5     # Damping ratio\n\n# Define the transfer function G(s)\nnum = [omega_n**2]\nden = [1, 2 * zeta * omega_n, 0]\nG = ctl.TransferFunction(num, den)\n\n# Nyquist plot\n_, contour = ctl.nyquist(G, plot=True, return_contour=True)\n\nreal, imag = np.real(G(contour)), np.imag(G(contour))\n\n# Plot the unit circle for reference\ncircle = plt.Circle((0, 0), 1, color='blue', fill=False, linestyle='dotted')\nplt.gca().add_artist(circle)\n\n# Annotations for Gain Margin and Phase Margin\ngm, pm, wg, wp = ctl.margin(G)\n# Gain Margin\n# plt.plot([real[0], 1], [imag[0], 0], 'g--')\nplt.text(0.5, 0, f'GM: {gm:.2f}', color='green')\n# Phase Margin\nplt.plot([0, -1], [0, -np.tan(pm * np.pi / 180)], 'r--')\nplt.text(-1, -np.tan(pm * np.pi / 180), f'PM: {pm:.2f}°', color='red')\n\nplt.title(\"Nyquist Plot of a Standard Second-Order System with Phase and Gain Margins\")\nplt.xlabel(\"Real\")\nplt.ylabel(\"Imaginary\")\nplt.grid(True)\nplt.axis('equal')\nplt.xlim((-2,1))\nplt.ylim((-2,2))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nGuadagno di frequenza di crossover e margine di fase\n\nDerivazione della frequenza di crossover del guadagno (\\(\\omega_{gc}\\))\nPer un sistema standard del secondo ordine, la frequenza di crossover del guadagno può essere trovata impostando l’ampiezza della risposta in frequenza ad anello aperto uguale a 1:\n\\[\nG(j\\omega) = \\frac{\\omega_n^2}{j\\omega(j\\omega + 2\\zeta\\omega_n)}\n\\]\nda cui:\n\\[\n\\left| G(j\\omega) \\right| = \\frac{\\omega_n^2}{\\omega\\sqrt{(\\omega^2 + 4\\zeta^2\\omega_n^2)}}\n\\]\nImposta questa grandezza uguale a 1 e risolvi per \\(\\omega\\), che ti dà la frequenza di crossover del guadagno \\(\\omega_{gc}\\).\n\\[\n\\omega_{gc} = \\omega_nk\n\\]\nDove\n\\[\nk=\\sqrt{\\sqrt{4\\zeta^4+1} - 2\\zeta^2}\n\\]\nSi noti che lo stiamo ottenendo direttamente dalla risposta in frequenza ad anello aperto, senza tracciare la risposta in frequenza ad anello chiuso.\n\n\nMargine di fase di derivazione, PM (\\(\\phi\\))\n\\[\nPM = 180^\\circ + \\text{fase di } G(j\\omega_gc) = \\tan^{-1}\\frac{2\\zeta}{k}\n\\]\nDobbiamo stare attenti ai segni degli angoli:\n\n\n\n\n\n\n\n\n\nMargine di fase in funzione del rapporto di smorzamento (\\(\\zeta\\))\nPer un sistema standard del secondo ordine, il margine di fase è una funzione solo di \\(\\zeta\\).\nUn’osservazione interessante è che per valori di \\(\\zeta\\) inferiori a 0,5, il margine di fase è approssimativamente lineare ed è pari a \\(100 \\times \\zeta\\).\nPer tracciare il Margine di Fase (PM) in gradi in funzione del rapporto di smorzamento (\\(\\zeta\\)), possiamo scrivere un semplice script Python. La formula del margine di fase fornita è:\n\\[\nPM =  \\tan^{-1}\\left(\\frac{2\\zeta}{k}\\right)\n\\]\ndove $ k = $.\nQuesto script creerà un grafico del margine di fase (PM) in gradi rispetto al rapporto di smorzamento (\\(\\zeta\\)). Puoi regolare l’intervallo dei valori \\(\\zeta\\) in “zeta_values” se desideri esplorare intervalli diversi.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the range of zeta values\nzeta_values = np.linspace(0.01, 1, 500)  # Avoid starting from 0 to prevent division by zero\n\n# Calculate k and PM for each zeta\nk_values = np.sqrt(np.sqrt(4 * zeta_values**4 + 1) - 2 * zeta_values**2)\npm_values = np.arctan2(2 * zeta_values, k_values) * 180 / np.pi  # Convert from radians to degrees\n\n# Calculate the linear relationship PM = 100 * zeta\nlinear_pm_values = 100 * zeta_values\n\n# Plot PM as a function of zeta\nplt.figure()\nplt.plot(zeta_values, pm_values, label='PM vs. Zeta (Complex Formula)')\nplt.plot(zeta_values, linear_pm_values, label='PM = 100 * Zeta (Linear Approximation)', linestyle='--')\nplt.title('Phase Margin (PM) as a Function of Damping Ratio (Zeta)')\nplt.xlabel('Damping Ratio (Zeta)')\nplt.ylabel('Phase Margin (PM) in Degrees')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCorrelazione degli indici nel dominio della frequenza con il comportamento nel dominio del tempo\n\nMargine di fase e frequenza di crossover del guadagno come indicatori\n\nRappresentazione del dominio della frequenza:\n\nIl margine di fase e la frequenza di crossover del guadagno formano insieme un insieme di parametri che rappresentano effettivamente il comportamento di un sistema nel dominio della frequenza.\n\nDeduzione del comportamento nel dominio del tempo:\n\nAnalizzando questi due parametri, possiamo trarre delle inferenze su come si comporta il sistema nel dominio del tempo. Ciò include la risposta del sistema ai cambiamenti degli input e le sue caratteristiche generali di stabilità.\n\nComprensione del margine di guadagno nei sistemi di secondo ordine:\n\nÈ importante notare che per un sistema del secondo ordine, il margine di guadagno è tipicamente infinito. Tuttavia, quando si ha a che fare con sistemi di ordine superiore, il margine di guadagno diventa un valore finito e gioca un ruolo significativo nel processo di progettazione.\nUn margine di guadagno più ampio implica una maggiore stabilità relativa del sistema, indicando una maggiore tolleranza agli aumenti di guadagno prima di diventare instabile.\n\n\n\n\nIntegrazione del margine di fase e della frequenza di crossover del guadagno nella progettazione\n\nSpecifiche di progettazione dell’edificio:\n\nPossiamo incorporare il margine di fase (PM) e la frequenza di crossover del guadagno nelle nostre specifiche di progettazione.\nQueste specifiche aiuteranno a guidare il processo di progettazione, garantendo che il sistema soddisfi sia i requisiti nel dominio della frequenza che le prestazioni desiderate nel dominio del tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#specifiche-di-progettazione-del-sistema-di-controllo",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#specifiche-di-progettazione-del-sistema-di-controllo",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Specifiche di progettazione del sistema di controllo",
    "text": "Specifiche di progettazione del sistema di controllo\nQuando si progettano sistemi di controllo, la selezione delle specifiche giuste è importante per ottenere le prestazioni del sistema desiderate. Queste specifiche non solo influenzano la progettazione ma aiutano anche a mettere a punto il sistema per funzionare efficacemente sia nel dominio della frequenza che in quello del tempo.\n\nSpecifiche chiave nella progettazione del sistema di controllo\n\nParametri essenziali:\n\nLa progettazione tipica di un sistema di controllo potrebbe includere diverse specifiche critiche:\n\nPicco risonante (\\(M_r\\))\nLarghezza di banda (\\(\\omega_b\\))\nMargine di fase (PM)\nGuadagno frequenza crossover (\\(\\omega_{gc}\\))\nCostanti di errore in stato stazionario (\\(K_p\\), \\(K_v\\), \\(K_a\\))\n\n\nGuidare il processo di progettazione:\n\nQuesti parametri non sono solo valori arbitrari; sono lì per guidare il processo di progettazione e garantire che il sistema raggiunga i suoi obiettivi prestazionali.\n\n\n\n\nApprocci di progettazione basati sulle specifiche\n\nA partire dal picco risonante e dalla larghezza di banda:\n\nUn approccio consiste nell’iniziare la progettazione concentrandosi sul picco risonante (\\(M_r\\)) e sulla larghezza di banda (\\(\\omega_b\\)). Dopo la progettazione iniziale, controlliamo quindi come il sistema si allinea con le altre specifiche.\n\nUtilizzo del margine di fase e della larghezza di banda:\n\nUn altro metodo comune consiste nell’utilizzare il margine di fase e la larghezza di banda come punti di partenza per la progettazione.\nIl margine di fase è indicativo del rapporto di smorzamento (\\(\\zeta\\)) e la larghezza di banda è importante per definire le capacità di filtraggio del rumore del sistema.\n\nProgettazione con risposta in frequenza ad anello aperto:\n\nSe si lavora principalmente con dati di risposta in frequenza ad anello aperto, il margine di fase e la frequenza di crossover del guadagno (\\(\\omega_{gc}\\)) diventano specifiche più rilevanti.\nIn questi casi, se è presente anche una specifica sulla larghezza di banda (\\(\\omega_b\\)), il progetto inizia con il margine di fase e il guadagno della frequenza di crossover, quindi controlla se la specifica della larghezza di banda è soddisfatta calcolando la risposta in frequenza ad anello chiuso.\nSe emergono discrepanze, viene utilizzato un processo di tentativi ed errori per adattare il progetto fino al raggiungimento del risultato desiderato.\n\n\n\n\nConclusione e applicazione pratica\n\nFlessibilità nella progettazione: questi approcci progettuali illustrano la flessibilità e l’adattabilità richieste nella progettazione del sistema di controllo, garantendo che il sistema finale soddisfi tutti i criteri specificati.\nBilanciamento delle specifiche: la chiave è bilanciare queste specifiche, comprendendo che ciascuna influenza le prestazioni del sistema in modi distinti.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#verifica-la-tua-comprensione",
    "href": "IT_🇮🇹/feedback_system_performance_based_on_frequency_response_it.html#verifica-la-tua-comprensione",
    "title": "Prestazioni del sistema di feedback basate sulla risposta in frequenza",
    "section": "Verifica la tua comprensione",
    "text": "Verifica la tua comprensione\nDomanda pop-up: Cosa implica un margine di fase elevato sulla stabilità del sistema?\nRisposta: Un margine di fase elevato indica che il sistema ha un buon grado di stabilità relativa ed è lontano dall’orlo dell’instabilità.\nDomanda pop-up: In che modo specifiche come \\(M_r\\) e \\(\\omega_b\\) influenzano la progettazione finale del sistema?\nRisposta: Specifiche come \\(M_r\\) e \\(\\omega_b\\) influenzano direttamente le caratteristiche di smorzamento e la velocità di risposta del sistema, influenzando così le sue prestazioni complessive.\nDomanda pop-up: Perché è importante considerare più specifiche nella progettazione del sistema di controllo?\nRisposta: Considerare più specifiche è importante perché garantisce un approccio olistico alla progettazione, in cui la stabilità, la reattività, l’immunità al rumore e la gestione degli errori del sistema sono tutti ottimizzati per funzionare insieme in modo armonioso.",
    "crumbs": [
      "IT_🇮🇹",
      "Prestazioni del sistema di feedback basate sulla risposta in frequenza"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html",
    "title": "Compensatori e luogo delle radici",
    "section": "",
    "text": "Benvenuti alla prossima fase del nostro corso sui Principi di Controllo Automatico. In questo quaderno approfondiremo il Root Locus Design.\nCominciamo rivisitando alcuni dei concetti di cui abbiamo parlato in precedenza per poi passare ad esempi pratici di progettazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html#cosè-un-compensatore",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html#cosè-un-compensatore",
    "title": "Compensatori e luogo delle radici",
    "section": "Cos’è un compensatore?",
    "text": "Cos’è un compensatore?\nUn compensatore è un tipo di controller, come PI (Proporzionale-Integrale), PD (Proporzionale-Derivativo) o PID (Proporzionale-Integrale-Derivativo), progettato per migliorare le prestazioni di un sistema.\nLe prestazioni nei sistemi di controllo sono generalmente classificate in due tipologie:\n\nPrestazioni transitorie: il modo in cui il sistema risponde ai cambiamenti nel tempo, soprattutto quando si sta adattando per raggiungere il suo stato stazionario.\nPrestazioni allo stato stazionario: il comportamento del sistema una volta che si è stabilizzato in uno schema coerente nel tempo.\n\nLe prestazioni transitorie sono cruciali perché determinano la rapidità e la precisione con cui il sistema raggiunge lo stato desiderato dopo un disturbo. Le prestazioni in stato stazionario, d’altro canto, sono importanti per la stabilità e l’accuratezza a lungo termine del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html#struttura-del-sistema-con-compensatori",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html#struttura-del-sistema-con-compensatori",
    "title": "Compensatori e luogo delle radici",
    "section": "Struttura del sistema con compensatori",
    "text": "Struttura del sistema con compensatori\nConsideriamo una tipica struttura del sistema di controllo:\n\nL’impianto: la parte centrale del sistema controllato.\nIl controller/compensatore: Un dispositivo o algoritmo che regola la produzione dell’impianto in base al feedback.\n\n\n\n\n\n\n\n\nIn questa configurazione il compensatore (\\(D(s)\\)) è posto in cascata con l’impianto. Questa disposizione può anche essere modificata con circuiti di feedback minori, che possono essere rappresentati in un formato strutturale simile a fini di progettazione.\nÈ fondamentale comprendere che la scelta del compensatore influisce sia sul comportamento transitorio che su quello stazionario del sistema. Un compensatore ben scelto può migliorare significativamente la risposta del sistema ai cambiamenti e mantenere la stabilità nel tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html#tipi-di-compensatori",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html#tipi-di-compensatori",
    "title": "Compensatori e luogo delle radici",
    "section": "Tipi di compensatori",
    "text": "Tipi di compensatori\n\nCompensatore di fase\nDefinizione e funzione di trasferimento\nUn compensatore di anticipo di fase viene utilizzato per migliorare le prestazioni transitorie spostando il luogo delle radici a sinistra, migliorando così la stabilità del sistema. La funzione di trasferimento di un compensatore di fase è data da:\n\\[ D(s) = K_c \\frac{(s + z_c)}{(s + p_c)} \\]\nDove: - $ K_c $ è il guadagno. - $ z_c $ è lo zero del compensatore. - $ p_c $ è il polo del compensatore.\n\nRealizzazione fisica: spesso realizzata utilizzando un circuito Op-Amp con valori specifici di resistore e condensatore che determinano $ z_c $, $ p_c $ e $ K_c $.\n\n\n\n\n\n\n\n\nFigura: grafico che illustra il diagramma polo-zero di un compensatore di fase. Lo zero è in $ -z_c $ e il polo in $ -p_c $, con il polo più lontano dall’origine rispetto allo zero.\n\nPrincipi di progettazione del compensatore\n\nLo zero nel compensatore di anticipo di fase (a $ s = -z_c $) introduce un’azione derivativa, spostando il diagramma del luogo delle radici verso la metà sinistra del piano, migliorando così la stabilità e le prestazioni transitorie.\nPer l’attenuazione del rumore, in particolare del rumore ad alta frequenza, è incluso un polo aggiuntivo, rappresentato dal polo in $ s = -p_c $.\nIl posizionamento del compensatore principale è fondamentale nei casi in cui è necessario migliorare le prestazioni transitorie.\nIl controller PD è un caso speciale di compensatore di fase che non include il polo.\n\nDomanda pop-up: Perché viene utilizzato un compensatore di fase per migliorare le prestazioni transitorie? Risposta: Perché sposta il luogo delle radici a sinistra, migliorando la stabilità del sistema e la risposta transitoria.\n\n\n\nEsempio: compensatore di anticipo di fase\nApplichiamo questi concetti ad un esempio pratico: il controllo dell’assetto di un satellite. Il sistema può essere modellato come $ $.\n\nScenario: Controllo dell’assetto satellitare\nModello di sistema:\n\\[ G(s) = \\frac{1}{s^2} \\]\nIngresso: Coppia $ T(t) $ Risultato: Angolo di attitudine $ (t) $ Tipo di sistema: Tipo-2 (implica buone prestazioni in stato stazionario: errore zero per gli ingressi di gradino e rampa ed errore finito per gli ingressi di accelerazione)\nDichiarazione del problema: Affrontare l’instabilità dovuta a un doppio integratore all’origine.\n\n\n\n\n\n\n\n\n\nProgettazione iniziale del sistema\nIniziamo a considerare la semplice situazione in cui\n\\[\nD(s) = K\n\\]\nCiò corrisponde alla situazione in cui \\(D(s)=K\\) è la costante di un attuatore che converte i segnali elettrici in una coppia \\(T(t)\\) per i propulsori.\nFunzione di trasferimento ad anello aperto:\n\\[ G(s) = \\frac{K}{s^2} \\]\nComportamento a circuito chiuso:\nPossiamo analizzarlo utilizzando il luogo delle radici al variare di \\(K\\).\n\n\n\n\n\n\n\n\n\n\nComprendere il diagramma del luogo delle radici\nRicordate, il grafico del luogo delle radici è una rappresentazione grafica di come i poli a circuito chiuso di un sistema di controllo variano con le modifiche di un parametro di sistema, in genere il guadagno.\nPer il sistema $ $, il grafico del luogo delle radici indica una natura oscillatoria. Questo perché per tutti i valori di ‘s’ le radici giacciono sull’asse immaginario del piano s, che è caratteristico delle oscillazioni non smorzate.\nPossiamo tracciare il luogo delle radici usando Python in questo modo:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\nnumerator = [1]\ndenominator = [1, 0, 0]\nG = ctl.TransferFunction(numerator, denominator)\n\n# Plot the root locus\nplt.figure(figsize=(10, 6))\nctl.root_locus(G, plot=True);\nplt.title(f'Root locus of {G}');\n\n\n\n\n\n\n\n\nEcco uno script Python che simula il sistema a ciclo chiuso:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System parameters\nK = 1  # You can modify this gain value as needed\n\n# Transfer function of the system\nnumerator = [K]\ndenominator = [1, 0, 0]  # s^2 term has a coefficient of 1, s term is 0, constant term is 0\nsystem = ctl.tf(numerator, denominator)\n\n# Closed loop transfer function with a unity feedback\n# For a unity feedback system, the feedback transfer function is simply 1\nclosed_loop_system = ctl.feedback(system, 1)\n\n# Time parameters for simulation\nt = np.linspace(0, 100, 1000)  # Simulation from 0 to 10 seconds, with 1000 points\n\n# Step response\nt, y = ctl.step_response(closed_loop_system, t)\n\n# Plotting\nplt.plot(t, y)\nplt.title('Closed-Loop Step Response of the System K/s^2')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Response')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nProcesso decisionale nella progettazione del compensatore\n\nScelta tra anticipo di fase e compensatore di ritardo di fase\n\nCompensatore di fase principale: ideale per migliorare le prestazioni transitorie spostando il luogo della radice a sinistra, migliorando la stabilità.\nCompensatore di ritardo di fase: aggiunge un altro integratore al sistema (o qualcosa di molto simile), rendendolo un sistema di tipo 3, che porta all’instabilità. Viene generalmente utilizzato per migliorare la precisione in stato stazionario. Modifica il codice Python sopra o traccia il luogo delle radici per un sistema di tipo 3.\n\nNel nostro scenario attuale, la preoccupazione principale non è la precisione dello stato stazionario ma le prestazioni transitorie. Pertanto, la scelta preferita è un compensatore di fase.\n\n\n\nImplementazione del compensatore di anticipo di fase\n\nIl concetto\nIl compensatore di fase è rappresentato dalla funzione di trasferimento:\n\\[ D(s) = K_c \\frac{(s + z_c)}{(s + p_c)} \\]\ndove $ K_c $, $ z_c $ e $ p_c $ sono i parametri che possiamo determinare per soddisfare i nostri requisiti.\nNota: i concetti alla base del design sono più importanti del design specifico. Possono essere adatti più modelli.\n\n\nL’approccio progettuale\n\nRappresentazione del sistema: La funzione di trasferimento dell’impianto è data da $ G(s) = $, dove $ K $ è un guadagno regolabile. Possiamo quindi prendere il compensatore come $ $.\nConsiderazioni sull’implementazione: A seconda dell’hardware, il guadagno $ K $ potrebbe essere regolato all’interno dell’impianto o tramite uno stadio di amplificazione esterno nel compensatore.\n\nCi sono tre parametri sotto il nostro controllo. Il modo in cui implementiamo questi parametri dipende dall’hardware.\nChiamiamo $ $ come sistema non compensato che in questo caso include il parametro di progettazione \\(K\\).\nConsideriamo un sistema di controllo dell’assetto per un satellite: - Sistema non compensato: \\[ \\frac{K}{s^2} \\] - Compensatore: \\[ D(s) = \\frac{s + z_c}{s + p_c} \\]\n\n\n\nProgettazione per requisiti prestazionali specifici\n\nTradurre le prestazioni in posizioni dei poli a circuito chiuso\nSupponiamo che i requisiti di progettazione siano un rapporto di smorzamento $ = 0,707 $ e un tempo di assestamento $ t_s = 2$ secondi. Il nostro obiettivo è tradurre questi requisiti nelle posizioni dei poli a circuito chiuso desiderate.\nRicorda che i requisiti transitori potrebbero esserti forniti in termini di $_n $ (frequenza naturale), \\(M_p\\) (Overshoot Peak), ecc.\nRicordatevi inoltre che spesso possiamo passare da una specifica esigenza all’altra. Ad esempio possiamo calcolare:\n\\[\n\\zeta\\omega_n = \\frac{4}{t_s} = 2\n\\]\nDa questi valori è possibile determinare la posizione dei poli del circuito chiuso. Di seguito i passaggi per farlo.\nPer calcolare la posizione dei poli desiderati ad anello chiuso per un sistema di controllo con un rapporto di smorzamento $ $ e un tempo di assestamento $ t_s $ specificati, utilizziamo le formule standard relative alle caratteristiche di risposta del sistema del secondo ordine.\nI poli desiderati a circuito chiuso sono generalmente coniugati complessi per sistemi sottosmorzati e la loro posizione nel piano s è determinata dal rapporto di smorzamento $ $ e dalla frequenza naturale $ _n $.\nDato: - Rapporto di smorzamento $= 0,707 $ - Tempo di assestamento $ t_s = 2 $ secondi\n\n**Calcola la frequenza naturale ($ _n $)**: Il tempo di assestamento per un sistema del secondo ordine è approssimato da $ t_s $. Riorganizziamo questo per risolvere $ _n $:\n\\[ \\omega_n = \\frac{4}{\\zeta t_s} \\]\nSostituendo i valori dati:\n\\[ \\omega_n = \\frac{4}{0,7 \\times 2} = \\frac{4}{1,4} \\approx 2,857 \\, \\text{rad/s} \\]\nDeterminare le parti reale e immaginaria dei poli: La forma generale dei poli ad anello chiuso per un sistema del secondo ordine è:\n\\[ s = -\\zeta \\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nLa parte reale (sigma) è data da $ -_n $ e la parte immaginaria (omega) da $ _n $.\nCalcolando questi:\n\nParte reale: $ -_n = -0.7 $\nParte immaginaria: $ _n = 2.857 $\n\nPosizioni dei poli ad anello chiuso: Pertanto, i poli ad anello chiuso si trovano approssimativamente a:\n\\[ s = -2 \\pm j2 \\]\n\nQuesti calcoli forniscono le posizioni desiderate per i poli a circuito chiuso nel piano s per ottenere il rapporto di smorzamento e il tempo di assestamento specificati nella progettazione del sistema di controllo.\nPossiamo tracciarlo sul piano s:\n\n\n\n\n\n\n\nFigura: grafico del luogo delle radici del sistema non compensato. È possibile identificare dove dovrebbero essere i poli dell’anello chiuso per la prestazione desiderata.\nDobbiamo modificare il comportamento del luogo delle radici per passare attraverso i poli desiderati a circuito chiuso in modo che i requisiti sulla precisione transitoria siano soddisfatti.\n\n\n\nProgettazione del compensatore di fase: posizionamento dello zero e del polo\n\nPassaggio 1: posizionamento iniziale di zero e polo sul piano s\nInizia posizionando provvisoriamente lo zero ($ z_c \\() e il polo (\\) p_c $) del compensatore sul piano s. Questo posizionamento iniziale non deve essere esatto; è un punto di partenza per la messa a punto.\n\nZero ($ z_c $): posizionalo più vicino all’asse immaginario.\nPole ($ p_c $): posizionalo più a sinistra dello zero sull’asse reale.\n\n\n\nPassaggio 2: regolazione del criterio dell’angolo\nPer garantire che la risposta a circuito chiuso del sistema soddisfi i nostri requisiti, il luogo delle radici deve passare attraverso le posizioni dei poli a circuito chiuso desiderate. Ciò richiede il rispetto del criterio dell’angolo in questi punti.\n\nComprensione del criterio dell’angolo:\n\nIl criterio dell’angolo afferma che la somma degli angoli di fase da tutti i poli e gli zeri a un punto sul piano s deve essere uguale a un multiplo dispari di 180 gradi affinché il punto si trovi sul luogo delle radici.\nPer un compensatore in piombo, gli angoli importanti sono quelli forniti dallo zero del compensatore ($ {z_c} \\() e dal polo (\\) {p_c} \\(), e l'angolo formato dai poli della pianta (\\) _1 $) .\n\nCalcolo dei contributi angolari:\n\nDobbiamo trovare gli angoli $ {z_c} $ e $ {p_c} $ tali che soddisfino l’equazione:\n\\[ \\theta_{z_c} - \\theta_{p_c} - 2\\theta_1 = -180^\\circ \\]\nQui, $ {z_c} $ e $ {p_c} $ sono rispettivamente gli angoli dallo zero e dal polo del compensatore alla posizione desiderata del polo a circuito chiuso, e $ 2_1 $ è il contributo del polo della pianta poli.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuida passo passo alla progettazione del compensatore con il luogo delle radici\n\nComprendere il ruolo dei poli e degli angoli\n\nPunto iniziale: Conosciamo i poli della pianta, quindi possiamo determinare $ _1 $, il contributo angolare di questi poli a qualsiasi punto nel piano s.\nPoli desiderati ad anello chiuso: nel nostro esempio, sono a $ -2 j2 $. Questo ci fornisce un riferimento per determinare i contributi angolari necessari dal compensatore.\n\n\n\nCalcolo del contributo del compensatore\n\nContributo angolare netto: Il compensatore deve fornire un angolo netto $ {z_c} - {p_c} $, dove $ {z_c} $ e $ {p_c} $ sono gli angoli dallo zero e dal polo del compensatore ai poli desiderati ad anello chiuso.\nFormula: Dati $ _1 = 135^$, calcoliamo:\n\\[\n\\theta_{z_c} - \\theta_{p_c} = -180^\\circ + 2 \\cdot 135^\\circ = -180^\\circ + 270^\\circ = 90^\\circ\n\\]\n\n\n\nPosizionamento dello zero e determinazione del polo\n\nStrategia generale: in genere, scegliamo una posizione per lo zero e quindi calcoliamo dove dovrebbe trovarsi il polo per soddisfare la condizione dell’angolo.\nEsempio di calcolo:\n\nPosizionare lo zero a -1 sull’asse reale del piano s.\nIl luogo delle radici risultante mostra che la condizione dell’angolo è soddisfatta (l’abbiamo progettata per soddisfarla) e che il luogo passa attraverso i poli desiderati del circuito chiuso.\n\n\n\n\n\n\n\n\n\n\n\nValutazione del design\n\nCondizione di dominanza: anche se la condizione dell’angolo è soddisfatta, dobbiamo garantire che sia soddisfatta anche la condizione di dominanza. Ciò significa che il comportamento del sistema progettato dovrebbe corrispondere strettamente al comportamento atteso da un sistema di secondo ordine con $ $ dato.\nProblema con il terzo polo: nel nostro esempio, il terzo polo si sposta vicino allo zero, influenzando potenzialmente il superamento del sistema e non soddisfacendo la condizione di dominanza.\n\n\n\nCalcolo del terzo polo e verifica della dominanza\n\nCriterio di magnitudo: utilizzare il criterio di magnitudo per calcolare il valore di $ K $ corrispondente ai poli desiderati a circuito chiuso. In questo caso, $ K = 16 $.\nTrovare il terzo polo: Con $ K = 16 $, individua il terzo polo e verifica se la condizione di dominanza è soddisfatta.\nSimulazione: se la condizione di dominanza non è soddisfatta, simula la risposta del sistema per valutare l’influenza del terzo polo.\n\n\n\nLinee guida per posizionare lo zero\n\nPosizione preferita: Idealmente, posizionare lo zero a sinistra dei poli a circuito chiuso coniugati complessi desiderati. Ciò garantisce che il terzo polo si trovi a sinistra dei poli desiderati, soddisfacendo la condizione di dominanza. Questo perché il ramo del luogo delle radici terminerà in quello zero.\nEccezioni: a volte questo posizionamento ideale non è possibile. In questi casi, come nel caso del nostro contributo dell’angolo netto di 90°, potrebbe essere necessario posizionare lo zero a destra.\n\n\n\nRisolvere per \\(K\\)\nPer risolvere il guadagno $ K $ nel nostro esempio di sistema di controllo, dove lo zero del compensatore $ z_c $ è a -1 e il polo $ p_c $ è a -6, seguiamo i passaggi descritti in precedenza. Dobbiamo calcolare $ K $ in modo tale che la condizione di magnitudo sia soddisfatta ai poli desiderati del circuito chiuso $ -2 j2 $.\nDato:\n\nPoli desiderati in anello chiuso: $ -2 j2 $\nZero $ z_c = -1 $\nPolo $ p_c = -6 $\n\nLa funzione di trasferimento ad anello aperto $ G(s) $ è:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} \\]\nSostituendo $ z_c = -1 $ e $ p_c = -6 $ nella funzione di trasferimento, otteniamo:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + 1)}{s^2 \\cdot (s + 6)} \\]\n\n\nApplicazione della condizione di grandezza\nOra applichiamo la condizione di magnitudo a uno dei poli desiderati del circuito chiuso, diciamo $ s = -2 + j2 $:\n\\[ |G(-2 + j2)| = 1\\]\n\\[ \\frac{K \\cdot \\left|(-2 + j2) + 1\\right|}{\\left|(-2 + j2)^2\\right| \\cdot \\left|(-2 + j2) + 6\\right|} = 1 \\]\nSemplifichiamo questa equazione:\n\\[ \\frac{K \\cdot \\left|-1 + j2\\right|}{\\left| (-2 + j2)^2\\right| \\cdot \\left|4 + j2\\right|} = 1 \\]\n\n\nRisolvere per $ K $\nPer prima cosa dobbiamo semplificare i numeri complessi nell’equazione:\n\nNumeratore: $ -3 + j2 $\nDenominatore: semplifichiamo $ (-2 + j2)^2 $ e $ (4 + j2) $, quindi li moltiplichiamo insieme.\n\nFacciamo questi calcoli:\n\n$ |(-2 + j2)^2| = |(-2)^2 + (j2)^2 + 2 (-2) j2 | = |- 8j| = 8$\n\nQuindi, calcola le magnitudini:\n\nEntità del numeratore: $ = 2.23$\nEntità del denominatore: $ = 8$ e $ = 4.47$.\n\nInfine, risolvi $ K $ utilizzando:\n\\[ \\frac{K \\cdot \\text{Ampiezza del numeratore}}{\\text{Ampiezza del denominatore}} = \\frac{8(4.47)}{2.23} = 16\\]\n\n\n\nBilanciare la condizione di angolo e l’attenuazione del rumore nella progettazione del compensatore\nNella progettazione di un compensatore, in particolare di un compensatore in anticipo di fase, un aspetto cruciale da considerare è il rapporto tra il polo e lo zero del compensatore. Questa relazione non è solo una questione di soddisfare le condizioni geometriche per i requisiti angolari, ma svolge anche un ruolo importante nell’attenuazione del rumore, soprattutto per i segnali ad alta frequenza.\n\nIl ruolo del rapporto poli-zero\n\nConsiderazioni geometriche per le condizioni angolari:\n\nIl posizionamento del polo e dello zero sul piano s è inizialmente guidato dalla necessità di soddisfare la condizione angolare del metodo del luogo delle radici.\nQuesta condizione garantisce che il compensatore alteri effettivamente il luogo delle radici del sistema per ottenere le caratteristiche di risposta transitoria desiderate.\n\nAspetto del filtraggio del rumore:\n\nOltre a soddisfare le condizioni angolari, il polo del compensatore funge da filtro per il rumore ad alta frequenza.\nLa posizione del polo rispetto allo zero influisce in modo significativo sulla capacità del compensatore di attenuare le componenti ad alta frequenza.\n\n\n\n\nRapporto ideale tra polo e zero\n\nFattore di 10 per l’attenuazione:\n\nIn genere si consiglia che il rapporto tra lo zero e il polo sia intorno a 10. È stato riscontrato che questo rapporto fornisce un’attenuazione efficace delle alte frequenze.\nAd esempio, se lo zero è posizionato a -1 sull’asse reale, un polo corrispondente a -10 può offrire un buon equilibrio tra soddisfazione della condizione angolare e riduzione del rumore.\n\n\n\n\nBilanciamento degli obiettivi di progettazione\n\nCompromessi nel design:\n\nSpesso, i progettisti dei sistemi di controllo si trovano ad affrontare un compromesso tra il rigoroso rispetto delle condizioni angolari per le prestazioni transitorie desiderate e il posizionamento del polo per un’attenuazione ottimale del rumore ad alta frequenza.\nQuesto equilibrio è fondamentale per garantire che il compensatore non solo migliori la risposta del sistema ma mantenga anche la robustezza contro i disturbi ad alta frequenza.\n\n\n\n\n\nTrovare il terzo polo\nPer calcolare la posizione del terzo polo in un sistema di controllo in cui è stato aggiunto un compensatore di fase ed è stato determinato il guadagno $ K $, possiamo seguire questi passaggi:\n\nFunzione di trasferimento ad anello aperto: richiama la funzione di trasferimento ad anello aperto con il compensatore: \\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} \\] dove $ z_c $ è lo zero e $ p_c $ è il polo del compensatore.\nValori noti sostitutivi: sostituisce i valori noti per $ K $, $ z_c $ e $ p_c $ nella funzione di trasferimento ad anello aperto.\nMetodo del luogo delle radici: per trovare la posizione del terzo polo, è possibile utilizzare il metodo del luogo delle radici. Ciò implica tracciare il luogo delle radici della funzione di trasferimento ad anello aperto e identificare dove si trova il terzo polo in base al valore di $ K $.\nApproccio analitico: In alternativa, per un approccio analitico, è possibile impostare l’equazione caratteristica del sistema a circuito chiuso, che è: \\[ 1 + G(s)H(s) = 0 \\] Risolvendo questa equazione otterrai i poli del sistema a circuito chiuso.\nRisoluzione dell’equazione caratteristica: L’equazione caratteristica sarà un’equazione cubica in $ s $ (poiché il sistema originale è del secondo ordine e il compensatore aggiunge un ordine). Risolvendo questa equazione cubica otterrai tre soluzioni, corrispondenti ai tre poli del sistema a circuito chiuso.\nIdentificazione del terzo polo: due di questi poli saranno i poli desiderati a circuito chiuso (ad esempio, $ -2 j2 $ nel nostro esempio). La terza soluzione sarà il polo aggiuntivo introdotto dal compensatore.\n\n\nConsiderazioni pratiche\n\nStrumenti computazionali: risolvere analiticamente l’equazione cubica può essere complesso. Spesso è più pratico utilizzare strumenti computazionali come MATLAB o Python, che possono calcolare in modo efficiente le radici delle equazioni polinomiali.\nDominanza dei poli: una volta trovato il terzo polo, dovresti verificarne la dominanza nella risposta del sistema. Se è all’estrema sinistra nel piano s, il suo effetto sulla risposta transitoria del sistema potrebbe essere trascurabile. Se è più vicino all’asse immaginario, potrebbe influenzare in modo significativo il comportamento del sistema.\n\n\nimport numpy as np\n\n# Coefficients of the cubic equation\ncoefficients = [1, 6, 16, 16]\n\n# Finding the roots\nroots = np.roots(coefficients)\n\n# Display the roots\nprint(\"The poles of the system are:\", roots)\n\nThe poles of the system are: [-2.+2.j -2.-2.j -2.+0.j]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\ndef calculate_settling_time(T, yout, tol=0.02):\n    # Settling time is the time at which the response remains within a certain tolerance\n    settled_value = yout[-1]\n    lower_bound = settled_value * (1 - tol)\n    upper_bound = settled_value * (1 + tol)\n    within_tol = np.where((yout &gt;= lower_bound) & (yout &lt;= upper_bound))[0]\n    if within_tol.size == 0:\n        return np.nan  # Return NaN if the system never settles\n    return T[within_tol[0]]\n\ndef calculate_steady_state_error(system_type, G, K, time_span):\n    G_closed_loop = ctl.feedback(K * G)\n    if system_type == 'step':\n        # Steady-state error for step input (Type 0 system)\n        T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n        steady_state_val = yout[-1]\n        return 1 - steady_state_val\n    elif system_type == 'ramp':\n        # Steady-state error for ramp input (Type 1 system)\n        Kv = ctl.dcgain(G_closed_loop * ctl.TransferFunction([1, 0], [1]))\n        return 1 / Kv if Kv != 0 else np.inf\n    else:\n        return np.nan\n\n# def plot_step_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n#     plt.plot(T, yout)\n#     settling_time = calculate_settling_time(T, yout)\n#     steady_state_error = calculate_steady_state_error('step', G, K, time_span)\n#     plt.title(f'Step Response for Gain K={K}\\nSettling Time: {settling_time:.2f}, Steady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n# def plot_ramp_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.forced_response(G_closed_loop, T=time_span, U=time_span)\n#     plt.plot(T, yout)\n#     steady_state_error = calculate_steady_state_error('ramp', G, K, time_span)\n#     plt.title(f'Ramp Response for Gain K={K}\\nSteady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n\ndef plot_root_locus_with_gain(K, numerator, denominator):\n    # Define the transfer function G(s)\n    G = ctl.TransferFunction(numerator, denominator)\n\n    # Calculate the closed-loop transfer function for the given gain\n    G_closed_loop = ctl.feedback(K * G)\n\n    # Find the poles for the specific gain\n    poles = ctl.pole(G_closed_loop)\n\n    # Plot the root locus\n    plt.figure(figsize=(10, 6))\n    ctl.root_locus(G, plot=True)\n\n    # Plot the poles for the specific gain\n    plt.plot(np.real(poles), np.imag(poles), 'ro', markersize=10, label=f'Poles for K={K}')\n\n    # Enhance plot\n    plt.xlabel('Real Axis')\n    plt.ylabel('Imaginary Axis')\n    plt.title(f'Root Locus of G(s) with Poles for Gain K={K}')\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \n    \ndef plot_all(K):\n    # Define the transfer function D(s)G(s)\n    numerator = [1, 1 * zc]     # 16s+16\n    denominator = [1, 6, 0, 0]  # s^3 + 6s^2\n\n    G = ctl.TransferFunction(numerator, denominator)\n    \n    # Time span for the responses\n    time_span = np.linspace(0, 10, 1000)\n\n    # Plot Root Locus\n    plot_root_locus_with_gain(K, numerator, denominator)\n\n#     # Plot Step Response\n#     plt.figure(figsize=(10, 4))\n#     plot_step_response(G, K, time_span)\n#     plt.show()\n\n#     # Plot Ramp Response\n#     plt.figure(figsize=(10, 4))\n#     plot_ramp_response(G, K, time_span)\n#     plt.show()\n    \n\nzc = 1  # Zero of the compensator\n\ninteract(plot_all, \n         K=FloatSlider(value=16, min=0, max=50, step=0.5, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_all(K)&gt;\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define system parameters\nK = 1   # This is one to have K to vary in the plot. We need to click on the value of gain 16.\nzc = 1  # Zero of the compensator\npc = 6  # Pole of the compensator\n\n# Define the transfer function\nnumerator = [K, K * zc] # 16s+16\ndenominator = [1, 6, 0, 0]  # s^3 + 6s^2\nsystem = ctl.tf(numerator, denominator)\n\n# Plot the root locus\nctl.rlocus(system)\nplt.show()\n\n# Use the plot to find the third pole at the specific gain K\n\n\n\n\n\n\n\n\n\n\nApprendimento interattivo\nPrendi in considerazione la progettazione di un compensatore di fase per un sistema in cui le prestazioni transitorie sono cruciali quanto la riduzione del rumore. La scelta delle posizioni polo e zero dovrebbe:\n\nSoddisfare le condizioni dell’angolo: assicurarsi che il luogo delle radici passi attraverso le posizioni dei poli ad anello chiuso desiderate per la risposta transitoria richiesta.\nFiltraggio del rumore ad alta frequenza: posizionare il palo in modo tale da filtrare efficacemente i componenti indesiderati ad alta frequenza, senza influire negativamente sulla risposta ai transitori.\n\nEsercizio interattivo: gli studenti possono impegnarsi in un esercizio utilizzando uno strumento software come MATLAB o Python per sperimentare diversi rapporti polo-zero. L’osservazione di come queste regolazioni influiscono sia sulla risposta transitoria che sull’attenuazione del rumore fornirà spunti pratici sui compromessi coinvolti nella progettazione del compensatore.\n\n\nRequisiti per lo stato stazionario\nDato che abbiamo un sistema di tipo 2 questo non è un problema, certamente non per gradini e rampe. Se si deve calcolare l’errore di accelerazione, è possibile farlo da:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} = \\frac{16 \\cdot (s + 1)}{s ^2 \\cdot (s + 6)} \\]\ne quindi la costante di accelerazione è:\n\\[\nK_a = \\frac{16}{6}\n\\]\ne il corrispondente errore di accelerazione è:\n\\[\ne_{ss} = \\frac{6}{16} radianti\n\\]\nQuesto è un valore finito e molto probabilmente accettabile. Seguire l’accelerazione è difficile e in genere ci accontentiamo degli input di gradino e rampa.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html#compensazione-del-ritardo-di-fase",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html#compensazione-del-ritardo-di-fase",
    "title": "Compensatori e luogo delle radici",
    "section": "Compensazione del ritardo di fase",
    "text": "Compensazione del ritardo di fase\nIn questa parte approfondiremo il concetto di compensazione del ritardo di fase. A differenza dei compensatori di anticipo di fase progettati per migliorare le prestazioni transitorie, i compensatori di ritardo di fase vengono utilizzati principalmente per migliorare la precisione in condizioni stazionarie.\n\nIl modello della rete a ritardo di fase\n\nFunzione di trasferimento del compensatore di ritardo di fase\nLa funzione di trasferimento per un compensatore di ritardo di fase è generalmente data da:\n\\[ D(s) = \\frac{s + z_c}{s + p_c} \\]\nDove: - $ z_c $ è lo zero del compensatore. - $ p_c $ è il polo del compensatore.\n\n\nConfigurazione Polo Zero\n\nIn un compensatore di sfasamento, il polo è solitamente posizionato vicino all’origine ma non necessariamente in corrispondenza di essa. Posizionando un polo all’origine lo si rende un controller Proporzionale-Integrale (PI).\nLo zero ($ z_c \\() è posizionato vicino al polo (\\) p_c $), essenziale per mantenere la stabilità del sistema. Altrimenti la presenza del polo all’origine potrebbe destabilizzare il sistema.\n\n\n\n\n\n\n\n\n\n\n\nScelta tra compensatori di ritardo di fase e di anticipo di fase\n\nCriteri decisionali\n\nRequisiti prestazionali temporanei:\n\nSe il sistema non compensato, tramite una regolazione del guadagno, soddisfa i requisiti di prestazione transitoria, allora si può prendere in considerazione un compensatore di ritardo di fase.\nIn caso contrario, e non è possibile scegliere un guadagno che soddisfi i requisiti di prestazione transitoria e se è necessario spostare il luogo della radice a sinistra, è più appropriato un compensatore di anticipo di fase.\nIl guadagno del sistema non compensato è un fattore critico. Regolando questo guadagno, potresti soddisfare i requisiti prestazionali transitori senza bisogno di compensazioni aggiuntive.\n\nPrecisione allo stato stazionario:\n\nPer migliorare la precisione in stato stazionario, in particolare nei sistemi di tipo 1 o tipo 0, un compensatore di ritardo di fase è una scelta adatta. L’utilizzo di un compensatore di ritardo con un sistema di tipo 2 è molto difficile a causa degli effetti instabilizzanti.\nL’utilizzo di un compensatore di ritardo è simile all’aggiunta di un integratore per migliorare le prestazioni in condizioni stazionarie. Il polo e lo zero sono scelti in modo che le prestazioni transitorie non siano deteriorate. Avere lo zero il più vicino possibile al polo significa che si vuole ridurre l’effetto che il compensatore potrebbe avere sul transitorio.\n\n\n\n\n\nEsempio: applicazione della compensazione del ritardo di fase\n\nModello di sistema\nConsideriamo un sistema di tipo 1 rappresentato da:\n\\[ G(s) = \\frac{K}{s(s + 2)} \\]\nQuesto modello potrebbe rappresentare un servosistema motore per il tracciamento della posizione.\n\n\nRequisiti di prestazione\n\nRapporto di smorzamento ($ $): 0,45\nCostante errore velocità ($ K_v $): 20 (per errore di rampa a regime)\n\n\n\n\nValutazione del sistema non compensato\n\nCostante di errore di velocità ($ K_v $)\nNell’esempio del nostro sistema di controllo, iniziamo valutando le prestazioni del sistema non compensato. Un parametro chiave in questa valutazione è la costante dell’errore di velocità, indicata come $ K_v $. Per il nostro sistema, $ K_v $ viene calcolato come segue:\n\\[ K_v = \\frac{K}{2} \\]\n\n$ K_v $ è una misura della capacità del sistema di tracciare gli ingressi della rampa. Un $ K_v $ più elevato implica migliori prestazioni di tracciamento per tali input.\n\n\n\n\nPosizioni desiderate dei poli a circuito chiuso\n\nCalcolo della posizione dei poli per un dato rapporto di smorzamento\n\nPer un rapporto di smorzamento ($ $) di 0,45, i poli del circuito chiuso si trovano a $ -1 2j $.\nQuesto calcolo si basa sulla dinamica del sistema standard del secondo ordine in cui le posizioni dei poli sono determinate dal rapporto di smorzamento e dalla frequenza naturale.\nLa posizione di questi poli nel piano s influenza direttamente il comportamento transitorio del sistema, compresi aspetti come il superamento e il tempo di assestamento.\n\n\n\n\nValutazione delle prestazioni del sistema a $ K = 5 $\n\nDeterminare quando i poli desiderati sono realizzabili\n\n\n\n\n\n\n\nFigura: grafico del luogo delle radici che mostra come la variazione di $ K $ influisce sulle posizioni dei poli.\n\nEsaminando il grafico del luogo delle radici, possiamo identificare che i poli desiderati ad anello chiuso a $ -1 2j $ sono ottenibili quando il guadagno $ K $ è impostato su 5.\n\n\n\nPrecisione allo stato stazionario\n\nQuando $ K = 5 $, la costante dell’errore di velocità è:\n\\[ K_v = \\frac{K}{2} = \\frac{5}{2} = 2.5 \\]\nTuttavia, questo valore di $ K_v $ è inferiore ai 20 richiesti per prestazioni adeguate in condizioni stazionarie.\n\n\n\n\nL’obiettivo della compensazione del ritardo di fase\n\nAumentare $ K_v $ per soddisfare i requisiti di stato stazionario\n\nL’obiettivo principale dell’introduzione di un compensatore di ritardo di fase in questo scenario è aumentare $ K_v $ per soddisfare il requisito di stato stazionario di 20.\nCiò deve essere ottenuto garantendo che il diagramma del luogo delle radici compensato passi attraverso i poli desiderati a circuito chiuso a $ -1 2j $.\n\n\n\nBilanciamento delle prestazioni in stato stazionario e transitorio\n\nLa sfida sta nell’incrementare $ K_v $ senza influenzare negativamente le prestazioni transitorie, che sono indicate dalle posizioni dei poli a circuito chiuso.\n\n\n\n\nSoddisfare i requisiti transitori\nPer ottenere il risultato desiderato, posizioneremo sia lo zero che il polo del compensatore vicino all’origine. L’obiettivo qui è garantire che il loro contributo combinato all’angolo di fase del sistema sia minimo, idealmente entro un intervallo compreso tra 1 e 5 gradi. In questo modo, possiamo effettivamente garantire che questi elementi abbiano un impatto trascurabile sul grafico del luogo delle radici originale del sistema. Questo posizionamento strategico è fondamentale per mantenere le caratteristiche originali del sistema implementando al tempo stesso il compensatore di ritardo di fase.\n\n\nSoddisfa il requisito \\(K_v\\)\n\\[ D(s) G(s) = \\frac{K (s+z_c)}{s(s + 2)(s+p_c)} \\]\nE\n\\[\nK_v = \\frac{K z_c}{2p_c} = 20\n\\]\nciò significa che possiamo utilizzare il rapporto \\(\\frac{z_c}{p_c}\\) per migliorare la nostra costante di velocità.\nPiù specificamente, per \\(K=5\\) (notare che per lo stesso motivo per cui lo zero e il polo non disturbano il transitorio, non cambiano molto il valore del guadagno del luogo della radice, il boost di cui abbiamo bisogno è \\(\\frac {z_c}{p_c}=8\\).\nQuesto ci aiuta a definire la relazione tra lo zero e il polo del compensatore.\n\nPosizionamento del polo e dello zero\n\nPartiamo dal porre lo zero a \\(z_c = -0.1\\) (questo deriva dalla condizione di dominanza come vedremo tra poco).\nIl polo quindi si trova a: \\(p_c = \\frac{-0.1}{8}=0.0125\\)\n\nIl luogo delle radici è (questa non è una scala troppo grande per evidenziare le relazioni):\n\n\n\n\n\n\n\n\n\nCondizione di dominanza\nÈ possibile verificare che il terzo polo deve essere reale, e quindi molto vicino allo zero. Ciò significa che la condizione di dominanza è soddisfatta (anche se è vicina all’asse immaginario). Se il terzo polo non è abbastanza vicino, possiamo apportare una modifica alle posizioni zero/polo per spostarlo più vicino allo zero. Questo viene in genere fatto utilizzando un software.\n\n\nSimulazioni\nInfine attraverso la simulazione possiamo verificare la piena prestazione (transitoria e stazionaria) del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensators_and_root_locus_it.html#compensazione-del-ritardo",
    "href": "IT_🇮🇹/compensators_and_root_locus_it.html#compensazione-del-ritardo",
    "title": "Compensatori e luogo delle radici",
    "section": "Compensazione del ritardo",
    "text": "Compensazione del ritardo\nConcludendo la nostra discussione sui compensatori del sistema di controllo, consideriamo come scegliere tra diversi tipi di compensatori in base alle prestazioni del sistema non compensato. Qui per “non compensato” intendiamo un sistema in cui sono consentite solo regolazioni del guadagno.\n\nProcesso decisionale per il tipo di compensatore\n\nQuando scegliere un compensatore di ritardo:\n\nSe le prestazioni transitorie del sistema non compensato sono soddisfacenti, allora un compensatore di ritardo è una scelta adeguata.\nIl ruolo principale del compensatore di ritardo in questo caso è quello di migliorare le prestazioni allo stato stazionario senza influenzare in modo significativo la risposta transitoria.\n\nScelta di un compensatore principale:\n\nSe le prestazioni transitorie sono insoddisfacenti, la soluzione migliore è un compensatore di piombo.\nIl compensatore principale è progettato per migliorare le prestazioni transitorie. Dopo averlo implementato, dovresti rivalutarlo per vedere se i requisiti di stato stazionario sono soddisfatti.\n\n\n\n\nGestione delle prestazioni sia transitorie che stazionarie\n\nScenario: Cosa succede se, dopo aver progettato un compensatore di fase, le prestazioni transitorie non sono soddisfacenti e i requisiti di stato stazionario non sono soddisfatti?\nSoluzione: In questi casi, prendere in considerazione l’utilizzo di un compensatore di piombo ritardato. Ciò comporta innanzitutto la progettazione di un compensatore principale per gestire le prestazioni transitorie e quindi la valutazione delle prestazioni allo stato stazionario.\n\n\n\nLa procedura finale standard\n\nValutare il sistema a circuito aperto:\n\nStudiare attentamente il sistema a circuito aperto con regolazioni del guadagno per valutare le prestazioni transitorie.\n\nProcesso di progettazione:\n\nSe le prestazioni transitorie sono adeguate, optare per un compensatore di ritardo.\nSe le prestazioni transitorie sono inadeguate, progettare un compensatore principale per correggere il problema.\nDopo aver implementato il compensatore del cavo, controllare l’errore a regime. Se è soddisfacente, il tuo progetto è completo.\n\nIncorporando un compensatore di ritardo se necessario:\n\nSe le prestazioni in stato stazionario sono ancora carenti, considerare il sistema compensato in anticipo come “non compensato” ai fini della progettazione di un compensatore del ritardo di fase.\nIl compensatore di ritardo, in questo caso, non disturberà i miglioramenti transitori apportati dal compensatore di anticipo.\n\n\n\n\nScelte progettuali finali\n\nLa scelta progettuale finale può essere un anticipo, un ritardo o una combinazione di compensatori anticipo-ritardo, a seconda dei requisiti del sistema.\nSono state discusse le realizzazioni dell’amplificatore operazionale (Op-Amp) sia per i compensatori lead-lag che per quelli lag-lead, consentendo l’implementazione pratica e la regolazione dei parametri.\n\nConclusione: la progettazione e la selezione dei compensatori dipendono dai requisiti prestazionali sia transitori che stazionari del sistema. Il processo decisionale prevede un’attenta valutazione delle prestazioni attuali del sistema e degli obiettivi che si intendono raggiungere con la remunerazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Compensatori e luogo delle radici"
    ]
  },
  {
    "objectID": "IT_🇮🇹/control_system_components_it.html",
    "href": "IT_🇮🇹/control_system_components_it.html",
    "title": "Componenti del sistema di controllo",
    "section": "",
    "text": "I sistemi di controllo automatico sono onnipresenti in vari settori e applicazioni. Aiutano a mantenere le condizioni di output desiderate regolando di conseguenza l’input. Un aspetto fondamentale per comprendere questi sistemi è il concetto di sistemi analoghi e la comprensione dei componenti che compongono un sistema di controllo.\nNei sistemi di controllo automatico, l’intero processo può essere visualizzato come una sequenza di componenti interconnessi. Questa sequenza inizia con l’impianto, che è essenzialmente il sistema che intendiamo controllare. L’impianto è azionato da un attuatore e la potenza di questo attuatore è controllata dal controller, che è il cervello del nostro sistema. Il controller prende decisioni in base al feedback che riceve dai sensori che monitorano il sistema.\nI sistemi di controllo sono costituiti da vari componenti che lavorano insieme per ottenere l’output desiderato.\nNella nostra discussione, ci concentreremo principalmente sui sistemi meccanici, ma, come abbiamo visto, esistono anche altri sistemi come i sistemi termici o a base liquida.\n\n\n\n\n\n\nComponenti del Sistema di Controllo:\n\nImpianto: il sistema primario da controllare. Nelle nostre discussioni spesso si tratta di un sistema meccanico, ma può anche essere un sistema termico, un sistema liquido o qualsiasi altro sistema che richiede controllo.\nAttuatore: Dispositivo che aziona o controlla l’impianto. Per i sistemi meccanici, i motori sono attuatori comuni.\nController: il cervello del sistema. Decide come pilotare l’attuatore in base alla differenza tra l’uscita desiderata e l’uscita effettiva. Può trattarsi di un circuito amplificatore operazionale (Op-Amp) o anche di un computer digitale nei sistemi moderni.\nSensore: dispositivo che misura la resa effettiva dell’impianto. Spesso necessita di filtri antirumore per rimuovere il rumore ad alta frequenza e di amplificatori per aumentare i segnali a livelli utilizzabili.\n\nIl cervello del sistema di controllo, il controller, è spesso di natura elettrica. Oggi, la maggior parte dei controller sono circuiti Op-Amp (legacy) o computer digitali. In passato venivano utilizzati regolatori idraulici o pneumatici. La tendenza si sta spostando verso questi controller per la loro versatilità ed efficienza.\nIl tuo ruolo:\n\nProgettare filtri antirumore per garantire che il rumore ad alta frequenza proveniente dai sensori non interferisca con il sistema.\nAmplificare o condizionare le uscite dei sensori per renderle compatibili con i segnali di ingresso standard o per adattarle all’hardware del controller. Ad esempio, l’uscita del sensore può essere millivolt o milliamper e richiedere un’amplificazione per utilizzarli insieme ai livelli del segnale di ingresso e con il controller.\nProgettare il controller, che è la parte più critica del sistema.\n\nRendiamo lo schema più preciso:\n\n\n\n\n\n\nIl controller può rispondere al segnale di errore in vari modi. Un approccio consiste nell’amplificare l’errore, denominato controller proporzionale. Un altro metodo prevede l’utilizzo di controllori che producono un segnale basato sia sull’errore che sul suo integrale. Ciò si traduce in un segnale composto da due parti: una direttamente proporzionale all’errore e un’altra proporzionale all’errore accumulato nel tempo. Parliamo in questo caso di regolatori proporzionali e integrali.\nOltre a questi, c’è il controller proporzionale-derivativo (PD), che non solo risponde all’errore presente ma anche al tasso di variazione di questo errore. Considerando la derivata o la velocità con cui l’errore cambia, il controllore PD può anticipare gli errori futuri e agire in modo più reattivo, rendendolo particolarmente utile negli scenari in cui sono essenziali correzioni rapide.\nInfine c’è il controller Proporzionale-Integrale-Derivativo (PID), che combina tutte e tre le strategie. Considera l’errore attuale (proporzionale), l’accumulo di errori passati (integrale) e il tasso di variazione dell’errore (derivativo). Utilizzando tutti e tre i componenti, il controller PID offre un approccio completo alla correzione degli errori, garantendo precisione costante, risposta rapida e anticipazione di errori futuri. Ciò rende il controller PID una delle strategie di controllo più utilizzate in vari settori grazie alla sua adattabilità ed efficienza in diversi scenari di controllo.\n\nRegolatore proporzionale (P): \\[\nu(t) = K_p \\cdot e(t)\n\\]\n\nDove: - $ u(t) $ è l’uscita di controllo. - $ K_p $ è il guadagno proporzionale. - $ e(t) $ è il segnale di errore.\n\nRegolatore Proporzionale-Integrale (PI): \\[\nu(t) = K_p \\cdot e(t) + K_i \\int e(t) \\, dt\n\\]\n\nDove: - $ K_i $ è il guadagno integrale.\n\nRegolatore proporzionale-derivato (PD):\n\n\\[\nu(t) = K_p \\cdot e(t) + K_d \\frac{d e(t)}{dt}\n\\]\nDove: - $ K_d $ è il guadagno derivato.\n\nRegolatore proporzionale-integrale-derivativo (PID):\n\n\\[\nu(t) = K_p \\cdot e(t) + K_i \\int e(t) \\, dt + K_d \\frac{d e(t)}{dt}\n\\]\nIn queste equazioni: - $ e(t) $ rappresenta il segnale di errore, ovvero la differenza tra il setpoint e la variabile di processo (o l’uscita misurata). - I guadagni $ K_p $, $ K_i $ e $ K_d $ determinano rispettivamente la forza della risposta del controllore all’errore, il suo accumulo e il suo tasso di variazione. La regolazione di questi guadagni consente di ottimizzare le prestazioni del controller per adattarle ad applicazioni specifiche.\nQuesti possono essere facilmente implementati come controller analogici utilizzando amplificatori operazionali.\n\nController analogici\nGli amplificatori operazionali (Op-Amp) sono componenti cruciali nei sistemi di controllo. Possono fungere da amplificatori, integratori o differenziatori, a seconda della loro configurazione.\n\nRegolatore Proporzionale (P):\n\n\nCircuito:\n\n\n\n\n\n\nFunzione di trasferimento:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=-\\frac{R2}{R1}\n\\]\n\nNotare che con due circuiti in serie si può eliminare il segno meno.\n\n\nRegolatore proporzionale-integrale (PI):\n\n\nCircuito:\n\n\n\n\n\n\nFunzione di trasferimento:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=-\\frac{R_2+\\frac{1}{sC}}{R_1} = -\\frac{R_2}{R_1} - \\frac{1}{R_1C }\\frac{1}{s}\n\\]\nche possiamo scriverlo come:\n\\[\ne_0(t) = -\\frac{R_2}{R_1}e_i(t) - \\frac{1}{R_1C}\\int_{0}^{t}e_i(\\tau)d\\tau\n\\]\n\nControllore Proporzionale-Derivativo (PD):\n\n\nCircuito:\n\n\n\n\n\n\nFunzione di trasferimento:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=\\frac{\\frac{R_2}{R_1\\frac{1}{sC}}}{R_1+\\frac{1}{sC}}\n\\]\ne con semplici manipolazioni possiamo ottenere la struttura standard.\n\nRegolatore proporzionale-integrale-derivativo (PID):\n\n\nCircuito:\n\n\n\n\n\n\nFunzione di trasferimento:\n\n\\[\n\\frac{E_0(s)}{E_i(s)} = -\\frac{Z_2(s)}{Z_1(s)}\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Componenti del sistema di controllo"
    ]
  },
  {
    "objectID": "TCLab/fitting_step_test_data_to_empirical_models.html",
    "href": "TCLab/fitting_step_test_data_to_empirical_models.html",
    "title": "Fitting Step Test Data to Empirical Models",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\ndf.plot(grid=True)",
    "crumbs": [
      "TCLab",
      "Fitting Step Test Data to Empirical Models"
    ]
  },
  {
    "objectID": "TCLab/fitting_step_test_data_to_empirical_models.html#read-the-data-file",
    "href": "TCLab/fitting_step_test_data_to_empirical_models.html#read-the-data-file",
    "title": "Fitting Step Test Data to Empirical Models",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\ndf.plot(grid=True)",
    "crumbs": [
      "TCLab",
      "Fitting Step Test Data to Empirical Models"
    ]
  },
  {
    "objectID": "TCLab/fitting_step_test_data_to_empirical_models.html#parameter",
    "href": "TCLab/fitting_step_test_data_to_empirical_models.html#parameter",
    "title": "Fitting Step Test Data to Empirical Models",
    "section": "Parameter",
    "text": "Parameter\n\nFitting the Step Change Data to a First Order Model\nFor a first-order linear system initially at steady-state, the response to a step input change at \\(t=0\\) is given by\n\\[y(t) = y(0) + K(1 - e^{-t/\\tau}) \\Delta U\\]\nwhere \\(\\Delta U\\) is the magnitude of the step change. Converting to notation used for the temperature control lab where \\(y(t) = T_1(t)\\) and \\(\\Delta U = \\Delta Q_1\\)\n\\[T_1(t) = T_1(0) + K_1(1 - e^{-t/\\tau_1}) \\Delta Q_1\\]\nthe following cells provide initial estimates for the steady state gain \\(K_1\\) and time constant \\(\\tau_1\\).\n\n\nReading Saved Data\n\ndf[['Q1','T1','T2']].plot(grid=True)\n\n\n\n\n\n\n\n\n\n\nEstimating Gain and Time Constant\nIn the limit \\(t\\rightarrow\\infty\\) the first order model becomes\n\\[T_1(\\infty) = T_1(0) + K_1\\Delta Q_1\\]\nwhich provides an method for estimating \\(K_1\\)\n\\[K_1 = \\frac{T_1(\\infty) - T_1(0)}{\\Delta Q_1}\\]\nThese calculations are performed below where we use the first and last measurements of \\(T_1\\) as estimates of \\(T_1(0)\\) and \\(T_1(\\infty)\\), respectively.\n\nT1 = df['T1']\nQ1 = df['Q1']\n\nDeltaT1 = max(T1) - min(T1)\nDeltaQ1 = Q1.mean()\n\nK1 = DeltaT1/DeltaQ1\nprint(\"K1 is approximately\", K1)\n\nK1 is approximately 0.6968700000000001\n\n\n\n# find when the increase in T1 gets larger than 63.2% of the final increase\ni = (T1 - T1.min()) &gt; 0.632*(T1.max()-T1.min())\ntau1 = T1.index[i].min()\nprint(\"tau1 is approximately\", tau1, \"seconds\")\n\ntau1 is approximately 163.0 seconds\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nexp = np.exp\nt = df.index\n\nT1_est = T1.min() + K1*(1 - exp(-t/tau1))*DeltaQ1\n\nplt.figure(figsize=(10,5))\nax = plt.subplot(2,1,1)\ndf['T1'].plot(ax = ax, grid=True)\nplt.plot(t,T1_est)\nplt.title('Step Test Data Compared to Model')\n\nplt.subplot(2,1,2)\nplt.plot(t,T1_est-T1)\nplt.grid()\nplt.title('Residual Error')\n\nText(0.5, 1.0, 'Residual Error')\n\n\n\n\n\n\n\n\n\nA first order model captures certain features, and provides a reasonably good result as the system approaches a new steady-state. The problem, however, is that for control we need a good model during initial transient. This is where the first-order model breaks down and predicts a qualitatively different response from what we observe.",
    "crumbs": [
      "TCLab",
      "Fitting Step Test Data to Empirical Models"
    ]
  },
  {
    "objectID": "TCLab/fitting_step_test_data_to_empirical_models.html#first-order-plus-dead-time",
    "href": "TCLab/fitting_step_test_data_to_empirical_models.html#first-order-plus-dead-time",
    "title": "Fitting Step Test Data to Empirical Models",
    "section": "First Order plus Dead Time",
    "text": "First Order plus Dead Time\n\\[T_1(t) = T_1(0) + K (1-e^\\frac{t-\\theta}{\\tau}) Q_{step}\\]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\n\nT1 = df['T1']\nQ1 = df['Q1']\nt = df.index\n\nDeltaT1 = max(T1) - min(T1)\nDeltaQ1 = Q1.mean()\n\nK1 = DeltaT1/DeltaQ1\ni = (T1 - T1.min()) &gt; 0.632*(T1.max()-T1.min())\ntau1 = T1.index[i].min()\n\ndef fopdt(K=K1, tau=tau1, theta=0, T10=T1.min()):\n    def Q1(t):\n        return 0 if t &lt; 0 else DeltaQ1\n    Q1vec = np.vectorize(Q1)\n    T1_fopdt = T10 + K*(1-np.exp(-(t-theta)/tau))*Q1vec(t-theta)\n    plt.figure(figsize=(10,5))\n    plt.subplot(2,1,1)\n    plt.plot(t,T1_fopdt)\n    plt.plot(t,df['T1'])\n    plt.subplot(2,1,2)\n    plt.plot(t,T1_fopdt - T1)\n    plt.show()\n    \ninteract(fopdt,K=(0,1,.001),tau=(50,200,.5),theta=(0,50,.5),T10=(15,25,.1))\n\n\n\n\n&lt;function __main__.fopdt(K=0.6968700000000001, tau=163.0, theta=0, T10=20.9)&gt;",
    "crumbs": [
      "TCLab",
      "Fitting Step Test Data to Empirical Models"
    ]
  },
  {
    "objectID": "TCLab/fitting_step_test_data_to_empirical_models.html#second-order",
    "href": "TCLab/fitting_step_test_data_to_empirical_models.html#second-order",
    "title": "Fitting Step Test Data to Empirical Models",
    "section": "Second Order",
    "text": "Second Order\nSEMD Eqn. 5-48\n\\[T_1(t) = T_1(0) + K\\left(1 - \\frac{\\tau_1 e^{-t/\\tau_1} - \\tau_2 e^{-t/\\tau_2}}{\\tau_1 - \\tau_2}\\right)Q_1(t)\\]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\n\nT1 = df['T1']\nQ1 = df['Q1']\nt = df.index\n\nDeltaT1 = max(T1) - min(T1)\nDeltaQ1 = Q1.mean()\n\nK1 = DeltaT1/DeltaQ1\ni = (T1 - T1.min()) &gt; 0.632*(T1.max()-T1.min())\ntau1 = T1.index[i].min()\n\ndef secondorder(K=K1, tau1=tau1, tau2=40, T10=T1.min()):\n    def Qscalar(t):\n        return 0 if t &lt; 0 else DeltaQ1\n    Q = np.vectorize(Qscalar)\n    exp = np.exp\n    T = T10 + K*(1 - (tau1*exp(-t/tau1) - tau2*exp(-t/tau2))/(tau1-tau2))*Q(t)\n    plt.subplot(2,1,1)\n    plt.plot(t,T)\n    plt.plot(t,df['T1'])\n    plt.subplot(2,1,2)\n    plt.plot(t,T1 - T)\n    plt.show()\n    \ninteract(secondorder,K=(0,1,.001),tau1=(1,200,.1),tau2=(0,200,.1),T10=(15,25,.1))\n\n\n\n\n&lt;function __main__.secondorder(K=0.6968700000000001, tau1=163.0, tau2=40, T10=20.9)&gt;\n\n\n\nfrom scipy.optimize import least_squares\nimport numpy as np\nQmax = 50\n\ndef f(x):\n    K,tau1,tau2,T10 = x\n    t = df.index\n    exp = np.exp\n    Tpred = T10 + K*(1 - (tau1*exp(-t/tau1) - tau2*exp(-t/tau2))/(tau1-tau2))*Qmax\n    resid = df['T1'] - Tpred\n    return resid\n\nic = [0.86,40,130,20]\n\nr = least_squares(f,ic,bounds=(0,np.inf))\nr.x\n\narray([  0.69537389,  19.68872647, 141.40950924,  20.91093839])\n\n\nAnd the resulting transfer function is:\n\\[ G_1(s) = \\frac{0.70}{(20s + 1)(141s + 1)} \\]",
    "crumbs": [
      "TCLab",
      "Fitting Step Test Data to Empirical Models"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html",
    "href": "TCLab/tclab_exercises_report_template.html",
    "title": "TCLab Exercises Report Template",
    "section": "",
    "text": "This report presents the key findings and insights from the TCLab exercises as part of the “Principles of Automatic Controls” course. These exercises are designed to provide hands-on experience in control systems using the Temperature Control Lab (TCLab) kit.",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html#introduction",
    "href": "TCLab/tclab_exercises_report_template.html#introduction",
    "title": "TCLab Exercises Report Template",
    "section": "",
    "text": "This report presents the key findings and insights from the TCLab exercises as part of the “Principles of Automatic Controls” course. These exercises are designed to provide hands-on experience in control systems using the Temperature Control Lab (TCLab) kit.",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html#exercise-summaries",
    "href": "TCLab/tclab_exercises_report_template.html#exercise-summaries",
    "title": "TCLab Exercises Report Template",
    "section": "Exercise Summaries",
    "text": "Exercise Summaries\nThe following sections summarize each exercise, highlighting the main objectives, methods used, and conclusions drawn.\n\n[Exercise Title]\n\nExercise Link: [Link to the specific exercise on the course website]\nObjectives: [Briefly state the objectives of this exercise]\nMethods Used: [Describe the methods or approaches used in the exercise]\nKey Findings: [Summarize the key findings or results from the exercise]\nPersonal Insights: [Discuss any personal insights or learning outcomes from completing this exercise]\n\n\n\n[Next Exercise Title]\n\nExercise Link: [Link to the next exercise]\nObjectives: […]\nMethods Used: […]\nKey Findings: […]\nPersonal Insights: […]",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html#challenges-and-solutions",
    "href": "TCLab/tclab_exercises_report_template.html#challenges-and-solutions",
    "title": "TCLab Exercises Report Template",
    "section": "Challenges and Solutions",
    "text": "Challenges and Solutions\n[In this section, discuss any challenges encountered during the exercises and how you addressed them. This might include troubleshooting technical issues, conceptual difficulties, or application of theory to practice.]",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html#application-of-theory-to-practice",
    "href": "TCLab/tclab_exercises_report_template.html#application-of-theory-to-practice",
    "title": "TCLab Exercises Report Template",
    "section": "Application of Theory to Practice",
    "text": "Application of Theory to Practice\n[Discuss how these exercises helped bridge the gap between theoretical knowledge and practical application. Reflect on how this hands-on experience has enhanced your understanding of control systems.]",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/tclab_exercises_report_template.html#conclusion",
    "href": "TCLab/tclab_exercises_report_template.html#conclusion",
    "title": "TCLab Exercises Report Template",
    "section": "Conclusion",
    "text": "Conclusion\n[Conclude your report with a summary of your overall experience with the TCLab exercises, emphasizing the most significant learnings and how they relate to the broader context of the course.]",
    "crumbs": [
      "TCLab",
      "TCLab Exercises Report Template"
    ]
  },
  {
    "objectID": "TCLab/pid_control.html",
    "href": "TCLab/pid_control.html",
    "title": "PID Control",
    "section": "",
    "text": "!pip install slycot\n!pip install control\n\nCollecting slycot\nInstalling collected packages: slycot\nSuccessfully installed slycot-0.2.0\nCollecting control\n  Using cached control-0.7.0-py2.py3-none-any.whl\nRequirement already satisfied: numpy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: scipy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: matplotlib in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: six&gt;=1.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: python-dateutil&gt;=2.0 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pytz in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nInstalling collected packages: control\nSuccessfully installed control-0.7.0\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# control constants\nKc = 0.85\ntauI = 10000\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\n# model transfer functions\nGp = control.tf([0.31],[16,1])*control.tf([1],[135,1])\n\n\nt = np.linspace(0,1000)\ny,t = control.step(Gp,t)\nplt.plot(t,50*y + 22)\n\n\n\n\n\n\n\n\n\n# control constants\nKc = 2\ntauI = 60\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\nt = np.linspace(0,1000)\n\nH = Gp*Gc/(1+Gp*Gc)\ny,t = control.step(H,t)\nplt.plot(t,y)",
    "crumbs": [
      "TCLab",
      "PID Control"
    ]
  },
  {
    "objectID": "TCLab/pid_control.html#pid-simulation",
    "href": "TCLab/pid_control.html#pid-simulation",
    "title": "PID Control",
    "section": "",
    "text": "!pip install slycot\n!pip install control\n\nCollecting slycot\nInstalling collected packages: slycot\nSuccessfully installed slycot-0.2.0\nCollecting control\n  Using cached control-0.7.0-py2.py3-none-any.whl\nRequirement already satisfied: numpy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: scipy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: matplotlib in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: six&gt;=1.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: python-dateutil&gt;=2.0 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pytz in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nInstalling collected packages: control\nSuccessfully installed control-0.7.0\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# control constants\nKc = 0.85\ntauI = 10000\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\n# model transfer functions\nGp = control.tf([0.31],[16,1])*control.tf([1],[135,1])\n\n\nt = np.linspace(0,1000)\ny,t = control.step(Gp,t)\nplt.plot(t,50*y + 22)\n\n\n\n\n\n\n\n\n\n# control constants\nKc = 2\ntauI = 60\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\nt = np.linspace(0,1000)\n\nH = Gp*Gc/(1+Gp*Gc)\ny,t = control.step(H,t)\nplt.plot(t,y)",
    "crumbs": [
      "TCLab",
      "PID Control"
    ]
  },
  {
    "objectID": "TCLab/pid_control.html#pid-implementation",
    "href": "TCLab/pid_control.html#pid-implementation",
    "title": "PID Control",
    "section": "PID Implementation",
    "text": "PID Implementation\n\nReference Conditions\nOne of the implementation issues for PID control of the Temperature Control Lab is choice of reference conditions. One reason is that the linearization on which PID analysis is based is only valid in some ‘neighborhood’ of a nominal operating condition. But perhaps a more typical situation in most practical\n\nimport sys\nsys.path.append('..')\nfrom tclab import TCLab, clock, pid\n\n# ambient and reference values\nTamb = 20\nTref = 50\nuref = (Tref - Tamb)/0.85\n\n# control parameters\nb = 1              # setpoint weighting\nkp = 0.8          # proportional control gain\nki = kp/60\n\n# sampling period\ntf = 1200           # experiment length (sec.)\nh = 1               # sample time (sec.)\n\n# setpoint function\ndef Tset(t):\n    if t &lt;= 900:\n        return 50\n    else:\n        return 35\n\n\nbi = ki*h\n\nr = Tset(0) - Tref\ny = Tamb - Tref\n\nP = kp*(b*r - y)\nI = 0\n\nuref,P,I,r\n\n(35.294117647058826, 24.0, 0, 0)\n\n\n\n# device initialization\nwith TCLab() as a:\n    a.initplot(tf)\n    for t in clock(tf,h):\n        r = Tset(t) - Tref\n        y = a.T1 - Tref\n    \n        P = kp*(b*r - y)\n        v = P + I\n    \n        u = max(0,min(200,v + uref))\n        I += bi*(r-y)\n    \n        a.Q1 = u\n        a.updateplot()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "PID Control"
    ]
  },
  {
    "objectID": "TCLab/relay_control.html",
    "href": "TCLab/relay_control.html",
    "title": "Relay Control",
    "section": "",
    "text": "The following code implements relay control for temperature T1 on the Temperature Control Lab.\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    Q^{max} &\\text{if $T \\leq T_{setpoint}$}\\\\\n    0       & \\text{if $T \\geq T_{setpoint}$}\n    \\end{cases}\n\\end{align}\\]\nThis is simple to implement, in fact it is just one line of code in the following cell. Adjust Tsetpoint to a desired setpoint value, then run the cell.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 40\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    for t in clock(tfinal, tstep):\n        T1 = a.T1                             # measure temperature\n        Q1 = Qmax if a.T1 &lt; Tsetpoint else 0  # compute manipulated variable\n        a.Q1(Q1)                              # adjust power\n        h.update(t)                           # log results\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Relay Control"
    ]
  },
  {
    "objectID": "TCLab/relay_control.html#simple-relay-control",
    "href": "TCLab/relay_control.html#simple-relay-control",
    "title": "Relay Control",
    "section": "",
    "text": "The following code implements relay control for temperature T1 on the Temperature Control Lab.\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    Q^{max} &\\text{if $T \\leq T_{setpoint}$}\\\\\n    0       & \\text{if $T \\geq T_{setpoint}$}\n    \\end{cases}\n\\end{align}\\]\nThis is simple to implement, in fact it is just one line of code in the following cell. Adjust Tsetpoint to a desired setpoint value, then run the cell.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 40\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    for t in clock(tfinal, tstep):\n        T1 = a.T1                             # measure temperature\n        Q1 = Qmax if a.T1 &lt; Tsetpoint else 0  # compute manipulated variable\n        a.Q1(Q1)                              # adjust power\n        h.update(t)                           # log results\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Relay Control"
    ]
  },
  {
    "objectID": "TCLab/relay_control.html#relay-control-with-hysteresis",
    "href": "TCLab/relay_control.html#relay-control-with-hysteresis",
    "title": "Relay Control",
    "section": "Relay Control with Hysteresis",
    "text": "Relay Control with Hysteresis\nOne of the issues with simple relay control is the potential for ‘chattering’, which are situations where the manipulated variable (in this case heater power) rapid on-and-off switching. This can be caused by systems that are highly response to control inputs or where the sensor measurements carry significant noise.\nThe typical home thermostat used for furnace control incorporates a simple but highly effective solution to the chattering period. The idea is to intentially overshoot the setpoint. Then, after the control switches state, there will be at least a short period of time where no further control action should be necessary. The control algorithm can be written\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    0       & \\text{if $T \\geq T_{Setpoint} - \\frac{d}{2}$}\\\\\n    Q^{max} &\\text{if $T \\leq T_{Setpoint} + \\frac{d}{2}$}\\\\\n    Q(t-\\delta t) & \\mbox{otherwise}\n    \\end{cases}\n\\end{align}\\]\nwhere \\(d\\) is the tolerance or hysteresis. For home heating systems a typical value is in the range of 0.5 to 1 degree F. This image shows how hystersis was adjusted on a typical home thermostat in common usage in the late 20th century.\n\nThe furnance is turned on for temperatures below the range\n\\[\\begin{align}\nT_{Setpoint} - \\frac{d}{2} \\leq T \\leq T_{Setpoint} + \\frac{d}{2}\n\\end{align}\\]\nand is turned for temperatures above the range. Within the range, however, the furnance may be on or off depending on what happened at the last decision point.\nThe following code implements relay control with hystersis.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 50\nd = 0.5\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    Q1 = a.Q1()\n    for t in clock(tfinal, tstep):\n        T1 = a.T1\n        if T1 &lt;= Tsetpoint - d/2:\n            Q1 = Qmax\n        if T1 &gt;= Tsetpoint + d/2:\n            Q1 = 0\n        a.Q1(Q1)\n        h.update()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Relay Control"
    ]
  },
  {
    "objectID": "TCLab/relay_control.html#multivariable-on-off-control",
    "href": "TCLab/relay_control.html#multivariable-on-off-control",
    "title": "Relay Control",
    "section": "Multivariable On-Off Control",
    "text": "Multivariable On-Off Control\n\nfrom tclab import TCLab, clock, Historian\n\nTsetpoint1 = 45\nTsetpoint2 = 35\nQmax = 100\ntfinal = 480\nd = 0.5\n\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    Q1 = a.Q1()\n    Q2 = a.Q2()\n    for t in clock(tfinal):\n        T1 = a.T1\n        if T1 &lt;= Tsetpoint1 - d/2:\n            Q1 = Qmax\n        if T1 &gt;= Tsetpoint1 + d/2:\n            Q1 = 0\n        a.Q1(Q1)\n\n        T2 = a.T2\n        if T2 &lt;= Tsetpoint2 - d/2:\n            Q2 = Qmax\n        if T2 &gt;= Tsetpoint2 + d/2:\n            Q2 = 0\n        a.Q2(Q2)\n        h.update()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Relay Control"
    ]
  },
  {
    "objectID": "TCLab/relay_control.html#exercises",
    "href": "TCLab/relay_control.html#exercises",
    "title": "Relay Control",
    "section": "Exercises",
    "text": "Exercises\n\nExamining the closed-loop responses, it’s obvious that the heater is oversized for the purpose of control at 40 deg C. Try other values for \\(Q^{\\max}\\) to see if you can improve closed-loop performance.\nWhat is the effect of sample time on control performance? What happens if you make the controller sample time longer?\nIn a new cell, create a modification of the script to include a change in setpoint from 40 deg C to 50 deg C at the 300 second mark. Run the experiment for at least 10 minutes to see the full effect.\nFor a relay control with hystersis, try to sketch a graph of \\(Q\\) as a function of \\(T\\) assuming \\(T_{Setpoint} = 50\\) and \\(h = 3\\). Can you draw a unique function? Why not?",
    "crumbs": [
      "TCLab",
      "Relay Control"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "",
    "text": "From https://github.com/jckantor/CBE30338\nand this one more specifically: https://github.com/jckantor/cbe30338-book/blob/main/notebooks/03.04-Relay-Control.ipynb\nThe purpose of this first laboratory session is to verify that you can interface and interact with the TCLab hardware, and familiarize you with the TCLab library. The first exercise will be to code a rudimentary relay (also called ‘on-off’ or thermostat) controller for one of the two heaters.\nBefore you begin, you should be familiar with the following reading meterials:",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-1.-download-and-install-tclab.py",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-1.-download-and-install-tclab.py",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 1. Download and install TCLab.py",
    "text": "Exercise 1. Download and install TCLab.py\nExecute the following cell to download and install the TCLab.py python library.\n\n!pip install tclab --upgrade",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-2.-verify-that-your-hardware-and-software-are-working-correctly.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-2.-verify-that-your-hardware-and-software-are-working-correctly.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 2. Verify that your hardware and software are working correctly.",
    "text": "Exercise 2. Verify that your hardware and software are working correctly.\nThe following cell should cause the LED on the TCLab shield to light up to 100% maximum brightness.\n\nfrom tclab import TCLab\n\nwith TCLab() as lab:\n    lab.LED(0)\n\nTCLab version 1.0.0\nArduino Leonardo connected on port /dev/cu.usbmodem142101 at 115200 baud.\nTCLab Firmware 3.0.0 Arduino Leonardo/Micro.\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-3.-turn-on-the-heaters-for-120-seconds-and-log-temperature-response.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-3.-turn-on-the-heaters-for-120-seconds-and-log-temperature-response.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 3. Turn on the heaters for 120 seconds and log temperature response.",
    "text": "Exercise 3. Turn on the heaters for 120 seconds and log temperature response.\nFor this exercise, write a code cell that turns on heater 1 at 100% power, then log the temperature response once per second for 120 seconds. The output of the cell should report the time, power level, and temperature for each measurement. You may wish to consult 01_Understanding_TCLab notebook for relevant code examples. You will need the clock function from tclab for this exercise.\n\nfrom tclab import TCLab, clock, Historian, Plotter, setup\n# TCLab = setup(connected=False, speedup=20)\n\n# control parameters\nU_min = 0\nU_max = 100\nT_SP = 40\n\n# time horizon and time step\nt_final = 250\nt_step = 1\n\n# perform experiment\nwith TCLab() as lab:\n    lab.P1 = 200\n    h = Historian(lab.sources)\n    p = Plotter(h, t_final)\n    for t in clock(t_final, t_step):\n        T1 = lab.T1                             # measure temperature\n        if lab.T1 &lt; T_SP:\n            U1 = U_max\n        else\n            U1 = U_min\n#         U1 = U_max if lab.T1 &lt; T_SP else U_min  # compute manipulated variable\n        lab.Q1(U1)                              # adjust power\n        p.update(t)                             # log results\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-4.-code-an-on-off-controller.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-4.-code-an-on-off-controller.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 4. Code an on-off controller.",
    "text": "Exercise 4. Code an on-off controller.\nCode an on-off controller for a setpoint of 40 degrees C using heater 1 as the manipulated variable, and temperature 1 as the measured variable. Operate the controller for at least 5 minutes (600 seconds), reporting time/power/temperature measurements every 2 seconds.\n\nfrom tclab import TCLab, clock, Historian, Plotter, setup\n\nTCLab = setup(connected=False, speedup=20)\n\n# control parameters\nU_min = 0\nU_max = 100\nT_SP = 40\n\n# time horizon and time step\nt_final = 250\nt_step = 1\n\n# perform experiment\nwith TCLab() as lab:\n    lab.P1 = 200\n    h = Historian(lab.sources)\n    p = Plotter(h, t_final)\n    for t in clock(t_final, t_step):\n        T1 = lab.T1                             # measure temperature\n        U1 = U_max if lab.T1 &lt; T_SP else U_min  # compute manipulated variable\n        lab.Q1(U1)                              # adjust power\n        p.update(t)                             # log results",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-5.-analysis",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller-solution.html#exercise-5.-analysis",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 5. Analysis",
    "text": "Exercise 5. Analysis\nExamine the results of the previous exercise and answer the following questions.\n\nApproximately how much time elapses between power on and power off events?\nWhat is the approximate duty cycle (i.e, fraction of time the heater is in the ‘on’ state) once the initial start-up period has passed.\nWhat is the size of the oscillation around the setpoint? Why does this occur?",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pid-control.html",
    "href": "TCLab/lab-assignment-pid-control.html",
    "title": "Lab Assignment: PID Control",
    "section": "",
    "text": "The first step is attempt completely manual control of the dual heaters. Using the GUI interface below, connect to the temperature control lab, and adjust heaters Q1 and Q2 to acheive steady state temperatures of 50°C for T1 and 40°C for T2.\nHint: The there is interaction between the heaters, i.e, an adjustment in either Q1 or Q2 will affect both T1 and T2. So this is exercise in satisfying two constraints by manipulating two variables.\n\nfrom tclab.gui import NotebookUI\n\ninterface = NotebookUI()\n\n\ninterface.gui",
    "crumbs": [
      "TCLab",
      "Lab Assignment: PID Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pid-control.html#part-1.-manual-control",
    "href": "TCLab/lab-assignment-pid-control.html#part-1.-manual-control",
    "title": "Lab Assignment: PID Control",
    "section": "",
    "text": "The first step is attempt completely manual control of the dual heaters. Using the GUI interface below, connect to the temperature control lab, and adjust heaters Q1 and Q2 to acheive steady state temperatures of 50°C for T1 and 40°C for T2.\nHint: The there is interaction between the heaters, i.e, an adjustment in either Q1 or Q2 will affect both T1 and T2. So this is exercise in satisfying two constraints by manipulating two variables.\n\nfrom tclab.gui import NotebookUI\n\ninterface = NotebookUI()\n\n\ninterface.gui",
    "crumbs": [
      "TCLab",
      "Lab Assignment: PID Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pid-control.html#part-2.-implementing-a-pid-controller",
    "href": "TCLab/lab-assignment-pid-control.html#part-2.-implementing-a-pid-controller",
    "title": "Lab Assignment: PID Control",
    "section": "Part 2. Implementing a PID Controller",
    "text": "Part 2. Implementing a PID Controller\nGiven a process variable \\(PV\\) and setpoint \\(SP\\), proportional-integral-derivative control determines the value of a manipulated variable MV by the rule\n\\[\\begin{align}\nMV & = \\bar{MV} + K_p\\left(SP - PV\\right) + K_i \\int_0^t \\left(SP-PV)\\right)dt + K_d \\frac{d\\left(SP-PV\\right)}{dt}\n\\end{align}\\]\nwhere \\(K_p\\), \\(K_i\\), and \\(K_d\\) are the proportional, integral, and derivative coefficients, respectively.\nThe following code defines a Python object that implements this algorithm.\n\nclass PID:\n    def __init__(self):\n        self.Kp = 1\n        self.Ki = 100\n        self.Kd = 0\n\n        self.e = 0\n        self.dedt = 0\n        self.eint = 0\n        self.mv = 0\n\n    def update(self, setpoint, pv):\n        e = setpoint - pv\n        self.dedt = self.e - e\n        self.eint += e\n        self.e = e\n\n        self.mv = self.Kp * self.e + self.Ki * self.eint + self.Kd * self.dedt\n        return self.mv\n\nThe following cell provides an initial implementation of PID control for heater T1. Modify this code to add a second controller, pid2, for heater T2. Test using the off-line simulator. When happy with the results, apply the control to the actual heater.\n\nfrom tclab import setup, clock, Historian, Plotter\n\nTCLab = setup(connected=False, speedup = 20)\n\npid1 = PID()\npid1.Kp = 2\npid1.Ki = .1\npid1.Kd = 2\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 800)\n    for t in clock(800):\n        lab.U1 = pid1.update(50, lab.T1)\n        p.update(t)\n\nSimulated TCLab\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Lab Assignment: PID Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pid-control.html#part-3.-tuning-the-pid-controller",
    "href": "TCLab/lab-assignment-pid-control.html#part-3.-tuning-the-pid-controller",
    "title": "Lab Assignment: PID Control",
    "section": "Part 3. Tuning the PID Controller",
    "text": "Part 3. Tuning the PID Controller\nUsing the code you developed above, create a new cell below and test the following issues:\n\nWhat happens when Ki = 0?\nWhat happens when Ki = 0.1 and Kd = 3?\n\nDescribe the benefits of integral and derivative action.",
    "crumbs": [
      "TCLab",
      "Lab Assignment: PID Control"
    ]
  },
  {
    "objectID": "TCLab/step_testing_tclab.html",
    "href": "TCLab/step_testing_tclab.html",
    "title": "Step Testing",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom tclab import TCLab, clock, Historian, Plotter\nRun the next cell if you only want to simulate TCLab\nfrom tclab import setup\nTCLab = setup(connected=False, speedup=20)",
    "crumbs": [
      "TCLab",
      "Step Testing"
    ]
  },
  {
    "objectID": "TCLab/step_testing_tclab.html#executing-the-step-test",
    "href": "TCLab/step_testing_tclab.html#executing-the-step-test",
    "title": "Step Testing",
    "section": "Executing the Step Test",
    "text": "Executing the Step Test\n\nVerify an Initial Steady State\nA step test assumes the system is initially at steady state. In the case of the Temperature Control Lab, the initial steady with no power input would be room temperature. It generally takes 10 minutes or more to reach steady state. We’ll do a measurement to confirm the initial temperature.\n\nlab = TCLab()\nprint(lab.T1, lab.T1)\nlab.close()\n\nTCLab version 1.0.0\nSimulated TCLab\n20.949499999999997 20.949499999999997\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Step Testing"
    ]
  },
  {
    "objectID": "TCLab/step_testing_tclab.html#conduct-the-experiment",
    "href": "TCLab/step_testing_tclab.html#conduct-the-experiment",
    "title": "Step Testing",
    "section": "Conduct the Experiment",
    "text": "Conduct the Experiment\n\n# experimental parameters\nQ1 = 50\ntfinal = 800\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    lab.Q1(0)\n    for t in clock(tfinal):\n        p.update(t)\n        lab.Q1(Q1)\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Step Testing"
    ]
  },
  {
    "objectID": "TCLab/step_testing_tclab.html#verify-the-experimental-data",
    "href": "TCLab/step_testing_tclab.html#verify-the-experimental-data",
    "title": "Step Testing",
    "section": "Verify the experimental data",
    "text": "Verify the experimental data\n\nh.columns\n\n['Time', 'T1', 'T2', 'Q1', 'Q2']\n\n\n\ntry:\n    t = h.t\n    T1 = h.T1\n    T2 = h.T2\n    Q1 = h.Q1\n    Q2 = h.Q2\nexcept:\n    t, T1, T2, Q1, Q2 = h.fields\n    \nplt.plot(t, T1, t, T2, t, Q1, t, Q2)\nplt.legend(['T1','T2','Q1','Q2'])\nplt.xlabel('time / seconds')\nplt.grid()\n\n\n\n\n\n\n\n\n\nConvert to a DataFrame\n\nimport pandas as pd\n\ndf = pd.DataFrame([t, T1, T2, Q1]).T\ndf.columns = ['Time', 'T1', 'T2', 'Q1']\ndf = df.set_index('Time')\ndf.plot(grid=True)\n\n\n\n\n\n\n\n\n\n\nSave DataFrame as a .csv file\n\ndf.to_csv('Step_Test_Data.csv')\n\n\n\nVerify the data file\n\npd.read_csv('Step_Test_Data.csv').set_index('Time').plot(grid=True)\n\n\n\n\n\n\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nT1\nT2\nQ1\n\n\nTime\n\n\n\n\n\n\n\n0.00\n20.6272\n20.6272\n0.0\n\n\n9.00\n20.9495\n20.9495\n50.0\n\n\n10.00\n20.9495\n20.9495\n50.0\n\n\n12.01\n20.9495\n20.9495\n50.0\n\n\n13.00\n20.9495\n20.9495\n50.0\n\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nT1\nT2\nQ1\n\n\nTime\n\n\n\n\n\n\n\n795.01\n50.6011\n25.784\n50.0\n\n\n796.00\n50.6011\n25.784\n50.0\n\n\n798.01\n50.6011\n25.784\n50.0\n\n\n799.01\n50.6011\n25.784\n50.0\n\n\n800.01\n50.6011\n25.784\n50.0",
    "crumbs": [
      "TCLab",
      "Step Testing"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html",
    "href": "TCLab/spacecraft_thermal_control_systems.html",
    "title": "The Temperature Control Laboratory",
    "section": "",
    "text": "This Jupyter notebook aims to provide a detailed exploration of the Temperature Control Lab (TCLab) as a practical tool for understanding control engineering concepts.\nThe Temperature Control Laboratory provides a hands-on learning environment for traditional courses in process control. The Arduino-based device consists of a two-input, two-output system of heaters and sensors.\nThis part of the coure aims to bridge the gap between theory and practical application, a challenge many engineers face when transitioning from academic training to real-world problem-solving.\nApplying theoretical knowledge to practical applications is not straightforward. This notebook will address these challenges, focusing on the iterative nature of engineering problem-solving and the importance of understanding there is often more than one right answer to a problem.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#spacecraft-thermal-control-systems",
    "href": "TCLab/spacecraft_thermal_control_systems.html#spacecraft-thermal-control-systems",
    "title": "The Temperature Control Laboratory",
    "section": "Spacecraft Thermal Control Systems",
    "text": "Spacecraft Thermal Control Systems\nWe are tasked with developing a thermal control system for an earth-orbiting satellite. This system must maintain the internal components, particularly the batteries, within a specific temperature range despite the harsh and variable conditions of space.\n\n\n\n\n\n\n\n\nFigure: Rosetta Thermal Control\nNice overview of the problem available at the NASA’s webpage State-of-the-Art of Small Spacecraft Technology",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#introduction-to-thermal-control-in-space",
    "href": "TCLab/spacecraft_thermal_control_systems.html#introduction-to-thermal-control-in-space",
    "title": "The Temperature Control Laboratory",
    "section": "Introduction to Thermal Control in Space",
    "text": "Introduction to Thermal Control in Space\nControlling the level of temperature of equipment, payloads, satellites, and launchers is a critical aspect in all phases of a space mission. This chapter describes some of the intricacies of thermal control in space, emphasizing its importance for the protection of flight hardware and the success of the mission.\n\nThe Concept of Thermal Control\nThermal control in space refers to the technology and methods used to maintain a spacecraft’s temperatures within specific parameters throughout its lifetime. This encompasses a broad range of temperatures, from cryogenic levels (down to -270°C) to high-temperature thermal protection systems (more than 2000°C).\n\nImportance of Temperature Management\n\nEquipment Safety: Overheating can damage or severely affect the performance of onboard equipment. In space, rectifying such issues is nearly impossible, highlighting the need for efficient and reliable thermal control systems.\nPerformance Optimization: For sensitive components like electronics or optical instruments, maintaining specified temperature stability is crucial for optimal functioning.\n\n\n\n\nVisual Aspects of Thermal Control\nThe thermal control subsystem is one of the most visually distinctive elements of a spacecraft. It often includes: - Insulation Blankets: These are foil-like materials, known as Multi-Layered Insulation (MLI) blankets, used to block a significant portion of solar heat flux. - Radiators: These are white-painted or mirror-like surfaces used to reject heat from the satellite to space, which is extremely cold (around -270°C).",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#why-is-thermal-control-important",
    "href": "TCLab/spacecraft_thermal_control_systems.html#why-is-thermal-control-important",
    "title": "The Temperature Control Laboratory",
    "section": "Why is Thermal Control Important?",
    "text": "Why is Thermal Control Important?\nThermal control is crucial for both the structural integrity and efficient operation of a satellite.\n\nFactors Affecting Satellite’s Temperature\n\nExternal Heat Sources: These include solar, albedo (reflected sunlight), and planet heat fluxes.\nInternal Heat Production: Heat generated by electronic equipment and other onboard systems.\nHeat Rejection: The process of dissipating heat into the cold expanse of space.\n\n\nImpacts of Temperature Variations\n\nOptimal Performance Range: Electronic equipment usually operates efficiently within a specific temperature range.\nInstrument Sensitivity: Some payloads, like infrared detectors, require extremely low temperatures.\nLifetime Reduction: High temperatures can significantly shorten the lifespan of various components.\nStructural Integrity: Large temperature differences can cause thermal expansion or contraction, potentially distorting the satellite’s structure.\n\n\n\n\nBalancing Heat in Spacecraft\nThe level of a spacecraft’s temperature is a balance between the heat it receives and the heat it rejects. Key elements in this balance include:\n\nMulti-Layered Insulation Blankets (MLIs): These insulation devices help block a substantial portion of the sun’s heat flux.\nRadiators: These components facilitate the rejection of heat to the cold vacuum of space.\n\n\n\nThermal Control System Objectives\nThe primary objectives of the thermal control subsystem are:\n\nMaintaining Overall Temperature: Ensuring that the spacecraft’s temperature remains within acceptable limits.\nTemperature Distribution Management: Achieving an optimal temperature distribution within the satellite to cater to different mission phases (launch, transfer orbit, operation in orbit).\n\n\n\nFurther Reading\n\n“Spacecraft Thermal Control” by José Meseguer, Isabel Pérez-Grande and Angel Sanz-Andrés: A comprehensive guide to the principles and practices of spacecraft thermal control.\n“Spacecraft Thermal Control Handbook” by David G. Gilmore: An in-depth exploration of various thermal control technologies and their applications in space missions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource Let’s talk science",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#understanding-the-problem",
    "href": "TCLab/spacecraft_thermal_control_systems.html#understanding-the-problem",
    "title": "The Temperature Control Laboratory",
    "section": "Understanding the Problem",
    "text": "Understanding the Problem\nThe key challenge is to maintain the battery temperature within operational limits (approximately 0 to 20 degrees Celsius) despite the average internal temperature being around -5 degrees Celsius. This implies a need for a heating mechanism rather than cooling.\nThe proper functioning of satellite batteries is critical to the mission’s success. Temperatures outside the operational range can lead to failure, risking the entire mission.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#exploring-solutions",
    "href": "TCLab/spacecraft_thermal_control_systems.html#exploring-solutions",
    "title": "The Temperature Control Laboratory",
    "section": "Exploring Solutions",
    "text": "Exploring Solutions\nSeveral solutions are considered, including passive thermal control and the use of thermal straps. However, the decision has been made to use a dedicated strip heater, offering more control and robustness, especially given the power availability.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#what-is-tclab",
    "href": "TCLab/spacecraft_thermal_control_systems.html#what-is-tclab",
    "title": "The Temperature Control Laboratory",
    "section": "1.1 What is TCLab?",
    "text": "1.1 What is TCLab?\n\nDescription: TCLab is a compact laboratory setup that includes an Arduino microcontroller, heaters, temperature sensors, and an LED. It is designed for learning and applying control engineering principles in a hands-on manner.\nComponents:\n\nArduino Microcontroller: Acts as the brain of the setup.\nHeaters: Provide thermal energy to the system.\nTemperature Sensors: Measure the system’s temperature.\nLED: Visual indicator for certain actions or states.\n\nPurpose: To understand and apply feedback control principles in a tangible setup.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#understanding-the-tclab-kit",
    "href": "TCLab/spacecraft_thermal_control_systems.html#understanding-the-tclab-kit",
    "title": "The Temperature Control Laboratory",
    "section": "Understanding the TCLab Kit",
    "text": "Understanding the TCLab Kit\n\nThe Core Components of TCLab\nThe Temperature Control Lab (TCLab) is an integrated system composed of several key components, each contributing significantly to its functionality:\n\nArduino Microcontroller:\n\nPurpose: Serves as the central processing unit for the TCLab.\nFunctionality: Processes input data from temperature sensors and manages the operation of heaters.\nConnectivity: Utilizes a USB connection for data transfer and allows for real-time control through Python scripts.\n\nHeaters:\n\nDescription: TCLab features two heaters, each capable of generating adjustable thermal energy.\nRole: Act as the main heat sources for experiments, replicating scenarios requiring temperature regulation. They function as the system’s actuators.\n\nTemperature Sensors:\n\nType: These sensors are thermistors, a kind of resistor whose resistance varies with temperature changes.\nMeasurement Range: Capable of measuring temperatures ranging from \\(-40^\\circ\\)C to \\(150^\\circ\\)C.\nFunctionality: Positioned near each heater to accurately measure temperature, providing essential feedback for temperature control.\n\nHeat Sinks:\n\nType: Comprised of transistor heat sinks.\nPurpose: Employed to efficiently dissipate heat away from the transistors.\n\nLED (Light Emitting Diode):\n\n\nPurpose: Serves as a visual indicator for various states or actions, such as signaling the activation of a heater.\n\n\n\nOperational Configurations of TCLab\nTCLab can be configured in various modes depending on the educational objectives:\n\nSingle Input Single Output (SISO):\n\nUtilizes only one heater and one sensor. Ideal for simple control experiments and learning the basics of temperature control.\n\nSingle Input Single Output (SISO) with Disturbance:\n\nEmploys one heater/sensor as the primary control system and the second heater as a source of external disturbance. This setup is useful for understanding how external factors influence control systems.\n\nMultiple Inputs Multiple Outputs (MIMO):\n\nInvolves using both heaters and sensors simultaneously. This more advanced configuration isn’t covered here but is valuable for complex control system studies.\n\n\nEach component of the TCLab plays a specific role, making it a versatile tool for teaching and experimenting with various aspects of control engineering. Whether for fundamental learning or advanced exploration, TCLab offers a practical platform for understanding the dynamics and control of temperature-based systems.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#how-tclab-works",
    "href": "TCLab/spacecraft_thermal_control_systems.html#how-tclab-works",
    "title": "The Temperature Control Laboratory",
    "section": "How TCLab Works",
    "text": "How TCLab Works\n\nOperation Flow:\n\nInput Signal: A Python script sends a command to the Arduino, setting the desired power level for the heaters.\nHeating Action: The heaters generate heat corresponding to the received power level commands.\nTemperature Measurement: The thermistors measure the resulting temperatures near the heaters.\nFeedback Loop: These temperature readings are sent back to the computer.\nAdjustments: The control algorithm in the Python script adjusts the heater power based on the temperature feedback, striving to reach and maintain a target temperature.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#arduino-microcontroller",
    "href": "TCLab/spacecraft_thermal_control_systems.html#arduino-microcontroller",
    "title": "The Temperature Control Laboratory",
    "section": "2.1 Arduino Microcontroller",
    "text": "2.1 Arduino Microcontroller\n\nDetailed Description: Provide specifics about the Arduino model used in TCLab, its capabilities, and its limitations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjectives:\n\nDynamic modeling with balance equations\nThe difference between manual and automatic control\nStep tests to generate dynamic data\nFitting dynamic data to a First Order Plus Dead Time (FOPDT) model\nObtaining parameters for PID control from standard tuning rules\nTuning the PID controller to improve performance",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#section-1-installing-python-using-conda",
    "href": "TCLab/spacecraft_thermal_control_systems.html#section-1-installing-python-using-conda",
    "title": "The Temperature Control Laboratory",
    "section": "Section 1: Installing Python Using Conda",
    "text": "Section 1: Installing Python Using Conda",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-mac",
    "href": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-mac",
    "title": "The Temperature Control Laboratory",
    "section": "Installing Python on Mac",
    "text": "Installing Python on Mac\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Mac.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Terminal.\nType conda --version and press Enter. If Anaconda is successfully installed, you’ll see the version number.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-windows",
    "href": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-windows",
    "title": "The Temperature Control Laboratory",
    "section": "Installing Python on Windows",
    "text": "Installing Python on Windows\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Windows.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Anaconda Prompt.\nType conda --version and press Enter.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Anaconda Prompt, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-linux",
    "href": "TCLab/spacecraft_thermal_control_systems.html#installing-python-on-linux",
    "title": "The Temperature Control Laboratory",
    "section": "1.3 Installing Python on Linux",
    "text": "1.3 Installing Python on Linux\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Linux.\nRun Installer: Open Terminal, navigate to the directory containing the downloaded file, and run the script using bash Anaconda3-XXXX.sh.\nVerify Installation:\n\nIn Terminal, type conda --version.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#setting-up-the-conda-environment",
    "href": "TCLab/spacecraft_thermal_control_systems.html#setting-up-the-conda-environment",
    "title": "The Temperature Control Laboratory",
    "section": "Setting Up the Conda Environment",
    "text": "Setting Up the Conda Environment\nTo set up the Conda environment for this course, follow these steps:\n\nDownload the tclab_environment.yml file from this repository.\nOpen your terminal or Anaconda Prompt and navigate to the directory where the file is located.\n\nThe file tclab_environment.yml looks like this:\nname: tclab_env\nchannels:\n  - defaults\ndependencies:\n  - python=3.10\n  - pip\n  - numpy\n  - matplotlib\n  - scipy\n  - pandas\n  - pip:\n    - tclab\n\nCreate the environment from the tclab_environment.yml file:\nconda env create -f tclab_environment.yml\nActivate the new environment:\nconda activate tclab\nTo verify that the environment was installed correctly, you can use:\nconda env list\n\n\nInstalling the TCLab Package\n\nActivating the Environment:\n\nEnsure your Anaconda environment is active. Open your Terminal (or Anaconda Prompt on Windows) and activate your environment:\nconda activate tclab_env\n\nInstalling TCLab:\n\nThe tclab library is pivotal for interfacing with the Temperature Control Lab hardware. Install it by entering the following command:\npip install tclab\nPress Enter to execute the command and complete the installation.\n\n\n\nInstalling Additional Useful Libraries\nFor a comprehensive experience with TCLab and to support various aspects of control engineering and data analysis, the following libraries will also be installed:\n\nnumpy:\n\nSignificance: A fundamental library for numerical computations in Python.\nInstallation Command:\npip install numpy\n\nmatplotlib:\n\nSignificance: Crucial for creating visual representations of data, especially for the analysis of TCLab experiments.\nInstallation Command:\npip install matplotlib\n\nscipy:\n\nSignificance: Provides a broad range of tools for scientific computing, including methods for solving ordinary differential equations, useful in system modeling.\nInstallation Command:\npip install scipy\n\npandas:\n\nSignificance: Offers extensive features for data manipulation and analysis, ideal for handling complex datasets.\nInstallation Command:\npip install pandas\n\ngekko:\n\nSignificance: Advanced package for optimization and control, suitable for implementing model predictive control strategies.\nInstallation Command:\npip install gekko",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#tclab-schematics",
    "href": "TCLab/spacecraft_thermal_control_systems.html#tclab-schematics",
    "title": "The Temperature Control Laboratory",
    "section": "TCLab Schematics",
    "text": "TCLab Schematics",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#initial-tests-with-tclab",
    "href": "TCLab/spacecraft_thermal_control_systems.html#initial-tests-with-tclab",
    "title": "The Temperature Control Laboratory",
    "section": "Initial Tests with TCLab",
    "text": "Initial Tests with TCLab\n\nStep 1: Connect TCLab\n\nConnect TCLab: Plug in the TCLab device to your computer using a USB cable.\n\n\n\nStep 2: Test TCLab Connection\n\nWrite Test Script:\n\nOpen your Python IDE or Jupyter Notebook.\nWrite the following Python code and run the script. If it prints the temperature, TCLab is connected properly.\n\n\n\nimport tclab\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")\n\nTCLab version 1.0.0\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\n\n\nRuntimeError: No Arduino device found.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "TCLab/spacecraft_thermal_control_systems.html#using-tclab-simulator",
    "href": "TCLab/spacecraft_thermal_control_systems.html#using-tclab-simulator",
    "title": "The Temperature Control Laboratory",
    "section": "Using TCLab Simulator",
    "text": "Using TCLab Simulator\n\nWhy Use a Simulator: The TCLab simulator is useful when you don’t have the physical hardware available.\nInstall Simulator: In Terminal or Anaconda Prompt, type pip install tclab again (it includes the simulator).\nTest Script with Simulator:\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.04 seconds. T1: 20.949499999999997°C\nTime 6.03 seconds. T1: 20.949499999999997°C\nTime 8.06 seconds. T1: 20.949499999999997°C\nTime 10.07 seconds. T1: 20.949499999999997°C\nTime 12.02 seconds. T1: 20.949499999999997°C\nTime 14.03 seconds. T1: 20.949499999999997°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.04 seconds. T1: 20.949499999999997°C\nTime 20.2 seconds. T1: 20.949499999999997°C\nTime 22.01 seconds. T1: 20.949499999999997°C\nTime 24.19 seconds. T1: 20.949499999999997°C\nTime 26.24 seconds. T1: 20.949499999999997°C\nTime 28.16 seconds. T1: 20.949499999999997°C\nTime 30.03 seconds. T1: 20.949499999999997°C\nTime 32.12 seconds. T1: 20.949499999999997°C\nTime 34.2 seconds. T1: 20.6272°C\nTime 36.04 seconds. T1: 20.949499999999997°C\nTime 38.02 seconds. T1: 20.6272°C\nTime 40.21 seconds. T1: 20.949499999999997°C\nTime 42.14 seconds. T1: 20.949499999999997°C\nTime 44.01 seconds. T1: 20.6272°C\nTime 46.3 seconds. T1: 20.949499999999997°C\nTime 48.22 seconds. T1: 20.949499999999997°C\nTime 50.07 seconds. T1: 20.949499999999997°C\nTime 52.27 seconds. T1: 20.949499999999997°C\nTime 54.09 seconds. T1: 20.949499999999997°C\nTime 56.28 seconds. T1: 20.949499999999997°C\nTime 58.19 seconds. T1: 20.949499999999997°C\nTime 60.04 seconds. T1: 20.949499999999997°C\nTime 62.2 seconds. T1: 20.949499999999997°C\nTime 64.11 seconds. T1: 20.949499999999997°C\nTime 66.08 seconds. T1: 20.949499999999997°C\nTime 68.23 seconds. T1: 20.6272°C\nTime 70.13 seconds. T1: 20.949499999999997°C\nTime 72.07 seconds. T1: 20.949499999999997°C\nTime 74.05 seconds. T1: 20.949499999999997°C\nTime 76.1 seconds. T1: 20.6272°C\nTime 78.1 seconds. T1: 20.6272°C\nTime 80.22 seconds. T1: 20.949499999999997°C\nTime 82.28 seconds. T1: 20.949499999999997°C\nTime 84.22 seconds. T1: 20.949499999999997°C\nTime 86.16 seconds. T1: 20.949499999999997°C\nTime 88.23 seconds. T1: 20.949499999999997°C\nTime 90.0 seconds. T1: 20.949499999999997°C\nTime 92.27 seconds. T1: 20.949499999999997°C\nTime 94.0 seconds. T1: 20.949499999999997°C\nTime 96.16 seconds. T1: 20.949499999999997°C\nTime 98.02 seconds. T1: 20.949499999999997°C\nTime 100.1 seconds. T1: 20.949499999999997°C\nTime 102.24 seconds. T1: 20.949499999999997°C\nTime 104.0 seconds. T1: 20.6272°C\nTime 106.18 seconds. T1: 20.949499999999997°C\nTime 108.27 seconds. T1: 20.949499999999997°C\nTime 110.27 seconds. T1: 20.949499999999997°C\nTime 112.1 seconds. T1: 20.949499999999997°C\nTime 114.22 seconds. T1: 20.949499999999997°C\nTime 116.24 seconds. T1: 20.949499999999997°C\nTime 118.18 seconds. T1: 20.949499999999997°C\nTime 120.19 seconds. T1: 20.949499999999997°C\nTime 122.06 seconds. T1: 20.949499999999997°C\nTime 124.22 seconds. T1: 20.6272°C\nTime 126.19 seconds. T1: 20.949499999999997°C\nTime 128.18 seconds. T1: 20.949499999999997°C\nTime 130.25 seconds. T1: 20.949499999999997°C\nTime 132.02 seconds. T1: 20.6272°C\nTime 134.2 seconds. T1: 20.949499999999997°C\nTime 136.27 seconds. T1: 20.949499999999997°C\nTime 138.01 seconds. T1: 20.6272°C\nTime 140.2 seconds. T1: 20.949499999999997°C\nTime 142.18 seconds. T1: 20.949499999999997°C\nTime 144.2 seconds. T1: 20.949499999999997°C\nTime 146.23 seconds. T1: 20.949499999999997°C\nTime 148.24 seconds. T1: 20.949499999999997°C\nTime 150.19 seconds. T1: 20.949499999999997°C\nTime 152.28 seconds. T1: 20.949499999999997°C\nTime 154.25 seconds. T1: 20.949499999999997°C\nTime 156.23 seconds. T1: 20.6272°C\nTime 158.04 seconds. T1: 20.949499999999997°C\nTime 160.11 seconds. T1: 20.949499999999997°C\nTime 162.04 seconds. T1: 20.949499999999997°C\nTime 164.05 seconds. T1: 20.949499999999997°C\nTime 166.01 seconds. T1: 20.949499999999997°C\nTime 168.23 seconds. T1: 20.6272°C\nTime 170.08 seconds. T1: 20.949499999999997°C\nTime 172.01 seconds. T1: 20.949499999999997°C\nTime 174.14 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.22 seconds. T1: 20.949499999999997°C\nTime 180.2 seconds. T1: 20.949499999999997°C\nTime 182.2 seconds. T1: 20.949499999999997°C\nTime 184.21 seconds. T1: 20.949499999999997°C\nTime 186.08 seconds. T1: 20.949499999999997°C\nTime 188.29 seconds. T1: 20.949499999999997°C\nTime 190.24 seconds. T1: 20.949499999999997°C\nTime 192.18 seconds. T1: 20.949499999999997°C\nTime 194.09 seconds. T1: 20.949499999999997°C\nTime 196.22 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.02 seconds. T1: 20.6272°C\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Laboratory"
    ]
  },
  {
    "objectID": "06_inverse_laplace_transform.html",
    "href": "06_inverse_laplace_transform.html",
    "title": "Inverse Laplace Transform: Partial fraction decomposition",
    "section": "",
    "text": "To find the inverse Laplace transform of a complicated function, we can convert the function to a sum of simpler terms for which we know the Laplace transform of each term. The result is called a partial-fraction expansion.\nGiven:\n\\[Y(s) = G(s)R(s) = \\frac{N(s)}{D(s)}R(s)\\]\nwhere the order of \\(N(s)\\) is less than the order of \\(D(s)\\), then a partial-fraction expansion can be made.\nIf the order of \\(N(s)\\) is greater than or equal to the order of \\(D(s)\\), then \\(N(s)\\) must be divided by \\(D(s)\\) successively until the result has a remainder whose numerator is of order less than its denominator.\nWe want to expand \\(G(s)\\) into the sum of functions for which we already know the inverse transform, then thanks to the linearity we can simply sum them all up to obtain the inverse of the entire function.\n\nCase 1. Roots of the Denominator of F(s) Are Real and Distinct\nLet’s suppose we have all distinct poles:\n\\[ D(s) = \\prod^{n}_{k=1}{(s-p_k)}\\]\nwe want to find the coefficient \\(P_k\\) such that:\n\\[ \\frac{N(s)}{\\prod^{n}_{k=1}{(s-p_k)}} = \\sum^{n}_{k=1}\\frac{P_k}{s-p_k}\\]\nMultiplying for \\((s-p_i)\\):\n\\[ (s-p_i)\\frac{N(s)}{\\prod^{n}_{k=1}{(s-p_k)}} = (s-p_i)\\sum^{n}_{k=1}\\frac{P_k}{s-p_k}\\]\nwe obtain:\n\\[P_i = [(s-p_i)G(s)] \\big|_{s=p_i}\\]\nand finally:\n\\[ g(t) = \\mathcal {L}^{-1}[G(s)]=\\mathcal {L}^{-1} \\bigg[\\sum^{n}_{k=1}\\frac{P_k}{s-p_k}\\bigg] = \\sum^{n}_{k=1} P_k e^{p_kt}\\]\nFor example:\n\\[G(s) = \\frac{s-10}{(s+2)(s+5)}\\]\n\\[P_1=(s+2)\\frac{s-10}{(s+2)(s+5)}\\bigg|_{s=-2}=-\\frac{12}{3}=-4\\] \\[P_2=(s+5)\\frac{s-10}{(s+2)(s+5)}\\bigg|_{s=-5}=\\frac{-15}{-3}=5\\]\nwhich means that:\n\\[G(s) = \\frac{-4}{(s+2)} + \\frac{5}{(s+5)}\\]\nand finally:\n\\[ g(t) = \\mathcal {L}^{-1}[G(s)] = -4e^{-2t} + 5e^{-5t}\\]\n\n\nCase 2. Roots of the Denominator of F(s) Are Real and Repeated\nIf we have muliple poles the decomposition is similar.\nLet’s consider, as an example\n\\[\nY(s) =  \\frac{2}{(s+1)(s+2)^2}\n\\]\nThe roots of \\((s+2)^2\\) in the denominator are repeated, since the factor is raised to an integer power higher than 1. In this case, the denominator root at \\(-2\\) is a multiple root of multiplicity 2.\nWe can write the partial-fraction expansion as a sum of terms, where each factor of the denominator forms the denominator of each term.\nIn addition, each multiple root generates additional terms consisting of denominator factors of reduced multiplicity.\nIn our case\n\\[\nY(s) =  \\frac{2}{(s+1)(s+2)^2} = \\frac{K_1}{(s+1)} + \\frac{K_2}{(s+2)^2} + \\frac{K_3}{(s+2)}\n\\]\n\nWe obtain \\(K_1\\) as before. In this case \\(K_1=2\\)\nWe obtain \\(K_2\\) multiplying the previous equation by \\((s+2)^2\\):\n\n\\[\n\\frac{2}{(s+1)} = \\frac{K_1(s+2)^2}{(s+1)} + K_2 + K_3(s+2)\n\\]\nWhen \\(s \\rightarrow -2\\), \\(K_2=-2\\)\n\nWe obtain \\(K_3\\) differentiating the previous equation with respect to \\(s\\):\n\n\\[\n\\frac{-2}{(s+1)^2} = \\frac{2(s+2)K_1}{(s+1)^2} + K_3\n\\]\nFrom which \\(K_3\\) can be isolated and found if we let \\(s \\rightarrow -2\\). Hence, \\(K_3=-2\\).\nIn this case then:\n\\[\nY(s) =  \\frac{2}{(s+1)(s+2)^2} = \\frac{2}{(s+1)} + \\frac{-2}{(s+2)^2} + \\frac{-2}{(s+2)}\n\\]\nand the inverse transform is:\n\\[\ny(t) = 2e^{-t} - 2te^{-2t} -2e^{-2t}\n\\]\nIf the denominator root is of higher multiplicity than 2, successive differentiation would isolate each residue in the expansion of the multiple root.\nIn general, given a \\(H(s)\\) whose denominator has real and repeater roots:\n\\[H(s) = \\frac{N(s)}{(s+p_1)^r(s+p_2)...(s+p_n)}\\]\nWe can find the general expression for \\(K_i\\) (the coefficient of the roots with multiplicity greater than 1):\n\\[\nK_i = \\frac{1}{(i-1)!}\\frac{d^{i-1}(F(s)(s+p_1)^r)}{ds^{i-1}}\\Big|_{s\\rightarrow-p_1} \\;\\; i=1,2,...,r\n\\]\n\n\nCase 3. Roots of the Denominator of F(s) Are Complex or Imaginary\nThe technique used for the partial-fraction expansion of \\(F(s)\\) with real roots in the denominator can be used for complex and imaginary roots.\nHowever, the residues of the complex and imaginary roots are themselves complex conjugates.\nIn this case, the resulting terms can be identified as:\n\\[\n\\frac{e^{j\\theta}+e^{-j\\theta}}{2} = \\cos{\\theta}\n\\]\nand\n\\[\n\\frac{e^{j\\theta}-e^{-j\\theta}}{2j} = \\sin{\\theta}\n\\]\nFor example:\n\\[\nF(s) = \\frac{3}{s(s^2+2s+5)} = \\frac{3}{s(s+1+j2)(s+1-j2)} = \\frac{K_1}{s} + \\frac{K_2}{s+1+j2} + \\frac{K_3}{s+1-j2}\n\\]\n\\(K_1\\) is found as usual, and found \\(K_1=3/5\\).\nTo find \\(K_2\\):\n\\[\nK_2 = \\frac{3}{s(s+1-j2)}\\Big|_{s\\rightarrow -1-j2} = \\frac{-3}{20}(2+j1)\n\\]\n\\(K_3\\) is found to be the complex conjugate of \\(K_2\\).\n\\[\nF(s) = \\frac{3/5}{s} - \\frac{3}{20}\\Big(\\frac{2+j1}{s+1+2j} + \\frac{2-j1}{s+1-2j}\\Big)\n\\]\nwhich we can inverse transform to obtain:\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{20}\\Big[ (2+j1)e^{-(1+j2)t} + (2-j1)e^{-(1-j2)t} \\Big]\n\\]\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{20} e^{-t}\\Big[4 \\Big( \\frac{e^{j2t}+e^{-j2t}}{2}\\Big) + 2 \\Big(\\frac{e^{j2t}-e^{-j2t}}{2j} \\Big) \\Big]\n\\]\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{5} e^{-t} \\Big( cos(2t) + \\frac{1}{2}sin(2t) \\Big) = 0.6 - 0.671e^tcos(2t-\\phi)\n\\]\nwhere \\(\\phi = arctan0.5=26.57^o\\)\n\n\n\n\n\n\n\nfrom http://www.dii.unimo.it/~zanasi/didattica/Fondamenti%20CA_Mec/Luc_CA_06_Fratti_semplici.pdf",
    "crumbs": [
      "Inverse Laplace Transform: Partial fraction decomposition"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html",
    "href": "models_of_control_devices_and_systems.html",
    "title": "Models of Controlled Devices",
    "section": "",
    "text": "Having been introduced to various plant models we frequently encounter in various applications, we are now well-poised to delve into the complete feedback control system. Consequently, our focus with this notebook is on models of controlled devices, as well as the complete systems we’ll build using these devices.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#revisiting-plant-models",
    "href": "models_of_control_devices_and_systems.html#revisiting-plant-models",
    "title": "Models of Controlled Devices",
    "section": "Revisiting Plant Models",
    "text": "Revisiting Plant Models\nIn order to ensure that we have a clear foundation, let’s review the scenario with respect to the plant models that we have modeled through transfer functions and block diagrams.\n\n\n\n\n\n\nThis diagram encapsulates the plant’s dynamics through a transfer function, \\(G(s)\\). The input to the plant, denoted as \\(R(s)\\), produces an output, \\(Y(s)\\). This output, also named as the controlled variable of the system, will always be the result of multiplying the transfer function \\(G(s)\\) with the input \\(R(s)\\).\n\\[\nY(s) = G(s)R(s)\n\\]\nThis equation provides a mathematical representation in the transform domain for the plant, which serves as a subsystem in the overarching control system we’ll soon explore.\nPop-up Question: In the equation \\(Y(s) = G(s)R(s)\\), where \\(Y(s) =\\frac{1}{s+1}\\) and \\(R(s)=1\\), , what would \\(Y(s)\\) be? Answer: \\(\\frac{1}{s+1}\\)",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#cascade-of-blocks",
    "href": "models_of_control_devices_and_systems.html#cascade-of-blocks",
    "title": "Models of Controlled Devices",
    "section": "Cascade of Blocks",
    "text": "Cascade of Blocks\nLet’s now assume we now have two blocks, \\(G_1(s)\\) and \\(G_2(s)\\).\n\n\n\n\n\n\nIf \\(R(s)\\) is the input to the first block and \\(Y(s)\\) is the output of the entire setup, and \\(X(s)\\) is the signal between the two blocks, we can state:\n\\[\n\\begin{align}\nX(s) &= G_1(s)*R(s)\\\\\nY(s) &= G_2(s)*X(s)\\\\\n\\end{align}\n\\]\nCombining these equations, we derive:\n\\[\nY(s) =  G_1(s) \\cdot G_2(s) \\cdot R(s)\n\\]\nThis illustrates that when two blocks (or subsystems) are cascaded, their transfer functions can be multiplied to ascertain the relationship between the input and the output.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#summing-junctions-take-off-points",
    "href": "models_of_control_devices_and_systems.html#summing-junctions-take-off-points",
    "title": "Models of Controlled Devices",
    "section": "Summing Junctions & Take-off Points",
    "text": "Summing Junctions & Take-off Points\nWe’ve also frequently seen circles together with algebraic signs in our block diagrams. These denote either error detectors or summing junctions.\n\n\n\n\n\n\nFor instance, if \\(R(s)\\) and \\(B(s)\\) are signals at a junction, the resulting signal \\(E(s)\\) is calculated as:\n\\[E(s)=R(s)−B(s)\\]\nor \\(E(s)=R(s)+B(s)\\) if the signals are being added.\nThis symbolic representation serves as a convenient method to depict algebraic manipulations of multiple signals.\nIn some instances, we might wish to tap into a signal for feedback. Such take-offs (or banch-offs) have been illustrated in our diagrams by branching off a main signal line. This ensures that the value of the signal being fed back remains consistent.\n\n\n\n\n\n\nTo summarize, any system can be comprehensively represented using a combination of these four foundational block diagram elements: a basic block, cascaded blocks, summing junctions, and take-off points.\n\nLiquid Level System: A Detailed Look\nTo provide further clarity, let’s discuss a liquid level system.\n\n\n\n\n\n\nWhen modeling a single tank, we primarily concern ourselves with the dynamics between the inflow, outflow, and the height of the liquid. The most common and simplified model is based on the balance of liquid volume, considering the inflow and outflow rates.\nBasic Assumptions:\n\nThe cross-sectional area of the tank is constant.\nThe liquid in the tank is well-mixed and has a uniform density.\nThe outflow rate depends on the liquid height (due to gravitational pressure).\n\nThis system’s primary objective is to control the liquid height within a tank. When modeling such a tank, we often derive a first-order system model, with the tank’s dynamics epitomized by a system gain and time constant.\n\\[\n\\frac{H_1(s)}{Q_i(s)} = \\frac{\\frac{R_1}{\\rho g}}{\\tau_1 s+1}\n\\]\nWhere:\n\n\\(H(s)\\) is the Laplace transform of the liquid height \\(h(t)\\).\n\\(Q_i(s)\\) is the Laplace tranform of the inflow rate \\(q_in(t)\\).\n\\(\\rho\\) is the density of the liquid\n\\(g\\) is the acceleration due to gravity.\n\\(R\\): resistance to the flow, typically determined by the size and shape of the outlet.\n\nConsider two tanks. The second tank’s input comes from the first tank’s output. By using our previously derived models, and if we factor in the input flow and liquid height, we can determine the relationship between the tanks and their respective outputs.\n\n\n\n\n\n\nWe can model the second tank as we did for the first one:\n\\[\n\\frac{H_2(s)}{Q_1(s)} = \\frac{\\frac{R_2}{\\rho g}}{\\tau_2 s+1}\n\\]\nwe can represent this dynamic relationship with block diagrams:\n\n\n\n\n\n\nThe input for the second system is \\(Q_1(s)\\). However:\n\\[\nq_1 = \\frac{p_1}{R_1}\n\\]\nwhere \\(p_1\\) is the pressure at the outflow of the first tank, and the total pressure is \\(\\bar{p_1}+p_1\\), and \\(\\bar{p_1}\\) is the static pressure.\nWe can hence write:\n\\[\nq_1 = \\frac{p_1}{R_1} = \\frac{\\rho g h_1}{R_1}\n\\]\nAnd this is how we can relate \\(Q_1\\) and \\(H_1\\), but note that the output of the first tank, according to our model is \\(H_1\\) and not \\(Q_1\\), the second transfer function is different from the first one.\nFor the second system, the input is \\(Q_1\\) (inflow) and the controlled variable is \\(H_2\\).\nHowever, a crucial point of note is that the dynamics of the second tank, do not influence the dynamics of the first tank. This characteristic implies that the second system doesn’t “load” the first. Only in such scenarios can the transfer functions of the two systems be multiplied.\nYet, if the tanks were connected differently, where the second tank’s pressure influences the first tank’s flow, then this “loading” effect would prevent us from simply multiplying their transfer functions. This loading effect can drastically alter the system’s dynamics, even changing a first-order system to a second-order one.\n\n\n\n\n\n\nIf we model this case.\nThe rate of storage in the tank 1 is:\n\\[\n\\begin{align}\nC_1\\frac{dp_1}{dt} &= q_i - \\frac{p_1-p_2}{R_1}\n\\end{align}\n\\]\nand the rate of storage in the second tank is:\n\\[\n\\begin{align}\nC_2\\frac{dp_2}{dt} &= q_1 - \\frac{p_2}{R_2}\n\\end{align}\n\\]\nwhere \\(p_2\\) is the pressure of the second tank. Notice how this affects the flow of the first tank (right most term in the equation (1) above), and hence there is a loading effect of the second tank on the first one.\nIn this case, the two systems cannot be written as cascading systems! The two subsystems are not independent, and they cannot be considered as two separate blocks.\nWe can find the overall transfer function as (obtained from the previous two equations):\n\\[\n\\frac{H_2(s)}{Q_i(s)} = \\frac{\\frac{R_2}{\\rho g}}{\\tau_1\\tau_2s^2+(\\tau_1 + \\tau_2 + \\frac{R_2}{R_1})s + 1}\n\\]\nNote, while in liquid and thermal systems, we typically have first-order systems, the presence of a loading effect produces a second-order system. In industrial settings, individual tanks are generally modeled using a time constant and system gain. When connected in non-loading fashion, the system’s transfer function remains a second-order one, but is represented by two distinct time constants. In contrast, when connected in a loading manner, the system’s transfer function is again second-order, but characterized by a quadratic lag.\nTo reiterate and emphasize: In our block diagram representations, if we depict two systems, \\(G_1\\) and \\(G_2\\), in cascade, it’s implied that \\(G_2\\) doesn’t load \\(G_1\\). This is a crucial assumption that ensures the accuracy of our models and subsequent calculations.\nYou can have suitable buffers (electrical, hydraulic, thermal, etc.) to avoid the loading effect and the two transfer function can be considered independently. If this is not possible then the two systems must be considered together and will be represented by a single transfer function.\n\n\nSidebar - Modeling a Single Tank\nWhen modeling a single tank, we primarily concern ourselves with the dynamics between the inflow, outflow, and the height of the liquid. The most common and simplified model is based on the balance of liquid volume, considering the inflow and outflow rates.\n\nBasic Assumptions:\n\nThe cross-sectional area of the tank is constant.\nThe liquid in the tank is well-mixed and has a uniform density.\nThe outflow rate depends on the liquid height (due to gravitational pressure).\n\n\n\nMathematical Representation:\nLet’s define the following variables:\n\n$ h(t) $: height of the liquid at time $ t $.\n$ A $: cross-sectional area of the tank.\n$ Q_{in}(t) $: inflow rate at time $ t $.\n$ Q_{out}(t) $: outflow rate at time $ t $.\n$ $: density of the liquid.\n$ g $: acceleration due to gravity.\n$ R $: resistance to the flow, typically determined by the size and shape of the outlet.\n\nFrom the principle of conservation of mass:\n\\[\nA \\frac{dh(t)}{dt} = Q_{in}(t) - Q_{out}(t)\n\\]\nUsing Torricelli’s law, the outflow rate, $ Q_{out}(t) $, from the tank through an orifice can be related to the height of the liquid:\n\\[\nQ_{out}(t) = \\frac{\\rho g h(t)}{R}\n\\]\nSubstitute the outflow rate in the conservation of mass equation:\n\\[\nA \\frac{dh(t)}{dt} = Q_{in}(t) - \\frac{\\rho g h(t)}{R}\n\\]\nThis is a first-order differential equation which represents the dynamics of the tank. It relates the rate of change of liquid height to the inflow and the height itself. The solution to this equation, given appropriate initial conditions, will give you the height of the liquid in the tank as a function of time.\n\n\nTransfer Function Model:\nIn control theory, it’s often useful to describe systems in the frequency domain using a transfer function. The transfer function of the tank can be derived by taking the Laplace transform of the differential equation. Assuming zero initial conditions and denoting the Laplace transform variable as $ s $:\n\\[\nA s H(s) = Q_{in}(s) - \\frac{\\rho g}{R} H(s)\n\\]\nWhere: - $ H(s) $ is the Laplace transform of the liquid height $ h(t) $. - $ Q_{in}(s) $ is the Laplace transform of the inflow rate $ Q_{in}(t) $.\nRearranging and solving for the transfer function $ G(s) = $:\n\\[\nG(s) = \\frac{A}{As + \\frac{\\rho g}{R}}\n\\]\nThis transfer function relates the liquid height to the inflow rate in the frequency domain.\nRearrange the terms:\n\\[\nA \\frac{dh(t)}{dt} + \\frac{\\rho g h(t)}{R} = Q_{in}(t)\n\\]\nNow, let’s take the Laplace transform of both sides. Assuming zero initial conditions:\n\\[\nA s H(s) + \\frac{\\rho g}{R} H(s) = Q_{in}(s)\n\\]\nFactor out \\(H(s)\\):\n\\[\nH(s) \\Big( A s + \\frac{\\rho g}{R} \\Big) = Q_{in}(s)\n\\]\nwhich brings:\n\\[\nG(s) = \\frac{H(s)}{Q_{in}(s)} = \\frac{1}{\\Big( A s + \\frac{\\rho g}{R} \\Big)}\n\\]\nNow, the steady-state gain of the system, when \\(s=0\\), is:\n\\[\n\\frac{1}{\\frac{\\rho g}{R}} = \\frac{R}{\\rho g}\n\\]\nSetting \\(A=\\tau\\) - the time constant τ is equal to the cross-sectional area \\(A\\) of the tank, we obtain:\n\\[\n\\frac{H(s)}{Q_{in}(s)} = \\frac{\\frac{R}{\\rho g}}{\\tau s+1}\n\\]\n— END OF SIDEBAR",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#standard-block-diagram-for-feedback-design",
    "href": "models_of_control_devices_and_systems.html#standard-block-diagram-for-feedback-design",
    "title": "Models of Controlled Devices",
    "section": "Standard Block Diagram for Feedback Design",
    "text": "Standard Block Diagram for Feedback Design\nFor ease of analysis, we can rearrange the block diagram.\n\n\n\n\n\n\nIn this diagram: - The transfer function between \\(Y\\) and \\(W\\) is \\(G_P(s)\\). - The transfer function between \\(Y\\) and \\(U\\) is \\(G_A(s)G_P(s)\\).",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#a-convenient-block-diagram",
    "href": "models_of_control_devices_and_systems.html#a-convenient-block-diagram",
    "title": "Models of Controlled Devices",
    "section": "A Convenient Block Diagram",
    "text": "A Convenient Block Diagram\nWe can also manipulate the diagram for further convenience.\n\n\n\n\n\n\nIn this diagram: - The transfer function between \\(Y\\) and \\(W\\) is \\(N(s)\\). - The transfer function between \\(Y\\) and \\(U\\) is \\(G_A(s)G_P(s)\\).\nBy setting \\(N(s)=G_P(s)\\), both diagrams become identical. Consequently, the position of the summing junction becomes inconsequential. Furthermore, the two subsystems, \\(G_A(s)\\) and \\(G_P(s)\\) can be combined to form a unified transfer function represented as \\(G=G_A(s)G_P(s)\\).\nThe diagram becomes:\n\n\n\n\n\n\nAs we progress deeper into the realm of control systems, our visual representation of systems—block diagrams—become indispensable. These diagrams are symbolic representations of the mathematical equations that describe our system. But like any language, there are many ways to convey the same message. Thus, manipulating our block diagrams for clarity or convenience is often necessary.\nPop question: Manipulate the block diagram so that the block \\(A(s)\\) does not appear in the forward path. - Hint: the signal \\(\\hat{e}\\) must be the same in both cases.\nAnswer: \\(\\hat{e} = Ay_r - Hy\\). If we were to compute the controlled signal \\(u\\) in this setup, it would be:\n\\[ u = DAy_r − DHy\\]\nThis equation describes the relationship between the command signal (\\(y_r\\)), the controlled signal (\\(u\\)), and the outpu (\\(y\\)).\nIf we move the subsystem \\(A(s)\\) after the summation junction:\n\n\n\n\n\n\nIn this modified version, our controlled signal \\(u\\) can be expressed as:\n\\[\nu = ADy_r - \\frac{H}{A}ADy\n\\]\nThe comparison of these two equations confirms the equivalence of both block diagrams. The transformations we applied to go from the initial to the simplified diagram are purely symbolic, yet they present the system in a more digestible manner. We do this because the resulting system becomes more convenient.\nNote: - In this last diagram we can say \\(y_r=r\\) because there is no explicit reference element. Moving the block \\(A\\) inside the feedback loop, the mathematic representation would be identical and we can say \\(y_r=r\\). Note that physically it might not make any sense, but the mathematical equations would be the same.\n\nIf \\(H=A\\) then the signal out of the summation junction becomes \\(e=y_r-y\\). In all other cases is \\(\\hat{e}\\).\n\nPopup Question: Why is it essential to confirm the equivalence of the two block diagrams?\nAnswer: Confirming the equivalence ensures that our simplifications or manipulations don’t inadvertently alter the system’s behavior. The system’s performance and response should remain unchanged regardless of its representation.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#unity-feedback-system",
    "href": "models_of_control_devices_and_systems.html#unity-feedback-system",
    "title": "Models of Controlled Devices",
    "section": "Unity Feedback System",
    "text": "Unity Feedback System\nA further transformation can lead us to what’s referred to as a “Unity Feedback System”.\nWhen \\(H(s)\\) matches \\(A(s)\\) — meaning the sensor transfer function aligns with the reference transfer function (a scenario which might be intentionally designed) — the block diagram becomes more streamlined:\n\n\n\n\n\n\nThis block diagram is of paramount importance. Frequently, we can adapt the system to align with this depiction, making it particularly advantageous for design considerations. Due to its significance, it’s referred to as the “unity-feedback system.”\nThe term “unity” here does not necessarily imply that the sensor transfer function H(s)H(s) is unity (or 1). Rather, through careful manipulation and under certain conditions (like \\(H=A\\)), we can arrive at a block diagram representation that seems to imply a direct feedback without any transformation. But remember, this is just a representation.\nA common misconception is the belief that the signal \\(y\\) is fed back directly to the summation junction without the intervention of a sensor, or under the assumption that the sensor transfer function is always 1. However, this isn’t necessarily true. While the sensor transfer function can indeed be 1, there can also be a distinct sensor transfer function \\(H\\). By judiciously selecting the reference transfer function, one can achieve the unity feedback structure.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#disturbances-matter",
    "href": "models_of_control_devices_and_systems.html#disturbances-matter",
    "title": "Models of Controlled Devices",
    "section": "Disturbances Matter",
    "text": "Disturbances Matter\nLastly, a crucial element we should never overlook is the disturbance, which we represent as \\(w\\).\nThe very essence of feedback control theory revolves around disturbances. If our systems experienced no disturbances, the entire field of feedback control might not exist. Open-loop systems could handle undisturbed scenarios perfectly well.\n\n\n\n\n\n\nThis will be the Feedback Block Diagram that we will mostly use.\nThese block diagrams are to represent the relationships between signals of interest. They are constructed to capture the dynamic relationship between all the variables.\nWhen you model a system, you will always be able to reconduct its model to one of these standard block diagrams.\nPopup Question: Why are disturbances crucial in feedback control systems?\nAnswer: Disturbances are unexpected or unpredictable changes in a system’s environment or inputs. Feedback control systems are designed to mitigate the effects of these disturbances, ensuring the system operates as desired despite these unforeseen changes.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#setting-disturbance-to-zero",
    "href": "models_of_control_devices_and_systems.html#setting-disturbance-to-zero",
    "title": "Models of Controlled Devices",
    "section": "Setting Disturbance to Zero",
    "text": "Setting Disturbance to Zero\n\\[\\frac{Y(s)}{R(s)}\\Big|_{w=0}=\\frac{D(s)G(s)}{1+D(s)G(s)H(s)} = M(s)\\]\nIt’s important to note that if our system were a positive feedback loop instead, this equation would see a minus sign in the denominator.\nThis is called Reference Transfer Function because it relates the reference \\(R\\) with the output \\(Y\\).",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#setting-the-reference-input-to-zero",
    "href": "models_of_control_devices_and_systems.html#setting-the-reference-input-to-zero",
    "title": "Models of Controlled Devices",
    "section": "Setting the Reference Input to Zero",
    "text": "Setting the Reference Input to Zero\nWe are now interested in the transfer function between the system output \\(Y\\) and the disturbance input \\(W\\), represented as:\n\n\n\n\n\n\n\\[\n\\frac{Y(s)}{W(s)}\\Big|_{R(s)=0} = ?\n\\]\nThis transfer function effectively captures the system’s response to disturbances. It’s a measure of how external disturbances are filtered or amplified by the system dynamics before influencing the output.\nTo make our task more manageable, we can streamline our block diagram by combining elements. Specifically, by taking the negative sign of the error detector and consolidating it with our existing minus sign, we can simplify our representation.\n\n\n\n\n\n\nFrom this modified diagram, we can derive two fundamental relationships:\n\n\\(\\hat{E}(s) = -H(s)Y(s)\\)\n\\(Y(s) = D(s)G(s)\\hat{E}(s) + N(s)W(s)\\)\n\nBy manipulating and combining these equations, we can eliminate \\(\\hat{E}(s)\\) to determine the relationship between \\(Y(s)\\) and \\(W(s)\\).\n\\[\nY(s) = -D(s)G(s)H(s)Y(s) + N(s)W(s)\n\\]\nAnd therefore:\n\\[\n\\frac{Y(s)}{W(s)}\\Big|_{R(s)=0} = \\frac{N(s)}{1+D(s)G(s)H(s)} = M_W(s)\n\\]\nThis is called Disturbance Transfer Function.\n**Note that both in the reference transfer funtion and in the disturbance transfer function the denominator is the same: \\(1+D(s)G(s)H(s)\\).",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#the-loop-transfer-function",
    "href": "models_of_control_devices_and_systems.html#the-loop-transfer-function",
    "title": "Models of Controlled Devices",
    "section": "The loop transfer function",
    "text": "The loop transfer function\nThe expression:\n\\[\nD(s)G(s)H(s)\n\\]\nis termed as the “Loop Transfer Function”. This name originates from the fact that it represents the combined effect of all the transfer functions present within the feedback loop.\nPopup Question: Why is the denominator the same for both the reference and disturbance transfer functions?\nAnswer: The denominator represents the loop transfer function, which is the product of all transfer functions in the feedback loop. This remains consistent, irrespective of the input under consideration.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#dissecting-a-multi-loop-system",
    "href": "models_of_control_devices_and_systems.html#dissecting-a-multi-loop-system",
    "title": "Models of Controlled Devices",
    "section": "Dissecting a Multi-loop System",
    "text": "Dissecting a Multi-loop System\nConsider a multi-loop configuration, as presented in our example. The diagram showcases multiple loops, with the primary loop being the one where the controlled output, \\(Y\\), is fed back against the reference input \\(R\\). This primary loop is complemented by several minor feedback loops, making the system’s structure more intricate.\n\n\n\n\n\n\nThe challenge lies in determining the relationship between \\(Y\\) and \\(R\\). This is the relationship that I need from a control perspective.\nNote that if we were given the differential equations we could have manipulated them directly to obtain the desired relationship. Alternatively, given the equations we can write the equivalent block diagram and then manipulate the block diagram to obtain the relationship that we need between any variable of interest.\nThe challenge here is that often these diagrams aren’t immediately reducible to a basic feedback loop. Therefore, we might need to rearrange summing junctions, take-off points, or even move blocks around to create identifiable basic feedback loops.\n\nSolution\n\nIdentifying the Basic Feedback Loop:\n\nOur first task is to transform the multi-loop system into basic feedback loops. A basic feedback loop provides a direct relationship between the input and output, facilitating a simpler analysis.\n\n\n\n\n\n\nFigure: Basic Feedback Loop\n\nManipulating the Block Diagram: There are no basic feedback loops in our diagram for now.\n\nTo achieve a basic feedback loop, we may need to relocate summing junctions or take-off points. The goal is to identify and isolate these basic loops, making the system more amenable to analysis.\n\nApplying Reduction Formulas: Once the basic feedback loops are identified, we apply the standard formula:\n\n\\[\n\\frac{Y(s)}{R(s)}=\\frac{G(s)}{1±G(s)H(s)}\n\\]\nThis formula allows us to reduce a basic feedback loop into a single block, simplifying the entire system.\n\nIterative Reduction: The process is iterative. We continue to identify basic feedback loops, apply the reduction formula, and simplify the system until we obtain the desired relationship between \\(Y\\) and \\(R\\).\n\nThe procedure is not unique.\nIn our case we can start from:\n\n\n\n\n\n\n\nIf the input of block \\(H_2\\) continue to be \\(X\\) (or the output of block \\(H_2\\) remains \\(H_2X\\), then we can move the take off point after the block \\(G_4\\). This infact ensures that the input into the rest of the diagram remains the same.\n\nWe can then modify the previous diagrom to be:\n\n\n\n\n\n\nor to make the take off points more explicit:\n\n\n\n\n\n\nThis last diagram makes it easy to identify the first basic feedback loop (Note that it is a positive feedback loop).\nWe can then reorganise the block diagram as:\n\n\n\n\n\n\nwhich, once we reduce the cascading blocks, we can write as:\n\n\n\n\n\n\nAnd now it is easy to see the remaining basic feedback loops. The first one is highlighted in red.\nFinally we obtain:\n\n\n\n\n\n\nwhich we can reduce once more to obtain the final close loop equivalent:\n\n\n\n\n\n\nPop-up Question: Can two different block diagrams represent the same system equations?\nAnswer: Yes, two different block diagrams can represent the same system equations if they capture the same relationships and dynamics.\n\n\nAlternative solution\nThe sequence of reduction is not unique. Different approaches might yield the same result. For instance, relocating summing junctions can offer an alternative method of reduction.\n\n\n\n\n\n\nTo make this change, let’s call the signal that comes out of the block \\(H_1\\),\\(Z = H_1Y\\). Since the signal \\(Z\\) is arriving as input to \\(G_3\\), it means that if we move the summation before the \\(G_2\\) block, this block will contribute to an additional gain of \\(G_2\\). We need to take care of this gain to have an equivalent relationship, and divide by \\(G_2\\) in the feedback path.\n\n\n\n\n\n\n\n\n\n\n\n\nor also equivalently\n\n\n\n\n\n\nWe can do this because block diagrams are not representing physical systems, they are a mathematical representation.\nIn conclusion, block diagrams offer a powerful tool for system analysis and design for automatic control. By visually representing system equations, they facilitate understanding, especially for complex systems.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#rules-for-block-diagram-manipulation",
    "href": "models_of_control_devices_and_systems.html#rules-for-block-diagram-manipulation",
    "title": "Models of Controlled Devices",
    "section": "Rules for Block Diagram Manipulation",
    "text": "Rules for Block Diagram Manipulation",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#from-block-diagrams-to-signal-flow-graphs",
    "href": "models_of_control_devices_and_systems.html#from-block-diagrams-to-signal-flow-graphs",
    "title": "Models of Controlled Devices",
    "section": "From Block Diagrams to Signal Flow Graphs",
    "text": "From Block Diagrams to Signal Flow Graphs\nBefore delving into the intricacies of Mason’s Gain formula, it’s essential to understand how to convert a block diagram into its corresponding signal flow graph. This transformation is not only pivotal for better visualization but also facilitates the application of Mason’s Gain formula.\n\nUnderstanding Nodes and Paths in SFGs\nIn a signal flow graph, the term “node” represents a variable or signal, while the arrows or paths between nodes represent the system gain or transmittance.\nLet’s break down additional concepts:\n\nInput Node: A node with no incoming signals. The value of such a node is externally defined. For instance, the node labeled “R” in our previous examples.\nOutput Node: A node from which there are no outgoing branches. It’s essentially the end point or the result of our system.\n\n\n\nConstructing the Signal Flow Graph\nGiven the block diagram, let’s attempt to construct its corresponding signal flow graph:\n\nIdentify the input node(s). In our example, R serves as the input node.\nTrace the path from the input to the output, ensuring you only traverse a node or branch once. This is what defines a “forward path.”\nMark the transmittances or gains along each branch. For instance, a branch with a gain of \\(G1\\) should be labeled as such.\n\nLet’s take a basic block with input \\(R\\) and output \\(Y\\), connected through a system \\(G\\)\n\n\n\n\n\n\nWhere: - \\(R\\) is a variable - \\(Y\\) is a variable - \\(G\\) is the system gain\nWe can build the equivalent signal flow graph as:\n\n\n\n\n\n\nIn a signal flow graph, \\(R\\) and \\(Y\\) become nodes, and \\(G\\) becomes a branch transmittance.\nThe key concept in signal flow graphs is the idea of nodes representing variables and branches indicating the relationship (or gain) between these nodes.\nTo keep in mind that _The sum of incoming signals to a node gives the node’s value. The outgoing signal is the value of the node variable.\nConsider a feedback loop where a signal \\(Y\\) is fed back through a gain \\(H\\).\n\n\n\n\n\n\nTo convert it to a signal flow diagram:\n\nHow many variables there are? 4: \\(R\\), \\(Y\\), \\(B\\), \\(\\hat{E}\\).\nHow many gains there are? 2: \\(G\\), \\(H\\)\n\nWe start from the two variables of interest: \\(R\\) and \\(Y\\) and we draw them as nodes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe previous diagram can also be represented expliciting the node \\(B\\) and separating the \\(H\\) and \\(-1\\) contributions. In this case the previous representation is enough to capture the dynamics that we need.\n\n\n\n\n\n\nAnd finally we obtain:\n\n\n\n\n\n\nIn the signal flow graph, the node labeled “R” doesn’t have any incoming signals. In our terminology, such a node with no incoming branches is referred to as an “input node”.\nThis is because its value is externally defined, and hence the value of the “R” node depends on what we assign to it.\nThe signal originating from “R” travels along a branch, getting multiplied by a transmittance of 1, before reaching the next node.\nSimilarly, the “Y” signal travels along its branch, getting multiplied by a transmittance of \\(-H\\), before it reaches its destination node. As a result, the value at this node is the algebraic sum of these two signals.\nMeanwhile, the “\\(\\hat{E}\\)” signal travels along another branch, getting multiplied by the gain “G”, before it reaches its destination. Consequently, the value of the output node “Y” is given by $ G $.\nJust for the sake of better visualization, if I were to introduce an additional branch (which isn’t present in the original block diagram) and label it “Y”, this addition wouldn’t impact our system equations. Essentially, this equation suggests \\(Y=Y\\).\n\n\n\n\n\n\nWhile this may seem redundant, it offers an advantage in terms of clarity. We can now term this as an “output node”. An output node is characterized by having no outgoing branches, while an input node is one devoid of incoming branches. Introducing this output node helps to clearly delineate the attribute of interest.",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "models_of_control_devices_and_systems.html#a-more-complex-example",
    "href": "models_of_control_devices_and_systems.html#a-more-complex-example",
    "title": "Models of Controlled Devices",
    "section": "A more complex example",
    "text": "A more complex example",
    "crumbs": [
      "Models of Controlled Devices"
    ]
  },
  {
    "objectID": "design_with_the_root_locus.html",
    "href": "design_with_the_root_locus.html",
    "title": "Design with the Root Locus",
    "section": "",
    "text": "The root locus is a graphical method used to analyze how the roots (poles) of a system’s characteristic equation change as a parameter, typically the controller gain (\\(K\\)), varies. It helps us understand how the system’s stability and transient response depend on the control gain.\nMany industrial control systems are designed using either the root locus approach or the frequency domain approach (based on Bode plots). These methods ensure that the system meets performance requirements.",
    "crumbs": [
      "Design with the Root Locus"
    ]
  },
  {
    "objectID": "design_with_the_root_locus.html#example-problem",
    "href": "design_with_the_root_locus.html#example-problem",
    "title": "Design with the Root Locus",
    "section": "Example Problem",
    "text": "Example Problem\nLet’s consider an example to apply the root locus method. We have a plant with the transfer function:\n\\[\nG(s) = \\frac{5}{s(\\frac{1}{6}s+1)(0.5s + 1} = \\frac{60K_A}{s(s+2)(s+6)}\n\\]\nThis plant model represents a motor servo system, where the output is the position, and the input is the manipulated signal.\n\n\n\n\n\n\n\nAs usual, the first thing we would like to understand is if a controller gain can solve our problem.\n\nSteady-State Accuracy and Transient Requirements\nOur design strategy is to first meet the transient performance and steady-state accuracy requirements and then check for robustness and disturbance rejection.\nRemember that transient requirements include relative stability and speed of response. - Relative stability is related to peak overshoot, which can be specified using the damping ratio (\\(\\zeta\\)) or the percent overshoot (\\(M_p\\)). - The speed of response can be specified using settling time (\\(t_s\\)), rise time (\\(t_r\\)), or natural frequency (\\(\\omega_n\\)).\nIn the context of second-order systems, it’s important to remember to check for the ‘dominance condition.’ This condition ensures that the main characteristics of a system are governed by its dominant poles. If the dominance condition is met, great! However, if it’s not, we need to address the influence of other poles, like third poles, on the system’s performance. This is a crucial aspect to consider when tackling a design problem.\nRequirements - Steady-state accuracy: $K_v $ or \\(e_{ss} \\le 0.2\\)\nIn control system design, we often focus on steady-state accuracy. For a type-1 system like ours, steady-state error to a step input is zero. Therefore, we specify the steady-state accuracy in terms of the velocity error constant, \\(K_v\\). In this example, we want \\(K_v\\) to be greater than or equal to 5.\nTo satisfy the steady-state accuracy requirement, we need to select an appropriate gain, \\(K_A\\). Given that we would like to focus on a pure gain adjustment, and we have a type-1 system, then the acceleration constant is always \\(K_a=0\\) and the steady-state error to parabolic inputs is infinite. The system will not be able to follow acceleration inputs.\nNote also that this discussion means that for this system any stead-state requirement must be specified in terms of accuracy to ramp inputs. It is the only input that makes sense to analyse. If we restrict to selecting a pure gain, the error to step is alway zero; error to ramp is always inifite.\n\n\nRoot Locus Analysis\nThe first thing to do is to put the transfer function in the root locus form. In this case:\n\\[\nG(s) = \\frac{60K_A}{s(s+2)(s+6)} = \\frac{K}{s(s+2)(s+6)}\n\\]\nwhere \\(K=60K_A\\) is the root locus gain.\nIn this case, we can calculate \\(K_v\\):\n\\[\nK_v = \\lim_{s\\rightarrow0} s \\frac{60K_A}{s(s+2)(s+6)} = 5K_A\n\\]\nand our requirement is satisfied for \\(K_A=1\\), and hence it is satisfied for a root locus gain \\(K=60\\).\n\nWe can draw a rough root locus plot and locate the poles when \\(K=60\\) applying the magnitude condition.\n\n\n\n\n\n\n\n\n\nFrom the position of the closed loop poles we can determine the damping angle \\(\\theta\\) and the damping ratio \\(\\zeta=\\cos(\\theta) = 0.105\\).\nWe can also obtain the corresponding \\(\\omega_n = 2.85\\)\n\n\nSettling time\nOne key parameter to evaluate transient performance is settling time (\\(t_s\\)). Settling time represents how quickly the system reaches a steady-state after a disturbance or change in input. It is typically defined with respect to a 2 percent tolerance band around the final value.\nThe formula to calculate settling time is:\n\\[\nt_s = \\frac{4}{\\zeta \\cdot \\omega_n} = 13.36\\;\\;sec\n\\]\nwhere \\(\\zeta\\) is the damping ratio and \\(\\omega_n\\) is the natural frequency. We can easily calculate \\(t_s\\) if we know \\(\\zeta\\) and \\(\\omega_n\\).\n\n\nDominance condition\nIn control system design, we aim for stability and satisfactory transient response. The dominance condition helps us determine whether we can neglect certain poles in the system.\nThe dominance condition states that if the complex conjugate poles that govern transient response are significantly farther to the left on the real axis than other poles, we can ignore the latter ones. This simplification allows us to focus on the dominant poles when analyzing transient performance.\nIn our case, the specific transient response characteristics only make sense if we have a pair of dominant poles. In this case however, the dominance condition is certainly verified. The two closed loop are with real part less than one and the third pole is moving away from -6 towards \\(-\\infty\\). If this was not the case, we would have located the third pole usign the magnitude condition and verified explicitly the dominance condition.\nNote that the relative stability is quite poor, the system oscillates and is very slow. With a simple amplifier we will not be able to meet the transient requirement while simultaneously meeting the steady-state accuracy.\n\n\n\nMeeting Transient Requirements\nLet’s consider an example where the user specifies transient requirements:\n\nDamping ratio (\\(\\zeta\\)) equal to 0.6\nSettling time (\\(t_s\\)) less than or equal to 4 seconds\n\n\n1. Finding Dominant Poles\nTo satisfy the transient requirements, we need to locate dominant poles. We start by setting \\(\\zeta\\) to 0.6. Rememebr that if we focus on using a simple gain, we only have one degree of freedom and hence we need to choose the specific parameter we want to start with.\nBy trial and error, we locate a point on the root locus plot that satisfies both the angle criterion and \\(\\zeta\\) requirement. This point represents the dominant poles.\n\n\n\n\n\n\n\n\n\n2. Evaluating Settling Time\nHaving found the dominant poles, we can calculate the settling time using the formula mentioned earlier. For the given design, the settling time is approximately 5.3 seconds:\n\\[\nt_s = 5.3\n\\]\nIt is higher than 4s but potentially not too far off..\nIf we started from the settling time requirements we would need to consider what is the vertical line on the root locus plot that meets the requirements on the settling time.\nGiven \\(t_s\\) we can calculate the corresponding \\(\\zeta\\omega_n\\).\nNote that, as usual with our rough plots, the specific point that we pick might not lie exactly on the root locus plot and we need to re-adjust the plot with trial and error (moving along the \\(t_s\\) line with our trial points) until we have refined the plot as needed (the point satisfies the angle condition) and found the correct point corresponding to the desired closed loop poles.\nYou then calculate the corresponding \\(\\zeta\\) and verify if this is acceptable with respect to the requirements.\n\n\n\n\n\n\n\n\n\n3. Calculating the root locus gain \\(K\\)\nGiven the specific point selected, we apply the magnitude condition to calculate the root locus gain, which in this case \\(K=10.5\\), and the corresponding \\(K_A = 10.5/60\\).\n\n\n4. Steady-State Accuracy\nTo ensure that the system reaches the desired final value without error, we use the velocity error constant (\\(K_v\\)).\nThe formula to calculate \\(K_v\\) is:\n\\[\nK_v = \\lim_{s \\to 0} s \\cdot G(s) = \\frac{10.5}{12} = 0.825\n\\]\nWith a steady state error of \\(e_{ss} = 1.14\\) rad.\nThe steady state error is too high to meet our specifications.\nA simple gain cannot meet our requirements unfortunately.\n\n\n\n2.5 Reassessing Design Requirements\nThe damping ratio determines how oscillatory the system’s response will be. A lower \\(\\zeta\\) leads to a more oscillatory response, while a higher \\(\\zeta\\) leads to a more damped system.\nWe often face a trade-off in control system design between transient response (how quickly the system responds to changes) and steady-state accuracy (how accurately the system maintains its output over time).\nThink of it as tuning a car’s suspension: too stiff (high ζ), and it’s not responsive enough; too soft (low ζ), and it oscillates too much.\n\n\n\n\n\n\n\nFigure: For \\(\\zeta = 0.15\\) (K = 60), the complex roots are located at a specific point on the plot and they move a s we modify the gain.\n\n\nIntroducing a Zero to the System\nAs control system designers, we face a trade-off between transient and steady-state performance. By introducing a zero into the system, we can adjust the root locus to meet the transient requirements. However, this may affect the steady-state accuracy. We must carefully reassess the user’s requirements and communicate the trade-offs to them.\nTo strike a balance between transient and steady-state performance, we introduce a zero into the system’s transfer function at \\(s = -3\\). This zero has a stabilizing effect and affects the root locus plot.\nBy introducing a zero at s = -3, we modify the system’s dynamics. This can help balance our transient and steady-state requirements.\n\n\n\n\n\n\n\nThe plot has been pulled to the left, and hence the addition of a zero has stabilised the system. The system was osciallatory and had very poor relative stability properties. Adding a zero improves relative stability, it is similar to increasing the damping of the system. Adding a zero can be thought of as adding a “counter-weight” in our system that helps adjust its dynamic response.\nWe have now a PD compensator which effectively adds a zero to the forward path transfer function, enhancing system stability and response.\n\nUnderstanding the Impact of Adding a Zero\nWhen we say “the plot has been pulled to the left,” we are referring to the root locus plot of our system. This leftward shift is significant because:\n\nStabilization of the System: In control systems, moving the poles of a system to the left in the s-plane (which is what the root locus plot represents) generally means the system is becoming more stable.\nImproving Relative Stability: Originally, our system was oscillatory with poor relative stability. Think of relative stability as the system’s ability to resist oscillations and remain stable under different conditions.\n\n\n\nThe Role of a PD (Proportional-Derivative) Compensator\n\nWhat is a PD Compensator?: A PD compensator is a type of controller used in control systems to improve the stability and response. It adjusts the control signal based on the current error (proportional part) and the rate of change of the error (derivative part).\nEffect of a PD Compensator: By adding a PD compensator to our system, we effectively add a zero to the forward path transfer function. This is like adding a carefully calculated counter-weight to our previously rocky boat, now making it more stable and responsive to changes.\n\nA good way to illustrate this concept is to simulate the system’s response with and without the PD compensator. Let’s how the system’s oscillations decrease and stability improves when the compensator is added.\nNow, let’s write the Python code. We’ll simulate two systems: one without the PD compensator and one with it.\n\n\n\nPython Code to Compare the Systems\nTo demonstrate how a system’s oscillations decrease and its stability improves when a PD compensator is added, compared to a proportional controller, we’ll use Python. We’ll consider two cases: one with a proportional controller and the other with a PD controller.\nFirst, let’s define the system and the controllers:\n\nOriginal System (Proportional Controller): \\[ G(s) = \\frac{K}{s(s+2)(s+6)} \\] For this example, let’s assume ( K = 60K_A ). The exact value of ( K_A ) isn’t specified, so we’ll choose a value that demonstrates the system behavior.\nSystem with PD Controller: \\[ G(s) = \\frac{16(s+3)}{s(s+2)(s+6)} \\] Here, the zero at ( s = -3 ) represents the derivative action of the PD controller.\n\nBoth systems will be in a unity feedback configuration. We’ll use the Python libraries matplotlib for plotting and control for control system analysis.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n\n# Define the transfer function of the original system (Proportional Controller)\nK = 60  # Assuming a value for K\nG_proportional = ctl.TransferFunction(K, [1, 8, 12, 0])\n\n# Define the transfer function of the system with PD Controller\nG_PD = ctl.TransferFunction([16, 48], [1, 8, 12, 0])\n\n# Creating unity feedback loop for both systems\nH = ctl.TransferFunction([1], [1])  # Unity feedback\nclosed_loop_proportional = ctl.feedback(G_proportional, H)\nclosed_loop_PD = ctl.feedback(G_PD, H)\n\n# Time vector for simulation\ntime = np.linspace(0, 10, 1000)\n\n# Step response for the Proportional Controller with unity feedback\nt1, y1 = ctl.step_response(closed_loop_proportional, time)\n\n# Step response for the PD Controller with unity feedback\nt2, y2 = ctl.step_response(closed_loop_PD, time)\n\n# Plotting\nplt.figure()\nplt.plot(t1, y1, label='Proportional Controller (Unity Feedback)')\nplt.plot(t2, y2, label='PD Controller (Unity Feedback)')\nplt.title('Step Response Comparison in Unity Feedback Configuration')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nExpected Outcome\nThe plot generated by this script will show the step responses of the two systems. You should observe that:\n\nThe system with the proportional controller may exhibit more oscillations and a slower response.\nThe system with the PD controller should show improved damping (less oscillation) and faster stabilization, thanks to the added zero at $ s = -3 $.\n\nPop-Up Question: How does adding a zero to a control system’s forward path transfer function affect its stability?\nAnswer: Adding a zero typically improves the system’s stability by making it less oscillatory and more resistant to disturbances, similar to increasing the system’s damping.\nLet’s now consider a \\(\\zeta = 0.6\\) requirement and as usual let’s put it on the root locus plot.\n\n\n\n\n\n\n\nThe forward path transfer function becomes:\n\\[\nG(s) = \\frac{(s+3)}{s(s+2)(s+6)}\n\\]\nWe can then calculate the gain at which we obtain the desired closed loop poles to obtain:\n\\[K = 16\\]\nAnd finally the settling time:\n\\[\nt_s = \\frac{4}{\\zeta\\omega_n} = 1.96\\;\\;sec\n\\]\nand the velocity constant:\n\\[\nK_v = \\frac{16\\cdot3}{12} = 4\n\\]\nWe had a requirement that \\(K_v \\ge 5\\) so we have not fully achieved it, but now with some trial and error we can obtian the performance that we desire.\nDominance condition:the third pole now lies in the \\(-6\\) to \\(-3\\) region and there is the risk that the dominance condition might be violated. If this was the case, we need to mitigate the effect of this pole. For example, if the distance cannot be 5 times we can try and make it at a distance which is three to four times the position of the right-most poles. Alternatively, instead of designing for \\(\\zeta=0.6\\) you can design for some other value.\nSimulation will be helpful to understand the full effects.\nNote also that if the third pole moves close enough to the zero their combined effect in closed-loop will be nullified and the system will behave as a second-order system. The dominance condition is respected.\n\nDealing with the Third Pole\nIn our system, we have a situation where the third pole is located in the region between -6 and -3. This creates a risk that the dominance condition may be violated, meaning this third pole could unduly influence the system’s behavior.\n\n\nStrategies for Mitigating the Third Pole’s Effect\n\nDistance Consideration: Ideally, we want this third pole to be at least five times the distance away from the imaginary axis as the right-most poles. If this isn’t possible, we aim for it to be three to four times the distance.\nDesign Adjustments: If maintaining the desired distance is challenging, we could redesign the system for a different damping ratio (\\(\\zeta\\)), other than 0.6.\nSimulation Benefits: Simulating the system’s response with these variations will provide a clearer picture of how these changes affect performance.\n\nInstructor Note: Conduct a simulation showing the system’s response with the third pole at different distances from the dominant poles and the zero. This will visually demonstrate the impact on system behavior.\nTHE SCRIPT BELOW HAS AN ERROR IN HOW THE RAMP STEADY STEATE ERROR IS CALCULATED. FIX IT.\n\n# %matplotlib inline\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import control as ctl\n# from ipywidgets import interact, FloatSlider\n\n\n# def calculate_settling_time(T, yout, tol=0.02):\n#     # Settling time is the time at which the response remains within a certain tolerance\n#     settled_value = yout[-1]\n#     lower_bound = settled_value * (1 - tol)\n#     upper_bound = settled_value * (1 + tol)\n#     within_tol = np.where((yout &gt;= lower_bound) & (yout &lt;= upper_bound))[0]\n#     if within_tol.size == 0:\n#         return np.nan  # Return NaN if the system never settles\n#     return T[within_tol[0]]\n\n# def calculate_steady_state_error(system_type, G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     if system_type == 'step':\n#         # Steady-state error for step input (Type 0 system)\n#         T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n#         steady_state_val = yout[-1]\n#         return 1 - steady_state_val\n#     elif system_type == 'ramp':\n#         # Steady-state error for ramp input (Type 1 system)\n#         Kv = ctl.dcgain(G_closed_loop * ctl.TransferFunction([1, 0], [1]))\n#         return 1 / Kv if Kv != 0 else np.inf\n#     else:\n#         return np.nan\n\n# def plot_step_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n#     plt.plot(T, yout)\n#     settling_time = calculate_settling_time(T, yout)\n#     steady_state_error = calculate_steady_state_error('step', G, K, time_span)\n#     plt.title(f'Step Response for Gain K={K}\\nSettling Time: {settling_time:.2f}, Steady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n# def plot_ramp_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.forced_response(G_closed_loop, T=time_span, U=time_span)\n#     plt.plot(T, yout)\n#     steady_state_error = calculate_steady_state_error('ramp', G, K, time_span)\n#     plt.title(f'Ramp Response for Gain K={K}\\nSteady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n\n# def plot_root_locus_with_gain(K):\n#     # Define the transfer function G(s)\n#     numerator = [1, 3]\n#     denominator = [1, 8, 12, 0]\n#     G = ctl.TransferFunction(numerator, denominator)\n\n#     # Calculate the closed-loop transfer function for the given gain\n#     G_closed_loop = ctl.feedback(K * G)\n\n#     # Find the poles for the specific gain\n#     poles = ctl.pole(G_closed_loop)\n\n#     # Plot the root locus\n#     plt.figure(figsize=(10, 6))\n#     ctl.root_locus(G, plot=True)\n\n#     # Plot the poles for the specific gain\n#     plt.plot(np.real(poles), np.imag(poles), 'ro', markersize=10, label=f'Poles for K={K}')\n\n#     # Enhance plot\n#     plt.xlabel('Real Axis')\n#     plt.ylabel('Imaginary Axis')\n#     plt.title(f'Root Locus of G(s) with Poles for Gain K={K}')\n#     plt.grid(True)\n#     plt.legend()\n#     plt.show()\n    \n    \n# def plot_all(K):\n#     # Define the transfer function G(s)\n#     numerator = [16, 48]\n#     denominator = [1, 8, 12, 0]\n#     G = ctl.TransferFunction(numerator, denominator)\n    \n#     # Time span for the responses\n#     time_span = np.linspace(0, 10, 1000)\n\n#     # Plot Root Locus\n#     plot_root_locus_with_gain(K)\n\n#     # Plot Step Response\n#     plt.figure(figsize=(10, 4))\n#     plot_step_response(G, K, time_span)\n#     plt.show()\n\n#     # Plot Ramp Response\n#     plt.figure(figsize=(10, 4))\n#     plot_ramp_response(G, K, time_span)\n#     plt.show()\n    \n\n# # interact(plot_root_locus_with_gain, \n# #          K=FloatSlider(value=16, min=0, max=50, step=0.5, description='Gain K:'))\n\n# interact(plot_all, \n#          K=FloatSlider(value=16, min=0, max=50, step=0.5, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_all(K)&gt;\n\n\n\n\nPole-Zero Cancellation\n\nMoving Close to the Zero: If the third pole moves sufficiently close to the zero we’ve added, their effects in the closed-loop system can cancel each other out. This makes the system behave like a second-order system, respecting the dominance condition.\nDesign Flexibility: If the third pole is neither far enough from the dominant poles nor close enough to the added zero, we still have some flexibility. We can utilize the margin we have in the settling time (the time it takes for the system to stabilize) to adjust our design accordingly.\n\nPop-Up Question: Why is it important to respect the dominance condition in control system design?\nAnswer: Respecting the dominance condition ensures that the system behaves in a predictable and stable manner, primarily influenced by the dominant poles, and minimizes the impact of other less significant poles.\n\n\n\nPhysical Realization of the Compensator\nWe have chosen a controller that is\n\\[ D(s) = s + z_c \\]\nwhere $ z_c $ is the compensator zero, and this is added to enhance its transient response and stability.\nIn practice, pure differentiators are avoided due to their sensitivity to high-frequency noise.\nTherefore, this types of compensators are usually implemented with an additional pole to attenuate high frequencies.\nThe practical realization of this compensator includes adding a filter to reduce the impact of high frequency noise.\nThe actual compensator has the form:\n\\[\nD(s) = \\frac{s + z_c}{s + p_c}\n\\]\nHere, $ z_c $ is the zero and $ p_c $ is a pole introduced to filter high-frequency noise.\nThe purpose of this pole is not to help with the compensation part, so we want it to be far away from the rest of our poles and zeros. In our case, for example we could place it at -10 or farther. It might depend on the realisation requirements. Numerical accuracy might put specific constraints on how far it can be.\nThe addition of another pole modifies the root locus which becomes:\n\n\n\n\n\n\n\nThe addition of another pole has a destibilising effect. You need to choose the pole so that the root locus around our requirments is not disturbed. For example, \\(\\zeta=0.6\\) continues to lie on the root locus, and \\(K_v=4\\) continues to be satisfied (at least approximately).\nIn this case the final performance are:\n\\[\n\\zeta = 0.6\n\\]\n\\[\nt_s = 3.33\\;\\; sec\n\\]\n\\[\nK_v = 1.7\n\\]\nThe velocity constant is now poorer! And hence we have higher steady-state error. We might need to adjust the compensator again.\nYou need to adjust the zero-pole pair to achieve the desired performance. We have an additional degree of freedom.\nOverall we can change: \\(z_c\\), \\(p_c\\) and \\(K_A\\).\n\n\nPhase Lead Compensation\nThis type of controller is called Phase Lead Compensator. It adds a lead angle. This will become clearer when we discuss frequency-based design.\n\n\n\n\n\n\n\nThis network can be implemented as:\n\n\n\n\n\n\n\nand its transfer function is:\n\\[\nD(s) =  \\frac{-R_F(sR_1C+1)}{sR_1R_2C+R_1R_2}\n\\]\nand we can adjust the pole and zero locations choosing resistors and capacitors appropriately.\nThe transfer function above can be rearranged to have our typical form as:\n\\[\nD(s) = \\frac{-K_C(\\tau s + 1)}{\\alpha\\tau s + 1}\n\\]\nwhere\n\n\\(\\tau = R_1C\\)\n\\(K_C = \\frac{R_F}{R_1+R_2}\\)\n\\(\\alpha = \\frac{R_2}{R_1+R_2}\\)",
    "crumbs": [
      "Design with the Root Locus"
    ]
  },
  {
    "objectID": "design_with_the_root_locus.html#effects-of-adding-a-pole-at-the-origin",
    "href": "design_with_the_root_locus.html#effects-of-adding-a-pole-at-the-origin",
    "title": "Design with the Root Locus",
    "section": "Effects of Adding a Pole at the Origin",
    "text": "Effects of Adding a Pole at the Origin\nImpact on System Dynamics\nPlacing a pole at the origin significantly affects both the transient and steady-state behavior of the system.\n\nSteady-State Accuracy\nWhen a pole is added at the origin, the system’s type number increases, which in turn increases the steady-state gain $ K_v $ to infinity for a ramp input. This improves the steady-state accuracy.\n\n\nTransient Response\nHowever, adding a pole at the origin can adversely affect the system’s transient response, potentially destabilizing the system for all values of gain $ K $.\n\n\nVisualizing Through Root Locus\nTo demonstrate this, we can draw the root locus of the system with an added pole at the origin.\n\n\n\n\n\n\n\n\n\nAdding a zero close to the origin\nTo recover the stability we have to pull the system to the left, and to do this we can add a zero close to the origin.\nNow the root locus becomes:\n\n\n\n\n\n\n\nWe are now using a controller of the form:\n\\[\nD(s) = \\frac{s+z_c}{z} = 1 + \\frac{z_c}{s} = 1 + \\frac{1}{T_is}\n\\]\nwhich is a PI controller.\n\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\ndef get_closed_loop_system(K, z_c, z=1):\n    # Open-loop transfer function G(s)\n    G = ctl.TransferFunction([K], [1, 8, 12, 0])\n\n    # Compensator D(s)\n    D = ctl.TransferFunction([1, z_c], [z, 0])\n\n    # Combined system\n    open_loop_system = G * D\n\n    # Closing the loop with unity feedback\n    return ctl.feedback(open_loop_system, 1)\n\n\ndef plot_root_locus(K, z_c=1):\n    system = get_closed_loop_system(K, z_c)\n    plt.figure(figsize=(10, 6))\n    ctl.root_locus(system, plot=True)\n    plt.xlabel('Real Axis')\n    plt.ylabel('Imaginary Axis')\n    plt.title(f'Root Locus with Gain K = {K}')\n    plt.grid(True)\n    plt.show()\n\n    \ninteract(plot_root_locus, K=FloatSlider(value=1, min=0, max=100, step=.1, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_root_locus(K, z_c=1)&gt;\n\n\n\n\nPractical Approach: Phase Lag Compensator\nThe design of a phase lag compensator involves carefully selecting the locations of the compensator pole and zero to balance transient and steady-state requirements.\nIf we look back at our original specification, we did not have a specific requirement to have \\(K_v=0\\) (which would have justified placing a pole at the origin).\nInstead of placing the compensator pole exactly at the origin, placing it close to the origin can provide a more balanced design. This approach allows for flexibility in meeting both steady-state and transient accuracy requirements.\nThe compensator takes the form:\n\\[\nD(s) = \\frac{ s + z_c }{  s + p_c }\n\\]\nThis controller provides a negative angle contribution and for this reason is called Phase-Lag controller.",
    "crumbs": [
      "Design with the Root Locus"
    ]
  },
  {
    "objectID": "design_with_the_root_locus.html#phase-lag-compensator-practical-realization",
    "href": "design_with_the_root_locus.html#phase-lag-compensator-practical-realization",
    "title": "Design with the Root Locus",
    "section": "Phase Lag Compensator: Practical Realization",
    "text": "Phase Lag Compensator: Practical Realization\nThe physical realization of a phase lag compensator typically involves using resistors and capacitors to create a network that mimics the desired transfer function.\nA typical phase lag compensator can be realized using an operational amplifier (Op-Amp) circuit. The design involves selecting appropriate resistor and capacitor values to achieve the desired $s + z_c $ and $ s + p_c $ values.",
    "crumbs": [
      "Design with the Root Locus"
    ]
  },
  {
    "objectID": "performance_of_feedback_systems.html",
    "href": "performance_of_feedback_systems.html",
    "title": "Performance of Feedback Systems",
    "section": "",
    "text": "In this notebook, we delve into the quantitative aspects of control system performance. We will build upon our prior qualitative discussions, transitioning from a general understanding of what we expect from a control system to a more rigorous, quantitative specification of performance. This transition is crucial for designing effective control systems.",
    "crumbs": [
      "Performance of Feedback Systems"
    ]
  },
  {
    "objectID": "performance_of_feedback_systems.html#introduction-to-quantitative-performance-specifications",
    "href": "performance_of_feedback_systems.html#introduction-to-quantitative-performance-specifications",
    "title": "Performance of Feedback Systems",
    "section": "",
    "text": "In this notebook, we delve into the quantitative aspects of control system performance. We will build upon our prior qualitative discussions, transitioning from a general understanding of what we expect from a control system to a more rigorous, quantitative specification of performance. This transition is crucial for designing effective control systems.",
    "crumbs": [
      "Performance of Feedback Systems"
    ]
  },
  {
    "objectID": "performance_of_feedback_systems.html#revisiting-qualitative-aspects",
    "href": "performance_of_feedback_systems.html#revisiting-qualitative-aspects",
    "title": "Performance of Feedback Systems",
    "section": "Revisiting Qualitative Aspects",
    "text": "Revisiting Qualitative Aspects\nBefore we advance, let’s briefly recap the qualitative aspects we’ve discussed so far:\n\nStability: The primary requirement for any control system is stability. An unstable system cannot perform its intended function. Stability is the cornerstone of control system performance. A system is considered stable if, in response to a bounded input, it produces a bounded output. In practical terms, this means the system will not exhibit runaway behavior or oscillations that grow indefinitely over time.\nTransient Response: The transient response of a control system is crucial in determining how quickly and accurately it reaches the desired state following a change. Ideal transient behavior is characterized by rapid attainment of the target value with minimal overshoot and reduced oscillations, ensuring efficient and responsive system performance.\nSteady-State Accuracy: In the steady-state phase, where transient effects are no longer significant, the primary focus is on the accuracy with which the system’s output aligns with the commanded value. High steady-state accuracy is vital for most systems to ensure minimal tracking errors and consistent performance over time.\nSensitivity and Robustness: A robust control system maintains its performance reliability even when faced with variations in system parameters or discrepancies in modeling. The goal is to design a system that functions effectively, regardless of whether the actual parameters deviate from those initially used in the design.\nDisturbance Rejection: Effective disturbance rejection is critical, particularly in the steady-state phase of the control system. The system should be designed to minimize the impact of uncontrolled external disturbances, ensuring that the output remains stable and unaffected, both during transients and in steady-state operation.\n\nWith these qualitative requirements outlined, we are now prepared to delve into the quantitative analysis and specification of these aspects.\n\n\n\n\n\n\n#### SIDEBAR - Exploration of Control System Performance Criteria\n\n\n### 1. Stability\n\n\n#### Definition and Importance Stability is the cornerstone of control system performance. A system is considered stable if, in response to a bounded input, it produces a bounded output. In practical terms, this means the system will not exhibit runaway behavior or oscillations that grow indefinitely over time.\n\n\n#### Mathematical Representation - BIBO Stability: A system is Bounded-Input Bounded-Output (BIBO) stable if every bounded input produces a bounded output. Mathematically, if $ |x(t)| &lt; M &lt; $ for all $ t $, then $ |y(t)| &lt; N &lt; $ for all $ t $, where $ x(t) $ is the input, $ y(t) $ is the output, and $ M, N $ are constants. - Routh-Hurwitz Criterion: This criterion provides a method to determine the stability of a system by examining the location of the poles of the system’s transfer function. If all poles are in the left-half of the complex plane, the system is stable.\n\n\n#### Practical Considerations - Stability Margins: In design, it’s not just about achieving stability, but ensuring a degree of robustness in stability, known as stability margins. These margins indicate how much a system’s parameters can vary before it becomes unstable.\n\n\n### 2. Transient Response\n\n\n#### Characterizing Transient Behavior Transient response refers to the system’s reaction from an initial state to reaching its steady state. Key characteristics include: - Rise Time: Time taken for the response to rise from 10% to 90% of its final value. - Settling Time: Time taken for the response to stay within a certain percentage (commonly 2% or 5%) of the final value. - Overshoot: The amount by which the response exceeds the final value. - Damping Ratio: A measure of the oscillations in the response.\n\n\n#### Design Objectives - Speed of Response: A faster rise time is often desirable, but can lead to increased overshoot. - Oscillation Control: Minimizing overshoot and ensuring the system settles quickly without prolonged oscillations.\n\n\n### 3. Steady-State Accuracy\n\n\n#### Understanding Steady-State Once transient effects have diminished, a system enters steady-state. Here, the output should ideally match the commanded value as closely as possible.\n\n\n#### Measures of Steady-State Accuracy - Error Metrics: Common measures include steady-state error, tracking error, and error constants like position, velocity, and acceleration error constants. - System Type and Error: The type of control system (Type 0, Type 1, etc.) determines its ability to handle different kinds of steady-state errors, particularly for step, ramp, and parabolic inputs.\n\n\n#### Designing for Accuracy - Feedback Control: Incorporating feedback effectively reduces steady-state error. - Integral Control: Adding an integral component can eliminate steady-state error for certain types of inputs.\n\n\n### 4. Sensitivity and Robustness\n\n\n#### Resilience to Variations Sensitivity and robustness measure a system’s ability to maintain performance despite changes in system parameters or environmental conditions.\n\n\n#### Quantitative Analysis - Sensitivity Function: This function quantifies how sensitive the system’s output is to changes in a particular parameter. - Robust Design Techniques: Methods like H-infinity and μ-synthesis are used to design systems that maintain performance over a range of uncertainties.\n\n\n#### Practical Application - Worst-Case Analysis: Assessing system performance under extreme variations to ensure robust operation.\n\n\n### 5. Disturbance Rejection\n\n\n#### Minimizing External Impact Control systems often operate in environments with external disturbances. Effective disturbance rejection minimizes the impact of these disturbances on the system’s output.\n\n\n#### Evaluating Disturbance Rejection - Transient Response to Disturbance: Observing how quickly and effectively the system mitigates the impact of a disturbance. - Steady-State Error due to Disturbance: Ensuring that, in steady-state, the disturbance has minimal or no impact on the output.\n\n\n#### Control Strategies - Feedforward Control: Anticipating disturbances and compensating for them before they affect the system. - Feedback Control: Adjusting system behavior in response to disturbances detected in the output.\n\n\n— END OF SIDEBAR\n\n\n## Transition to Quantitative Specifications\n\n\nIn control system design, we often start by specifying: - the desired transient - and steady-state accuracy.\n\n\nOnce a system is designed with these specifications, we then evaluate its performance in terms of robustness and disturbance rejection.\n\n\nNote: Current research in control system design is evolving towards including sensitivity and robustness in the initial design phase itself. However, this is still an emerging area and not widely incorporated in standard curricula. We will focus on the classical way of control design, and this will provide the base to understand robustness and sensitivity.\n\n\n### Classical Approach in Control System Design\n\n\nIn the traditional methodology of control system engineering, the primary focus is initially set on transient and steady-state accuracy. This methodical approach encompasses several key steps:\n\n\n1. Assurance of System Stability: This initial phase involves the application of analytical tools such as the Routh stability criterion. These tools are employed to ascertain the stability conditions of the system by determining the specific ranges of parameters that ensure stability. The stability of the system is a primary requirement. If this does not hold everything else does not matter.\n\n\n2. Optimization for Transient and Steady-State Performance: The next step is the careful selection of system parameters. These parameters are chosen from within the identified stability domains with the objective of achieving the desired levels of transient and steady-state accuracy. This selection process is crucial for the system to respond effectively to changes and maintain accuracy over time. This is the quantitative specification of the system performance.\n\n\n3. Assessment of Robustness and Disturbance Rejection Capabilities: The final phase involves a thorough simulation of the control system. This simulation is critical to evaluate whether the system meets predefined standards for robustness and its ability to reject disturbances. If these standards are not met, it triggers a re-evaluation and redesign of the control strategy. This iterative nature of design acknowledges that achieving optimal performance often requires multiple adjustments and refinements.\n\n\nBy following these steps, the classical approach ensures a comprehensive and iterative development process, aiming to create a control system that is stable, accurate, robust, and capable of effectively rejecting disturbances.\n\n\n### Design Methodology for Control System: Stability, Accuracy, and Robustness Assessment\n\n\n1. Identifying Stability Domains of Parameters: - The initial step in the design of a control system involves determining the conditions under which the system will remain stable. - Stability, in control systems, means that the system will not exhibit unbounded or erratic behavior in response to a given input. - To find these conditions, we use analytical methods like the Routh stability criterion. This criterion helps in identifying the ‘domains’ or ranges of system parameters (like gain, damping ratio, etc.) that ensure the system remains stable. - For example, we might solve problems where we manipulate one or two parameters (like adjusting the gain of a controller) to see how these changes affect system stability.\n\n\n2. Ensuring Transient and Steady-State Accuracy: - Once we’ve identified the stability domains, the next step is to refine the system parameters within these domains. - This refinement aims to achieve specific performance goals related to how the system responds over time (transient performance) and how accurately it maintains its output in the long term (steady-state performance). - Transient accuracy involves how quickly and effectively the system responds to changes, while steady-state accuracy focuses on how closely the system’s output matches the desired output after initial fluctuations have settled.\n\n\n3. Evaluating Robustness and Disturbance Rejection: - After satisfying the transient and steady-state requirements, we return to the original system configuration. - Here, we simulate the system under various conditions to assess its robustness (how well it performs under different operating conditions or parameter variations) and its ability to reject disturbances (how well it maintains its performance in the presence of unexpected external influences). - If the system fails to meet the robustness or disturbance rejection criteria, the design process may need to be revisited. This might involve adjusting the parameters again or even redesigning certain aspects of the system.\n\n\nBy following this structured approach, we ensure that the control system we design is not only stable but also meets specific performance criteria in both the short and long term, and is resilient to external disturbances and internal parameter changes. This comprehensive evaluation is crucial for creating a reliable and efficient control system.\n\n\n## Exploring Transient Performance Specifications\n\n\n### Unity-Feedback Systems\n\n\nFor simplicity, we’ll consider a unity-feedback system, though the principles apply to non-unity-feedback systems as well.\n\n\n\n\n\n- The system transfer function is:\n\n\n\\[ Y(s) / R(s) = G(s) / (1 + G(s)) \\]\n\n\n- Here, $ Y(s) $ is the output, $ R(s) $ is the input, and $ G(s) $ is the system’s transfer function.\n\n\n### Nature of Input Signals\n\n\nIn practical control systems, the nature of the input signal is unpredictable. Therefore, we use standard test signals (step, ramp, parabola) to design and evaluate the system. If they system performs well for these signals, it should perform well for any other signal.\n\n\nThe transient performance is depended by the system’s poles and is relatively independent of the input signal’s nature.\n\n\nFor example, if the poles are on the LHP, the transient will die out. The transient hence is dependent on the system’s characteristic and not on the specific input.\n\n\nIn other words, in control system design, it’s crucial to evaluate how the system will respond to various types of input signals. Since it’s impractical to predict every possible input a system might encounter in real-world operations, we use standard test inputs as benchmarks. These include step, ramp, and parabolic signals, among others.\n\n\n- Step Input: This is a sudden change, typically from zero to a fixed value. It’s useful for observing the system’s immediate reaction and its transient response characteristics.\n\n\n- Ramp Input: This input increases linearly over time, representing a continuously changing setpoint. It helps in understanding how the system tracks a gradually varying input and can be particularly revealing for systems where the rate of change of the input is significant.\n\n\n- Parabolic Input: This represents a scenario where the input changes at an accelerating rate, providing insights into how the system handles more complex, dynamically changing conditions.\n\n\nThe choice of these test signals is not arbitrary. They are selected because they effectively excite different aspects of the system’s behavior. The step input tests the system’s basic stability and transient response. The ramp input examines the system’s ability to keep up with a continuously changing setpoint, which is crucial for tracking performance. The parabolic input, by introducing an accelerating change, challenges the system’s responsiveness to more complex and dynamic inputs.\n\n\nBy designing a control system that performs satisfactorily with these standard test inputs, we can infer that it will likely handle a wide range of real-world inputs effectively. This approach simplifies the design process by reducing the infinite variety of possible inputs into a manageable set of standard tests, each focusing on a critical aspect of system performance.\n\n\n### Utilizing Step Input for Transient Response Analysis\n\n\n- In the context of transient response analysis, the step input, represented by a unit-step function $ (t) $, is commonly employed. - The underlying reasoning for this choice is that a step input is particularly effective in stimulating all the modes of the system. This comprehensive excitation enables a detailed observation and analysis of the system’s transient response. It’s important to note that the stability and transient characteristics of a control system are primarily determined by the locations of its poles, which are inherent properties of the system itself, rather than the nature of the input signal. Therefore, by using the simplest form of test input, the step input, we can efficiently evaluate the system’s behavior without the need for more complex input forms. This approach simplifies the analysis while still providing a thorough understanding of the system’s transient dynamics.\n\n\nFor this reason, the unit-step input is used to quantitatively specify the transient characteristics of the system. Note also that a larger ampliture does not change the nature of the response, it will only change the amplitude of the response.\n\n\n\n\n\n🤔Pop-up Question: Why do we prefer a unit-step input for transient analysis?\n\n\nAnswer: A unit-step input simplifies the analysis and is effective in exciting all system modes, making it ideal for observing the transient behavior of the system.\n\n\n## Steady-State Performance Specifications\n\n\n### Dependency on Input and System Characteristics\n\n\nUnlike transient performance, the steady-state response depends on both the system characteristics and the nature of the input signal. Therefore, a single type of input signal may not suffice to fully characterize steady-state performance.\n\n\nIdeally, to thoroughly characterize the steady-state behavior, the actual input that the system will encounter in real-world operations would be required. However, in practical scenarios, this specific input may not always be predetermined or known in advance. As a result, the necessity arises to utilize standardized test signals. These test signals serve as proxies to approximate a range of possible real-world inputs, thereby enabling a more robust evaluation of the system’s steady-state performance under various hypothetical conditions.\n\n\n## Dealing with Unknown Inputs in Control Systems\n\n\n### Real-World Examples and the Challenge of Unpredictable Inputs\n\n\nWhen designing control systems, we often face the challenge of unknown or variable inputs. Let’s explore this through a few examples:\n\n\n#### Example 1: Tracking Radar System - Scenario: A radar system designed to track aircraft movements. - Challenge: Predicting the exact motion profile of the aircraft is nearly impossible. The system must be adaptable to various possible trajectories.\n\n\n#### Example 2: Numerical Control of Machine Tools - Situation: Machines designed for cutting or shaping materials. - Complexity: The machine could be required to perform a range of tasks, from tapering to cutting parabolic profiles. The system must handle any shape it’s tasked with.\n\n\n#### Example 3: Residential Heating System - Condition: Variability in environmental temperatures across seasons. - Impact: This variation significantly changes the disturbance signals the system must handle, from summer to winter.\n\n\nIn each of these cases, the control system’s input and the disturbance signals it encounters cannot be precisely predetermined. This uncertainty directly affects the steady-state performance, which is inherently dependent on the nature of the input.\n\n\n### Addressing Unpredictable Inputs\n\n\n#### Polynomial Representation of Inputs\n\n\nTo overcome the challenge of unpredictable inputs, a strategy is to represent the actual input as a sum of polynomial functions. Mathematically, any complex function can be decomposed into a series of simpler polynomial functions. Thus, ensuring satisfactory performance for a range of polynomial inputs can provide confidence that the system will perform well for various real-world inputs.\n\n\n- Polynomial Function Representation:\n\n\nAccording to the previous discussion we can see the input \\(r(t)\\) as a generic polynomial function indexed by \\(k\\):\n\n\n\\[ r(t) = \\frac{1}{k!} t^k \\mu(t) \\]\n\n\nHere, $ r(t) $ is a polynomial function of time, $ k $ is the order of the polynomial, and $ (t) $ is the unit-step function.\n\n\n#### Standard Polynomial Inputs for Steady-State Performance\n\n\nFor different values of $ k $, we get various standard test inputs:\n\n\n- $ k = 0 $: $ r(t) = (t)$ becomes a unit-step function. - $ k = 1 $: $ r(t) = t (t)$ represents a ramp function. - $ k = 2 $: $ r(t) = t^2(t)$ forms a parabolic function.\n\n\nAs $ k $ increases, the input becomes faster, but in practical scenarios, values of $ k $ beyond 2 are rarely needed. This is because real-world system inputs are generally not as fast as higher-order polynomials. Therefore, in most cases, satisfying the performance criteria for $ k = 1 $ (ramp function) and $ k = 2 $ (parabolic function) is sufficient.\n\n\n#### Practical Considerations in Control Design\n\n\n- Complexity and Stability: As the order $ k $ increases, control system design becomes more challenging, particularly regarding maintaining stability. For $ k &gt; 3 $ maintaining stability is very difficult.\n\n\n- Industrial Relevance: For many industrial applications, a value of $ k = 1 $ is often sufficient, aligning with practical requirements.\n\n\nMoving forward, our analysis will concentrate on three fundamental test inputs, each characterized by their unique time-dependent behavior and their distinctive “unit” nature, derived from the property that their derivatives are scaled to unity:\n\n\n1. Unit-Step Function: - Mathematical Representation: $ r(t) = (t) $ - Characteristics: This function represents a sudden change at $ t = 0 $, transitioning sharply from 0 to 1. It is termed ‘unit-step’ because its derivative, a delta function, peaks at unit height.\n\n\n2. Unit-Ramp Function: - Expression: $ r(t) = t (t) $ - Description: This linearly increasing function symbolizes a ramp input that starts at $ t = 0 $ and increases at a constant rate. The ‘unit’ designation is due to its derivative being constant (unity) over time.\n\n\n3. Unit-Parabola Function: - Formulation: $ r(t) = t^2 (t) $ - Explanation: This function represents a parabolic curve, starting at $ t = 0 $ and increasing quadratically over time. The factor \\(\\frac{1}{2}\\) ensures that the derivative of this function, $ t (t) $, aligns with the unit-ramp function, hence the term ‘unit-parabola’.\n\n\nEach of these inputs serves as a standard test signal in control systems analysis, providing a basis for examining system responses under different types of input scenarios.\n\n\n## Transient Performance Specifications\n\n\n### Industry-Based Approach\n\n\nInstead of relying solely on mathematical models, an industry-based approach involves examining real-world control systems. By exciting these systems with a standard step input and observing their response, we can derive practical transient performance specifications.\n\n\n### Observations and Indices for Transient Performance\n\n\n- Typical Response: The transient response of a practical control system often exhibits damped oscillations before reaching steady state.\n\n\n\n\n\n- Acceptability of Oscillations: Some overshoot is generally acceptable in practical scenarios.\n\n\n### Key Performance Indices\n\n\n1. Rise Time ($ t_r $): This is the duration required for the system’s response to initially reach the final value (or steady-state level) 100% for the first time. It provides insight into the response speed of the system following a change.\n\n\n2. Peak Overshoot ($ M_p $): This parameter measures the maximum level by which the system’s response exceeds its final value. If the peak overshoot is within acceptable limits, it is generally assumed that any subsequent fluctuations in magnitude will also be acceptable, as they are typically smaller.\n\n\n3. Peak Time ($ t_p $): This refers to the time elapsed from the initiation of the response until it reaches its maximum overshoot. It indicates how quickly the system reaches its peak response following a disturbance or a change.\n\n\n4. Settling Time: This is the time required for the system’s response to consistently remain within a specific tolerance range around the final value. The tolerance range, often set at 2% or 5% of the final value, varies based on the accuracy requirements of the application. This metric is crucial for determining how quickly the system stabilizes following transient fluctuations.\n\n\n#### Additional Note on Mathematical Characterization of Settling Time:\n\n\nConsider a function of the form \\(e^{-t/\\tau}\\), which represents an exponential decay.\n\n\nMathematically, such a function only completely settles as \\(t\\) approaches infinity (\\(t \\rightarrow \\infty\\)).\n\n\nIn other words, its theoretical settling time is infinite. However, in practical control system analysis and design, we define a settling time within a band of practical acceptability to reflect realistic operating conditions. This approach acknowledges that, in practice, a system is considered ‘settled’ when its response is close enough to the steady-state value, even if it hasn’t reached it exactly.\n\n\nFinally, it is worth noticing that we will tackle steady-steady accuracy separately because it is not only specified for a unit-step but also for ramp and parabolic inputs.\n\n\nGiven these four parameters, we can almost reconstruct the step reponse.\n\n\n### Exploring Transient Dynamics in Second-Order Systems: An Interactive Simulation\n\n\nWe can see the effect of changing these parameters using the following python code.\n\n\n#### Instructions for Use:\n\n\n1. Zeta Slider: Adjust this slider to change the damping ratio of the system. A lower value means less damping (more oscillatory response), and a higher value means more damping (less oscillatory response). 2. Omega_n Slider: This slider changes the natural frequency of the system. A higher natural frequency generally leads to a faster response.\n\n\n3. Sim Time Slider: This slider changes the simulation time.\n\n\nWith these sliders, you can observe how varying the damping ratio and natural frequency affects the transient response of a stable second-order system.\n\n\n::: {#8ee42504 .cell} ``` {.python .cell-code} # Import necessary libraries import numpy as np import matplotlib.pyplot as plt import control\n\n\ndef find_max_consecutive_index(arr): max_consecutive_index = None consecutive_start = None\n\n\nfor i in range(len(arr) - 1): if arr[i] + 1 != arr[i + 1]: if consecutive_start is not None: max_consecutive_index = consecutive_start consecutive_start = None elif consecutive_start is None: consecutive_start = i + 1\n\n\n# Check if the entire array is consecutive if consecutive_start is not None: max_consecutive_index = consecutive_start\n\n\nreturn max_consecutive_index if max_consecutive_index is not None else len(arr) - 1\n\n\n# Define a function to calculate and plot the system response with performance parameters def plot_response(zeta, omega_n, sim_time): # System parameters: zeta (damping ratio), omega_n (natural frequency) num = [omega_n**2] # Numerator (assuming unit gain) den = [1, 2 * zeta * omega_n, omega_n**2] # Denominator\n\n\n# Create a transfer function model system = control.tf(num, den)\n\n\n# Time parameters t = np.linspace(0, sim_time, int(sim_time*100)) # Time vector\n\n\n# Step response t, y = control.step_response(system, t) steady_state_value = y[-1]\n\n\n# Rise Time rise_time_indices = np.where(y &gt;= steady_state_value)[0] rise_time = t[rise_time_indices[0]] if rise_time_indices.size else None\n\n\n# Peak Overshoot and Peak Time peak_overshoot = np.max(y) - steady_state_value peak_time = t[np.argmax(y)]\n\n\n# Settling Time (within 2% of steady-state value). This is found numerically. settling_time_indices = np.where(abs(y - steady_state_value) &lt;= 0.02 * steady_state_value)[0] ts_index = find_max_consecutive_index(settling_time_indices) settling_time = t[settling_time_indices[ts_index]] if settling_time_indices.size else None\n\n\n# Plot plt.figure(figsize=(10, 6)) plt.plot(t, y, label=‘System Response’) plt.axhline(steady_state_value, color=‘r’, linestyle=‘–’, label=‘Steady State’) # tolerange band (0.02 percent) plt.axhline(steady_state_value * 1.02, color=‘g’, linestyle=‘:’, label=‘Settling Time Bound’) plt.axhline(steady_state_value * 0.98, color=‘g’, linestyle=‘:’)\n\n\nif rise_time: plt.axvline(rise_time, color=‘y’, linestyle=‘-’, label=f’Rise Time: {rise_time:.2f}s’) plt.axvline(peak_time, color=‘b’, linestyle=‘-’, label=f’Peak Time: {peak_time:.2f}s’) plt.scatter(peak_time, np.max(y), color=‘black’, label=f’Peak Overshoot: {peak_overshoot:.2f}’)\n\n\nif settling_time: plt.scatter(settling_time, y[settling_time_indices[ts_index]], color=‘purple’) plt.axvline(settling_time, color=‘purple’, linestyle=‘-’, label=f’Settling Time: {settling_time:.2f}s’)\n\n\nplt.title(‘Transient Response with Performance Parameters’) plt.xlabel(‘Time (seconds)’) plt.ylabel(‘Output’) plt.legend() plt.grid(True) plt.show()\n\n\n# Interactive sliders from ipywidgets import interact, FloatSlider interact(plot_response, zeta=FloatSlider(value=0.3, min=0.01, max=1.0, step=0.01), omega_n=FloatSlider(value=2, min=1, max=10, step=0.1), sim_time=FloatSlider(value=10, min=1, max=50, step=1)) ```\n\n\n::: {.cell-output .cell-output-display}\n\n\n{=html} &lt;script type=\"application/vnd.jupyter.widget-view+json\"&gt; {\"model_id\":\"95764ec2f5204f0a954d0b87d489585a\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"} &lt;/script&gt;\n\n\n:::\n\n\n::: {.cell-output .cell-output-display}",
    "crumbs": [
      "Performance of Feedback Systems"
    ]
  },
  {
    "objectID": "performance_of_feedback_systems.html#design-challenges-and-steady-state-performance-in-control-systems",
    "href": "performance_of_feedback_systems.html#design-challenges-and-steady-state-performance-in-control-systems",
    "title": "Performance of Feedback Systems",
    "section": "Design Challenges and Steady-State Performance in Control Systems",
    "text": "Design Challenges and Steady-State Performance in Control Systems\nAs we delve deeper into the realm of control system design, we encounter a crucial aspect that significantly impacts the effectiveness of a system: the inherent conflict among design parameters. This section explores this conflict and its implications for system performance.\n\nUnderstanding the Conflict\nIn control systems, certain desirable qualities are inherently at odds with each other. For example:\n\nRise Time ($ t_r $): Ideally, we want $ t_r $ to be as small as possible. A smaller $ t_r $ implies a faster system response, avoiding sluggish behavior. However, reducing $ t_r $ often comes at a cost.\nPeak Time ($ t_p $): We also desire $ t_p $ to be small for the system to quickly reach its peak and then settle. Similarly, a small $ t_p $ can have adverse effects on other system parameters.\nSettling Time ($ t_s \\()** and **Peak Overshoot (\\) M_p $): Both these parameters should ideally be small. However, efforts to minimize one often result in increasing the other.\n\nThis conflict arises because the system’s dynamic characteristics are interconnected. Adjusting one parameter to improve a certain aspect of the system’s performance can inadvertently worsen another aspect.\n\nExample: Trade-off in Design\nConsider a scenario where reducing the rise time results in a larger peak overshoot. This is a common trade-off in control systems. A system that responds quickly (small $ t_r $) might overshoot its target significantly (large $ M_p $), potentially leading to instability or inefficiencies.\n\n\n\nSteady-State Performance Specifications\nMoving on to steady-state performance, let’s consider the unity-feedback system with error function $ e(t) $ defined as $ r(t) - y(t) \\(. The steady-state error (\\) e_{ss} $) is given by:\n\\[ e_{ss} = \\lim_{t \\to \\infty} [r(t) - y(t)] \\]\n\n\n\n\n\n\n\nSteady-State Error Specifications for Various Inputs\nIn control systems, the steady-state error ($ e_{ss} $) is a key metric for evaluating how well the system maintains its output in line with the desired input over time. The steady-state error varies depending on the type of input signal applied to the system. Commonly considered input types include:\n\nUnit Step Input: When a unit step function $ r(t) = (t) $ is applied, the steady-state error $ e_{ss} $ evaluates how closely the system’s output matches a constant value after initial transients have died out. It’s a measure of the system’s ability to maintain a steady output in response to a sudden, fixed change in input.\nUnit Ramp Input: For a ramp input $ r(t) = t (t) $, which increases linearly over time, the steady-state error $ e_{ss} $ assesses the system’s capability to track a continuously changing input. A ramp input challenges the system’s ability to adjust its output at a rate matching the input’s rate of change.\nUnit Parabola Input: With a parabolic input $ r(t) = t^2 (t) $, representing an input that changes at an accelerating rate, the steady-state error $ e_{ss} $ indicates the system’s performance in tracking an input with increasing acceleration.\n\n\n\nThe Significance of “And/Or” in Specifications\nThe steady state specifications are typically defined as: \\(e_{ss}|_{\\mu(t)}\\) and/or \\(e_{ss}|_{t\\mu(t)}\\) and/or \\(e_{ss}|_{.5t^2\\mu(t)}\\).\nThe term “and/or” in the context of these specifications implies flexibility in the system requirements. Not all systems need to excel in responding to every type of input. Depending on the application’s needs, the design criteria can be tailored:\n\nLess Stringent Requirements: If the application doesn’t demand high accuracy for varying input types, specifying $ e_{ss} $ for just a unit step input might be adequate. This scenario simplifies the design process, as the system only needs to be optimized for a constant input after the initial transient period.\nStringent and Diverse Requirements: In contrast, if an application requires precise tracking of inputs that change over time (like ramp or parabolic inputs), then the system must also satisfy $ e_{ss} $ for these types of inputs. This requirement makes the design process more complex. The system must be versatile enough to handle not just a constant input but also inputs that change linearly or quadratically over time.\n\n🤔 Pop-Up Question: Why does specifying $ e_{ss} $ for multiple input types complicate the design process?\nAnswer: Specifying $ e_{ss} $ for various input types like step, ramp, and parabola imposes multiple constraints on the system. Each type of input tests different aspects of the system’s behavior, and designing a system that performs well for all these inputs requires more intricate tuning of the system parameters.\n\n\nAnalyzing System Response to Unit-Step, Unit-Ramp, and Unit-Parabola Inputs\nTo gain deeper insights into this aspect, let’s explore the behavior of a system when subjected to input signals such as the unit-step, unit-ramp, and unit-parabola. The following code demonstrates this analysis.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n# Define system parameters (modify as needed for your example)\nKp = 1.0    # Proportional gain\nomega_n = 1.0  # Natural frequency\nzeta = 0.5  # Damping ratio\nnum = [Kp * omega_n**2]\nden = [1, 2 * zeta * omega_n, omega_n**2]\n\n# Create transfer function\nG = control.tf(num, den)\n\n# Time vector\nt = np.linspace(0, 20, 1000)\n\n# Unit Step Input\nt_step, y_step = control.step_response(G, t)\ne_step = 1 - y_step  # Steady-state error for step input\n\n# Unit Ramp Input\nt_ramp, y_ramp = control.forced_response(G, t, t)\ne_ramp = t - y_ramp  # Steady-state error for ramp input\n\n# Unit Parabola Input\nt_parabola, y_parabola = control.forced_response(G, t, t**2 / 2)\ne_parabola = t**2 / 2 - y_parabola  # Steady-state error for parabola input\n\n# Plotting\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.plot(t_step, y_step, label='Response')\nplt.plot(t_step, np.ones_like(t_step), 'r--', label='Step Input')\nplt.plot(t_step, e_step, 'g:', label='Error')\nplt.title('Response to Unit Step Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(t_ramp, y_ramp, label='Response')\nplt.plot(t_ramp, t_ramp, 'r--', label='Ramp Input')\nplt.plot(t_ramp, e_ramp, 'g:', label='Error')\nplt.title('Response to Unit Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t_parabola, y_parabola, label='Response')\nplt.plot(t_parabola, t_parabola**2 / 2, 'r--', label='Parabola Input')\nplt.plot(t_parabola, e_parabola, 'g:', label='Error')\nplt.title('Response to Unit Parabola Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Performance of Feedback Systems"
    ]
  },
  {
    "objectID": "performance_of_feedback_systems.html#the-robustness-of-design",
    "href": "performance_of_feedback_systems.html#the-robustness-of-design",
    "title": "Performance of Feedback Systems",
    "section": "The Robustness of Design",
    "text": "The Robustness of Design\nA critical aspect of control system design is ensuring robustness. Robustness refers to the system’s ability to maintain satisfactory performance under a range of conditions, particularly when the actual system parameters vary from the nominal values used in the design.\n\nSimulation as a Key Tool in Design Validation\n\nVarying Model Parameters: When designing a control system, you initially work with a mathematical model that represents the physical system. However, this model is based on certain assumptions and nominal parameters. In reality, the actual physical system may exhibit variations in these parameters due to manufacturing tolerances, environmental changes, aging, or other factors.\nClosing the Gap Between Model and Reality: To ensure that your control system design is robust and effective in real-world conditions, you need to account for possible deviations from the nominal model. This is where simulation plays a crucial role. By varying the parameters of the model within a reasonable range, you can simulate how the actual system might behave under different scenarios.\nSimulation Approach:\n\nYou adjust various parameters of the system model — such as gain values, time constants, damping ratios, etc. — within their expected ranges of variation.\nYou then run simulations to observe how these changes affect the performance of the control system. This approach helps identify potential weaknesses or failure points in the design.\n\nEvaluating Design Robustness: The goal is to ensure that the control system still meets the desired performance criteria (like stability, transient response, steady-state error) under these varied conditions. If the system performs satisfactorily across a wide range of parameter variations, it indicates a robust design.\nFinal Stage of Design: This process is critical before finalizing a design. If the design holds up well in these simulations, it gives confidence that it will perform reliably when implemented in the actual physical system. Essentially, this step is about stress-testing your design against the uncertainties and variabilities of real-world applications.\n\n\n\nWhy Simulation is Essential\n\nBridging Theory and Practice: Simulations bridge the gap between theoretical models and practical applications. They provide a controlled environment to test how the system might respond to real-world unpredictability.\nCost-Effective and Safe Testing: It allows for extensive testing without the costs and risks associated with experimenting on physical systems, especially where failures can be expensive or dangerous.\nIterative Improvement: The insights gained from simulation studies can lead to iterative improvements in the design, enhancing the system’s performance and reliability.\n\nIn summary, simulation is an indispensable step in control system design, providing a platform to test and refine the system under a variety of conditions, ensuring that the final design is not only theoretically sound but also practically viable and robust.",
    "crumbs": [
      "Performance of Feedback Systems"
    ]
  },
  {
    "objectID": "stability.html",
    "href": "stability.html",
    "title": "Stability Analysis in Control Systems",
    "section": "",
    "text": "Today, we embark on an exploration of the stability problem, a pivotal and essential aspect in the realm of control system design. Adjustments in controller parameters, fundamental to any design process, must invariably adhere to the domain of stability. Fulfilling stability conditions is not just a requirement, but a cornerstone of successful system design. To grasp this complex topic, we will first tap into our intuitive understanding of stability. This foundational knowledge will then serve as a springboard for delving into more quantitative and analytical methods. Let’s embark on this journey to demystify the principles of stability in control systems.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability.html#bibo-stability",
    "href": "stability.html#bibo-stability",
    "title": "Stability Analysis in Control Systems",
    "section": "BIBO Stability",
    "text": "BIBO Stability\nBIBO stability is a critical concept in the study of control systems, especially for linear time-invariant systems.\nIn BIBO stability, we consider a system that is initially relaxed, which means that at time $ t = 0 $, all state variables $ x $ are at zero (unexcited), and the system has no initial energy stored.\n\\[\n\\textbf{x}(t=0)=\\textbf{0}\n\\]\nThis scenario provides a reference point for analyzing how the system responds to external inputs.\n\nNote that \\(t=0\\) is a reference time, for Linear Time Invariant (LTI) systems is your initial time. The stability analysis for time variant and/or non-linear systems is more complex and beyond the scope of this course.\nThis assumption simplifies the stability analysis as we can focus on the transfer function model to analyze stability.\n\nFor a relaxed system, the initial energy is zero and this means that all state variables are not excited and we can safely neglect them. Since all initial conditions are zeros we can study the stability only in terms of its transfer function (which completely characterise relaxed systems).\nThe key principle here is that if the external input $ r $ is bounded, then the output $ y $ should also remain bounded.\n\nQuantitative Analysis of BIBO Stability\nThe quantitative method to establish BIBO stability involves ensuring that the output $ y $ remains bounded for any bounded input $ r $.\n\nThis principle applies regardless of the nature of the input, whether it’s a desired command input or a disturbance from the environment.\nThe boundedness of the output is a fundamental requirement for a control system to be considered stable under BIBO criteria.\nIn BIBO stability, we focus on the response of the system to external inputs (command and disturbance) while assuming zero initial energy.\nThe stability can be analyzed using the transfer function model, as a relaxed system can be fully described by this model.\nThe aim is to ensure that for any bounded input $ r $, the output $ y $ remains bounded.\n\n\n\nExample for BIBO Stability\n\nConsider a system with a step input. If the step input is bounded, the output response of the system should also exhibit bounded behavior, not growing indefinitely.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability.html#zero-input-stability",
    "href": "stability.html#zero-input-stability",
    "title": "Stability Analysis in Control Systems",
    "section": "Zero-Input Stability",
    "text": "Zero-Input Stability\nThe second aspect of our stability study is zero-input stability, where the external input is assumed to be zero.\nHowever, the initial state $ x_0 $ can change due to external inputs, affecting the energy storage in the system.\nThe mathematical model for zero-input stability is represented by:\n\\[\n\\dot{x} = Ax\n\\]\nwhere $ x(t = 0) = x_0 $.\n\nThe focus here is on whether the system state $ x(t) $ remains bounded for all $ t $ when varying $ x_0 $. If so, the system preserves zero-input stability.\n\n\nSummary\n\nZero-input stability considers the system’s response when external inputs are assumed to be zero.\nThe focus is on how variations in the initial state $ x_0 $ affect the system’s state $ x(t) $ over time.\nThe goal is to ensure that the system’s states remain bounded for all time $ t $ under zero external input.\n\nWe call a time-invariant system where the input is zero, an autonomous system. This concept is crucial for studying zero-input stability.\nPop-up Question: Why is zero-input stability important, and how does it differ from BIBO stability?\nAnswer: Zero-input stability focuses on the system’s behavior in the absence of external inputs, emphasizing the system’s response based on its initial state. It differs from BIBO stability, which deals with the system’s response to external bounded inputs, ensuring the output remains bounded.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability.html#combining-bibo-and-zero-input-stability",
    "href": "stability.html#combining-bibo-and-zero-input-stability",
    "title": "Stability Analysis in Control Systems",
    "section": "Combining BIBO and Zero-Input Stability",
    "text": "Combining BIBO and Zero-Input Stability\n\nFor a linear system, if both BIBO and zero-input stability conditions are satisfied, it can be inferred that for any bounded inputs $ r $ and $ w $, the system states and output will remain bounded.\n\n\nBIBO Stability and Impulse Response\n\nThe impulse response $ g(t) $ of a system provides a complete characterization of a relaxed system. The output of the system is given by:\n\n\\[\ny(t) = \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau\n\\]\nwhere \\(r(t)\\) is the input.\nSince we are interested in BIBO stability, this means we are interested in amplitudes. In this case, the following relationship holds:\n\\[\n|y(t)| = \\Big| \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau \\Big| \\le \\int_{0}^{\\infty} |g(\\tau)| |r(t-\\tau)| d\\tau\n\\]\nIf the input is bounded, i.e., \\(|r(t-\\tau)| \\le M\\), with \\(M\\) finite,\n\\[\n|y(t)| = \\Big| \\int_{0}^{\\infty} g(\\tau)r(t-\\tau) d\\tau \\Big| \\le \\int_{0}^{\\infty} |g(\\tau)| |r(t-\\tau)| d\\tau \\le M \\int_{0}^{\\infty} |g(\\tau)| d\\tau \\le N &lt; \\infty\n\\]\nThis means that for BIBO stability, the integral of the modulus of the impulse response should be finite.\nThe integral of the modulus of the impulse response of the system characterizes BIBO stability. Specifically, a system is BIBO stable if and only if:\n\\[\n\\int_{0}^{\\infty} |g(t)| dt &lt; \\infty\n\\]\nThis condition implies that the area under the absolute value curve of the impulse response must be finite.\n\nPoles, Zeros, and Transfer Function Analysis\nNow, let’s translate our understanding to the poles and zeros requirements, as reflected in the transfer function model of a control system. Consider the transfer function represented as:\n\\[ \\frac{Y(s)}{R(s)} = G(s) = \\frac{b_0 s^m + b_1 s^{m-1} + \\ldots + b_m}{a_0 s^n + a_1 s^{n-1} + \\ldots + a_n} \\]\nwhere $ m n $. This inequality ensures that the system is either proper or strictly proper, crucial for realizable systems.\n\nThe characteristic equation, derived from the denominator of the transfer function, is:\n\n\\[ \\Delta(s) = a_0 s^n + a_1 s^{n-1} + \\ldots + a_n = 0 \\]\n\nThe roots of this equation, which are the poles of the transfer function, determine the system’s stability.\n\nIf we take the partial fraction expansion,\n\nThe zeros (roots of the numerator) influence the magnitude and shape of the transient response but do not alter the system’s stability.\nThe poles dictate the system’s stability, and its intrinsic behaviour.\nFor example, a first-order factor in the transfer function results in an exponential response (growing or decaying), while a second-order factor leads to an oscillatory response (growing or decaying).\n\n\n\n\nAnalysis in the s-Plane\nLet’s analyze the s-plane to understand how poles affect system behavior:\n\nLeft Half-Plane: Poles in the left half of the s-plane lead to a decaying response, indicating a stable system. Even complex poles in this region result in oscillatory but decaying responses.\nRight Half-Plane: Poles in the right half of the s-plane result in a growing response, indicating an unstable system. This holds true for any real, complex, repeated, or distinct poles in this region.\n\nThe section and diagrams below show the impulse response (\\(R(s)=1\\)) for possible pole locations.\n\n\nPoles and Zeros in Transfer Function Analysis\nIn analyzing the transfer function of a system, the poles and zeros play a significant role in determining the behaviour of the system. - The poles, which are the roots of the characteristic equation of the system, dictate the system’s stability. - In contrast, the zeros influence the transient response but do not affect stability.\n\nScanning the s-Plane for Pole Locations\nExamining the s-plane, we analyze the position of the poles to determine stability. If a pole lies in the left half of the s-plane, it contributes to a decaying impulse response, indicating stability. Conversely, poles in the right half or on the imaginary axis can lead to instability.\n\n\n\n\n\nAnalysis of the \\(j\\omega\\) axis:\n\n\n\n\n\n\n\nMarginally Stable Systems\nIn control systems, the concept of marginal stability emerges when dealing with poles on the imaginary axis, especially simple poles. Let’s delve deeper into this scenario and understand its implications:\n\nMathematics vs. User Perspective:\n\nMathematically, systems with poles on the imaginary axis are deemed unstable.\nHowever, from a practical standpoint, such systems might still be of interest under certain conditions.\n\nAnalysis of a Specific Transfer Function:\n\nConsider a transfer function:\n\\[\nG(s) = \\frac{N(s)}{s(s + j\\omega)(s - j\\omega)} = \\frac{Y(s)}{R(s)}\n\\]\nThis system is mathematically unstable, but let’s examine it from a user’s point of view.\n\nBounded Response for Specific Inputs:\n\nIt’s observed that for most inputs $ R(s) $, except specific ones that match the poles on the imaginary axis, the system response remains bounded - in this case, the input matches the simple poles and make them double poles.\nIn our specific case above, the critical inputs to avoid are $ R(s) = $ or $ R(s) = $. Except for these, the system exhibits a non-growing response (e.g., oscillatory response, constant response, etc).\n\nAcceptance of the System Based on Application:\n\nThe decision to accept or reject such a system depends on its application and whether it can handle the specific conditions where the response remains bounded.\n\nConcept of Marginal Stability:\n\nMarginally stable systems are those where simple poles exist on the imaginary axis, but the response remains bounded for inputs not matching these poles.\nThis concept implies a cautious approach, where systems are analyzed more thoroughly before being deemed stable or unstable based on their specific use case.\nIt is a boundary condition that mathematics lables as unstable, but from the user perspective might depend on the application.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability.html#zero-input-stability-and-state-variables",
    "href": "stability.html#zero-input-stability-and-state-variables",
    "title": "Stability Analysis in Control Systems",
    "section": "Zero-Input Stability and State Variables",
    "text": "Zero-Input Stability and State Variables\nNow, let’s transition to the concept of zero-input stability, leveraging the knowledge we have of state variables:\n\nThe Linear Autonomous System:\n\nConsider a linear autonomous system: \\[ \\dot{x} = Ax \\] \\[ x(0) = x_0 \\]\n\nLaplace Transform and System Analysis:\n\nApplying the Laplace transform, we obtain: \\[ sX(s) - x_0 = AX(s) \\]\nwhere \\[X(s) = \\begin{bmatrix}\nx_1(s) \\\\\nx_2(s) \\\\\n\\vdots \\\\\nx_n(s)\n\\end{bmatrix}\n\\]\nRearranging gives: \\[ X(s) = (sI - A)^{-1}x_0 \\]\nHere, $ X(s) $ represents the Laplace transform of the state vector $ x $, and $ A $ is a matrix of constant coefficients.\n\nInverse Transform for Stability Analysis:\n\nTo analyze stability, we focus on the inverse Laplace transform of $ X(s) $, which involves the matrix $ (sI - A)^{-1} $. For each initial state \\(x_0\\), we want to study how \\(x(t)\\) behaves.\nThis matrix can be represented as:\n\\[ X(s) = (sI - A)^{-1} x_0= \\frac{(sI - A)_{\\text{adjoint}}}{\\Delta(s)} x_0 \\]\nWhere $ (s) = (sI - A) $ is the determinant of the matrix.\n\nCharacteristic Polynomial and Eigenvalues:\n\nThe characteristic polynomial \\(\\Delta(s)\\) for an $ n n $ matrix $ A $ is given by a n-th order polynomial:\n\\[ \\Delta(s) = \\alpha_0 s^n + \\alpha_1 s^{n-1} + \\ldots + \\alpha_n \\]\nThe roots of $ (s) $ are the eigenvalues of $ A $, determining the system’s stability in the zero-input case.\n\n\nNow, let’s focus on the characteristic equation derived from the state variable model of the system. This equation plays a crucial role in understanding the system’s dynamics:\n\nThe State Variable Model:\n\nFor an $ n n $ matrix $ A $, the determinant of $ sI - A $ results in an nth-order polynomial, characterizing the system’s dynamics.\nThis determinant is also referred to as the characteristic equation when derived from the state variable model.\n\n\n\nUnderstanding the Adjoint Matrix Entries\n\nAdjoint Matrix of $ sI - A $:\n\nWhen considering the adjoint matrix of $ sI - A $, each entry is a polynomial of order $ n - 1 $ (you can intuitively realise this point simply taking an example).\nThe cofactor of each element in the matrix contributes to these polynomial entries.\n\n\n\n\nStability and Zeros from the State Space\n\nStability Analysis:\n\nThe stability of the system is determined by the roots of the characteristic equation, $ (s) = (sI - A) $.\nZeros, which come from the adjoint matrix entries, do not affect stability. Therefore, for zero-input stability analysis, we focus only on the poles (roots of $ (s) $).\n\nState Response and Stability:\n\nIf the roots of $ (s) $ lie in the left half-plane, the state vector $ x(t) $ remains bounded, indicating stability.\nSimple poles on the imaginary axis lead to bounded responses but are considered marginally stable.\n\n\n\n\nAsymptotic Stability\n\nA system is asymptotically stable if all roots of $ (s) $ are in the left half-plane, causing all state variables to decay to zero as $ t $.\n\n\\[\n   \\lim_{t \\rightarrow \\infty } x(t) \\rightarrow 0\n   \\]\n\nThis concept is crucial because it ensures that the system’s response not only remains bounded but also approaches zero over time.\n\n\\[\n   x(t) = \\mathcal{L}^{-1}\\Big[\\frac{(sI - A)_{\\text{adjoint}}}{\\Delta(s)}\\Big] x_0\n   \\]\nNote that \\(x_0\\) is a scale factor (similarly to the zeros). The dynamics are driven by \\(\\Delta(s)\\).\n\n\nConditions for Stability, Instability, and Marginal Stability\n\nStability Conditions:\n\nAsymptotically Stable: All poles are in the left half-plane.\nUnstable: At least one pole in the right half-plane or multiple poles on the imaginary axis.\nMarginally Stable: All poles in the left half-plane, except for simple poles on the imaginary axis.\n\nMarginal stability, additional comments\nNote that in the Marginally Stable case, we are not matching the poles now as we did before. It is a different situation, \\(x_0\\) is a constant.\n\nA pole at the origin gives a constant response, multiplied by the constant \\(x_0\\), which means that \\(x(t)\\) remains bounded in a specific region.\nSimilarly for two imaginary poles. The response is oscillatory, multiplied by the constant \\(x_0\\), which means that \\(x(t)\\) remains bounded in a specific region.\n\nFor this reason, any simple pole on the imaginary axis give bounded state response, and this can be grouped under the marginal stability condition.\n\n\nRelationship Between Zero-Input Stability and BIBO Stability\n\nEquivalence of Stability Concepts:\n\nIf and only if, $(s)=(sI - A) $ is the same as the denominator of the system’s transfer function $ G(s) $, then asymptotic stability (zero-input stability) and BIBO stability are the same.\nIn many real-life systems this condition is satisfied. This is called Controllability and Observability condition.\n\n\n\n\n\n\nSIDEBAR - concepts of stability, particularly focusing on how the location of poles affects the stability of a control system, and the specific cases of simple poles on the imaginary axis, which lead to marginal stability.\n\n\nPoles on the Imaginary Axis and System Response\n\nSimple Poles on the Imaginary Axis:\n\nA simple pole on the imaginary axis (excluding the origin) corresponds to a sinusoidal component in the system’s response.\nWhen the system state $ x(t) $ is influenced by a simple pole on the imaginary axis, the response will be oscillatory. The magnitude of this oscillation is influenced by the initial condition $ x_0 $, but the response remains bounded - it neither grows to infinity nor decays to zero.\nThis bounded oscillatory behavior characterizes a marginally stable system.\n\nPole at the Origin:\n\nA simple pole at the origin of the s-plane corresponds to a constant component in the system’s response.\nThis leads to a steady-state value that depends on the initial condition $ x_0 $, resulting in a bounded response that doesn’t change over time.\n\n\n\n\nStability Classifications Based on Pole Locations\n\nAsymptotic Stability:\n\nA system is asymptotically stable if all poles are in the left half-plane. In this case, all modes of the system decay over time, leading to $ X(t) $ approaching zero as $ t $ tends to infinity.\n\nUnstable Systems:\n\nIf at least one pole is in the right half-plane, or if there are multiple poles on the imaginary axis, the system is unstable. This is because such pole positions lead to responses that grow unbounded over time.\n\nMarginal Stability:\n\nMarginal stability occurs when all poles are in the left half-plane, except for simple poles on the imaginary axis. These systems do not exhibit an unbounded growth in response, nor do they settle to a steady-state; instead, they sustain oscillations.\n\n\n\n\nEquivalence of Asymptotic and BIBO Stability\n\nConditions for Equivalence:\n\nAsymptotic stability (zero-input stability) and BIBO (Bounded-Input, Bounded-Output) stability become equivalent when the determinant of $ sI - A $ matches the denominator of the system’s transfer function $ G(s) $.\nThis condition is often satisfied in real-life systems, making the concepts of zero-input stability and BIBO stability practically synonymous in many cases.\nIn control theory, this equivalence is linked to concepts of controllability and observability.\n\n\n\n\nSimplified Stability Terms\n\nSimplified Classification:\n\nGiven the above understandings, we can simplify our terminology:\n\nStable: All poles are in the left half-plane.\nUnstable: At least one pole is in the right half-plane or multiple poles are on the imaginary axis.\nMarginally Stable: All poles are in the left half-plane except for simple poles on the imaginary axis.\n\n\n\n\n\nConcluding Remarks\nUnderstanding these nuances of stability based on pole locations is crucial in control system design and analysis. It helps in predicting the system’s behavior under various conditions and ensuring its safe and reliable operation. Marginally stable systems, while bounded, require careful consideration due to their sustained oscillations, which might be undesirable in certain applications.\n\n\n\nSIDEBAR - Adjoint Matrix\nTo understand why each entry in the adjoint matrix of $ sI - A $ is a polynomial of order $ n - 1 $, it’s important to delve into the concepts of matrices, determinants, and their adjoints in the context of linear algebra and control systems.\n\n\nBackground Concepts\n\nAdjoint Matrix:\n\nThe adjoint (or adjugate) of a matrix is formed by the cofactors of each element of the matrix.\nFor a square matrix $ A $, the adjoint is denoted as $ (A) $ and is the transpose of the cofactor matrix of $ A $.\n\nCofactor of an Element:\n\nThe cofactor of an element in a matrix is calculated by taking the determinant of the submatrix formed by eliminating the row and column of that element and then applying a sign based on the element’s position.\n\n\n\n\nAdjoint of $ sI - A $\nNow, consider the matrix $ sI - A $ for an $ n n $ matrix $ A $ and a scalar $ s $:\n\n$ sI $ is a diagonal matrix with $ s $ on its diagonal and zeros elsewhere.\n$ sI - A $ results in a matrix where the diagonal elements are $ s - a_{ii} $ (where $ a_{ii} $ are the diagonal elements of $ A $) and the off-diagonal elements are the negated elements of $ A $.\n\n\n\nPolynomial Order in Adjoint Entries\n\nPolynomial Order in Cofactors:\n\nWhen computing the cofactor of an element in $ sI - A $, we are essentially taking the determinant of an $ (n-1) (n-1) $ submatrix.\nThis determinant will be a polynomial in $ s $ since each determinant operation introduces a sum of products of matrix elements, which are linear in $ s $ due to the diagonal elements of $ sI - A $.\n\nOrder of the Polynomial:\n\nSince the determinant of an $ (n-1) (n-1) $ matrix involves a sum of products of $ (n-1) $ elements, the resulting polynomial in $ s $ will be of order $ n - 1 $.\nTherefore, each cofactor in the adjoint matrix, and hence each entry in $ (sI - A) $, is a polynomial of order $ n - 1 $.\n\n\n\n\nConclusion\nIn summary, the adjoint of $ sI - A $ consists of entries that are polynomials of order $ n - 1 $ because each entry is derived from the determinant of an $ (n-1) (n-1) $ submatrix, which inherently results in a polynomial of $ s $ of order $ n - 1 $. This understanding is crucial in control systems, particularly when analyzing the system’s stability through its state-space representation.\n— END OF SIDEBAR",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "feedback_systems_and_their_effects.html",
    "href": "feedback_systems_and_their_effects.html",
    "title": "Feedback systems and their effects",
    "section": "",
    "text": "With this notebook we are going to explore more deeply the basic principles of feedback control. Recall our earlier discussions on the sensitivity and robustness issues in control systems. We will now delve into this with more detail.\nBasic Block Diagram\nWe need to first lay out the basic block diagram. Here’s a description:\nThis gives us the error signal $e$ and the control signal $u$.\nError signal, designated as \\(e_{cap}\\), and the control signal, represented as \\(u\\), are intrinsic parts of this diagram.\nThe relationship between the output \\(y\\) and the reference input \\(r\\) can be expressed as the ratio \\(\\frac{Y(s)}{R(s)}\\). This relationship is denoted by \\(M(s)\\) and is given by the following equation:\n\\[\nM(s)=\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1 + D(s)G(s)H(s)}\n\\]\nThis equation represents the overall transfer function of the closed-loop system.",
    "crumbs": [
      "Feedback systems and their effects"
    ]
  },
  {
    "objectID": "feedback_systems_and_their_effects.html#dynamic-response-shaping-in-feedback-control-systems",
    "href": "feedback_systems_and_their_effects.html#dynamic-response-shaping-in-feedback-control-systems",
    "title": "Feedback systems and their effects",
    "section": "Dynamic Response Shaping in Feedback Control Systems",
    "text": "Dynamic Response Shaping in Feedback Control Systems\nRemember that we talk about shaping of dynamic response we are setting requirements on the transient and steady state response of the system.\nFor example, in notebook 13_Principles_of_Feedback_Control, we saw that we might want an oscillatory response or an overdamped response (depending on the application):\n\n\n\n\n\n\nShaping the Dynamic Response\nConsider the transfer function of a closed-loop system:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1+D(s)G(s)H(s)}\n\\]\nThe dynamic response of a system is significantly influenced by its poles and zeros.\nRecall, the poles of a system determine the nature of the system’s response, such as oscillatory or non-oscillatory behavior, while the zeros affect the magnitude of these responses.\n\nTransfer Function and System Poles and Zeros\n\nPoles: They dictate the nature of the system’s response (oscillatory, non-oscillatory, first-order, second-order, etc.).\nZeros: Affect the magnitude of the response. For example, the zeros only affect the residue of the partial fraction expansion.\n\nExample: - A first-order pole (e.g., $$) affects the speed of system response. - A zero affects the amplitude (\\(A_1\\)) of a specific mode in the response.\n\n\n\nExample\nConsider two impulse responses:\n\nFast Response: If \\(\\tau\\) is small, the response quickly settles.\nSlow Response: If \\(\\tau\\) is large, the response takes more time to settle.\n\nWe can create graphs to show the impact of varying pole and zero values on a system’s response using Python, specifically with libraries like Matplotlib and SciPy.\nHere’s a conceptual outline of how we might structure our Python code to generate these graphs:\n\nSet Up the Environment: Import necessary libraries.\nDefine the Transfer Functions: Create functions to represent transfer functions with varying poles and zeros.\nSimulate the Response: Use the step response function to simulate how the system responds over time.\nPlot the Responses: Use Matplotlib to create plots showing the system’s response.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import TransferFunction, impulse, step\n\ndef plot_responses(systems, title):\n    plt.figure(figsize=(10, 6))\n    for sys, label, color in systems:\n        t_imp, y_imp = impulse(sys)\n        t_step, y_step = step(sys)\n        plt.plot(t_imp, y_imp, label=f'Impulse - {label}', linestyle='--', color=color)\n        #plt.plot(t_step, y_step, label=f'Step - {label}', linestyle='-', color=color)\n\n    plt.title(title)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \ndef print_transfer_function(sys, label):\n    num, den = sys.num, sys.den\n    tf_expression = ' + '.join([f'{n}s^{len(num)-i-1}' for i, n in enumerate(num)])\n    tf_expression += ' / '\n    tf_expression += ' + '.join([f'{d}s^{len(den)-i-1}' for i, d in enumerate(den)])\n    print(f'{label}: {tf_expression}')\n    \n\n# User specified poles and zeros for first order systems\n# Example 1\npole1 = [-3]\nzero1 = []  # No zero\n\npole2 = [-5]\nzero2 = []  # No zero\n\n# Example 2\n# Compare what happens to the impulse response when we have the same pole but different zeros.\n# pole1 = [-5]\n# zero1 = [-1]  # Zero in -1\n\n# pole2 = [-5]\n# zero2 = [-2]  # Zero in -2\n\n\n# Creating transfer function systems\nsystem1 = TransferFunction(np.poly(zero1), np.poly(pole1))\nsystem2 = TransferFunction(np.poly(zero2), np.poly(pole2))\n\nprint_transfer_function(system1, 'System 1')\nprint_transfer_function(system2, 'System 2')\n\n# Plotting\nplot_responses([\n    (system1, 'System with Pole at s=-3', 'blue'),\n    (system2, 'System with Pole at s=-5 and Zero at s=0', 'red')\n], 'Comparison of First Order Systems')\n\nSystem 1: 1.0s^0 / 1.0s^1 + 3.0s^0\nSystem 2: 1.0s^0 / 1.0s^1 + 5.0s^0\n\n\n\n\n\n\n\n\n\n\nSidebar - Effect of Zeros on Impulse Response\nThe behavior of the impulse response in a system with zeros is closely tied to the system’s transfer function, particularly how the zeros and poles interact. Let’s discuss why the impulse response starts from a negative number when you have a zero and how the location of the zero affects this behavior.\n\nImpact of Zeros on Impulse Response:\n\nIn a transfer function, a zero essentially introduces a term in the numerator that can change the phase of the system’s response. When an impulse is applied, the immediate response of the system is influenced by the numerator of the transfer function.\nIf a zero is placed on the left-half of the s-plane (negative real part), it tends to introduce a phase shift that can cause the impulse response to start from a negative value.\n\nLocation of Zero and Response:\n\nThe effect of a zero on the impulse response is not just about its presence but also its location relative to the poles.\nThe closer the zero is to the origin (or to the pole), the more significant its impact on the initial response. However, the sign of the zero (whether it’s at -1 or 1) does not change the initial direction of the response. It’s the relative position of the zero to the poles that matters more.\n\nPositive Starting Impulse Response:\n\nTo have an impulse response that starts from a positive number, you should place the zero in such a way that it doesn’t dominate the initial response of the system. This typically means placing the zero further away from the origin than any poles, particularly in a first-order system.\n\nUnderstanding Through Experimentation:\n\nYou can experiment with the placement of the zero in your transfer function to observe how it affects the impulse response. Moving the zero further into the left-half plane (more negative) often reduces its immediate impact on the impulse response.\n\n\nHere’s a quick Python experiment you can try to observe these effects. Adjust the zero2 value in the following code snippet to see how different placements affect the impulse response:\n\nfrom scipy.signal import TransferFunction, impulse\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef create_system(pole, zero):\n    if zero:  # If zero list is not empty\n        numerator = np.poly(zero)\n    else:  # If zero list is empty, use a gain of 1\n        numerator = [1]\n    denominator = np.poly(pole)\n    return TransferFunction(numerator, denominator)\n\npole = [-3]\n# Place zeros at different locations and observe\nzero1 = []  # Zero at -1\nzero2 = [-10]    # No zero\n\n# Creating transfer function systems\nsystem1 = create_system(pole, zero1)\nsystem2 = create_system(pole, zero2)\n\n# Generating impulse responses\nt1, y1 = impulse(system1)\nt2, y2 = impulse(system2)\n\n# Plotting\nplt.plot(t1, y1, label=f'System with Zero at {zero1}')\nplt.plot(t2, y2, label=f'System with Zero at {zero2}')\nplt.title('Impulse Response of Systems with Different Zero Locations')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n— END OF SIDEBAR\n\n\n\nFeedback’s Role in Shaping the Dynamic Response\nConsider the transfer function of a closed-loop system:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1+D(s)G(s)H(s)}\n\\]\nLet’s consider $D(s)$, $G(s)$, and $H(s)$ as ratios of two polynomials:\n\\[\nD(s) = \\frac{D_1}{D_2}, \\quad G(s) = \\frac{G_1}{G_2}, \\quad H(s) = \\frac{H_1}{H_2}\n\\]\nSubstituting these into our transfer function \\(M(s)\\):\n\\[\nM(s) = \\frac{D_1 G_1 H_1}{D_2 G_2 H_2 + D_1 G_1 H_1}\n\\]\n\nShaping the dynamic response means making it different from the one in open loop.\nThe open loop response is driven by \\(G_2(s)\\), i.e., poles of \\(G\\). This means that the poles of \\(G\\) are not acceptable given your requirements.\n\n\nDesigning the Controller for Desired Dynamics\n\nObjective: Alter the closed-loop system’s poles to achieve a specific dynamic response.\nStrategy: Adjust the controller ($D_1$ and $D_2$) to achieve desired pole locations for $M(s)$.\n\nWe can change $D_1$ and $D_2$ so that the roots of the denominator \\(D_2 G_2 H_2 + D_1 G_1 H_1\\) are in suitable locations in the \\(s\\)-plane.\n\n\n\nDesign Problem\nGoal: Translate a desired dynamic response into specific pole locations.\nSteps: 1. Determine pole locations corresponding to desired dynamic response. 2. Design $D_1$ and $D_2$ in the controller to realize these pole locations in the closed-loop system.\nSuppose you would like to have this dynamic response:\n\n\n\n\n\nThe design strategy would be to place the poles where we can achieve the desired response. Through the design of \\(D(s)\\) of the controller, we will be able to move the poles of the close loop system to desired location so that the dynamic response is what we want.\nShaping the dynamic response is possible suitably designing the controller (and hence the numerator and denominator) so that the closed-loop poles of \\(M(s)\\) are those of the required dynamic shape.\n🤔 Pop-up Question: Why can’t we achieve desired dynamics through open-loop control? Answer: While open-loop control can theoretically achieve desired dynamics (placing the poles where we would like), it lacks the ability to adapt to changes in the system parameters over time, leading to potential instability and degraded performance.\n\n\nThe Limitations of Open-Loop Control in Dynamic Shaping\n\n\n\n\n\nThe poles of \\(G(s)\\) are not acceptable, they do not give us the desired response. We would like to move the poles where they give us the response we want.\n\nOpen-Loop Control Strategy\n\nIdea: Cancel the poles of $G(s)$ and replace them with desired poles.\nImplementation: Design $D(s)$ such that it cancels the poles of $G(s)$ and introduces the prescribed poles.\n\n\\[\nD(s) = \\frac{1}{G(s)} \\times \\hat{D}(s)\n\\]\nWhere \\(\\hat{D}(s)\\) has the desired poles, for example:\n\\[\n\\hat{D}(s) = \\frac{1}{s^2 + 2\\xi\\omega_n s + \\omega_n^2}\n\\]\nIn this case,\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{1}{s^2 + 2\\xi\\omega_n s + \\omega_n^2}\n\\]\nWhich is exactly want we want.\nThis is the most obvious way to achieve our objective. However, we never go for this solution…why?\n\n\nChallenges with Open-Loop Control\n\nModel-Plant Gap: The controller designed based on $G(s)$ might not effectively cancel the actual physical plant’s dynamics. We can only use a model and hence we have inaccuracy, so the dynamics of the plant will never be nullified. The cancellation is only possible with respect to the model and not to the plant. Also, since there is no feedback, there is no knowledge of this error at the controller.\nLack of Adaptability: The controller does not adapt to changes in the system parameters over time. If the plant changes over time (and it will) this might not be captured in the model, which means that the performance deteriorate over time.\nRobustness Issues: Open-loop control is sensitive to disturbances and modeling errors, leading to potential instability.\n\nDespite the complexity, feedback control is preferred due to its ability to handle robustness and disturbance rejection. Adjusting the closed-loop poles, though challenging, is crucial for ensuring the system’s stability and desired performance over time.\n🤔 Popup Question: Why is an open-loop controller, despite seeming straightforward, not often used for dynamic shaping? Answer: Open-loop controllers cannot adapt to the changing parameters of the actual plant over time, and any gap between the plant model and the actual plant can lead to performance issues and instability.",
    "crumbs": [
      "Feedback systems and their effects"
    ]
  },
  {
    "objectID": "feedback_systems_and_their_effects.html#steady-state-accuracy-in-feedback-control",
    "href": "feedback_systems_and_their_effects.html#steady-state-accuracy-in-feedback-control",
    "title": "Feedback systems and their effects",
    "section": "Steady State Accuracy in Feedback Control",
    "text": "Steady State Accuracy in Feedback Control\nLet’s consider a unity feedback control system, where the feedback factor is 1. In this system, the error signal, denoted as $e$, plays a critical role in determining the system’s performance.\n\n\n\n\n\n\nTransfer Function and Error Signal\nThe transfer function $Y(s)/R(s)$ for our system is given by:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1 + D(s)G(s)}\n\\]\nAnd the error signal transfer function $E(s)/R(s)$ is:\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1 + D(s)G(s)}\n\\]\nThis relationship is crucial as it lays the foundation for understanding steady state error.\n\n\nFinal Value Theorem and Steady State Error\nUsing the final value theorem, the steady state error $e_{ss}$ is determined by:\n\\[\ne_{ss} = \\lim_{s \\to 0} sE(s) = \\lim_{s \\to 0} \\frac{sR(s)}{1 + D(s)G(s)} = \\lim_{t \\to \\infty} e(t)\n\\]\nThis equation shows how the steady state error relates to the input $R(s)$ and the system’s transfer function.\n\n\nCase Study: Step Input Response\nLet’s analyze a specific case where $R(s) = $ (a step input).\nFor a step input, the steady state error $e_{ss}$ becomes:\n\\[\ne_{ss} = \\frac{1}{1 + D(0)G(0)}\n\\]\nHere, $D(0)G(0)$ represents the DC gain of the loop. This is the loop gain at low frequencies.\n\nBy designing the controller \\(D(s)\\) appropriately, we can manipulate this gain to reduce the steady state error, thereby improving steady state accuracy.\nIncreasing the loop gain we can obtain better steady state accuracy.\n\n\n\nComparison with Open-Loop Control\nIn an open-loop system, the error is: \\[\nE(s) = R(s) - Y(s) = R(s) - D(s)G(s)R(s) = R(s)\\Big[ 1 - D(s)G(s) \\Big]\n\\]\nand hence the steady state error for a step input (\\(R(s) = 1/s\\)) can be expressed as:\n\\[\ne_{ss} = 1 - D(0)G(0)\n\\]\nwhere we have again applied the Final Value Theorem.\nInterestingly, in open-loop control, it’s possible to completely eliminate the steady state error by setting $D(0)G(0) = 1$. However, this approach lacks robustness and disturbance rejection capabilities.\nIn closed loop we can obtain zero steady error only at the limit.\n\n\nConcluding Remarks on Steady State Accuracy\nWe’ve seen that feedback control, primarily employed for its robustness and disturbance rejection qualities, also allows us to finely tune steady state accuracy. However, achieving the perfect balance between robustness, accuracy, and stability requires careful design and consideration of all system aspects.",
    "crumbs": [
      "Feedback systems and their effects"
    ]
  },
  {
    "objectID": "feedback_systems_and_their_effects.html#high-loop-gain-benefits-and-challenges",
    "href": "feedback_systems_and_their_effects.html#high-loop-gain-benefits-and-challenges",
    "title": "Feedback systems and their effects",
    "section": "High Loop Gain: Benefits and Challenges",
    "text": "High Loop Gain: Benefits and Challenges\nHigh loop gain is a fundamental design tool in automatic control, but it comes with its own set of benefits and challenges.\nBenefits of High Loop Gain\n\nSensitivity Reduction: High loop gain reduces the system’s sensitivity to parameter variations.\nDisturbance Rejection: It enhances the system’s ability to reject external disturbances.\nSteady State Accuracy: Increasing loop gain can improve the system’s steady state accuracy.\n\nChallenges and Trade-offs\n\nNoise Problems: High loop gain can amplify high-frequency noise, reducing the signal-to-noise ratio.\nSaturation and Input Amplitude Constraints: Excessive gain might cause system components to saturate.\nStability Issues: A higher loop gain can make the system more oscillatory and prone to instability.\n\nThese trade-offs highlight the complexity of control system design. Achieving the right balance between these factors is essential for optimal system performance.\n🤔 Pop-up Question: Why can’t we always use high loop gain to improve system performance? Answer: While high loop gain improves sensitivity, disturbance rejection, and steady state accuracy, it can introduce problems like noise amplification, system saturation, and stability issues. Thus, a balance must be struck in the design.\n\nNeed for Beyond Proportional Control\nA simple amplification (gain) may not satisfy all control requirements (i.e., merely increasing the amplifier gain in the controller $D(s)$), might not meet all control requirements. Therefore, we need to explore additional control actions, namely derivative and integral actions.\n\nDerivative and Integral Control\n\nDerivative Control: Involves injecting a signal proportional to the derivative of the error into the loop.\nIntegral Control: Involves using the integral of the error signal.\n\nThese control strategies help address the limitations of proportional control, leading to a more robust and versatile control system.",
    "crumbs": [
      "Feedback systems and their effects"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html",
    "href": "principles_of_feedback_control.html",
    "title": "Principles of Feedback Control",
    "section": "",
    "text": "To kickstart our journey, let’s revisit the basic feedback diagram we previously discussed. Here’s a visualization:\n\n\n\n\n\n\n\\(G(s)\\): This represents the plant, which we will, for simplification, denote as SG.\n\\(D\\): The transfer function of our controller.\n\\(N\\): A model capturing disturbances acting on the system.\n\\(H\\): The transfer function of our sensor.\n\\(y\\): Our controlled variable.\n\\(y_r\\): The command or reference signal.\n\\(e = y_r - y\\): The error signal\n\nThe error detector compares the reference signal with the feedback signal to produce the actuating signal, \\(\\hat{e}\\). Our controlled signal is denoted by \\(u\\).\nBroadly, this diagram encapsulates the features of most control systems you’ll encounter.\n🤔 Pop-Up Question: What do the symbols G, D, and H represent in the feedback control system diagram? - A. Controlled Variable, Disturbance, Sensor - B. Plant, Controller, Sensor - C. Actuating Signal, Controller, Error\nAnswer: B. Plant, Controller, Sensor*",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#feedback-control-system-diagram",
    "href": "principles_of_feedback_control.html#feedback-control-system-diagram",
    "title": "Principles of Feedback Control",
    "section": "",
    "text": "To kickstart our journey, let’s revisit the basic feedback diagram we previously discussed. Here’s a visualization:\n\n\n\n\n\n\n\\(G(s)\\): This represents the plant, which we will, for simplification, denote as SG.\n\\(D\\): The transfer function of our controller.\n\\(N\\): A model capturing disturbances acting on the system.\n\\(H\\): The transfer function of our sensor.\n\\(y\\): Our controlled variable.\n\\(y_r\\): The command or reference signal.\n\\(e = y_r - y\\): The error signal\n\nThe error detector compares the reference signal with the feedback signal to produce the actuating signal, \\(\\hat{e}\\). Our controlled signal is denoted by \\(u\\).\nBroadly, this diagram encapsulates the features of most control systems you’ll encounter.\n🤔 Pop-Up Question: What do the symbols G, D, and H represent in the feedback control system diagram? - A. Controlled Variable, Disturbance, Sensor - B. Plant, Controller, Sensor - C. Actuating Signal, Controller, Error\nAnswer: B. Plant, Controller, Sensor*",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#objectives-of-design",
    "href": "principles_of_feedback_control.html#objectives-of-design",
    "title": "Principles of Feedback Control",
    "section": "Objectives of Design",
    "text": "Objectives of Design\nOur primary objective? Ensure that the controlled variable, \\(y\\), closely mirrors \\(y_r\\) for all time \\(t \\ge t_0\\) (where \\(t_0\\) marks the point when control begins):\n\\[\ny(t) \\approx y_r(t)\\;\\;\\;t \\ge t_0\n\\]\nHowever, challenges arise. Let’s dive deeper.\nA common industrial scenario is when \\(y_r\\) remains constant over an extended period (set-point), and the goal is for \\(y\\) to swiftly align with \\(y_r\\) and maintain that value.\nThis scenario is termed as set-point control or regulator problem.\nTwo key performance measures arise:\n\nSettling Time: The duration \\(y\\) takes to approach \\(y_r\\). Lower settling times indicate a system’s superior speed of response (quicker response).\nSteady State Accuracy: Once equilibrium is achieved, \\(y\\) should stay close to \\(y_r\\). The difference, or steady state error, ideally should be zero.\n\nThese are in a nutshel the control requirements.\nHowever, the real-world is complex, and various constraints can impede our objectives. Let’s explore these:\n\n1. Stability\nA paramount consideration. A stable system doesn’t exhibit large response variations to minor changes in command signals, disturbances, or system parameters. While we will delve into a quantitative definition of stability later, always remember that all performance specifications must be met under the umbrella of stability.\n\n\n2. Input Amplitude Constraints\nThe validity of our linear model hinges on ensuring signal amplitudes remain within certain bounds. Exceeding these can render our linear model assumptions void.\nIt is essential to understand that when we adopt a transfer function model, we’re assuming that it accurately represents every component of the system. This encompasses the plant, controller, sensor, and more. This is validated by the type of block diagram we use for our designs.\nHowever, not everything is straightforward. Ponder this: What if the amplitude of various signals exceeds a certain threshold? The repercussions would be significant. The linearity assumption, which is foundational for our system, would no longer hold. As a result, the fundamental block diagram underpinning our design would be rendered inaccurate. This deviation could lead to unsatisfactory results in real-world applications.\nIt’s clear that our design should remain within certain amplitude constraints. If not, our system’s linear model might be invalidated, compromising the reliability of the entire system.\nThis is also true when you simulate your system in the lab. You must take into account the limits on the signals so that you can stay under your linear assumptions.\n🤔 Pop-up Question: What happens if the amplitude of signals surpasses a certain limit in our control system?\nAnswer: The linearity assumption becomes invalid, making our foundational block diagram inaccurate. This can result in the design not performing as expected in real-world situations.\n\n\n3. Disturbance Rejection:\nOur system should maintain its accuracy and speed of response, even in the face of disturbances. Thus, a good design should effectively filter out disturbances’ effects.\nEvery control system aspires for two primary goals:\n\nSpeed of Response: This refers to how quickly a system reacts to an input signal.\nSteady State Accuracy: This implies how accurately the system can maintain its state in response to a command signal.\n\nYet, disturbances pose challenges. It’s imperative for the system to mitigate disturbances effectively to ensure that they don’t jeopardize its speed of response or steady-state accuracy. Disturbances are particularly problematic because they’re typically unknown. If we could predict them, they wouldn’t pose as much of a challenge. However, real-world disturbances are often random and unpredictable.\n🤔 Popup Question: Why are disturbances challenging for a control system?\nAnswer: They are typically unknown, random, and can negatively affect the system’s speed of response and steady-state accuracy.\n\nUpcoming Discussions\nWe’ve touched upon some vital aspects of feedback control theory today. As we continue, we will delve deeper into each constraint and explore strategies to navigate them. Moreover, in our subsequent sessions, real-world application examples will further illustrate these concepts.\nFor now, keep these concepts fresh in your mind, and as always, feel free to revisit previous chapters to reinforce your understanding.\n\n\nNoise Filtering\nOne intrinsic downside of feedback control is the inevitable use of a sensor. In an ideal world, without the need for feedback, we wouldn’t require sensors (no feedback would be required). But sensors, while vital, introduce high-frequency noise into the system. If this noise dominates, the system might end up responding more to the noise than to the actual signal, leading to undesirable outcomes. Addressing this requires introducing suitable high-frequency filters within the feedback loop.\n\n\nSensitivity and Robustness\nThe concepts of sensitivity and robustness are intertwined. A control system’s plant is modeled by a function, \\(G(s)\\).\nThis model encompasses various physical components. During our modeling endeavors, it’s evident that capturing every nuance of a physical system within a model is not possible. This results in modeling errors.\nFor example, when we model the temperature in a tank we assume that the temperature is uniform through the tank. However the actual system is distributed and different parts of the tank can be at different temperatures. Or in a mechanical system, the spring effect (torsion) of the shaft of a motor is usually considered zero.\nNow, while it’s possible to create more complex models to better capture the nuances, this often leads to equally complex design algorithms. And therein lies the conundrum. Sometimes, simpler models with simpler design algorithms prove more effective than their complex counterparts.\nOne reason for this is that we have very powerful design tools for simple linear models. Using complex models might mean that we do not have an appropriate design algorithm which needs to be researched and worked on. This might become so complex that might not even be worth it.\nWhen we talk about our plant model \\(G(s)\\), we always need to be aware that we will have: - modeling errors. Appropriate tests should be done on your design to verify that approximations and model simplifications are valid. - parameter changes with time.\nRobustness is the system’s ability to perform satisfactorily despite finite changes in its model, either due to errors or parameter variations.\nIn contrast, sensitivity relates to how a system responds to differentially small changes. A system that is insensitive to parameter variations is often considered robust.\n🤔 Popup Question: What differentiates robustness from sensitivity in a control system?\nAnswer: Robustness pertains to a system’s performance despite finite model changes, while sensitivity relates to its reaction to very small changes.\nThe term “robustness” is still a topic of active research. While we might occasionally refer to a design as “robust,” it’s essential to remember that in our context, it often denotes a qualitative form of sensitivity-based design.\n\n\nShaping the Dynamic Response\nWhen we talk about control systems, one of the essential aspects to understand is the shaping of the dynamic response (or improving its transient response). This aspect plays a crucial role in achieving the desired performance for our system.\nWhile theoretically, we might desire instantaneous reactions, physical components always introduce some delay. This delay manifests as a “settling time,” the time the system takes to stabilize its output. Additionally, there’s the steady-state error, the deviation between the desired and actual outputs once the system stabilizes.\n\n\n\n\n\nWith reference to the picture above: At t=0, imagine a constant command signal $ y_r $ is given to the system. Now, ideally, the controlled variable $ y $ should track $ y_r $ as closely as possible, achieving a near-instantaneous response.\nBut here’s the catch! Achieving an instantaneous response is impractical because every system component has a certain delay or lag. Due to these lags, the system takes a finite amount of time to reach the desired value $ y_r $.\nThese lags or delays in the system response can be due to various factors like the inherent nature of the components used, external disturbances, and even intentional dampening added for stability purposes.\n\nSettling Time and Speed of Response\nIf our system response were to look something like this,\n\n\n\n\n\nFigure: the controlled variable’s response over time, oscillating around the desired signal $ y_r $ before finally settling.\nThe time it takes for the system response to stabilize around the desired output is called the “settling time”. A lower settling time indicates a faster system response, often referred to as the “speed of response”.\n\n\nSteady-State Accuracy\nOnce the system settles, it is crucial to check the difference between the actual controlled variable $ y $ and the desired signal $ y_r $. This difference is the steady-state error, and minimizing this error is a measure of the system’s steady-state accuracy.\n🤔 Popup Question: What is steady-state error? Answer: Steady-state error is the difference between the actual controlled variable and the desired signal once the system has settled.\n\n\nTo Oscillate or Not to Oscillate?\nA key question in control systems! Oscillations can be beneficial as they can increase the speed of response. However, large oscillations might lead to system saturation or even damage components.\nAn oscillatory response can be a sign of an underdamped system, which may have good speed of response but risks overshooting. An overdamped system, on the other hand, might have a slower response but will not overshoot the desired output.\n🤔Popup Question: What might be the risks of an underdamped system? Answer: An underdamped system may have a faster response but risks overshooting the desired output and might lead to large oscillations, which can damage system components or lead to system saturation.\nOn the other hand, a heavily damped or overdamped system might suppress oscillations and take longer to reach the steady-state. This results in a slower speed of response. Therefore, a balance or compromise is often sought in design.\nThe customer might only tell you: “this is the maximum amplitude of the response and this is the speed of response, and it will be your responsibility as control engineer to shape the dynamic response to meet the constaints on the input/output amplitude and the speed of response (and any other you might have).”\n\n\nSettling Time Illustrated\nTo clarify, imagine two responses:\n\nOverdamped Response: Takes longer to settle, but with no oscillations.\nUnderdamped Response: Settles faster, but with oscillations.\n\nThe time taken for each system to settle within a certain acceptable range (like 2% or 5%) around the steady state value defines the settling time. This definition helps designers determine if the system meets user requirements.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)\n\n# Overdamped Response\n# Parameters for the overdamped system\na1, a2 = .5, 1\ny_overdamped = 1 - np.exp(-a1 * t)\n\n# Underdamped Response\n# Parameters for the underdamped system\nomega_d = 1.5  # damped frequency\nzeta = 0.2  # damping ratio (zeta &lt; 1 for underdamped)\ny_underdamped = 1- np.exp(-zeta * omega_d * t) * np.cos(omega_d * t)\n\nomega_d = 1.5  # damped frequency\nzeta = 0.05  # damping ratio (zeta &lt; 1 for underdamped)\ny_underdamped_1 = 1- np.exp(-zeta * omega_d * t) * np.cos(omega_d * t)\n\n\n# Create plots\nplt.figure(figsize=(12, 6))\n\n# Overdamped plot\nplt.subplot(1, 2, 1)\nplt.plot(t, y_overdamped, label='Overdamped')\nplt.title('Overdamped Response')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\n\n# Underdamped plot\nplt.subplot(1, 2, 2)\nplt.plot(t, y_underdamped, label=r'Underdamped $\\zeta=0.2$', color='r')\nplt.plot(t, y_underdamped_1, label=r'Underdamped $\\zeta=0.05$', color='g')\nplt.title('Underdamped Response with Oscillations')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSteady state accuracy\nFinal requirement that we consider.\nSteady-state accuracy refers to the ability of a system (often a control system) to accurately reach its desired output value (or set-point) in the steady state, i.e., after any transient effects have decayed and the system has settled. It is a measure of how close the steady-state output of a system is to its desired value.\nIn control systems, steady-state errors are common specifications to evaluate how well a system can track a reference input, such as step, ramp, or parabolic inputs. The steady-state error is the difference between the actual output and the desired output as time approaches infinity (after all transient behaviors have disappeared).\n\n\nConflict in Design Requirements\nAchieving an optimal design is complex due to the conflicts between various requirements. For instance:\n\nImproving steady-state accuracy (which typically involes introducing integral control actions) might result in larger oscillations or even instability.\nFiltering out disturbances might increase the effects of noise on the system.\n\nIt becomes evident that these requirements are not always harmonious. Achieving one might compromise another. This is why the role of a system designer is so crucial; they must strike the right balance between these conflicting requirements.\n🤔 Popup Question: Why can’t we always achieve the best of all requirements in control system design? Answer: Many design requirements are in conflict. For instance, improving steady-state accuracy might lead to larger oscillations or instability. Hence, a balance is needed, and achieving the best of all worlds might not be possible.",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#feedback-vs-open-loop-systems-in-sensitivity-analysis",
    "href": "principles_of_feedback_control.html#feedback-vs-open-loop-systems-in-sensitivity-analysis",
    "title": "Principles of Feedback Control",
    "section": "Feedback vs Open-loop Systems in Sensitivity Analysis",
    "text": "Feedback vs Open-loop Systems in Sensitivity Analysis\nFeedback and open-loop systems are fundamental concepts in control engineering. In this part of the notebook, we will delve into the sensitivity analysis of these systems. Sensitivity analysis helps us understand how small changes in system parameters can impact the overall performance.\n\nQuick Recap:\nFeedback System (Closed-loop System): A system where a portion of the output is fed back to the input to regulate its behavior.\nOpen-loop System: A system that functions without considering any feedback from its output.\nNow, let us unravel the sensitivity issues related to these systems.",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#sensitivity-analysis",
    "href": "principles_of_feedback_control.html#sensitivity-analysis",
    "title": "Principles of Feedback Control",
    "section": "Sensitivity Analysis",
    "text": "Sensitivity Analysis\nSensitivity, in the context of systems, refers to the measure of how a change in a system parameter affects the system’s performance.\nMathematically, consider $ J $ to be a performance measure like speed of response, which is a function of a parameter $ $ of the plant.\nAssuming $ $ has a nominal value $ _n $ with a deviation $ $, the sensitivity is concerned with how small variations in $ $ impact $ J $.\nThe nominal value of your performance (e.g., speed of response) is:\n\\[\nJ_n = J( \\theta_n )\n\\]\nSince sensitivity is concerned with differentially small variations, we can use the Taylor series expansion for \\(J\\) around its nominal point.\nUsing Taylor series expansion, the effect of changes in $ $ on $ J $ can be represented as:\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta + \\text{higher order terms}\n\\]\nFor our analysis, we neglect the higher order terms, considering only the first order variation, and hence our equation becomes:\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#quantitative-sensitivity-definition",
    "href": "principles_of_feedback_control.html#quantitative-sensitivity-definition",
    "title": "Principles of Feedback Control",
    "section": "Quantitative Sensitivity Definition",
    "text": "Quantitative Sensitivity Definition\nThe sensitivity of $ J $ with respect to variations in $ $, symbolized by $ S^J_{} $, is defined as:\n\\[ S^J_{\\theta} = \\frac{\\Delta J / J_n}{\\Delta \\theta / \\theta_n} \\]\nThis formula represents an input-output sensitivity model.\n\nHere, $ / _n $ can be considered as the input, and $ J / J_n $ as the output.\nThis sensitivity function $ S^J_{} $ helps in determining how the system responds to various variations in $ / _n $.\n\n\n\n\n\n\nOnce the model $ S^J_{} $ is available, it becomes a simulation exercise to understand the impact of the parameter variations on the performance. Exactly how we do it for the plant.\nNote that we will give finite variations to the parameters even though our model is developed for differentially small changes. This model fortunally works also for finite small variations.",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "principles_of_feedback_control.html#feedback-system-and-sensitivity",
    "href": "principles_of_feedback_control.html#feedback-system-and-sensitivity",
    "title": "Principles of Feedback Control",
    "section": "Feedback System and Sensitivity",
    "text": "Feedback System and Sensitivity\nLet’s calculate our model.\nFrom\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]\nwe obtain that:\n\\[\n\\Delta J = J(\\theta_n + \\Delta \\theta) - J(\\theta_n) = \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]\nAnd therefore:\n\\[\nS^J_{\\theta} = \\frac{\\Big [ \\frac{d J}{d \\theta} \\Big|_{\\theta = \\theta_n} \\Delta \\theta \\Big]/J_n }{\\Delta \\theta / \\theta_n} = \\Big [ \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Big]\\frac{\\theta_n}{J_n}\n\\]\nFor a specific system you will need to evaluate \\(\\frac{d J}{d \\theta} \\Big|_{\\theta = \\theta_n}\\), \\(\\theta_n\\) and \\(J_n\\) are the nominal values.\n\nEffect of Feedback on Sensitivity\nGiven our understanding of sensitivity, let’s examine the effect of feedback on sensitivity. For this, consider the basic feedback loop (assume no disturbance):\n\n\n\n\n\nThe transfer function of this system is:\n\\[\nM = \\frac{Y}{R} = \\frac{D \\cdot G}{1 + D \\cdot G \\cdot H}\n\\]\nAnalysis:\n\nParameters of the controller $ D $ are within our control (it is an open system that we design), while $ G $ and $ H $ (system hardware) might change.\nTo understand how variations in $ G $ (or $ H $) affect the output $ Y $, we can derive two sensitivity functions:\n\n\\[ S^M_{G} \\] and \\[ S^M_{H} \\]\nBoth \\(G\\) and \\(H\\) depend on paramater variations: - \\(G\\) is a function of \\(\\theta\\), \\(G(\\theta)\\), and - \\(H\\) is a function of \\(\\alpha\\), \\(H(\\alpha)\\).\nWe would like to study: - the effect of variations of \\(\\theta\\) on \\(Y\\) (using \\(S^M_{G}\\)): equivalent to study the effects of variations of \\(G\\) on \\(M\\) - the effect of variations of \\(\\alpha\\) on \\(Y\\) (using \\(S^M_{H}\\)): equivalent to study the effects of variations of \\(H\\) on \\(M\\)\nAt this point, expliciting the presence of the parameter \\(\\theta\\) we can write:\n\\[\nM(\\theta_n, s) = \\frac{D(s)G(\\theta_n,s)}{1 + D(s) \\cdot G(\\theta_n, s) \\cdot H(s)}\n\\]\nUsing the sensitivity definition, we can now calculate the sensitivity of $ M $ with respect to $ G $, \\(S^M_{G}\\).\nFirst, we need to calculate:\n\\[\n\\begin{align}\n\\frac{dM}{d\\theta}\\Bigg|_{\\theta = \\theta_n} = \\frac{D}{(1+D\\cdot G\\cdot H)^2}\\frac{dG(\\theta,s)}{d\\theta}\\Bigg|_{\\theta=\\theta_n}\n\\end{align}\n\\]\nFrom this expression we can find \\(S^M_{G}\\).\nFirst we can convert differential changes into finite changes and calculate \\(\\frac{\\Delta M}{M}\\) - dividing the above expression (1) by \\(M\\):\n\\[\n\\frac{\\Delta M}{M} \\Bigg|_{\\theta=\\theta_n} = \\frac{D}{1+D\\cdot G\\cdot H}  \\times \\frac{1+D\\cdot G\\cdot H}{DG} \\frac{dG}{d\\theta}\\Bigg|_{\\theta=\\theta_n} = \\frac{1}{1+D\\cdot G\\cdot H}\\frac{dG}{G}\\Bigg|_{\\theta=\\theta_n}\n\\]\nfrom this expression we can obtain:\n\\[\nS^M_{G} = S(\\theta_n, s) = \\frac{1}{1 + D(s) \\cdot G(\\theta_n,s) \\cdot H(s)}\n\\]\nWhich is simply obtained dividing \\(\\frac{\\Delta M}{M}\\) by \\(\\frac{dG}{G}\\).\n\nComments\n\nFrom the above expression, the interpretation is clear: by suitably controlling the gain of the controller $ D \\(, we can adjust the loop gain (\\)D(s) G(_n,s) H(s)$) and thereby reduce the sensitivity to a desired level. Essentially, higher loop gain results in lower sensitivity.\n$ D(s) $ represents the controller. What’s unique about $ D(s) $ is that it’s within our control; we can modify it as per our needs.\nBy adeptly controlling the gain of $ D $, we can manipulate this loop gain to adjust the system’s sensitivity as desired. The underlying principle is straightforward: higher the loop gain, the lower the system’s sensitivity.\n\n🤔 Popup Question: What is the sensitivity of an open-loop system? Answer: In an open-loop system, since there is no feedback, $ H = 0 $. Hence, the sensitivity of the system with respect to $ G $ would be 1, indicating that any change in $ G $ would result in a proportional change in the output.\nSensitivity of Open-Loop and Closed-Loop Systems A key question arises: What is the sensitivity of an open-loop system? To understand this, let’s evaluate the feedback diagram.\nIn the scenario where $ H $ is set to zero (i.e., $ H = 0 $), effectively eliminating the feedback loop, the sensitivity of the system with respect to $ G $ becomes 1:\n\\[\nS^M_{G} = 1\\;\\;\\; \\text{for the open loop system}\n\\]\nThis conclusion can be derived from our initial expression. When you eliminate $ H $, the expression clearly points to the sensitivity being equal to 1.\nThis points to a pivotal understanding: An open-loop system is highly sensitive to variations in $ G $ with a sensitivity of 1.\nHowever, the beauty of feedback control emerges here. By judiciously designing the feedback control, specifically the controller $ D(s) $, we can manage and curtail this sensitivity as per our requirements.\nSensitivity with respect to the Sensor\nLet’s delve into another dimension of sensitivity: the sensitivity of $ M $ with respect to $ H $, the sensor.\nThe sensitivity of $ M $ with respect to $ H $ can be expressed as (its derivation is left to the reader):\n\\[ S^M_{H} = \\frac{-D(s) \\cdot G(s) \\cdot H(s)}{1 + D(s) \\cdot G(s) \\cdot H(\\alpha, s)} \\]\n\nWhen you increase the loop gain, the system’s sensitivity to changes in the plant parameters decreases. However, it also means that the system becomes very sensitive to variations in the sensor parameters.\nWhen the loop gain increases \\(S^M_{H}\\rightarrow 1\\).\n\n🤔 Popup Question: How does the sensitivity of the system change with variations in $ H $ (when we increase the loop gain)?\nAnswer: The system becomes more sensitive to the sensor as the loop gain increases. The magnitude of the sensitivity approaches 1.\nThis means that by introducing a sensor into the system, we have inadvertently also introduced a potential point of high sensitivity. This emphasizes the importance of the sensor’s design. The hardware design must account for sensitivity issues, ensuring that the sensor is appropriate for the specific plant under consideration.\nOn the Importance of Sensor Design The feedback mechanism’s introduction, while crucial for control, brings along the challenge of sensitivity due to variations in sensor parameters. It underscores the need for meticulous sensor design.\nNote that this is due to the fact that we have a sensor to close the loop. The introduction of the feedback has brought a potential new problem. This means that when we select a sensor we need to ensure that the sensor parameters will not change.\nWhile modifying a plant—often a vast industrial setting—is a daunting, if not impossible, task, modifying a sensor is more feasible. Therefore, the design of the sensor must be such that its parameters remain consistent and reliable. Otherwise, the sensor could introduce unforeseen challenges into the loop, potentially undermining the entire control system.\nIt’s worth noting that in industrial applications, the cost of modifying an entire plant can be exorbitant, but sensors are comparatively cheaper and more flexible components. Hence, investing time and resources in perfecting the sensor design pays dividends in the long run.\n🤔 Popup Question: Why is the design of the sensor so crucial in control systems?\nAnswer: Because the introduction of feedback makes the system highly sensitive to the sensor, and ensuring that the sensor parameters don’t change is often more feasible than modifying an entire plant.\n\n\n\n\nSidebar - derivative of \\(M\\) with respect to \\(\\theta\\)\nGiven the function $ M(, s) $ as:\n$ M(, s) = $\nYou want the partial derivative with respect to $ $.\n\nDifferentiate a Quotient: If you have a function $ f(x) = $, its derivative is given by\n\n$ f’(x) = $\nWhere $ u’ $ and $ v’ $ are the derivatives of $ u $ and $ v $ respectively.\n\nNow, applying this to our function, let:\n\n\\[ u(\\theta, s) = D(s)G(\\theta,s) \\]\n\\[ v(\\theta, s) = 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\]\nThen, the partial derivatives are:\n\\[ \\frac{\\partial u}{\\partial \\theta} = D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\]\nSince $ D(s) $ is not a function of $ $.\n\\[ \\frac{\\partial v}{\\partial \\theta} = D(s) \\cdot H(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\]\nAgain, this is because only $ G(,s) $ is dependent on $ $.\n\nNow, plug these into our quotient rule:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{\\left( D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\right) \\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right) - \\left( D(s)G(\\theta,s) \\right) \\left( D(s) \\cdot H(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\right)}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\n\nNow, simplifying, we get:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} + D(s)^2 \\frac{\\partial G(\\theta,s)}{\\partial \\theta} G(\\theta, s) H(s) - D(s)^2 G(\\theta,s) H(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta}}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\n\nCombining the terms with common factors:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} (1 + D(s) G(\\theta, s) H(s) - D(s) G(\\theta,s) H(s))}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\n\nContinuing to simplify:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta}}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\nThat’s the partial derivative of $ M(, s) $ with respect to $ $.\n– END OF SIDEBAR",
    "crumbs": [
      "Principles of Feedback Control"
    ]
  },
  {
    "objectID": "the_nyquist_stability_criterion_and_relative_stability.html",
    "href": "the_nyquist_stability_criterion_and_relative_stability.html",
    "title": "The Nyquist Stability Criterion and Relative Stability",
    "section": "",
    "text": "Relative stability refers to the degree to which a system tolerates changes in its parameters before becoming unstable. Unlike absolute stability, which simply tells us whether a system is stable or not, relative stability provides a measure of how close the system is to the boundary of instability.\nConsider a plot representing the closed-loop poles on the sigma-jω (σ-jω) plane. Suppose we have two dominant poles in this system. If these poles are closer to the jω axis, the transient response of the system decays faster.\nThis positioning of the poles relative to the jω axis indicates the system’s relative stability.\nThe real part guides the envelope of the oscillating response.\n\n\n\n\n\n\n\n\n\n\nDominant poles are those which have the most significant effect on the system’s behavior.\nThe closer these poles are to the jω axis, the slower the transient response decays, indicating poorer relative stability.\n\n\n\n\nNow, let’s interpret these concepts in the frequency domain using the Nyquist plot.\nThe plots corresponding to the previous s-plane example might be as below (note that this is only an example):\n\n\n\n\n\n\n\n\n\nInsert two Nyquist plots here: 1. A plot showing a response closer to the point (-1, j0), indicating a system closer to instability. 2. Another plot showing a response further from the point (-1, j0), indicating a more stable system.\n\n\n\n\nThe Nyquist plot’s proximity to the point (-1, j0) gives us an indication of the system’s relative stability.\n\n\n\nEnclosing the point (-1, j0) indicates absolute stability.\nThe closer the plot is to this point, the higher the risk of instability.\n\n\n\n\n\nThe polar plot is a graphical representation of a system’s frequency response, spanning from ω = 0 to ω = ∞.\nThe proximity of the polar plot to the critical point (-1, j0) is indicative of the system’s potential for sustained oscillations or instability.\nIncreasing the gain of the system tends to shift the polar plot closer to the critical point (-1, j0).\nIf this plot encircles the point (-1, j0), it is a signal that the system is moving towards instability.\n\n\n\n\n\n\n\n\n\n\n\n\nThe key to understanding a system’s relative stability lies in gauging the distance of the polar (or Nyquist) plot from the point (-1, j0).\nDetermining this “relative distance” involves measuring how close the plot is to (-1, j0), which in turn reflects the system’s susceptibility to instability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot only the intersection with the negative real axis but also the phase angle of the plot is critical in assessing relative stability.\nTwo indices are often used to measure this: the point of intersection on the real axis and the phase angle at the point where the magnitude is unity.\n\n\n\n\n\n\n\n\n\n\n\n\nMagnitude at Intersection: This is measured where the Nyquist plot intersects the negative real axis. The lower this magnitude, the more stable the system is considered.\nPhase Angle: A unit circle centered at (-1, j0) is considered. The angle at which this circle intersects the Nyquist plot provides a measure of relative stability.\n\nYou can also say that these two indices are not necessarily enough. However, they provide a simple algorithm to quantify the relative stability.\n\n\n\n\n\n\nLet’s delve into the scenario where the system’s gain, denoted as \\(K\\), is progressively increased. With this increment in gain, the overall magnitude of the Nyquist plot also rises. At a specific gain value, the plot intersects the critical point of (-1, j0).\nTo determine the precise gain increment required for the plot to intersect (-1, j0), we use the factor \\(\\frac{1}{a}\\). Here, \\(a\\) represents the distance of the plot’s intersection from the real axis in its original state (before gain increase).\nBy applying a gain of \\(\\frac{1}{a}\\) to your polar plot, you align its intersection with the real axis precisely at the -1 point.\nThe Gain Margin (GM) is mathematically expressed as \\[GM = \\frac{1}{a}.\\] This value represents the threshold before the system reaches a state of marginal stability or instability.\nThe gain margin looks at the amplification factor at which a system becomes unstable.\nThe following illustration depicts this concept visually:\n\n\n\n\n\n\n\n\n\n\nTo further clarify this concept, let’s examine a specific example:\nConsider the transfer function:\n\\[\nG(s) = K_1\\frac{1 + sT_1}{s(1 + sT_2)}\n\\]\nIn this case, the number of open-loop poles in the right-half plane, denoted as \\(P\\), equals 0. This scenario corresponds to the Nyquist plot shown below:\n\n\n\n\n\n\n\nFocusing on the phase margin, denoted as \\(\\phi\\), we analyze its significance in system stability:\n\nThe phase margin \\(\\phi\\) represents the additional phase lag that can be introduced into the system without causing it to intersect the critical point (-1, j0).\nEssentially, it quantifies the system’s capacity to handle phase shifts without falling into instability.\n\nWhen considering the phase margin, a positive value of \\(\\phi\\) is indicative of the system’s robustness.\nThis positive phase margin is the threshold of additional phase lag that, if incorporated into the system, would lead it to the very edge of instability, yet not cross over into an unstable state.\nThe presence of a positive phase margin serves as a safeguard against instability, demonstrating the system’s ability to withstand certain levels of phase alterations.",
    "crumbs": [
      "The Nyquist Stability Criterion and Relative Stability"
    ]
  },
  {
    "objectID": "the_nyquist_stability_criterion_and_relative_stability.html#introduction-to-relative-stability",
    "href": "the_nyquist_stability_criterion_and_relative_stability.html#introduction-to-relative-stability",
    "title": "The Nyquist Stability Criterion and Relative Stability",
    "section": "",
    "text": "Relative stability refers to the degree to which a system tolerates changes in its parameters before becoming unstable. Unlike absolute stability, which simply tells us whether a system is stable or not, relative stability provides a measure of how close the system is to the boundary of instability.\nConsider a plot representing the closed-loop poles on the sigma-jω (σ-jω) plane. Suppose we have two dominant poles in this system. If these poles are closer to the jω axis, the transient response of the system decays faster.\nThis positioning of the poles relative to the jω axis indicates the system’s relative stability.\nThe real part guides the envelope of the oscillating response.\n\n\n\n\n\n\n\n\n\n\nDominant poles are those which have the most significant effect on the system’s behavior.\nThe closer these poles are to the jω axis, the slower the transient response decays, indicating poorer relative stability.\n\n\n\n\nNow, let’s interpret these concepts in the frequency domain using the Nyquist plot.\nThe plots corresponding to the previous s-plane example might be as below (note that this is only an example):\n\n\n\n\n\n\n\n\n\nInsert two Nyquist plots here: 1. A plot showing a response closer to the point (-1, j0), indicating a system closer to instability. 2. Another plot showing a response further from the point (-1, j0), indicating a more stable system.\n\n\n\n\nThe Nyquist plot’s proximity to the point (-1, j0) gives us an indication of the system’s relative stability.\n\n\n\nEnclosing the point (-1, j0) indicates absolute stability.\nThe closer the plot is to this point, the higher the risk of instability.\n\n\n\n\n\nThe polar plot is a graphical representation of a system’s frequency response, spanning from ω = 0 to ω = ∞.\nThe proximity of the polar plot to the critical point (-1, j0) is indicative of the system’s potential for sustained oscillations or instability.\nIncreasing the gain of the system tends to shift the polar plot closer to the critical point (-1, j0).\nIf this plot encircles the point (-1, j0), it is a signal that the system is moving towards instability.\n\n\n\n\n\n\n\n\n\n\n\n\nThe key to understanding a system’s relative stability lies in gauging the distance of the polar (or Nyquist) plot from the point (-1, j0).\nDetermining this “relative distance” involves measuring how close the plot is to (-1, j0), which in turn reflects the system’s susceptibility to instability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot only the intersection with the negative real axis but also the phase angle of the plot is critical in assessing relative stability.\nTwo indices are often used to measure this: the point of intersection on the real axis and the phase angle at the point where the magnitude is unity.\n\n\n\n\n\n\n\n\n\n\n\n\nMagnitude at Intersection: This is measured where the Nyquist plot intersects the negative real axis. The lower this magnitude, the more stable the system is considered.\nPhase Angle: A unit circle centered at (-1, j0) is considered. The angle at which this circle intersects the Nyquist plot provides a measure of relative stability.\n\nYou can also say that these two indices are not necessarily enough. However, they provide a simple algorithm to quantify the relative stability.\n\n\n\n\n\n\nLet’s delve into the scenario where the system’s gain, denoted as \\(K\\), is progressively increased. With this increment in gain, the overall magnitude of the Nyquist plot also rises. At a specific gain value, the plot intersects the critical point of (-1, j0).\nTo determine the precise gain increment required for the plot to intersect (-1, j0), we use the factor \\(\\frac{1}{a}\\). Here, \\(a\\) represents the distance of the plot’s intersection from the real axis in its original state (before gain increase).\nBy applying a gain of \\(\\frac{1}{a}\\) to your polar plot, you align its intersection with the real axis precisely at the -1 point.\nThe Gain Margin (GM) is mathematically expressed as \\[GM = \\frac{1}{a}.\\] This value represents the threshold before the system reaches a state of marginal stability or instability.\nThe gain margin looks at the amplification factor at which a system becomes unstable.\nThe following illustration depicts this concept visually:\n\n\n\n\n\n\n\n\n\n\nTo further clarify this concept, let’s examine a specific example:\nConsider the transfer function:\n\\[\nG(s) = K_1\\frac{1 + sT_1}{s(1 + sT_2)}\n\\]\nIn this case, the number of open-loop poles in the right-half plane, denoted as \\(P\\), equals 0. This scenario corresponds to the Nyquist plot shown below:\n\n\n\n\n\n\n\nFocusing on the phase margin, denoted as \\(\\phi\\), we analyze its significance in system stability:\n\nThe phase margin \\(\\phi\\) represents the additional phase lag that can be introduced into the system without causing it to intersect the critical point (-1, j0).\nEssentially, it quantifies the system’s capacity to handle phase shifts without falling into instability.\n\nWhen considering the phase margin, a positive value of \\(\\phi\\) is indicative of the system’s robustness.\nThis positive phase margin is the threshold of additional phase lag that, if incorporated into the system, would lead it to the very edge of instability, yet not cross over into an unstable state.\nThe presence of a positive phase margin serves as a safeguard against instability, demonstrating the system’s ability to withstand certain levels of phase alterations.",
    "crumbs": [
      "The Nyquist Stability Criterion and Relative Stability"
    ]
  },
  {
    "objectID": "the_nyquist_stability_criterion_and_relative_stability.html#infinite-gain-margin",
    "href": "the_nyquist_stability_criterion_and_relative_stability.html#infinite-gain-margin",
    "title": "The Nyquist Stability Criterion and Relative Stability",
    "section": "Infinite Gain Margin",
    "text": "Infinite Gain Margin\nConsider a system where the Nyquist plot becomes asymptotic to a line but never intersects. In such cases, the gain margin is considered infinite.\nConsider the transfer function:\n\\[\nG(s) = \\frac{K}{s(1 + sT)}\n\\]\nThis function has the following Polar plot, which never intersects the point -1. It asymptotically gets closer to the real axis for \\(K\\) increasing.\n\n\n\n\n\n\n\n\n\n\nImplication:\nWhile it may sound ideal, an infinite gain margin often indicates other stability factors to consider, primarily the phase margin. The phase margin in this case is better suited to measure the distance to the -1 point, and it reduces when we increase \\(K\\).\n\nUnderstanding Gain and Phase Margins in Open-Loop Stable Systems\nIt’s important to recognize that open-loop unstable systems fall outside the scope of the conventional definitions of gain and phase margins.\nThese margins are specifically designed and applicable for systems that exhibit stability in their open-loop configuration.\nConsequently, the assessments of gain and phase margins are primarily relevant and meaningful when dealing with open-loop stable systems. In cases where the system is open-loop unstable, these definitions are not directly applicable, and alternative methods of stability analysis should be considered.\nWhile the majority of industrial plants and control systems are inherently open-loop stable, it is crucial to exercise special caution when encountering an open-loop unstable system. This scenario, though less common, requires a more nuanced approach to ensure effective and safe plant operation. Understanding and addressing the unique challenges posed by open-loop unstable systems is essential for maintaining system stability and reliability.\n\n\nType-0 Systems\nLet’s explore a specific example of a type-0 system, where the degrees of the numerator and denominator of the transfer function are equal.\n\nTransfer Function:\n\n\\[\nG(s)H(s) = \\frac{1 + sT_1}{1 + sT_2}\n\\]\nThis is a type-0 system with the following Nyquist Plot:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{1 + j\\omega T_1}{1 +  j\\omega T_2}\n\\]\n\nStability Analysis: The system is stable for all \\(T_1\\) and \\(T_2\\). This makes the traditional definitions of gain and phase margin less meaningful.\n\nWe can show this using Python:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nimport matplotlib.cm as cm\n\n# Define the ranges for T1 and T2 values\nT1_values = np.linspace(0.2, 1, 5)  # Adjust the number of values as needed\nT2_values = np.linspace(0.5, 1.5, 5)  # Adjust the number of values as needed\n\n# Prepare a colormap\nnum_plots = len(T1_values) * len(T2_values)\ncolors = cm.viridis(np.linspace(0, 1, num_plots))  # Use 'viridis' colormap\n\n# Prepare the plot\nplt.figure(figsize=(10, 8))\nplt.title('Nyquist Plots for Different T1 and T2 Values')\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\n\n# Iterate over combinations of T1 and T2\ncolor_idx = 0\nfor T1 in T1_values:\n    for T2 in T2_values:\n        num = [1, T1]\n        den = [1, T2]\n        G = ctl.TransferFunction(num, den)\n\n        # Extract real and imaginary parts\n        _, contour = ctl.nyquist(G, omega=np.logspace(-2, 1, 1000), return_contour=True)\n        real, imag = np.real(G(contour)), np.imag(G(contour))\n\n        # Plot each curve with a label and the same color for mirror image\n        color = colors[color_idx]\n        plt.plot(real, imag, label=f'T1 = {T1:.1f}, T2 = {T2:.1f}', color=color)\n        plt.plot(real, -imag, color=color)  # Nyquist plot is symmetric\n        color_idx += 1\n\n# Add legend, grid, and axis lines\nplt.legend()\nplt.grid(True)\nplt.axhline(y=0, color='k')  # Add x-axis\nplt.axvline(x=0, color='k')  # Add y-axis\nplt.xlim([-2, 2])  # Adjust x-axis limits as needed\nplt.ylim([-2, 2])  # Adjust y-axis limits as needed\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "The Nyquist Stability Criterion and Relative Stability"
    ]
  },
  {
    "objectID": "the_nyquist_stability_criterion_and_relative_stability.html#addressing-open-loop-unstable-systems",
    "href": "the_nyquist_stability_criterion_and_relative_stability.html#addressing-open-loop-unstable-systems",
    "title": "The Nyquist Stability Criterion and Relative Stability",
    "section": "Addressing Open-Loop Unstable Systems",
    "text": "Addressing Open-Loop Unstable Systems\nWhen discussing gain margin and phase margin, their application in the context of open-loop unstable systems requires special attention.\n\nDealing with Open-Loop Unstable Systems\n\nCharacteristics: These are systems where one or more open-loop poles are located in the right-half of the s-plane.\nRelevance to Stability Margins: In such systems, the conventional interpretations of gain and phase margin are not straightforwardly applicable. A key aspect of these systems is that their Polar Plot needs to encircle the critical point (-1+j0) a specific number of times to achieve closed-loop stability.\n\n\n\nAn Illustrative Example\n\nTransfer Function: \\[\nG(s)H(s) = \\frac{s + \\frac{1}{2}}{s(s + 1)(s - 1)}\n\\] In this instance, the Nyquist plot must loop around the point (-1+j0) once to ensure stability.\nAdditional Notes: For open-loop unstable systems, comprehensive Nyquist plots or alternative techniques such as root locus analysis are typically employed. The conventional stability margins of gain and phase are not typically used to evaluate the robustness of these systems, as they may not provide clear insights. In each case, a tailored approach is needed to account for the specific encirclements in the Nyquist plot.\n\nBelow is a Python script to visualize its Nyquist Plot.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the numerator and denominator of the transfer function\n# G(s)H(s) = (s + 0.5) / (s*(s + 1)*(s - 1))  \nnum = [1, 0.5]\nden = [1, 0, -1, 0]\n\n# Create the transfer function\nG = ctl.TransferFunction(num, den)\n\n# Compute and plot the Nyquist plot\nctl.nyquist_plot(G)\nplt.title('Nyquist Plot of G(s)H(s)')\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.grid(True)\n\n# Show the plot\nplt.show()",
    "crumbs": [
      "The Nyquist Stability Criterion and Relative Stability"
    ]
  },
  {
    "objectID": "the_nyquist_stability_criterion_and_relative_stability.html#understanding-crossover-frequencies",
    "href": "the_nyquist_stability_criterion_and_relative_stability.html#understanding-crossover-frequencies",
    "title": "The Nyquist Stability Criterion and Relative Stability",
    "section": "Understanding Crossover Frequencies",
    "text": "Understanding Crossover Frequencies\nIn control systems, two critical frequencies are the gain crossover frequency (\\(\\omega_{gc}\\)) and the phase crossover frequency (\\(\\omega_{pc}\\)).\nThese frequencies are important to determine the stability and performance of a system.\n\nGain Crossover Frequency (\\(\\omega_{gc}\\))\n\nDefinition: The frequency at which the magnitude of the open-loop transfer function G(jω)H(jω) is 1 (0 dB).\nImportance: It is the frequency at which the system’s gain equals unity.\nCalculation: Determine \\(\\omega_{gc}\\) from the Nyquist or polar plot where |G(jω)H(jω)| = 1.\n\n\n\nPhase Crossover Frequency (\\(\\omega_{pc}\\))\n\nDefinition: The frequency at which the phase angle of G(jω)H(jω) reaches -180°.\nImportance: It indicates the frequency at which the system’s phase shift might lead to instability.\nCalculation: Determine \\(\\omega_{pc}\\) from the Nyquist or polar plot where the phase angle of G(jω)H(jω) is -180°.er (\\(\\omega_{PC}\\)):** This is the frequency at which the phase angle of the system reaches -180 degrees.\n\n\n\n\n\n\n\n\n\n\nClarifying Gain and Phase Margins in Control Systems\nThe gain margin, denoted as $ $, is a critical parameter in assessing a system’s stability. It’s important to understand that this margin is not directly the gain of the system itself. Instead, it becomes the gain only in the context of a system whose original plot is based on unity gain. In other cases, the gain margin represents the factor by which the system’s original gain can be modified.\n\nFurther Comments on the Gain Margin\n\nAssuming an Open-Loop Stable system (\\(P=0\\))\nFor a stable system, the gain margin is always greater than 1.\nFor an unstable system, the gain margin is less than 1.\nIf the gain margin is less than 1, it implies that the system’s gain has been increased to a level where instability has been introduced. To return the system to a stable state, the gain must be reduced by this margin factor.\n\n\n\nFurther Comments on the Phase Margin\n\nThe phase margin is determined by measuring a specific angle on the Nyquist plot. This angle represents the amount by which the phase can be increased without leading to instability.\nIn systems that are open-loop stable, a positive phase margin indicates a buffer against instability, whereas a negative phase margin is a sign of potential instability.\nAssume to measure the phase margin angle with respect to the negative real axis.",
    "crumbs": [
      "The Nyquist Stability Criterion and Relative Stability"
    ]
  },
  {
    "objectID": "dynamic_response.html",
    "href": "dynamic_response.html",
    "title": "Dynamic response of control systems",
    "section": "",
    "text": "Today, we delve deeper into understanding the dynamic response of control systems.\nHaving introduced the transfer function of a plant, which refers to the modeling of the plant, and models of disturbances and test signals, we are poised to explore the dynamic response of the system. Let’s visualize our model.\nRemember, the general form for the system’s output in the Laplace domain is \\(Y(s)=G(s)R(s)\\). This relationship transforms convolution in the time domain to multiplication in the s-domain.\nWhen interested in the time response \\(y(t)\\), we’ll have to obtain \\(G(s)\\) and \\(R(s)\\), calculate \\(Y(s)\\), and finally invert to get \\(y(t)\\).\nConsidering the inversion of Laplace, it’s tabulated in various textbooks, so we won’t delve deep into its derivations. Rather, we’ll utilize these tables for inversion purposes.\nRecall that \\(R(s)\\) are modeled typically through impulse, step, ramp, and parabolas.",
    "crumbs": [
      "Dynamic response of control systems"
    ]
  },
  {
    "objectID": "dynamic_response.html#common-laplace-transform-pairs",
    "href": "dynamic_response.html#common-laplace-transform-pairs",
    "title": "Dynamic response of control systems",
    "section": "Common Laplace Transform pairs",
    "text": "Common Laplace Transform pairs\n\n\n\n\n\n\n\nPop-up Question: Can you recall the significance of the transfer function in control systems?\nAnswer: The transfer function, \\(G(s)\\), represents the relationship between the input and output of a system in the Laplace domain. It is a crucial tool for analysis and design in control systems.\nFor better clarity, let’s dive into a few examples:\n\nExample 1\n\\[\nG(s) = \\frac{1}{s^2+3s+2}\n\\]\nIt’s observed that the numerator polynomial is of zero order, and the denominator polynomial is of second order, implying a second-order system. To represent it in pole-zero form:\n\\[\nG(s) = \\frac{1}{(s+1)(s+2)}\n\\]\nGiven the input $ r(t) = 5 (t) $, a step input of magnitude 5, we know that $ R(s) = $.\nTherefore, $ Y(s) = G(s) R(s) $ becomes:\n\\[  Y(s) = \\frac{5}{s(s+1)(s+2)} \\]\nWe now have three poles in the response transfer.\nLet’s derive the response \\(y(t)\\) from \\(Y(s)\\).\nFor systems like this, using partial fraction decomposition helps in breaking down complex expressions, which can then be inversely transformed to the time domain easily.\nLet’s delve on how to do this: 06_inverse_laplace_transform\nApplying fraction expansion we obtain:\n\\[  Y(s) = \\frac{5}{s(s+1)(s+2))} = \\frac{5/2}{s} - \\frac{5}{s+1} + \\frac{5/2}{(s+2)}\\]\nNote: - \\(- \\frac{5}{s+1} + \\frac{5/2}{(s+2)}\\) are due to the system poles - \\(\\frac{5/2}{s}\\) is due to the excitation pole\nInverting \\(Y(s)\\) we obtain:\n\\[\ny(t) = \\frac{5}{2} - 5e^{-t} + \\frac{5}{2}e^{-2t}\n\\]\n\nThe terms \\(- 5e^{-t} + \\frac{5/2}e^{-2t}\\) are generated when the system is excited by the step input. These two terms die away as time increases. This is the transient response of the system\nThe term \\(\\frac{5}{2}\\) is due to the input, and its nature is similar to the input itself. However its amplitude has been modified, and this depends on the response of the system to the input. Since the input persist for all time, this specific response will persist for all time. This is called the steady state response.\n\n\n\nThe final value theorem\nThe final value theorem is an indispensable tool for determining the steady-state value of a system’s response without having to compute the entire time-domain response.\n\\[\ny_{ss} = \\lim_{t \\to \\infty} y(t) = \\lim_{s \\to 0} s Y(s)\n\\]\nIt is essential to note that the Final Value Theorem is applicable if and only if the following conditions are met:\n\nThe poles of \\(Y(s)\\) are located in the left half of the s-plane, ensuring the function is stable. \\[\\Downarrow\\] This means that \\(s Y(s)\\) has no poles on \\(j\\omega-axis\\) and/or the right half plance.\n\nPop-up Question: Why do we focus on the left half of the s-plane for the application of the Final Value Theorem?\nAnswer: Systems with poles in the right half of the s-plane are unstable, and their responses tend to infinity as \\(t→∞\\). The theorem requires the function to stabilize or reach a steady-state value as time approaches infinity.\nIn our case:\n\\[\ns Y(s) = \\frac{5s}{s(s+1)(s+2)}\n\\]\nand hence:\n\\[\ny_{ss} = \\lim_{s \\to 0} s Y(s) = \\frac{5}{2}\n\\]\nWe can now plot the step response of the system, i.e., \\(y(t)\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\n# Python code to obtain time response\nsys = lti([5], [1, 3, 2])\nt, y = step(sys)\nplt.plot(t, y, label='y(t)')\nplt.plot(t, np.linspace(5,5,num=len(t)), label='input')\nplt.plot(t, np.linspace(5/2,5/2,num=len(t)), label='y_{ss}')\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nExample 2\nWe consider the same plant as before:\n\\[\nG(s) = \\frac{1}{(s+1)(s+2)} = \\frac{1}{s^2+3s+2}\n\\]\nbut now with a ramp input:\n\\[\nr(t) = 5t\\mu(t)\n\\]\nwhose Laplace transform is\n\\[\nR(s) = \\frac{5}{s^2}\n\\]\nand the response tranform is:\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)}\n\\]\nWe can calculate the inverse transform with partial fraction decomposition.\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)} = \\\\\n\\frac{5/2}{s^2} + \\frac{K}{s} + \\frac{5}{s+1} - \\frac{5/4}{s+2}\n\\]\nwhere\n\\[\nK= \\frac{d}{ds}\\Big[\\frac{5}{(s+1)(s+2)}\\Big]\\Big|_{s=0} = \\frac{d}{ds}\\Big[\\frac{5}{(s^2+3s+2)}\\Big]\\Big|_{s=0} = - \\frac{5(2s+3)}{(s^2+3s+2)^2}\\Big|_{s=0} = \\frac{-15}{4}\n\\]\nand hence the full expression is:\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)} = \\\\\n\\frac{5/2}{s^2} - \\frac{15/4}{s} + \\frac{5}{s+1} - \\frac{5/4}{s+2}\n\\]\nWe can invert:\n\\[\ny(t) = \\frac{5}{2}t - \\frac{15}{4} + 5e^{-t} - \\frac{5}{4}e^{-2t}\n\\]\n\nAgain the terms due to the system poles go to zeros (transient component) - last two terms in the equation.\nThe other components (first two components) are due to the presence of the specific ramp input.\n\nThe steady state in this case hence is:\n\\[\ny_{ss} = \\frac{5}{2}t - \\frac{15}{4}\n\\]\nThe response is hence of the form:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nsys = lti([5], [1, 3, 2])\nt, y = step(sys)\n\n# Python code to obtain time response\ny = 5/2*t-15/4 + 5*np.exp(-t) - 5/4*np.exp(-2*t)\nplt.plot(t, y, label=r'$y(t)=\\frac{5}{2}t-\\frac{15}{4}+5e^{-t}-\\frac{5}{4}e^{-2t}$')\nplt.plot(t, 5*t, label=r'input: $5t$')\nplt.plot(t, 5/2*t-15/4, label=r'$y_{ss}=\\frac{5}{2}t-\\frac{15}{4}$')\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nCan we apply the final value theorem?\n\\[\ny_{ss} = \\lim_{t \\to \\infty} y(t) = \\lim_{s \\to 0} s Y(s) = \\lim_{s \\to 0} \\frac{5s}{s^2(s+1)(s+2)} = \\inf\n\\]\n\nHowever there is a pole at the origin and the final value theorem is not applicable.\nIn this case, the steady state is not \\(\\infty\\) and is given by:\n\n\\[\ny_{ss} = \\frac{5}{2}t - \\frac{15}{4}\n\\]\n\nThe steady state starts as soon as the transient dies out.\nThe two values match at infinity, but the total steady state expression is not obtained by the final value theorem due to the presence of a pole at the origin in \\(sY(s)\\).",
    "crumbs": [
      "Dynamic response of control systems"
    ]
  },
  {
    "objectID": "dynamic_response.html#first-order-systems",
    "href": "dynamic_response.html#first-order-systems",
    "title": "Dynamic response of control systems",
    "section": "First-Order Systems",
    "text": "First-Order Systems\nConsider a simple mechanical system: an inertial load with a moment of inertia, \\(J\\). This load is connected to a rigid shaft, implying the spring constant for this shaft is zero (it’s non-flexible).\n\n\n\n\n\n\n\nThe friction environment of the system can be schematically illustrated through two force bearings characterized by a viscous friction coefficient, \\(B\\).\nIn this system:\n\nInput Variable: Torque, \\(T(t)\\)\nOutput Variable: Speed, \\(ω(t)\\)\nConstant Parameters: \\(J\\) and \\(B\\)\n\nBased on Newton’s laws, the governing equation becomes:\n\\[\nJ\\dot\\omega(t)+B\\omega(t)=T(t)\n\\]\nAfter applying the Laplace transformation:\n\\[\nJs\\omega(s)+B\\omega(s)=T(s)\n\\]\nNote: In our discussions, the systems will be considered “relaxed”, meaning initial conditions are not appearing in the transformed equation.\nFrom this, the transfer function \\(G(s)\\) is derived:\n\\[\nG(s)=\\frac{\\omega(s)}{T(s)} = \\frac{1}{Js+B}\n\\]\nwhich is a first-order model, with parameters \\(J\\) and \\(B\\).",
    "crumbs": [
      "Dynamic response of control systems"
    ]
  },
  {
    "objectID": "dynamic_response.html#a-general-model-for-first-order-systems",
    "href": "dynamic_response.html#a-general-model-for-first-order-systems",
    "title": "Dynamic response of control systems",
    "section": "A General Model for First-Order Systems",
    "text": "A General Model for First-Order Systems\nEvery first-order system, irrespective of its domain (mechanical, electrical, thermal, etc.), can be generalized using the following form:\n\\[\nG(s) = \\frac{K}{(\\tau s+1)}\n\\]\nWith parameters: - \\(K\\): system gain. - \\(\\tau\\): time constant of the system.\nThe term “system gain” refers to the steady-state change in output for a unit change in input. Meanwhile, the time constant describes how fast the system responds to changes.\nFor instance, if we apply a unit step input:\n\\[\nT(s)=\\frac{1}{s},\n\\]\nthe response becomes:\n\\[\n\\omega(s) = \\frac{K}{s(\\tau s+1)}\n\\]\nThe time domain response, \\(\\omega(t)\\), after inversion, characterizes the system’s dynamic behavior:\n\\[\n\\omega(t) = K \\Big[ 1 - e^{-t/\\tau}\\Big]\n\\]\n\nDecoding the Parameters:\n\nSystem Gain, \\(K\\): As \\(t→∞\\), \\(\\omega(t)\\) approaches \\(K\\), illustrating why \\(K\\) is termed the system gain.\n\nThe speed of our system (the inertial load) changes to the value \\(K\\) in response to a unit step. It changes the output of the system by \\(K\\).\n\nTime Constant, \\(\\tau\\): The time constant signifies the system’s speed of response.\n\nTo understand this, let’s sketch the system’s response:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\ntau = 1\n\nt = np.linspace(0, 5, 50)\nw_t = K*(1-np.exp(-t/tau))\ntransient = -K*np.exp(-t/tau)\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\n\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\nax.plot(t, transient, label=r'$-K*e^{(-t/\\tau)}$', linewidth=3)\nax.plot(t, w_t, label=r'$\\omega(t)=K*(1-e^{(-t/\\tau)})$', linewidth=3)\nax.plot(t[0:11], K/tau*t[0:11]-K)\n\nfor t_bar in [tau, 2*tau, 3*tau, 4*tau, 5*tau]:\n    ax.plot(t_bar, -K*np.exp(-t_bar/tau), markersize=15, marker='.', color='k')\n\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"w(t)\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(tau, 0.03, r'$\\tau$', fontsize=14)\nax.text(0.2, K, 'K', fontsize=14)\nax.text(0.2, -K, '-K', fontsize=14)\n\nax.text(tau+0.1, -K*0.3629, '-.3629K', fontsize=14)\nax.text(4*tau+0.1, -K*0.0183-0.1, '-.0183K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe final value of the response is \\(K\\).\nAs for the transient term \\(-Ke^{-t/\\tau}\\), it diminishes to zero when \\(t\\) approaches infinity.\n\nLet’s dive into the transient.\nBy evaluating:\n\\[\n\\frac{d}{dt}\\Big( -Ke^{-t/\\tau} \\Big) \\Big|_{t=0} = \\frac{K}{\\tau}\n\\]\nwe infer that the initial rate of change of the transient at \\(t=0\\) is \\(\\frac{K}{\\tau}\\) (initial slope).\nIf the transient maintained its initial rate of decrease, it would vanish in a duration of \\(\\tau\\).\nThis time constant gives us an idea about the duration it would take for the transient to wane if the decline was solely guided by its initial rate of change \\(\\frac{K}{\\tau}\\).\nYet, this rate isn’t static. Observing the specific values:\n\n\n\n\\(t\\)\n\\(e^{-t/\\tau}\\)\n\n\n\n\n\\(\\tau\\)\n0.3679\n\n\n\\(4\\tau\\)\n0.0183\n\n\n\\(5\\tau\\)\n0.0067\n\n\n\nWe see that between \\(4\\tau\\) and \\(5\\tau\\), the transient is nearly non-existent, indicating the time it takes for the system to stabilize. Do remember, however, it truly becomes zero only as \\(t\\) approaches infinity.\nFrom a pragmatic standpoint, it’s reasonable to assert that the system has reached its stable state in \\(5\\tau\\).\nPop-up Question: Why is the time constant crucial in control system design?\nAnswer: The time constant indicates the system’s speed of response. For desired fast responses, a smaller time constant is preferable. Larger time constants might render the system’s response sluggish, which is often undesirable in control applications.\n\nSpeed of response\nIn control system dynamics, the speed of response with which a system reacts is important. Upon an input’s introduction, one of our goal is (typically) for the plant to respond without delay.\nConsidering the system’s time constant — where it takes between \\(4\\tau\\) and \\(5\\tau\\) to achieve steady-state — a shorter time constant implies a quicker response. In contrast, a lengthier time constant suggests the system’s tendency to respond more sluggishly.\n\n\nSluggish and fast Systems:\nA system termed as ‘sluggish’ typically possesses a large time constant. Systems managing temperature control, liquid levels, pressure, or chemical compositions – these are the realms of process control applications and most of these applications usually have large time constants; in essence, they are ‘sluggish’.\nThis stands in contrast to systems like speed control or radar tracking. These latter systems have smaller time constants, marking them ‘fast’ systems.\nJust to provide a scale, the time constant of systems can range anywhere from mere milliseconds (as seen in radar tracking or speed control systems) to a few minutes, commonly observed in temperature control setups among others.\n\n\nFirst order lag\nThe transfer function we saw before\n\\[\nG(s) = \\frac{K}{(\\tau s+1)}\n\\]\nis known as the first-order lag. Essentially, when we see this term, it hints that the system does not allow for instantaneous response.\n\nThis system, either termed as the first-order lag or simply as a ‘simple lag’, is completely characterized by two parameters: \\(K\\) (system gain) and \\(\\tau\\) (time constant).",
    "crumbs": [
      "Dynamic response of control systems"
    ]
  },
  {
    "objectID": "dynamic_response.html#a-general-model-for-second-order-systems",
    "href": "dynamic_response.html#a-general-model-for-second-order-systems",
    "title": "Dynamic response of control systems",
    "section": "A General Model for Second-Order Systems",
    "text": "A General Model for Second-Order Systems\nWhile the terms \\(J\\), \\(B\\), and \\(k\\) are specific to our example, in the broader control system context, we often employ three general parameters to describe the behavior of a second-order system:\n\n\\(\\omega_n\\): natural frequency,\n\\(\\zeta\\): damping ratio,\n\\(K\\): system gain.\n\nThe general transfer function model becomes:\n\\[\nG(s) = \\frac{K}{\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1}\n\\]\nwhere, in our example:\n\n\\(K = \\frac{1}{k}\\)\n\\(\\omega_n = \\sqrt{\\frac{k}{J}}\\)\n\\(\\zeta = \\frac{1}{2}\\frac{B}{\\sqrt{kJ}}\\)\n\nWe now delve into the intricacies of second-order systems by examining their response to a step input. A deep comprehension of this behavior helps in delineating the significant roles played by the parameters: \\(\\omega_n\\) (natural frequency), \\(\\zeta\\) (damping ratio), \\(K\\) (system gain).\n\nParameter \\(K\\)\nThe parameter \\(K\\) determines, as before, the gain of the system. The final value theorem can be employed to validate that for a unit step input, the final value of the response value is governed by \\(K\\).\n\\[\nY(s) = \\frac{K}{s\\Big(\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 \\Big)}\n\\]\n\\[\nsY(s) = \\frac{K}{\\Big(\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 \\Big)}\n\\]\nAssuming that the values of \\(\\omega_n\\) (natural frequency) and \\(\\zeta\\) (damping ratio) are such that the roots of the denominator are in the left half plane, we can apply the Final Value Theorem:\n\\[\nlim_{s \\rightarrow 0} sY(s) = K\n\\]\n\n\nParameters \\(\\omega_n\\) and \\(\\zeta\\)\n\\[\n\\frac{\\theta(s)}{T(s)} = \\frac{K\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\n\\]\nSince \\(T(s)=\\frac{1}{s}\\) (step input):\n\\[\n\\theta(s) = \\frac{K\\omega_n^2}{s\\Big(s^2 + 2\\zeta\\omega_n s + \\omega_n^2\\Big)}\n\\]\nThe time domain response, \\(\\theta(t)\\), after inversion, characterizes the system’s dynamic behavior:\n\\[\n\\theta(t) = \\mathcal{L}^{-1}\\Big[\\theta(s)\\Big]\n\\]\nLet’s consider four cases:\n\ncase 1: \\(\\zeta=0\\)\ncase 2: \\(0&lt;\\zeta&lt;1\\)\ncase 3: \\(\\zeta=1\\)\ncase 4: \\(\\zeta&gt;1\\)\n\nCase 1, in our example, corresponds to \\(B=0\\) (no damping). All the other cases correspond to \\(B\\ne0\\) (damping)\n\n\nCase 1, \\(\\zeta=0\\)\n\\[\n\\theta(s) = \\frac{K\\omega_n^2}{s\\Big(s^2 + \\omega_n^2\\Big)} = K\\Big[ \\frac{1}{s} - \\frac{s}{s^2+\\omega_n^2}\\Big]\n\\]\n\\[\n\\theta(t) = K(1-\\cos(\\omega_nt))\n\\]\n\nimport sympy as sp\n\n# Define the symbols\ns, t, K, omega_n = sp.symbols('s t K omega_n', real=True)\n\n# Define theta(s)\ntheta_s = K * omega_n**2 / (s * (s**2 + omega_n**2))\n\n# Calculate the inverse Laplace transform\ntheta_t = sp.inverse_laplace_transform(theta_s, s, t)\n\n# Display the result\nsp.pprint(theta_t, use_unicode=True)\n\n    2 ⎛  cos(ωₙ⋅t)⋅θ(t)   θ(t)⎞\nK⋅ωₙ ⋅⎜- ────────────── + ────⎟\n      ⎜         2           2 ⎟\n      ⎝       ωₙ          ωₙ  ⎠\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\n\nt = np.linspace(0, 15, 50)\ntheta_t = K*(1-np.cos(omega_n*t))\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\n\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\nax.plot(t, theta_t, label=r'$K(1-\\cos(\\omega_nt))$', linewidth=3)\n\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn this scenario, the system exhibits oscillations around the value of \\(K\\). These oscillations, owing to the absence of damping, are referred to as un-damped oscillations.\n\nThe frequency of these oscillations, \\(\\omega_n\\), is termed as the un-damped natural frequency.\n\nNote: This is typically an unwanted behaviour (e.g., industrial setting), but depends on the requirements.\nPop-up Question: Why is the oscillating behavior not preferable in most control systems?\nAnswer: In most industrial scenarios, oscillations can lead to inefficiencies, system wear, or undesirable outcomes.\nExample: Think about residential heating with an on/off control system. The temperature oscillates within a certain range, which might be acceptable for heating but not for precision-controlled processes.\n\n\nCase 2, \\(0&lt;\\zeta&lt;1\\), Underdamped Case\n\\[\n\\theta(s) = \\frac{K\\omega_n^2}{s\\Big(s^2 + 2\\zeta\\omega_n s + \\omega_n^2\\Big)} = K\\Big[\\frac{1}{s} - \\frac{s+\\zeta\\omega_n}{(s+\\zeta\\omega_n)^2 + \\omega_d^2} - \\frac{\\zeta\\omega_n}{(s+\\zeta\\omega_n)^2 + \\omega_d^2} \\Big]\n\\]\nThe response, in this case, showcases damped oscillations. In our example, this corresponds to \\(B\\ne0\\).\nThis case corresponds, in our example, to the case where the parameters of our original system must verify:\n\\[\n\\frac{k}{J} &gt; \\Big(\\frac{B}{2J}\\Big)^2\n\\]\nwith response:\n\\[\n\\theta(t) = K\\Big[1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}} \\sin\\Big(\\omega_d t + \\tan^{-1} \\frac{\\sqrt{1-\\zeta^2}}{\\zeta}\\Big)\\Big]\n\\]\nwhere: - \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\), is called damped natural frequency (the name will be clear looking at the response curves).\n\n\nResponse curves\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzetas = [0.1, 0.3, 0.6, 0.999]\n\nt = np.linspace(0, 15, 50)\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\nfor zeta in zetas:\n    omega_d = omega_n*np.sqrt(1-zeta**2)\n    theta_t = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2)*np.sin(omega_d*t + np.arctan(np.sqrt(1-zeta**2)/zeta)))\n    #theta_t = K*(1 - (1/np.sqrt(1-zeta**2)) * np.exp(-zeta*omega_n*t) * np.sin(omega_d*t+np.arccos(zeta)))\n    ax.plot(t, theta_t, label=r'$\\zeta$='+f\"{zeta}\", linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn this regime, the system’s response is oscillatory. However, these oscillations are not unbounded. Instead, they die out over time, which is often described as “damped oscillations”, and decrease when \\(\\zeta\\) increases.\nLimiting situations\n\nWhen \\(\\zeta=1\\) is the limiting situation where the oscillations have just died out.\nThe other limiting case is of course the one where \\(\\zeta=0\\), which we have just seen, and for which the oscillations are undamped.\n\nNote from the graph above how the system becomes sluggish as the value of \\(\\zeta\\) increases: the settling time, the speed of response, increases. If the \\(\\zeta\\) decreases however you are increases the oscillations.\n\n\nPractical Implications:\n\nSystem Behaviour: In industrial control systems, the under-damped behavior is usually desired because it achieves a quick response without prolonged oscillations. Oscillations are typically seen as undesirable in control systems as they indicate instability or inefficiencies.\nBalancing Speed and Oscillation: There’s a delicate balance to strike. If \\(\\zeta\\) is too small (close to 0), the system can be too oscillatory, leading to potential instability. On the other hand, if \\(\\zeta\\) is too large (approaching 1), the system can become sluggish.\nApplication Examples: For applications that can tolerate some oscillation in exchange for a rapid response (e.g., certain manufacturing processes), a slightly under-damped system might be ideal. In scenarios where the precision of settling is vital (e.g., robotic arm positioning), it’s crucial to design the system so that oscillations are minimal, even at the cost of a slower response.\n\nThe choice of damping level in system design often involves trade-offs. While the under-damped case is often preferred, understanding the exact needs of a particular application or process is crucial. This ensures that the system responds optimally, balancing speed, oscillation, and stability.\nLet’s take a more detailed view now of the oscillations, looking at a typical under-damped response:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzeta = 0.3\n\nt = np.linspace(0, 15, 50)\n\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\n\nomega_d = omega_n*np.sqrt(1-zeta**2)\ntheta_t = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2)*np.sin(omega_d*t + np.arctan(np.sqrt(1-zeta**2)/zeta)))\n\nenvelope_plus = K*(1 + np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2))\nenvelope_minus = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2))\n\nax.plot(t, envelope_plus, linewidth=3, color='b')\nax.plot(t, envelope_minus, linewidth=3, color='b')    \n\nax.plot(t, theta_t, label=r'$\\zeta$='+f\"{zeta}\", linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\nax.text(6, 1.5, r'$K (1+\\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})$', fontsize=14)\n\nax.text(6, 0.5, r'$K (1-\\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})$', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThe blue lines represent the envelope of the response:\n\\[\nK (1 \\pm \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})\n\\]\nThe decay of the oscillations is determined by the envelope of the oscillatory response. The decay of the envelope depends on the exponential factor:\n\\[\ne^{-\\zeta\\omega_nt}\n\\]\nThe time constant of this is:\n\\[\ne^{-t/\\tau} = e^{-\\zeta\\omega_nt}\n\\]\nor\n\\[\n\\tau = \\frac{1}{\\zeta\\omega_n}\n\\]\nThe higher the value of \\(\\zeta\\omega_n\\), the quicker the oscillations die out.\nThe system oscillates at a damped natural frequency, \\(\\omega_d\\), which is expressed as:\n\\[\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\]\nand where \\(\\omega_n\\) is the undamped natural frequency.\n\nCase 3, \\(\\zeta=1\\), Critically Damped\nHere, the system is on the brink of oscillating. The response showcases a scenario where oscillations are just eliminated.\nIn our example this corresponds to:\n\\[\n\\frac{k}{J} = \\Big(\\frac{B}{2J}\\Big)^2\n\\]\nwith response:\n\\[\n\\theta(t) = K\\Big[1 - e^{-\\omega_n t} - \\omega_n t e^{-\\omega_n t} \\Big]\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzeta = 1\n\nt = np.linspace(0, 10, 50)\n\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\n\ntheta_t = K*(1 - np.exp(-zeta*omega_n*t)  -omega_n*t*np.exp(-zeta*omega_n*t))\n\n\nax.plot(t, theta_t, label=r'$\\theta_t$', linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nAchieving critical damping is challenging, as it requires precise tuning. Even slight deviations can lead the system to become over or under-damped.\nCritically damped systems return to equilibrium or the steady-state value without overshooting (oscillating) and in the quickest possible time.\nWhile under-damped systems oscillate around the equilibrium before settling, critically damped systems do not. They approach the equilibrium directly, with the quickest response time that avoids oscillation.\nFor a second-order linear homogeneous differential equation describing a system, the critically damped state produces two equal real roots. This results in a solution that’s a combination of exponential decay terms.\n\nApplication Examples: - Vehicle Suspension: In cars, the shock absorbers aim to be critically damped to provide a comfortable ride by quickly absorbing bumps without causing the car to oscillate. - Electronics: In circuit design, critically damped responses are preferred for signal processing where the signal needs to settle quickly without overshooting.\n\n\nCase 4, \\(\\zeta&gt;1\\), Over-Damped\n\nThe Over-damped Case represents a situation where the damping is excessive, leading to a slow return to equilibrium.\nOver-damped systems return to equilibrium slower than both critically damped and under-damped systems, with no overshooting.\nFor the second-order linear homogeneous differential equation describing such a system, the over-damped state produces two distinct real roots. This results in a response combining two distinct exponential decay terms.\nThere are cases where over-damping is intentional. In some sensitive equipment or processes, oscillation (even if it’s minor) can be harmful or undesirable, making a slower return to equilibrium an acceptable trade-off. The over-damped case underscores the need for careful consideration in control and system design. While it might appear suboptimal due to its slow response, in certain contexts, this deliberate delay is crucial for maintaining safety and functionality\n\nApplication Examples: - Door Closers: Many commercial door closers are over-damped to ensure that doors close completely without slamming or bouncing back. - Safety Systems: Certain safety mechanisms might employ over-damping to guarantee a gentle, albeit slower, return to a safe state.",
    "crumbs": [
      "Dynamic response of control systems"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/step_testing_tclab_it.html",
    "href": "IT_TCLab_🇮🇹/step_testing_tclab_it.html",
    "title": "Passo Test",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom tclab import TCLab, clock, Historian, Plotter\nEsegui la cella successiva se vuoi solo simulare TCLab\nfrom tclab import setup\nTCLab = setup(connected=False, speedup=20)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Passo Test"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#esecuzione-dello-step-test",
    "href": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#esecuzione-dello-step-test",
    "title": "Passo Test",
    "section": "Esecuzione dello Step Test",
    "text": "Esecuzione dello Step Test\n\nVerifica uno stato stazionario iniziale\nUno step test presuppone che il sistema sia inizialmente allo stato stazionario. Nel caso del Laboratorio di Controllo della Temperatura, il valore iniziale stabile senza assorbimento di corrente sarebbe la temperatura ambiente. Generalmente sono necessari 10 minuti o più per raggiungere lo stato stazionario. Faremo una misurazione per confermare la temperatura iniziale.\n\nlab = TCLab()\nprint(lab.T1, lab.T1)\nlab.close()\n\nTCLab version 1.0.0\nSimulated TCLab\n20.949499999999997 20.949499999999997\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Passo Test"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#conduci-lesperimento",
    "href": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#conduci-lesperimento",
    "title": "Passo Test",
    "section": "Conduci l’esperimento",
    "text": "Conduci l’esperimento\n\n# experimental parameters\nQ1 = 50\ntfinal = 800\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    lab.Q1(0)\n    for t in clock(tfinal):\n        p.update(t)\n        lab.Q1(Q1)\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Passo Test"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#verifica-i-dati-sperimentali",
    "href": "IT_TCLab_🇮🇹/step_testing_tclab_it.html#verifica-i-dati-sperimentali",
    "title": "Passo Test",
    "section": "Verifica i dati sperimentali",
    "text": "Verifica i dati sperimentali\n\nh.columns\n\n['Time', 'T1', 'T2', 'Q1', 'Q2']\n\n\n\ntry:\n    t = h.t\n    T1 = h.T1\n    T2 = h.T2\n    Q1 = h.Q1\n    Q2 = h.Q2\nexcept:\n    t, T1, T2, Q1, Q2 = h.fields\n    \nplt.plot(t, T1, t, T2, t, Q1, t, Q2)\nplt.legend(['T1','T2','Q1','Q2'])\nplt.xlabel('time / seconds')\nplt.grid()\n\n\n\n\n\n\n\n\n\nConverti in un DataFrame\n\nimport pandas as pd\n\ndf = pd.DataFrame([t, T1, T2, Q1]).T\ndf.columns = ['Time', 'T1', 'T2', 'Q1']\ndf = df.set_index('Time')\ndf.plot(grid=True)\n\n\n\n\n\n\n\n\n\n\nSalva DataFrame come file .csv\n\ndf.to_csv('Step_Test_Data.csv')\n\n\n\nVerificare il file di dati\n\npd.read_csv('Step_Test_Data.csv').set_index('Time').plot(grid=True)\n\n\n\n\n\n\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\n\nT1\nT2\nQ1\n\n\nTime\n\n\n\n\n\n\n\n0.00\n20.6272\n20.6272\n0.0\n\n\n9.00\n20.9495\n20.9495\n50.0\n\n\n10.00\n20.9495\n20.9495\n50.0\n\n\n12.01\n20.9495\n20.9495\n50.0\n\n\n13.00\n20.9495\n20.9495\n50.0\n\n\n\n\n\n\n\n\n\ndf.tail()\n\n\n\n\n\n\n\n\n\nT1\nT2\nQ1\n\n\nTime\n\n\n\n\n\n\n\n795.01\n50.6011\n25.784\n50.0\n\n\n796.00\n50.6011\n25.784\n50.0\n\n\n798.01\n50.6011\n25.784\n50.0\n\n\n799.01\n50.6011\n25.784\n50.0\n\n\n800.01\n50.6011\n25.784\n50.0",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Passo Test"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html",
    "title": "Comprendere TCLab",
    "section": "",
    "text": "Lo schema allegato mostra come accedere al laboratorio di controllo della temperatura utilizzando la libreria TCLab.\n\nQuaderni Jupyter e script Python: Il livello più alto è costituito dal codice che scrivi per implementare gli algoritmi di controllo. Questa operazione può essere eseguita nei notebook Jupyter/Python, direttamente da Python utilizzando un ambiente di sviluppo come Spyder o PyCharm. Questo repository contiene diversi esempi, lezioni e progetti degli studenti.\nTCLab: TCLab è costituito da una libreria Python intitolata “tclab” che fornisce accesso di alto livello a sensori, riscaldatori e un orologio pseudo-in tempo reale. Il pacchetto include la classe TCLab() che crea un oggetto per accedere al dispositivo, un iteratore clock per la sincronizzazione con un orologio in tempo reale, la classe Historian() per creare oggetti per la registrazione dei dati e un Plotter( ) per visualizzare i dati in tempo reale.\nSchizzo TCLab: Il repository github TCLab-sketch fornisce il firmware per garantire il funzionamento intrinsecamente sicuro della scheda e dello scudo Arduino. Lo schizzo viene scaricato su Arduino utilizzando l’Arduino IDE. Il caricamento del firmware su Arduino è un’operazione che si effettua una sola volta.\nArduino: La piattaforma hardware per il Laboratorio di Termoregolazione. Gli strumenti e le librerie Python sono stati testati con le schede Arduino Uno e Arduino Leonardo.\nDa: CBE32338\n\n\n  \nIl Temperature Control Lab (TCLab) è un sistema integrato composto da diversi componenti chiave, ciascuno dei quali contribuisce in modo significativo alla sua funzionalità:\n\nMicrocontrollore Arduino:\n\nScopo: Serve come unità di elaborazione centrale per TCLab.\nFunzionalità: elabora i dati di input dai sensori di temperatura e gestisce il funzionamento dei riscaldatori.\nConnettività: utilizza una connessione USB per il trasferimento dei dati e consente il controllo in tempo reale tramite script Python.\n\nRiscaldatori:\n\nDescrizione: TCLab è dotato di due riscaldatori, ciascuno in grado di generare energia termica regolabile.\nRuolo: Agire come principale fonte di calore per gli esperimenti, replicando scenari che richiedono la regolazione della temperatura. Funzionano come gli attuatori del sistema.\n\nSensori di temperatura:\n\nTipo: questi sensori sono termistori, un tipo di resistore la cui resistenza varia con le variazioni di temperatura.\nIntervallo di misurazione: in grado di misurare temperature comprese tra $ -40^$C e \\(150^\\circ\\)C.\nFunzionalità: posizionato vicino a ciascun riscaldatore per misurare con precisione la temperatura, fornendo un feedback essenziale per il controllo della temperatura.\n\nDissipatori di calore:\n\nTipo: Composto da dissipatori di calore a transistor.\nScopo: impiegato per dissipare in modo efficiente il calore lontano dai transistor.\n\nLED (diodo a emissione luminosa):\n\n\nScopo: Serve come indicatore visivo per vari stati o azioni, come segnalare l’attivazione di un riscaldatore.\n\n\n\nTCLab può essere configurato in varie modalità a seconda degli obiettivi formativi:\n\nIngresso singolo Uscita singola (SISO):\n\nUtilizza solo un riscaldatore e un sensore. Ideale per semplici esperimenti di controllo e per apprendere le basi del controllo della temperatura.\n\nIngresso singolo Uscita singola (SISO) con disturbo:\n\nUtilizza un riscaldatore/sensore come sistema di controllo primario e il secondo riscaldatore come fonte di disturbo esterno. Questa configurazione è utile per comprendere come i fattori esterni influenzano i sistemi di controllo.\n\nIngressi multipli Uscite multiple (MIMO):\n\nImplica l’utilizzo simultaneo di riscaldatori e sensori. Questa configurazione più avanzata non è trattata qui ma è utile per studi di sistemi di controllo complessi.\n\n\nOgni componente del TCLab svolge un ruolo specifico, rendendolo uno strumento versatile per insegnare e sperimentare vari aspetti dell’ingegneria di controllo. Sia per l’apprendimento fondamentale che per l’esplorazione avanzata, TCLab offre una piattaforma pratica per comprendere la dinamica e il controllo dei sistemi basati sulla temperatura.\n\n\n\n\n\nFlusso operativo:\n\nSegnale di ingresso: uno script Python invia un comando ad Arduino, impostando il livello di potenza desiderato per i riscaldatori.\nAzione di riscaldamento: i riscaldatori generano calore corrispondente ai comandi del livello di potenza ricevuti.\nMisurazione della temperatura: i termistori misurano le temperature risultanti vicino ai riscaldatori.\nCiclo di feedback: queste letture della temperatura vengono inviate al computer.\nRegolazioni: l’algoritmo di controllo nello script Python regola la potenza del riscaldatore in base al feedback della temperatura, cercando di raggiungere e mantenere una temperatura target.\n\n\n[Inserisci qui il diagramma di flusso o il diagramma che mostra il ciclo di feedback]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#i-componenti-principali-di-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#i-componenti-principali-di-tclab",
    "title": "Comprendere TCLab",
    "section": "",
    "text": "Il Temperature Control Lab (TCLab) è un sistema integrato composto da diversi componenti chiave, ciascuno dei quali contribuisce in modo significativo alla sua funzionalità:\n\nMicrocontrollore Arduino:\n\nScopo: Serve come unità di elaborazione centrale per TCLab.\nFunzionalità: elabora i dati di input dai sensori di temperatura e gestisce il funzionamento dei riscaldatori.\nConnettività: utilizza una connessione USB per il trasferimento dei dati e consente il controllo in tempo reale tramite script Python.\n\nRiscaldatori:\n\nDescrizione: TCLab è dotato di due riscaldatori, ciascuno in grado di generare energia termica regolabile.\nRuolo: Agire come principale fonte di calore per gli esperimenti, replicando scenari che richiedono la regolazione della temperatura. Funzionano come gli attuatori del sistema.\n\nSensori di temperatura:\n\nTipo: questi sensori sono termistori, un tipo di resistore la cui resistenza varia con le variazioni di temperatura.\nIntervallo di misurazione: in grado di misurare temperature comprese tra $ -40^$C e \\(150^\\circ\\)C.\nFunzionalità: posizionato vicino a ciascun riscaldatore per misurare con precisione la temperatura, fornendo un feedback essenziale per il controllo della temperatura.\n\nDissipatori di calore:\n\nTipo: Composto da dissipatori di calore a transistor.\nScopo: impiegato per dissipare in modo efficiente il calore lontano dai transistor.\n\nLED (diodo a emissione luminosa):\n\n\nScopo: Serve come indicatore visivo per vari stati o azioni, come segnalare l’attivazione di un riscaldatore.\n\n\n\nTCLab può essere configurato in varie modalità a seconda degli obiettivi formativi:\n\nIngresso singolo Uscita singola (SISO):\n\nUtilizza solo un riscaldatore e un sensore. Ideale per semplici esperimenti di controllo e per apprendere le basi del controllo della temperatura.\n\nIngresso singolo Uscita singola (SISO) con disturbo:\n\nUtilizza un riscaldatore/sensore come sistema di controllo primario e il secondo riscaldatore come fonte di disturbo esterno. Questa configurazione è utile per comprendere come i fattori esterni influenzano i sistemi di controllo.\n\nIngressi multipli Uscite multiple (MIMO):\n\nImplica l’utilizzo simultaneo di riscaldatori e sensori. Questa configurazione più avanzata non è trattata qui ma è utile per studi di sistemi di controllo complessi.\n\n\nOgni componente del TCLab svolge un ruolo specifico, rendendolo uno strumento versatile per insegnare e sperimentare vari aspetti dell’ingegneria di controllo. Sia per l’apprendimento fondamentale che per l’esplorazione avanzata, TCLab offre una piattaforma pratica per comprendere la dinamica e il controllo dei sistemi basati sulla temperatura.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#come-funziona-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#come-funziona-tclab",
    "title": "Comprendere TCLab",
    "section": "",
    "text": "Flusso operativo:\n\nSegnale di ingresso: uno script Python invia un comando ad Arduino, impostando il livello di potenza desiderato per i riscaldatori.\nAzione di riscaldamento: i riscaldatori generano calore corrispondente ai comandi del livello di potenza ricevuti.\nMisurazione della temperatura: i termistori misurano le temperature risultanti vicino ai riscaldatori.\nCiclo di feedback: queste letture della temperatura vengono inviate al computer.\nRegolazioni: l’algoritmo di controllo nello script Python regola la potenza del riscaldatore in base al feedback della temperatura, cercando di raggiungere e mantenere una temperatura target.\n\n\n[Inserisci qui il diagramma di flusso o il diagramma che mostra il ciclo di feedback]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "title": "Comprendere TCLab",
    "section": "Sezione 1: Installazione di Python utilizzando Conda",
    "text": "Sezione 1: Installazione di Python utilizzando Conda",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-mac",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-mac",
    "title": "Comprendere TCLab",
    "section": "Installazione di Python su Mac",
    "text": "Installazione di Python su Mac\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Mac.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri Terminale.\nDigita “conda –version” e premi Invio. Se Anaconda è stato installato correttamente, vedrai il numero di versione.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-windows",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-windows",
    "title": "Comprendere TCLab",
    "section": "Installazione di Python su Windows",
    "text": "Installazione di Python su Windows\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Windows.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri il prompt di Anaconda.\nDigita “conda –version” e premi Invio.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel prompt di Anaconda, digita “conda create -n tclab_env python=3.8” e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-linux",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#installazione-di-python-su-linux",
    "title": "Comprendere TCLab",
    "section": "Installazione di Python su Linux",
    "text": "Installazione di Python su Linux\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Linux.\nEsegui programma di installazione: apri Terminale, vai alla directory contenente il file scaricato ed esegui lo script utilizzando bash Anaconda3-XXXX.sh.\nVerifica installazione:\n\nNel Terminale, digita “conda –version”.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#configurazione-dellambiente-conda",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#configurazione-dellambiente-conda",
    "title": "Comprendere TCLab",
    "section": "Configurazione dell’ambiente Conda",
    "text": "Configurazione dell’ambiente Conda\nPer configurare l’ambiente Conda per questo corso, attenersi alla seguente procedura:\n\nScarica il file tclab_environment.yml da questo repository.\nApri il terminale o il prompt di Anaconda e vai alla directory in cui si trova il file.\n\nIl file tclab_environment.yml assomiglia a questo:\nnome: tclab_env\ncanali:\n  - valori predefiniti\ndipendenze:\n  - pitone=3.10\n  - pip\n  - insensato\n  - matplotlib\n  - scipito\n  - panda\n  - pip:\n    -tclab\n\nCrea l’ambiente dal file tclab_environment.yml:\nconda env create -f tclab_environment.yml\nAttiva il nuovo ambiente:\nconda attiva tclab\nPer verificare che l’ambiente sia stato installato correttamente, è possibile utilizzare:\nconda env list\n\n\nInstallazione del pacchetto TCLab\n\nAttivazione dell’ambiente:\n\nAssicurati che il tuo ambiente Anaconda sia attivo. Apri il tuo Terminale (o il prompt di Anaconda su Windows) e attiva il tuo ambiente:\nconda attiva tclab_env\n\nInstallazione di TCLab:\n\nLa libreria tclab si interfaccia con l’hardware del Temperature Control Lab. Installalo inserendo il seguente comando da una finestra (MacOS) o da una finestra di comando (PC):\npip installa tclab\nPremi Invio per eseguire il comando e completare l’installazione.\n\nIn alternativa, l’installazione può essere eseguita da un notebook Jupyter/Python con il comando\n!pip installa tclab\nCi sono aggiornamenti occasionali alla libreria. Questi possono essere installati aggiungendo un --upgrade ai comandi precedenti e dimostrati nella cella successiva.\n\n\n!pip install tclab --upgrade\n\nRequirement already satisfied: tclab in /Users/andreamunafo/opt/anaconda3/envs/tclab/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: pyserial in /Users/andreamunafo/opt/anaconda3/envs/tclab/lib/python3.10/site-packages (from tclab) (3.5)\n\n\n\nInstallazione di librerie utili aggiuntive\nPer un’esperienza completa con TCLab e per supportare vari aspetti dell’ingegneria di controllo e dell’analisi dei dati, verranno installate anche le seguenti librerie:\n\ninsensibile:\n\nSignificato: una libreria fondamentale per i calcoli numerici in Python.\nComando di installazione:\npip installa numpy\n\nmatplotlib:\n\nSignificato: fondamentale per creare rappresentazioni visive dei dati, in particolare per l’analisi degli esperimenti TCLab.\nComando di installazione:\npip installa matplotlib\n\nscipy:\n\nSignificato: fornisce un’ampia gamma di strumenti per il calcolo scientifico, compresi metodi per risolvere equazioni differenziali ordinarie, utili nella modellizzazione dei sistemi.\nComando di installazione:\npip installa scipy\n\npanda:\n\nSignificato: offre funzionalità estese per la manipolazione e l’analisi dei dati, ideali per la gestione di set di dati complessi.\nComando di installazione:\npip installa panda\n\ngeco:\n\nSignificatività: pacchetto avanzato per l’ottimizzazione e il controllo, adatto all’implementazione di strategie di controllo predittivo del modello.\nComando di installazione:\npip installa gekko",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#test-iniziali-con-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#test-iniziali-con-tclab",
    "title": "Comprendere TCLab",
    "section": "Test iniziali con TCLab",
    "text": "Test iniziali con TCLab\n\nPassaggio 1: collega TCLab\n\nConnetti TCLab: collega il dispositivo TCLab al computer utilizzando un cavo USB.\n\n\n\nPassaggio 2: testare la connessione TCLab\n\nScrivi script di prova:\n\nApri il tuo IDE Python o Jupyter Notebook.\nScrivi il seguente codice Python ed esegui lo script. Se stampa la temperatura, TCLab è collegato correttamente.\n\n\n\nimport tclab\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#utilizzo-del-simulatore-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#utilizzo-del-simulatore-tclab",
    "title": "Comprendere TCLab",
    "section": "Utilizzo del simulatore TCLab",
    "text": "Utilizzo del simulatore TCLab\n\nPerché utilizzare un simulatore: il simulatore TCLab è utile quando non si dispone dell’hardware fisico.\nInstalla simulatore: nel terminale o nel prompt di Anaconda, digita nuovamente pip install tclab (include il simulatore).\nScript di prova con simulatore:\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.04 seconds. T1: 20.949499999999997°C\nTime 6.03 seconds. T1: 20.949499999999997°C\nTime 8.06 seconds. T1: 20.949499999999997°C\nTime 10.07 seconds. T1: 20.949499999999997°C\nTime 12.02 seconds. T1: 20.949499999999997°C\nTime 14.03 seconds. T1: 20.949499999999997°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.04 seconds. T1: 20.949499999999997°C\nTime 20.2 seconds. T1: 20.949499999999997°C\nTime 22.01 seconds. T1: 20.949499999999997°C\nTime 24.19 seconds. T1: 20.949499999999997°C\nTime 26.24 seconds. T1: 20.949499999999997°C\nTime 28.16 seconds. T1: 20.949499999999997°C\nTime 30.03 seconds. T1: 20.949499999999997°C\nTime 32.12 seconds. T1: 20.949499999999997°C\nTime 34.2 seconds. T1: 20.6272°C\nTime 36.04 seconds. T1: 20.949499999999997°C\nTime 38.02 seconds. T1: 20.6272°C\nTime 40.21 seconds. T1: 20.949499999999997°C\nTime 42.14 seconds. T1: 20.949499999999997°C\nTime 44.01 seconds. T1: 20.6272°C\nTime 46.3 seconds. T1: 20.949499999999997°C\nTime 48.22 seconds. T1: 20.949499999999997°C\nTime 50.07 seconds. T1: 20.949499999999997°C\nTime 52.27 seconds. T1: 20.949499999999997°C\nTime 54.09 seconds. T1: 20.949499999999997°C\nTime 56.28 seconds. T1: 20.949499999999997°C\nTime 58.19 seconds. T1: 20.949499999999997°C\nTime 60.04 seconds. T1: 20.949499999999997°C\nTime 62.2 seconds. T1: 20.949499999999997°C\nTime 64.11 seconds. T1: 20.949499999999997°C\nTime 66.08 seconds. T1: 20.949499999999997°C\nTime 68.23 seconds. T1: 20.6272°C\nTime 70.13 seconds. T1: 20.949499999999997°C\nTime 72.07 seconds. T1: 20.949499999999997°C\nTime 74.05 seconds. T1: 20.949499999999997°C\nTime 76.1 seconds. T1: 20.6272°C\nTime 78.1 seconds. T1: 20.6272°C\nTime 80.22 seconds. T1: 20.949499999999997°C\nTime 82.28 seconds. T1: 20.949499999999997°C\nTime 84.22 seconds. T1: 20.949499999999997°C\nTime 86.16 seconds. T1: 20.949499999999997°C\nTime 88.23 seconds. T1: 20.949499999999997°C\nTime 90.0 seconds. T1: 20.949499999999997°C\nTime 92.27 seconds. T1: 20.949499999999997°C\nTime 94.0 seconds. T1: 20.949499999999997°C\nTime 96.16 seconds. T1: 20.949499999999997°C\nTime 98.02 seconds. T1: 20.949499999999997°C\nTime 100.1 seconds. T1: 20.949499999999997°C\nTime 102.24 seconds. T1: 20.949499999999997°C\nTime 104.0 seconds. T1: 20.6272°C\nTime 106.18 seconds. T1: 20.949499999999997°C\nTime 108.27 seconds. T1: 20.949499999999997°C\nTime 110.27 seconds. T1: 20.949499999999997°C\nTime 112.1 seconds. T1: 20.949499999999997°C\nTime 114.22 seconds. T1: 20.949499999999997°C\nTime 116.24 seconds. T1: 20.949499999999997°C\nTime 118.18 seconds. T1: 20.949499999999997°C\nTime 120.19 seconds. T1: 20.949499999999997°C\nTime 122.06 seconds. T1: 20.949499999999997°C\nTime 124.22 seconds. T1: 20.6272°C\nTime 126.19 seconds. T1: 20.949499999999997°C\nTime 128.18 seconds. T1: 20.949499999999997°C\nTime 130.25 seconds. T1: 20.949499999999997°C\nTime 132.02 seconds. T1: 20.6272°C\nTime 134.2 seconds. T1: 20.949499999999997°C\nTime 136.27 seconds. T1: 20.949499999999997°C\nTime 138.01 seconds. T1: 20.6272°C\nTime 140.2 seconds. T1: 20.949499999999997°C\nTime 142.18 seconds. T1: 20.949499999999997°C\nTime 144.2 seconds. T1: 20.949499999999997°C\nTime 146.23 seconds. T1: 20.949499999999997°C\nTime 148.24 seconds. T1: 20.949499999999997°C\nTime 150.19 seconds. T1: 20.949499999999997°C\nTime 152.28 seconds. T1: 20.949499999999997°C\nTime 154.25 seconds. T1: 20.949499999999997°C\nTime 156.23 seconds. T1: 20.6272°C\nTime 158.04 seconds. T1: 20.949499999999997°C\nTime 160.11 seconds. T1: 20.949499999999997°C\nTime 162.04 seconds. T1: 20.949499999999997°C\nTime 164.05 seconds. T1: 20.949499999999997°C\nTime 166.01 seconds. T1: 20.949499999999997°C\nTime 168.23 seconds. T1: 20.6272°C\nTime 170.08 seconds. T1: 20.949499999999997°C\nTime 172.01 seconds. T1: 20.949499999999997°C\nTime 174.14 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.22 seconds. T1: 20.949499999999997°C\nTime 180.2 seconds. T1: 20.949499999999997°C\nTime 182.2 seconds. T1: 20.949499999999997°C\nTime 184.21 seconds. T1: 20.949499999999997°C\nTime 186.08 seconds. T1: 20.949499999999997°C\nTime 188.29 seconds. T1: 20.949499999999997°C\nTime 190.24 seconds. T1: 20.949499999999997°C\nTime 192.18 seconds. T1: 20.949499999999997°C\nTime 194.09 seconds. T1: 20.949499999999997°C\nTime 196.22 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.02 seconds. T1: 20.6272°C\nTCLab Model disconnected successfully.\n\n\n\nImportazione\nUna volta installato, il pacchetto tclab può essere importato in Python e un’istanza creata con le istruzioni Python\nda tclab importa TCLab\nlaboratorio = TCLab()\nTCLab() tenta di trovare un dispositivo connesso a una porta seriale e restituire una connessione. Se non viene trovato alcun dispositivo viene generato un errore. La connessione deve essere chiusa quando non è più in uso.\nLa cella seguente dimostra questo processo e utilizza la funzione tclab LED() per far lampeggiare il LED sul laboratorio di controllo della temperatura per un periodo di 10 secondi a un livello di luminosità del 100%.\n\nfrom tclab import TCLab\n\nlab = TCLab()\nlab.LED(100)\nlab.close()\n\nTCLab version 1.0.0\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\n\n\nRuntimeError: No Arduino device found.\n\n\n\n\nUtilizzo di TCLab con l’istruzione with di Python\nL’istruzione Python with fornisce un mezzo conveniente per impostare e chiudere una connessione al Laboratorio di controllo della temperatura. In particolare, l’istruzione with stabilisce un contesto in cui viene creata un’istanza tclab, assegnata a una variabile e chiusa automaticamente al completamento. L’istruzione “with” è il modo preferito per collegare il laboratorio di controllo della temperatura per la maggior parte degli usi.\n\nfrom tclab import TCLab\n\nwith TCLab() as lab:\n    lab.LED(100)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#lettura-delle-temperature",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#lettura-delle-temperature",
    "title": "Comprendere TCLab",
    "section": "Lettura delle temperature",
    "text": "Lettura delle temperature\nUna volta creata e connessa un’istanza tclab a un dispositivo, è possibile accedere ai sensori di temperatura nel laboratorio di controllo della temperatura con gli attributi “.T1” e “.T2”. Ad esempio, data un’istanza “lab”, si accede alle temperature come\nT1 = lab.T1\nT2 = lab.T2\n“lab.T1” e “lab.T2” sono proprietà di sola lettura. Qualsiasi tentativo di impostarli su un valore restituirà un errore Python.\n\nfrom tclab import TCLab\n\nwith TCLab() as a:\n    print(\"Temperature 1: {0:0.2f} C\".format(a.T1))\n    print(\"Temperature 2: {0:0.2f} C\".format(a.T2))",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#impostazione-dei-riscaldatori",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#impostazione-dei-riscaldatori",
    "title": "Comprendere TCLab",
    "section": "Impostazione dei riscaldatori",
    "text": "Impostazione dei riscaldatori\nPer motivi tradizionali, esistono due modi per impostare i livelli di potenza dei riscaldatori.\nIl primo modo è utilizzare le funzioni.Q1() e .Q2() di un’istanza TCLab. Ad esempio, entrambi i riscaldatori possono essere impostati al 100% della potenza tramite le funzioni\nlaboratorio = TCLab()\nlab.Q1(100)\nlab.Q2(100)\nIl firmware del dispositivo limita i riscaldatori a un intervallo compreso tra 0 e 100%. È possibile accedere al valore corrente degli attributi tramite\nQ1 = lab.Q1()\nQ2 = lab.Q2()\nNote importanti: 1. Il LED sul laboratorio di controllo della temperatura passa da fioco a luminoso quando uno dei riscaldatori è acceso. 2. La chiusura dell’istanza TCLab spegne i riscaldatori. 3. Il livello di potenza dei due riscaldatori potrebbe essere diverso. Le versioni attuali del firmware limitano la potenza massima del primo riscaldatore a 4 watt e la potenza massima del secondo riscaldatore a 2 watt. 4. Oltre ai vincoli imposti dal firmware, l’alimentatore potrebbe non essere in grado di fornire tutta la potenza necessaria per far funzionare entrambi i riscaldatori al 100% 5. I valori recuperati da queste funzioni potrebbero essere diversi dai valori impostati a causa dei limiti di potenza imposti dal firmware del dispositivo.\n\nfrom tclab import TCLab\nimport time\n\nwith TCLab() as a:\n    print(\"\\nStarting Temperature 1: {0:0.2f} C\".format(a.T1),flush=True)\n    print(\"Starting Temperature 2: {0:0.2f} C\".format(a.T2),flush=True)\n\n    a.Q1(100)\n    a.Q2(100)\n    print(\"\\nSet Heater 1:\", a.Q1(), \"%\",flush=True)\n    print(\"Set Heater 2:\", a.Q2(), \"%\",flush=True)\n    \n    t_heat = 30\n    print(\"\\nHeat for\", t_heat, \"seconds\")\n    time.sleep(t_heat)\n\n    print(\"\\nTurn Heaters Off\")\n    a.Q1(0)\n    a.Q2(0)\n    print(\"\\nSet Heater 1:\", a.Q1(), \"%\",flush=True)\n    print(\"Set Heater 2:\", a.Q2(), \"%\",flush=True)\n    \n    print(\"\\nFinal Temperature 1: {0:0.2f} C\".format(a.T1))\n    print(\"Final Temperature 2: {0:0.2f} C\".format(a.T2))\n\nIn alternativa, i riscaldatori possono essere impostati utilizzando gli attributi “.U1” e “.U2” di un’istanza “TCLab”.\n\nlab = TCLab()\n\nprint('Setting power levels on heaters 1 and 2')\nlab.U1 = 50\nlab.U2 = 25\n\nprint('Current power level on Heater 1 is: ', lab.U1, '%')\nprint('Current power level on Heater 1 is: ', lab.U2, '%')\n\nlab.close()",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#sincronizzazione-in-tempo-reale-utilizzando-clock",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#sincronizzazione-in-tempo-reale-utilizzando-clock",
    "title": "Comprendere TCLab",
    "section": "Sincronizzazione in tempo reale utilizzando clock",
    "text": "Sincronizzazione in tempo reale utilizzando clock\nIl modulo tclab include clock per sincronizzare i calcoli in tempo reale. “clock(tperiod, tstep)” genera una sequenza di iterazioni su un periodo di “tperiod” secondi in modo uniforme per “tstep” secondi. Se “tstep” viene omesso, il periodo predefinito è impostato su 1 secondo.\n\nfrom tclab import clock\n\ntperiod = 6\ntstep = 2\nfor t in clock(tperiod,tstep):\n    print(t, \"sec.\")\n\nCi sono alcune considerazioni da tenere a mente quando si usa clock. Ancora più importante, per sua natura Python non è un ambiente in tempo reale. “clock” fa del suo meglio per rimanere sincronizzato con i tick equidistanti dell’orologio in tempo reale. Se, per qualche motivo, il ciclo resta indietro rispetto all’orologio in tempo reale, il generatore salterà l’evento per tornare in sincronia con l’orologio in tempo reale. Pertanto il numero totale di iterazioni potrebbe essere inferiore al previsto. Questo comportamento è illustrato nella cella seguente.\n\nfrom tclab import TCLab, clock\n\nimport time\n\ntfinal = 12\ntstep = 2\nfor t in clock(tfinal, tstep):\n    print(t, \"sec.\")\n    \n    # insert a long time out between 3 and 5 seconds into the event loop\n    if (t &gt; 3) and (t &lt; 5):\n        time.sleep(2.2)\n\n\nUtilizzo di clock con TCLab\n\nfrom tclab import TCLab, clock\n\ntperiod = 20\n\n# connect to the temperature control lab\nwith TCLab() as a:\n    # turn heaters on\n    a.Q1(100)\n    a.Q2(100)\n    print(\"\\nSet Heater 1 to {0:f} %\".format(a.Q1()))\n    print(\"Set Heater 2 to {0:f} %\".format(a.Q2()))\n\n    # report temperatures for the next tperiod seconds\n    sfmt = \"   {0:5.1f} sec:   T1 = {1:0.1f} C    T2 = {2:0.1f} C\"\n    for t in clock(tperiod):\n        print(sfmt.format(t, a.T1, a.T2), flush=True)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#lo-historian-di-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#lo-historian-di-tclab",
    "title": "Comprendere TCLab",
    "section": "Lo Historian di TCLab",
    "text": "Lo Historian di TCLab\nLa classe “Historian” fornisce mezzi per la registrazione dei dati. Data un’istanza “lab” di un oggetto TCLab, “lab.sources” è un elenco di tutte le origini dati e i metodi per accedere ai dati.\nlaboratorio = TCLab()\nh = Historian(lab.fonti)\nLo storico inizializza un registro dati. Il registro dati viene aggiornato emettendo un comando\nh.update(t)\ndove “t” indica l’ora corrente. La cella successiva registra 10 secondi di dati con un livello di potenza variabile nel riscaldatore 1, quindi salva i dati in un file.\n\nfrom tclab import TCLab, clock, Historian\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    for t in clock(10):\n        lab.Q1(100 if t &lt;= 5 else 0)\n        h.update(t)\n        \nh.to_csv('data.csv')\n\nUna volta salvati, i dati possono essere letti e tracciati utilizzando la Libreria di analisi dei dati di Pandas come dimostrato in questa cella.\n\nimport pandas as pd\ndata = pd.read_csv('data.csv')\ndata.index = data['Time']\nprint(data)\ndata[['Q1','Q2']].plot(grid=True)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#il-plotter-di-tclab",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#il-plotter-di-tclab",
    "title": "Comprendere TCLab",
    "section": "Il Plotter di TCLab",
    "text": "Il Plotter di TCLab\nLa classe “Plotter” aggiunge un tracciamento in tempo reale dei dati sperimentali. Un plotter viene creato da un’istanza di uno storico come segue\nh = Historian(lab.fonti)\np = Plotter(h)\nAggiornando il plotter si aggiorna anche lo storico associato.\np.update(t)\nL’esempio seguente mostra come funziona.\n\nfrom tclab import TCLab, clock, Historian, Plotter\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 10)\n    for t in clock(10):\n        lab.Q1(100 if t &lt;= 5 else 0)\n        p.update(t)\n        \nh.to_csv('data.csv')",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#utilizzo-di-tclab-offline",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#utilizzo-di-tclab-offline",
    "title": "Comprendere TCLab",
    "section": "Utilizzo di TCLab offline",
    "text": "Utilizzo di TCLab offline\n\nfrom tclab import clock, setup, Historian, Plotter\n\nTCLab = setup(connected=False, speedup=20)\n\nSP = 40\nwith TCLab() as a:\n    h = Historian(a.sources)\n    p = Plotter(h)\n    for t in clock(120,2):\n        PV = a.T1\n        MV = 100 if SP &gt; PV else 0\n        a.U1 = MV\n        p.update()\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/understanding_tclab_it.html#esecuzione-della-diagnostica",
    "href": "IT_TCLab_🇮🇹/understanding_tclab_it.html#esecuzione-della-diagnostica",
    "title": "Comprendere TCLab",
    "section": "Esecuzione della diagnostica",
    "text": "Esecuzione della diagnostica\n\nimport tclab\n\nprint(\"Version = \", tclab.__version__)\ntclab.diagnose()\n\nVersion =  1.0.0\n\nChecking connection\n-------------------\nLooking for Arduino on any port...\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\nNo known Arduino was found in the ports listed above.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Comprendere TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/pid_control_it.html",
    "href": "IT_TCLab_🇮🇹/pid_control_it.html",
    "title": "Controllo PID",
    "section": "",
    "text": "!pip install slycot\n!pip install control\n\nCollecting slycot\nInstalling collected packages: slycot\nSuccessfully installed slycot-0.2.0\nCollecting control\n  Using cached control-0.7.0-py2.py3-none-any.whl\nRequirement already satisfied: numpy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: scipy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: matplotlib in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: six&gt;=1.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: python-dateutil&gt;=2.0 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pytz in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nInstalling collected packages: control\nSuccessfully installed control-0.7.0\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# control constants\nKc = 0.85\ntauI = 10000\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\n# model transfer functions\nGp = control.tf([0.31],[16,1])*control.tf([1],[135,1])\n\n\nt = np.linspace(0,1000)\ny,t = control.step(Gp,t)\nplt.plot(t,50*y + 22)\n\n\n\n\n\n\n\n\n\n# control constants\nKc = 2\ntauI = 60\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\nt = np.linspace(0,1000)\n\nH = Gp*Gc/(1+Gp*Gc)\ny,t = control.step(H,t)\nplt.plot(t,y)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/pid_control_it.html#simulazione-pid",
    "href": "IT_TCLab_🇮🇹/pid_control_it.html#simulazione-pid",
    "title": "Controllo PID",
    "section": "",
    "text": "!pip install slycot\n!pip install control\n\nCollecting slycot\nInstalling collected packages: slycot\nSuccessfully installed slycot-0.2.0\nCollecting control\n  Using cached control-0.7.0-py2.py3-none-any.whl\nRequirement already satisfied: numpy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: scipy in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: matplotlib in /Users/jeff/anaconda3/lib/python3.6/site-packages (from control)\nRequirement already satisfied: six&gt;=1.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: python-dateutil&gt;=2.0 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pytz in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /Users/jeff/anaconda3/lib/python3.6/site-packages (from matplotlib-&gt;control)\nInstalling collected packages: control\nSuccessfully installed control-0.7.0\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# control constants\nKc = 0.85\ntauI = 10000\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\n# model transfer functions\nGp = control.tf([0.31],[16,1])*control.tf([1],[135,1])\n\n\nt = np.linspace(0,1000)\ny,t = control.step(Gp,t)\nplt.plot(t,50*y + 22)\n\n\n\n\n\n\n\n\n\n# control constants\nKc = 2\ntauI = 60\n\n# control transfer function\nGc = Kc*control.tf([tauI,1],[tauI,0])\n\nt = np.linspace(0,1000)\n\nH = Gp*Gc/(1+Gp*Gc)\ny,t = control.step(H,t)\nplt.plot(t,y)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/pid_control_it.html#implementazione-pid",
    "href": "IT_TCLab_🇮🇹/pid_control_it.html#implementazione-pid",
    "title": "Controllo PID",
    "section": "Implementazione PID",
    "text": "Implementazione PID\n\nCondizioni di riferimento\nUno dei problemi di implementazione del controllo PID del Laboratorio di Controllo della Temperatura è la scelta delle condizioni di riferimento. Uno dei motivi è che la linearizzazione su cui si basa l’analisi PID è valida solo in alcune “vicinanze” di una condizione operativa nominale. Ma forse una situazione più tipica e più pratica\n\nimport sys\nsys.path.append('..')\nfrom TCLab import TCLab, clock, pid\n\n# ambient and reference values\nTamb = 20\nTref = 50\nuref = (Tref - Tamb)/0.85\n\n# control parameters\nb = 1              # setpoint weighting\nkp = 0.8          # proportional control gain\nki = kp/60\n\n# sampling period\ntf = 1200           # experiment length (sec.)\nh = 1               # sample time (sec.)\n\n# setpoint function\ndef Tset(t):\n    if t &lt;= 900:\n        return 50\n    else:\n        return 35\n\n\nbi = ki*h\n\nr = Tset(0) - Tref\ny = Tamb - Tref\n\nP = kp*(b*r - y)\nI = 0\n\nuref,P,I,r\n\n(35.294117647058826, 24.0, 0, 0)\n\n\n\n# device initialization\nwith TCLab() as a:\n    a.initplot(tf)\n    for t in clock(tf,h):\n        r = Tset(t) - Tref\n        y = a.T1 - Tref\n    \n        P = kp*(b*r - y)\n        v = P + I\n    \n        u = max(0,min(200,v + uref))\n        I += bi*(r-y)\n    \n        a.Q1 = u\n        a.updateplot()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "",
    "text": "Lo scopo di questa prima sessione di laboratorio è verificare la tua capacità di interfacciarti e interagire con l’hardware TCLab e familiarizzare con la libreria TCLab. Il primo esercizio consisterà nel codificare un rudimentale controller a relè (chiamato anche “on-off” o termostato) per uno dei due riscaldatori.\nPrima di iniziare, dovresti avere familiarità con i seguenti materiali di lettura:",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-1.-scarica-e-installa-tclab.py",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-1.-scarica-e-installa-tclab.py",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "Esercizio 1. Scarica e installa TCLab.py",
    "text": "Esercizio 1. Scarica e installa TCLab.py\nEsegui la cella seguente per scaricare e installare la libreria Python TCLab.py.\n\n!pip install tclab --upgrade",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-2.-verifica-che-lhardware-e-il-software-funzionino-correttamente.",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-2.-verifica-che-lhardware-e-il-software-funzionino-correttamente.",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "Esercizio 2. Verifica che l’hardware e il software funzionino correttamente.",
    "text": "Esercizio 2. Verifica che l’hardware e il software funzionino correttamente.\nLa cella seguente dovrebbe far sì che il LED sullo schermo TCLab si accenda fino al 100% di luminosità massima.\n\nfrom tclab import TCLab\n\nwith TCLab() as lab:\n    lab.LED(0)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-3.-accendi-i-riscaldatori-per-120-secondi-e-registra-la-risposta-della-temperatura.",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-3.-accendi-i-riscaldatori-per-120-secondi-e-registra-la-risposta-della-temperatura.",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "Esercizio 3. Accendi i riscaldatori per 120 secondi e registra la risposta della temperatura.",
    "text": "Esercizio 3. Accendi i riscaldatori per 120 secondi e registra la risposta della temperatura.\nPer questo esercizio, scrivi una cella di codice che accende il riscaldatore 1 al 100% della potenza, quindi registra la risposta della temperatura una volta al secondo per 120 secondi. L’output della cella dovrebbe riportare l’ora, il livello di potenza e la temperatura per ciascuna misurazione. Potresti voler consultare il taccuino 01_Understanding_TCLab per esempi di codice rilevanti. Per questo esercizio avrai bisogno della funzione clock di tclab.\n\n# put your code here.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-4.-codifica-un-controller-on-off.",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-4.-codifica-un-controller-on-off.",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "Esercizio 4. Codifica un controller on-off.",
    "text": "Esercizio 4. Codifica un controller on-off.\nCodificare un controller on-off per un setpoint di 40 gradi C utilizzando il riscaldatore 1 come variabile manipolata e la temperatura 1 come variabile misurata. Utilizzare il controller per almeno 5 minuti (600 secondi), segnalando le misurazioni di tempo/potenza/temperatura ogni 2 secondi.\n\n# put your code here.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-5.-analisi",
    "href": "IT_TCLab_🇮🇹/tclab_lab_1_coding_a_relay_controller_it.html#esercizio-5.-analisi",
    "title": "TCLab Lab 1: Codifica di un controller relè",
    "section": "Esercizio 5. Analisi",
    "text": "Esercizio 5. Analisi\nEsamina i risultati dell’esercizio precedente e rispondi alle seguenti domande.\n\nQuanto tempo trascorre approssimativamente tra gli eventi di accensione e spegnimento?\nQual è il ciclo di lavoro approssimativo (ovvero, la frazione di tempo in cui il riscaldatore è nello stato “acceso”) una volta trascorso il periodo di avvio iniziale.\nQual è l’entità dell’oscillazione attorno al setpoint? Perché succede questo?",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 1: Codifica di un controller relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.integrate import odeint\nfrom scipy.optimize import minimize\n\n\n\nLa cella seguente legge i dati di risposta al gradino sperimentali precedentemente memorizzati.\n\ndf = pd.read_csv(\"tclab-data.csv\")\nt = np.array(df[\"Time\"])\nT1 = np.array(df[\"T1\"])\nT2 = np.array(df[\"T2\"])\nQ1 = np.array(df[\"Q1\"])\nQ2 = np.array(df[\"Q2\"])\n\n\n\n\nLa seguente semplice funzione di tracciamento dei dati viene utilizzata in questo notebook per confrontare i dati sperimentali con le previsioni del modello.\n\ndef plot_data(t, T, T_pred, Q):\n    \n    fig = plt.figure(figsize=(8,5))\n    grid = plt.GridSpec(4, 1)\n    ax = [fig.add_subplot(grid[:2]), fig.add_subplot(grid[2]), fig.add_subplot(grid[3])]\n\n    ax[0].plot(t, T, t, T_pred)\n    ax[0].set_ylabel(\"deg C\")\n    ax[0].legend([\"T\", \"T_pred\"])\n    \n    ax[1].plot(t, T_pred - T)\n    ax[1].set_ylabel(\"deg C\")\n    ax[1].legend([\"T_pred - \"])\n    \n    ax[2].plot(t, Q)\n    ax[2].set_ylabel(\"%\")\n    ax[2].legend([\"Q\"])\n    \n    for a in ax: a.grid(True)\n    ax[-1].set_xlabel(\"time / seconds\")\n    plt.tight_layout()\n    \nplot_data(t, T1, T1, Q1)\nplot_data(t, T2, T2, Q2)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#inizializzazioni",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#inizializzazioni",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.integrate import odeint\nfrom scipy.optimize import minimize\n\n\n\nLa cella seguente legge i dati di risposta al gradino sperimentali precedentemente memorizzati.\n\ndf = pd.read_csv(\"tclab-data.csv\")\nt = np.array(df[\"Time\"])\nT1 = np.array(df[\"T1\"])\nT2 = np.array(df[\"T2\"])\nQ1 = np.array(df[\"Q1\"])\nQ2 = np.array(df[\"Q2\"])\n\n\n\n\nLa seguente semplice funzione di tracciamento dei dati viene utilizzata in questo notebook per confrontare i dati sperimentali con le previsioni del modello.\n\ndef plot_data(t, T, T_pred, Q):\n    \n    fig = plt.figure(figsize=(8,5))\n    grid = plt.GridSpec(4, 1)\n    ax = [fig.add_subplot(grid[:2]), fig.add_subplot(grid[2]), fig.add_subplot(grid[3])]\n\n    ax[0].plot(t, T, t, T_pred)\n    ax[0].set_ylabel(\"deg C\")\n    ax[0].legend([\"T\", \"T_pred\"])\n    \n    ax[1].plot(t, T_pred - T)\n    ax[1].set_ylabel(\"deg C\")\n    ax[1].legend([\"T_pred - \"])\n    \n    ax[2].plot(t, Q)\n    ax[2].set_ylabel(\"%\")\n    ax[2].legend([\"Q\"])\n    \n    for a in ax: a.grid(True)\n    ax[-1].set_xlabel(\"time / seconds\")\n    plt.tight_layout()\n    \nplot_data(t, T1, T1, Q1)\nplot_data(t, T2, T2, Q2)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modelli-empirici",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modelli-empirici",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Modelli empirici",
    "text": "Modelli empirici\nLa modellazione empirica è un processo in cui tentiamo di scoprire modelli che descrivono accuratamente il comportamento input-output di un processo senza tener conto dei meccanismi sottostanti.\n\nModello lineare del primo ordine\nUna funzione di trasferimento del primo ordine è modellata dall’equazione differenziale\n\\[ \\tau \\frac{dy}{dt} + y = K u\\]\ndove \\(y\\) è la ‘deviazione’ della variabile di processo da uno stato stazionario nominale e \\(u\\) è la deviazione della variabile manipolata da uno stato stazionario nominale. Per il laboratorio di controllo della temperatura assegneremo le variabili di deviazione come segue:\n\\[\\begin{align*}\ny & = T_1 - T_{ambient} \\\\\nu & = Q_1\n\\end{align*}\\]\nIl parametro \\(K\\) è il guadagno del processo che può essere stimato come il rapporto tra la variazione di stato stazionario di \\(y\\) dovuta a una variazione di stato stazionario di \\(u\\). Il parametro \\(\\tau\\) è la “costante di tempo” del primo ordine che può essere stimata come il tempo necessario per raggiungere il 63,2% della variazione di stato stazionario della produzione per ottenere una variazione di stato stazionario di \\(u\\).\n\ndef model_first_order(param, plot=False):\n    # access parameter values\n    K, tau = param\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(y, ti):\n        dydt  = (K*u(ti) - y)/tau\n        return dydt\n    y = odeint(deriv, 0, t)[:,0]\n\n    # comparing to experimental data\n    T_ambient = T1[0]\n    T1_pred = y + T_ambient\n    if plot:\n        print(\"K =\", K, \"tau =\", tau)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n    \nparam_first_order = [0.62, 180.0]\nmodel_first_order(param_first_order, plot=True)\n\nK = 0.62 tau = 180.0\n\n\n24.649520390255464\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_first_order, param_first_order, method='nelder-mead')\nparam_first_order = results.x\nmodel_first_order(param_first_order, plot=True)\n\nK = 0.6370841237049034 tau = 199.8617397701267\n\n\n20.651093155278453\n\n\n\n\n\n\n\n\n\n\n\nModello lineare del primo ordine con ritardo temporale\nLa cella di codice qui sotto\n\ndef model_first_order_time_delay(param, plot=False):\n    # access parameter values\n    K, tau, tdelay = param\n    \n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1, left=0)\n    def deriv(y, ti):\n        dydt  = (K*u(ti-tdelay) - y)/tau\n        return dydt\n    y = odeint(deriv, 0, t)[:,0]\n\n    # comparing to experimental data\n    T_ambient = T1[0]\n    T1_pred = y + T_ambient\n    if plot:\n        print(\"K =\", K, \"tau =\", tau, \"tdelay =\", tdelay)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_first_order_time_delay = [0.62, 160.0, 15]\nmodel_first_order_time_delay(param_first_order_time_delay, plot=True)\n\nK = 0.62 tau = 160.0 tdelay = 15\n\n\n16.12137889182889\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_first_order_time_delay, param_first_order_time_delay, method='nelder-mead')\nparam_first_order_time_delay = results.x\nmodel_first_order_time_delay(param_first_order_time_delay, plot=True)\n\nK = 0.6228198545524255 tau = 167.7567962566444 tdelay = 20.18136187851927\n\n\n6.290512704413097",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modellazione-basata-su-principi-primi",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modellazione-basata-su-principi-primi",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Modellazione basata su principi primi",
    "text": "Modellazione basata su principi primi\n\nBilancio energetico del primo ordine per un riscaldatore\nSupponendo che il gruppo riscaldatore/sensore possa essere descritto come una massa a temperatura uniforme che scambia calore con l’ambiente circostante, si ottiene un modello lineare del primo ordine.\n\\[C_p\\frac{dT_{1}}{dt} = U_a (T_{amb} - T_{1}) + P Q_1\\]\nIl modello può essere riorganizzato nella forma di un sistema del primo ordine con costante di tempo \\(\\tau\\) e guadagno \\(K\\)\n\\[\\underbrace{\\frac{C_p}{U_a}}_{\\tau}\\underbrace{\\frac{d(T_1 - T_{amb})}{dt}}_{\\frac{dy}{dt}} + \\underbrace{T_1 - T_{amb}}_y = \\underbrace{\\frac{P}{U_a}}_K \\underbrace{Q_1}_u\\]\nUtilizzando i risultati precedenti si ottengono stime per \\(K\\) e \\(\\tau\\).\n\\[\\begin{align*}\nK = \\frac{P}{U_a} & \\implies U_a = \\frac{P}{K} = \\frac{0.04}{0.62} = 0.065 \\text{ watts/deg C} \\\\\n\\tau = \\frac{C_p}{U_a} & \\implies C_p = \\tau U_a = \\frac{\\tau P}{K} = \\frac{186 \\times 0.04}{0.62} = 12 \\text{ J/deg C}\n\\end{align*}\\]\n\nP = 0.04\n\nK, tau = param_first_order\n\nUa = P/K\nprint(\"Heat transfer coefficient Ua =\", Ua, \"watts/degree C\")\n\nCp = tau*P/K\nprint(\"Heat capacity =\", Cp, \"J/deg C\")\n\nHeat transfer coefficient Ua = 0.06278605683560866 watts/degree C\nHeat capacity = 12.548530552470801 J/deg C\n\n\n\ndef model_heater(param, plot=False):\n    # access parameter values\n    T_ambient, Cp, Ua = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(TH1, ti):\n        dT1  = (Ua*(T_ambient - TH1) + P1*u(ti))/Cp\n        return dT1\n    T1_pred = odeint(deriv, T_ambient, t)[:,0]\n\n    # comparing to experimental data\n    if plot:\n        print(\"Cp =\", Cp, \"Ua =\", Ua)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_heater = [T1[0], Cp, Ua]\nmodel_heater(param_heater, plot=True)\n\nCp = 12.548530552470801 Ua = 0.06278605683560866\n\n\n20.651088966149587\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_heater, param_heater, method='nelder-mead')\nparam_heater = results.x\nmodel_heater(param_heater, plot=True)\n\nCp = 10.313205580961114 Ua = 0.05862920031801483\n\n\n10.630933447435487\n\n\n\n\n\n\n\n\n\n\n\nModello a due stati\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1})\n\\end{align*}\\]\n\ndef model_heater_sensor(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        return [dT_H1, dT_S1]\n    T1_pred = odeint(deriv, [T_ambient, T_ambient], t)[:,1]\n\n    # comparing to experimental data\n    \n    if plot:\n        print(param)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_heater_sensor = [T1[0], Cp, Cp/5, Ua, Ua]\nmodel_heater_sensor(param_heater_sensor, plot=True)\n\n[23.81, 12.548530552470801, 2.50970611049416, 0.06278605683560866, 0.06278605683560866]\n\n\n89.2722844989071\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_heater_sensor, param_heater_sensor, method='nelder-mead')\nparam_heater_sensor = results.x\nmodel_heater_sensor(param_heater_sensor, plot=True)\n\n[23.71861419  6.88125133  2.74272516  0.06428723  0.07897125]\n\n\n4.554156209522013",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#due-riscaldatori-modello-a-quattro-stati",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#due-riscaldatori-modello-a-quattro-stati",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Due riscaldatori, modello a quattro stati",
    "text": "Due riscaldatori, modello a quattro stati\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_b(T_{H,2} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_a(T_{amb} - T_{H,2}) + U_b(T_{H,1} - T_{H,2}) + U_c(T_{S,2} - T_{H,2}) + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c(T_{H,2} - T_{S,2})\n\\end{align*}\\]\n\ndef model_complete(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1, T_H2, T_S2 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Ub*(T_H2 - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        dT_H2 = (Ua*(T_ambient - T_H2) + Ub*(T_H1 - T_H2) + Uc*(T_S2 - T_H2))/Cp_H\n        dT_S2 = Uc*(T_H2 - T_S2)/Cp_S\n        return [dT_H1, dT_S1, dT_H2, dT_S2]\n    T_pred = odeint(deriv, [T_ambient, T_ambient, T_ambient, T_ambient], t)\n    T1_pred = T_pred[:,1]\n    T2_pred = T_pred[:,3]\n\n    # comparing to experimental data\n    if plot:\n        print(param)\n        plot_data(t, T1, T1_pred, Q1)\n        plot_data(t, T2, T2_pred, Q1)\n    \n    return (np.linalg.norm(T1_pred - T1) + np.linalg.norm(T2_pred - T2))/2\n\nparam_complete = [T1[0], Cp, Cp/5, Ua, Ua, Ua]\nmodel_complete(param_complete, plot=True)\n\n[23.81, 12.548530552470801, 2.50970611049416, 0.06278605683560866, 0.06278605683560866, 0.06278605683560866]\n\n\n143.87441921309681\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_complete, param_complete, method='nelder-mead')\nparam_complete = results.x\nmodel_complete(param_complete, plot=True)\n\n[23.60707391  6.92707544  1.61783224  0.04676309  0.02633501  0.04303801]\n\n\n4.441799745669341",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#conseguenze",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#conseguenze",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Conseguenze",
    "text": "Conseguenze\n\ndef model_complete(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1, T_H2, T_S2 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Ub*(T_H2 - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        dT_H2 = (Ua*(T_ambient - T_H2) + Ub*(T_H1 - T_H2) + Uc*(T_S2 - T_H2))/Cp_H\n        dT_S2 = Uc*(T_H2 - T_S2)/Cp_S\n        return [dT_H1, dT_S1, dT_H2, dT_S2]\n    T_pred = odeint(deriv, [T_ambient, T_ambient, T_ambient, T_ambient], t)\n    T1_pred = T_pred[:,1]\n    T2_pred = T_pred[:,3]\n\n    # comparing to experimental data\n    if plot:\n        print(param)\n        plot_data(t, T_pred[:,1], T_pred[:,0], Q1)\n        plot_data(t, T_pred[:,3], T_pred[:,2], Q1)\n    \n    return (np.linalg.norm(T1_pred - T1) + np.linalg.norm(T2_pred - T2))/2\n\nmodel_complete(param_complete, plot=True)\n\n[23.60707391  6.92707544  1.61783224  0.04676309  0.02633501  0.04303801]\n\n\n4.441799745669341",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modello-spazio-stato",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#modello-spazio-stato",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Modello Spazio-Stato",
    "text": "Modello Spazio-Stato\nRichiamo delle equazioni del modello\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_b(T_{H,2} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_a(T_{amb} - T_{H,2}) + U_b(T_{H,1} - T_{H,2}) + U_c(T_{S,2} - T_{H,2}) + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c(T_{H,2} - T_{S,2})\n\\end{align*}\\]\nNormalizzazione delle derivate\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = -(U_a + U_b + U_c)T_{H,1} + U_c T_{S,1} + U_b T_{H,2} + U_a T_{amb} + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c T_{H,1} - U_c T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_b T_{H,1} - (U_a + U_b + U_c) T_{H,2} + U_c T_{S,2} + U_aT_{amb} + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c T_{H,2} - U_c T_{S,2}\n\\end{align*}\\]\nRaccolta dei termini sul lato destro\n\\[\\begin{align*}\n\\frac{dT_{H,1}}{dt} & = -\\frac{(U_a + U_b + U_c)}{C_p^H} T_{H,1} + \\frac{U_c}{C_p^H} T_{S,1} + \\frac{U_b}{C_p^H} T_{H,2} + \\frac{U_a}{C_p^H} T_{amb} + \\frac{P_1}{C_p^H} Q_1 \\\\\n\\frac{dT_{S,1}}{dt} & = \\frac{U_c}{C_p^S} T_{H,1} - \\frac{U_c}{C_p^S} T_{S,1} \\\\\n\\frac{dT_{H,2}}{dt} & = \\frac{U_b}{C_p^H} T_{H,1} - \\frac{(U_a + U_b + U_c)}{C_p^H} T_{H,2} + \\frac{U_c}{C_p^H} T_{S,2} + \\frac{U_a}{C_p^H} T_{amb} + \\frac{P_2}{C_p^H} Q_2 \\\\\n\\frac{dT_{S,2}}{dt} & = \\frac{U_c}{C_p^S} T_{H,2} - \\frac{U_c}{C_p^S} T_{S,2}\n\\end{align*}\\]\nModello dello spazio degli stati\n\\[ \\underbrace{\\begin{bmatrix} \\frac{dT_{H,1}}{dt} \\\\ \\frac{dT_{S,1}}{dt} \\\\ \\frac{T_{H,2}}{dt} \\\\ \\frac{T_{S,2}}{dt} \\end{bmatrix}}_{\\frac{dx}{dt}} = \\underbrace{\\begin{bmatrix} -\\frac{(U_a + U_b + U_c)}{C_p^H} & \\frac{U_c}{C_p^H} & \\frac{U_b}{C_p^H} & 0 \\\\ \\frac{U_c}{C_p^S} & - \\frac{U_c}{C_p^S} & 0 & 0 \\\\  \\frac{U_b}{C_p^H} & 0 & - \\frac{(U_a + U_b + U_c)}{C_p^H} & \\frac{U_c}{C_p^H} \\\\  0 & 0 & \\frac{U_c}{C_p^S} & - \\frac{U_c}{C_p^S} \\end{bmatrix}}_A\n\\underbrace{\\begin{bmatrix} T_{H,1} \\\\ T_{S,1} \\\\ T_{H,2} \\\\ T_{S,2} \\end{bmatrix}}_x + \\underbrace{\\begin{bmatrix} \\frac{P_1}{C_p^H} & 0 \\\\ 0 & 0 \\\\ 0 & \\frac{P_2}{C_p^H} \\\\ 0 & 0 \\end{bmatrix}}_B \\underbrace{\\begin{bmatrix} Q_1 \\\\ Q_2 \\end{bmatrix}}_u + \\underbrace{\\begin{bmatrix} \\frac{U_a}{C_p^H} \\\\ 0 \\\\ \\frac{U_a}{C_p^H} \\\\ 0 \\end{bmatrix}}_E \\underbrace{T_{amb}}_d\\]\n\\[\\underbrace{\\begin{bmatrix} T_1 \\\\ T_2 \\end{bmatrix}}_y = \\underbrace{\\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix }}_C \\underbrace{\\begin{bmatrix} T_{H,1} \\\\ T_{S,1} \\\\ T_{H,2} \\\\ T_{S,2} \\end{bmatrix}}_x + \\ underbrace{\\begin{bmatrix} 0 & 0 \\\\ 0 & 0\\end{bmatrix}}_D \\underbrace{\\begin{bmatrix} Q_1 \\\\ Q_2 \\end{bmatrix}}_u\\]\nFormulazione matriciale/vettoriale\n\\[\\begin{align*}\n\\frac{dx}{dt} & = A x + B u + E d \\\\\ny & = C x + D u\n\\end{align*}\\]\n\nP1 = 0.04\nP2 = 0.02\n\nT_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param_complete\n\nA = np.array([[-(Ua + Ub + Uc)/Cp_H, Uc/Cp_H, Ub/Cp_H, 0],\n     [Uc/Cp_S, -Uc/Cp_S, 0, 0],\n     [Ub/Cp_H, 0, -(Ua + Ub + Uc)/Cp_H, Uc/Cp_H],\n     [0, 0, Uc/Cp_S, -Uc/Cp_S]])\n\nB = np.array([[P1/Cp_H, 0], [0, 0], [0, P2/Cp_H], [0, 0]])\n\nC = np.array([[0, 1, 0, 0], [0, 0, 0, 1]])\n\nD = np.array([[0, 0], [0, 0]])\n\nE = np.array([[Ua/Cp_H], [0], [Ua/Cp_H], [0]])\n\nCostanti di tempo\n\neval, evec = np.linalg.eig(A)\n-1/eval\n\narray([191.1942343 ,  96.34592497,  27.18108829,  29.12414895])\n\n\n\nevec\n\narray([[ 0.44286448, -0.36815989, -0.25289296, -0.19739009],\n       [ 0.551245  , -0.60370381,  0.66033715,  0.67899717],\n       [ 0.44286448,  0.36815989,  0.25289296, -0.19739009],\n       [ 0.551245  ,  0.60370381, -0.66033715,  0.67899717]])",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#mettersi-al-lavoro",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_fitting_it.html#mettersi-al-lavoro",
    "title": "Identificazione del modello: adattamento dei modelli ai dati",
    "section": "Mettersi al lavoro",
    "text": "Mettersi al lavoro\n\nfrom control import *\nfrom control.matlab import *\n\n\nss = StateSpace(A, B, C, D)\n\n\nss\n\nA = [[-0.01676553  0.00621301  0.00380175  0.        ]\n [ 0.02660227 -0.02660227  0.          0.        ]\n [ 0.00380175  0.         -0.01676553  0.00621301]\n [ 0.          0.          0.02660227 -0.02660227]]\n\nB = [[0.00577444 0.        ]\n [0.         0.        ]\n [0.         0.00288722]\n [0.         0.        ]]\n\nC = [[0. 1. 0. 0.]\n [0. 0. 0. 1.]]\n\nD = [[0. 0.]\n [0. 0.]]\n\n\n\ny,t = step(ss, input=0)\nplt.plot(t,y)\n\n\n\n\n\n\n\n\n\npole(ss)\n\narray([-0.00523028, -0.01037927, -0.03679029, -0.03433577])\n\n\n\ntf(ss,)\n\n\\[\\begin{bmatrix}\\frac{0.0001536 s^2}{s^4 + 0.03957 s^3 + 0.0001796 s^2}&\\frac{7.681 \\times 10^{-5} s^2}{s^4 + 0.03957 s^3 + 0.0001796 s^2}\\\\\\frac{5.84 \\times 10^{-7} s + 1.554 \\times 10^{-8}}{s^4 + 0.08674 s^3 + 0.002428 s^2 + 2.358 \\times 10^{-5} s + 6.858 \\times 10^{-8}}&\\frac{7.681 \\times 10^{-5} s^2 + 3.331 \\times 10^{-6} s + 2.156 \\times 10^{-8}}{s^4 + 0.08674 s^3 + 0.002428 s^2 + 2.358 \\times 10^{-5} s + 6.858 \\times 10^{-8}}\\\\ \\end{bmatrix}\\]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Identificazione del modello: adattamento dei modelli ai dati"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "",
    "text": "Questo rapporto presenta i risultati e gli approfondimenti chiave degli esercizi TCLab nell’ambito del corso “Principi dei controlli automatici”. Questi esercizi sono progettati per fornire esperienza pratica nei sistemi di controllo utilizzando il kit Temperature Control Lab (TCLab).",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#introduzione",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#introduzione",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "",
    "text": "Questo rapporto presenta i risultati e gli approfondimenti chiave degli esercizi TCLab nell’ambito del corso “Principi dei controlli automatici”. Questi esercizi sono progettati per fornire esperienza pratica nei sistemi di controllo utilizzando il kit Temperature Control Lab (TCLab).",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#riepilogo-degli-esercizi",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#riepilogo-degli-esercizi",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "Riepilogo degli esercizi",
    "text": "Riepilogo degli esercizi\nLe sezioni seguenti riassumono ciascun esercizio, evidenziando gli obiettivi principali, i metodi utilizzati e le conclusioni tratte.\n\n[Titolo dell’esercizio]\n\nLink esercizio: [Link all’esercizio specifico sul sito del corso]\nObiettivi: [Indicare brevemente gli obiettivi di questo esercizio]\nMetodi utilizzati: [Descrivere i metodi o gli approcci utilizzati nell’esercizio]\nRisultati chiave: [Riassumere i risultati principali o i risultati dell’esercizio]\nApprofondimenti personali: [Discutere eventuali approfondimenti personali o risultati di apprendimento derivanti dal completamento di questo esercizio]\n\n\n\n[Titolo dell’esercizio successivo]\n\nLink all’esercizio: [Link all’esercizio successivo]\nObiettivi: […]\nMetodi utilizzati: […]\nRisultati chiave: […]\nApprofondimenti personali: […]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#sfide-e-soluzioni",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#sfide-e-soluzioni",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "Sfide e soluzioni",
    "text": "Sfide e soluzioni\n[In questa sezione, discuti eventuali sfide incontrate durante gli esercizi e come le hai affrontate. Ciò potrebbe includere la risoluzione di problemi tecnici, difficoltà concettuali o l’applicazione della teoria alla pratica.]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#applicazione-della-teoria-alla-pratica",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#applicazione-della-teoria-alla-pratica",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "Applicazione della teoria alla pratica",
    "text": "Applicazione della teoria alla pratica\n[Discutete di come questi esercizi abbiano contribuito a colmare il divario tra conoscenza teorica e applicazione pratica. Rifletti su come questa esperienza pratica ha migliorato la tua comprensione dei sistemi di controllo.]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#conclusione",
    "href": "IT_TCLab_🇮🇹/tclab_exercises_report_template_it.html#conclusione",
    "title": "Modello di report sugli esercizi TCLab",
    "section": "Conclusione",
    "text": "Conclusione\n[Concludi il tuo report con un riepilogo della tua esperienza complessiva con gli esercizi TCLab, sottolineando gli apprendimenti più significativi e il modo in cui si collegano al contesto più ampio del corso.]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modello di report sugli esercizi TCLab"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "",
    "text": "Questo notebook Jupyter mira a fornire un’esplorazione dettagliata del Temperature Control Lab (TCLab) come strumento pratico per comprendere i concetti di ingegneria del controllo.\nIl Laboratorio di controllo della temperatura fornisce un ambiente di apprendimento pratico per i corsi tradizionali sul controllo di processo. Il dispositivo basato su Arduino è costituito da un sistema di riscaldatori e sensori a due ingressi e due uscite.\nQuesta parte del corso mira a colmare il divario tra teoria e applicazione pratica, una sfida che molti ingegneri devono affrontare quando passano dalla formazione accademica alla risoluzione dei problemi nel mondo reale.\nApplicare le conoscenze teoriche alle applicazioni pratiche non è semplice. Questo notebook affronterà queste sfide, concentrandosi sulla natura iterativa della risoluzione dei problemi ingegneristici e sull’importanza di comprendere che spesso esiste più di una risposta giusta a un problema.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#sistemi-di-controllo-termico-per-veicoli-spaziali",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#sistemi-di-controllo-termico-per-veicoli-spaziali",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Sistemi di controllo termico per veicoli spaziali",
    "text": "Sistemi di controllo termico per veicoli spaziali\nAbbiamo il compito di sviluppare un sistema di controllo termico per un satellite in orbita terrestre. Questo sistema deve mantenere i componenti interni, in particolare le batterie, entro un intervallo di temperatura specifico nonostante le condizioni difficili e variabili dello spazio.\n\n\n\n\n\n\n\nFigura: Rosetta Thermal Control\nBella panoramica del problema disponibile sulla pagina web della NASA State-of-the-Art of Small Spacecraft Technology",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#introduzione-al-controllo-termico-nello-spazio",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#introduzione-al-controllo-termico-nello-spazio",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Introduzione al controllo termico nello spazio",
    "text": "Introduzione al controllo termico nello spazio\nIl controllo del livello di temperatura di apparecchiature, carichi utili, satelliti e lanciatori è un aspetto critico in tutte le fasi di una missione spaziale. Questo capitolo approfondisce le complessità del controllo termico nello spazio, sottolineandone l’importanza per la protezione dell’hardware di volo e il successo della missione.\n\nIl concetto di controllo termico\nIl controllo termico nello spazio si riferisce alla tecnologia e ai metodi utilizzati per mantenere la temperatura di un veicolo spaziale entro parametri specifici per tutta la sua vita. Ciò comprende un’ampia gamma di temperature, dai livelli criogenici (fino a -270°C) ai sistemi di protezione termica ad alta temperatura (oltre 2000°C).\n\nImportanza della gestione della temperatura\n\nSicurezza dell’attrezzatura: il surriscaldamento può danneggiare o compromettere gravemente le prestazioni dell’attrezzatura di bordo. Nello spazio, correggere tali problemi è quasi impossibile, evidenziando la necessità di sistemi di controllo termico efficienti e affidabili.\nOttimizzazione delle prestazioni: per componenti sensibili come strumenti elettronici o ottici, il mantenimento della stabilità della temperatura specificata è fondamentale per un funzionamento ottimale.\n\n\n\n\nAspetti visivi del controllo termico\nIl sottosistema di controllo termico è uno degli elementi visivamente più distintivi di un veicolo spaziale. Spesso include: - Coperte isolanti: si tratta di materiali simili a fogli, noti come coperte isolanti multistrato (MLI), utilizzati per bloccare una parte significativa del flusso di calore solare. - Radiatori: sono superfici verniciate di bianco o a specchio utilizzate per respingere il calore dal satellite allo spazio, che è estremamente freddo (intorno a -270°C).",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#perché-il-controllo-termico-è-importante",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#perché-il-controllo-termico-è-importante",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Perché il controllo termico è importante?",
    "text": "Perché il controllo termico è importante?\nIl controllo termico è fondamentale sia per l’integrità strutturale che per il funzionamento efficiente di un satellite.\n\nFattori che influenzano la temperatura del satellite\n\nFonti di calore esterne: includono i flussi di calore solare, dell’albedo (luce solare riflessa) e del pianeta.\nProduzione interna di calore: calore generato da apparecchiature elettroniche e altri sistemi di bordo.\nRifiuto del calore: il processo di dissipazione del calore nella fredda distesa dello spazio.\n\n\nImpatti delle variazioni di temperatura\n\nIntervallo di prestazioni ottimali: le apparecchiature elettroniche solitamente funzionano in modo efficiente entro un intervallo di temperature specifico.\nSensibilità dello strumento: alcuni carichi utili, come i rilevatori a infrarossi, richiedono temperature estremamente basse.\nRiduzione della durata: le alte temperature possono ridurre significativamente la durata di vari componenti.\nIntegrità strutturale: grandi differenze di temperatura possono causare espansione o contrazione termica, distorcendo potenzialmente la struttura del satellite.\n\n\n\n\nBilanciamento del calore nei veicoli spaziali\nIl livello della temperatura di un veicolo spaziale è un equilibrio tra il calore che riceve e il calore che respinge. Gli elementi chiave di questo equilibrio includono:\n\nCoperte isolanti multistrato (MLI): questi dispositivi isolanti aiutano a bloccare una parte sostanziale del flusso di calore solare.\nRadiatori: questi componenti facilitano il rifiuto del calore verso il vuoto freddo dello spazio.\n\n\n\nObiettivi del sistema di controllo termico\nGli obiettivi primari del sottosistema di controllo termico sono:\n\nMantenimento della temperatura generale: garantire che la temperatura del veicolo spaziale rimanga entro limiti accettabili.\nGestione della distribuzione della temperatura: raggiungimento di una distribuzione ottimale della temperatura all’interno del satellite per soddisfare le diverse fasi della missione (lancio, trasferimento in orbita, funzionamento in orbita).\n\n\n\nUlteriori letture\n\n“Controllo termico dei veicoli spaziali” di José Meseguer, Isabel Pérez-Grande e Angel Sanz-Andrés: una guida completa ai principi e alle pratiche del controllo termico dei veicoli spaziali.\n“Spacecraft Thermal Control Handbook” di David G. Gilmore: un’esplorazione approfondita di varie tecnologie di controllo termico e delle loro applicazioni nelle missioni spaziali.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#comprendere-il-problema",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#comprendere-il-problema",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Comprendere il problema",
    "text": "Comprendere il problema\nLa sfida principale è mantenere la temperatura della batteria entro i limiti operativi (circa da 0 a 20 gradi Celsius) nonostante la temperatura interna media sia intorno a -5 gradi Celsius. Ciò implica la necessità di un meccanismo di riscaldamento anziché di raffreddamento.\nIl corretto funzionamento delle batterie satellitari è fondamentale per il successo della missione. Temperature fuori dall’intervallo operativo possono portare al fallimento, mettendo a rischio l’intera missione.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#esplorare-soluzioni",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#esplorare-soluzioni",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Esplorare soluzioni",
    "text": "Esplorare soluzioni\nVengono prese in considerazione diverse soluzioni, tra cui il controllo termico passivo e l’uso di cinghie termiche. Tuttavia, è stata presa la decisione di utilizzare un riscaldatore a striscia dedicato, che offre maggiore controllo e robustezza, soprattutto data la disponibilità di energia.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#cosè-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#cosè-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "1.1 Cos’è TCLab?",
    "text": "1.1 Cos’è TCLab?\n\nDescrizione: TCLab è una configurazione da laboratorio compatta che include un microcontrollore Arduino, riscaldatori, sensori di temperatura e un LED. È progettato per apprendere e applicare i principi dell’ingegneria di controllo in modo pratico.\nComponenti:\n\nMicrocontrollore Arduino: funge da cervello della configurazione.\nRiscaldatori: forniscono energia termica al sistema.\nSensori di temperatura: misura la temperatura del sistema.\nLED: indicatore visivo per determinate azioni o stati.\n\nScopo: comprendere e applicare i principi del controllo del feedback in una configurazione tangibile.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#comprendere-il-kit-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#comprendere-il-kit-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Comprendere il kit TCLab",
    "text": "Comprendere il kit TCLab\n\nI componenti principali di TCLab\nIl Temperature Control Lab (TCLab) è un sistema integrato composto da diversi componenti chiave, ciascuno dei quali contribuisce in modo significativo alla sua funzionalità:\n\nMicrocontrollore Arduino:\n\nScopo: Serve come unità di elaborazione centrale per TCLab.\nFunzionalità: elabora i dati di input dai sensori di temperatura e gestisce il funzionamento dei riscaldatori.\nConnettività: utilizza una connessione USB per il trasferimento dei dati e consente il controllo in tempo reale tramite script Python.\n\nRiscaldatori:\n\nDescrizione: TCLab è dotato di due riscaldatori, ciascuno in grado di generare energia termica regolabile.\nRuolo: Agire come principale fonte di calore per gli esperimenti, replicando scenari che richiedono la regolazione della temperatura. Funzionano come gli attuatori del sistema.\n\nSensori di temperatura:\n\nTipo: questi sensori sono termistori, un tipo di resistore la cui resistenza varia con le variazioni di temperatura.\nIntervallo di misurazione: in grado di misurare temperature comprese tra $ -40^$C e \\(150^\\circ\\)C.\nFunzionalità: posizionato vicino a ciascun riscaldatore per misurare con precisione la temperatura, fornendo un feedback essenziale per il controllo della temperatura.\n\nDissipatori di calore:\n\nTipo: Composto da dissipatori di calore a transistor.\nScopo: impiegato per dissipare in modo efficiente il calore lontano dai transistor.\n\nLED (diodo a emissione luminosa):\n\n\nScopo: Serve come indicatore visivo per vari stati o azioni, come segnalare l’attivazione di un riscaldatore.\n\n\n\nConfigurazioni operative di TCLab\nTCLab può essere configurato in varie modalità a seconda degli obiettivi formativi:\n\nIngresso singolo Uscita singola (SISO):\n\nUtilizza solo un riscaldatore e un sensore. Ideale per semplici esperimenti di controllo e per apprendere le basi del controllo della temperatura.\n\nIngresso singolo Uscita singola (SISO) con disturbo:\n\nUtilizza un riscaldatore/sensore come sistema di controllo primario e il secondo riscaldatore come fonte di disturbo esterno. Questa configurazione è utile per comprendere come i fattori esterni influenzano i sistemi di controllo.\n\nIngressi multipli Uscite multiple (MIMO):\n\nImplica l’utilizzo simultaneo di riscaldatori e sensori. Questa configurazione più avanzata non è trattata qui ma è utile per studi di sistemi di controllo complessi.\n\n\nOgni componente del TCLab svolge un ruolo specifico, rendendolo uno strumento versatile per insegnare e sperimentare vari aspetti dell’ingegneria di controllo. Sia per l’apprendimento fondamentale che per l’esplorazione avanzata, TCLab offre una piattaforma pratica per comprendere la dinamica e il controllo dei sistemi basati sulla temperatura.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#come-funziona-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#come-funziona-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Come funziona TCLab",
    "text": "Come funziona TCLab\n\nFlusso operativo:\n\nSegnale di ingresso: uno script Python invia un comando ad Arduino, impostando il livello di potenza desiderato per i riscaldatori.\nAzione di riscaldamento: i riscaldatori generano calore corrispondente ai comandi del livello di potenza ricevuti.\nMisurazione della temperatura: i termistori misurano le temperature risultanti vicino ai riscaldatori.\nCiclo di feedback: queste letture della temperatura vengono inviate al computer.\nRegolazioni: l’algoritmo di controllo nello script Python regola la potenza del riscaldatore in base al feedback della temperatura, cercando di raggiungere e mantenere una temperatura target.\n\n\n[Inserisci qui il diagramma di flusso o il diagramma che mostra il ciclo di feedback]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#microcontrollore-arduino",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#microcontrollore-arduino",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "2.1 Microcontrollore Arduino",
    "text": "2.1 Microcontrollore Arduino\n\nDescrizione dettagliata: Fornisci dettagli sul modello Arduino utilizzato in TCLab, le sue capacità e i suoi limiti\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObiettivi:\n\nModellazione dinamica con equazioni di bilancio\nLa differenza tra controllo manuale e automatico\nTest di passaggio per generare dati dinamici\nAdattamento dei dati dinamici a un modello First Order Plus Dead Time (FOPDT).\nOttenimento dei parametri per il controllo PID dalle regole di ottimizzazione standard\nOttimizzazione del controller PID per migliorare le prestazioni",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#descrizione-dellhardware-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#descrizione-dellhardware-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Descrizione dell’hardware TCLab",
    "text": "Descrizione dell’hardware TCLab\nIncludere uno schema a blocchi",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Sezione 1: Installazione di Python utilizzando Conda",
    "text": "Sezione 1: Installazione di Python utilizzando Conda",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-mac",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-mac",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Installazione di Python su Mac",
    "text": "Installazione di Python su Mac\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Mac.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri Terminale.\nDigita “conda –version” e premi Invio. Se Anaconda è stato installato correttamente, vedrai il numero di versione.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-windows",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-windows",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Installazione di Python su Windows",
    "text": "Installazione di Python su Windows\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Windows.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri il prompt di Anaconda.\nDigita “conda –version” e premi Invio.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel prompt di Anaconda, digita “conda create -n tclab_env python=3.8” e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-linux",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#installazione-di-python-su-linux",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "1.3 Installazione di Python su Linux",
    "text": "1.3 Installazione di Python su Linux\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Linux.\nEsegui programma di installazione: apri Terminale, vai alla directory contenente il file scaricato ed esegui lo script utilizzando bash Anaconda3-XXXX.sh.\nVerifica installazione:\n\nNel Terminale, digita “conda –version”.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#configurazione-dellambiente-conda",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#configurazione-dellambiente-conda",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Configurazione dell’ambiente Conda",
    "text": "Configurazione dell’ambiente Conda\nPer configurare l’ambiente Conda per questo corso, attenersi alla seguente procedura:\n\nScarica il file tclab_environment.yml da questo repository.\nApri il terminale o il prompt di Anaconda e vai alla directory in cui si trova il file.\n\nIl file tclab_environment.yml assomiglia a questo:\nnome: tclab_env\ncanali:\n  - valori predefiniti\ndipendenze:\n  - pitone=3.10\n  - pip\n  - insensato\n  - matplotlib\n  - scipito\n  - panda\n  - pip:\n    -tclab\n\nCrea l’ambiente dal file tclab_environment.yml:\nconda env create -f tclab_environment.yml\nAttiva il nuovo ambiente:\nconda attiva tclab\nPer verificare che l’ambiente sia stato installato correttamente, è possibile utilizzare:\nconda env list\n\n\nInstallazione del pacchetto TCLab\n\nAttivazione dell’ambiente:\n\nAssicurati che il tuo ambiente Anaconda sia attivo. Apri il tuo Terminale (o il prompt di Anaconda su Windows) e attiva il tuo ambiente:\nconda attiva tclab_env\n\nInstallazione di TCLab:\n\nLa libreria tclab è fondamentale per l’interfacciamento con l’hardware del Laboratorio di controllo della temperatura. Installalo inserendo il seguente comando:\npip installa tclab\nPremi Invio per eseguire il comando e completare l’installazione.\n\n\n\nInstallazione di librerie utili aggiuntive\nPer un’esperienza completa con TCLab e per supportare vari aspetti dell’ingegneria di controllo e dell’analisi dei dati, verranno installate anche le seguenti librerie:\n\ninsensibile:\n\nSignificato: una libreria fondamentale per i calcoli numerici in Python.\nComando di installazione:\npip installa numpy\n\nmatplotlib:\n\nSignificato: fondamentale per creare rappresentazioni visive dei dati, in particolare per l’analisi degli esperimenti TCLab.\nComando di installazione:\npip installa matplotlib\n\nscipy:\n\nSignificato: fornisce un’ampia gamma di strumenti per il calcolo scientifico, compresi metodi per risolvere equazioni differenziali ordinarie, utili nella modellizzazione dei sistemi.\nComando di installazione:\npip installa scipy\n\npanda:\n\nSignificato: offre funzionalità estese per la manipolazione e l’analisi dei dati, ideali per la gestione di set di dati complessi.\nComando di installazione:\npip installa panda\n\ngeco:\n\nSignificatività: pacchetto avanzato per l’ottimizzazione e il controllo, adatto all’implementazione di strategie di controllo predittivo del modello.\nComando di installazione:\npip installa gekko",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#schemi-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#schemi-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Schemi TCLab",
    "text": "Schemi TCLab",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#test-iniziali-con-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#test-iniziali-con-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Test iniziali con TCLab",
    "text": "Test iniziali con TCLab\n\nPassaggio 1: collega TCLab\n\nConnetti TCLab: collega il dispositivo TCLab al computer utilizzando un cavo USB.\n\n\n\nPassaggio 2: testare la connessione TCLab\n\nScrivi script di prova:\n\nApri il tuo IDE Python o Jupyter Notebook.\nScrivi il seguente codice Python ed esegui lo script. Se stampa la temperatura, TCLab è collegato correttamente.\n\n\n\nimport tclab\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")\n\nTCLab version 1.0.0\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\n\n\nRuntimeError: No Arduino device found.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#utilizzo-del-simulatore-tclab",
    "href": "IT_TCLab_🇮🇹/spacecraft_thermal_control_systems_it.html#utilizzo-del-simulatore-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Utilizzo del simulatore TCLab",
    "text": "Utilizzo del simulatore TCLab\n\nPerché utilizzare un simulatore: il simulatore TCLab è utile quando non si dispone dell’hardware fisico.\nInstalla simulatore: nel terminale o nel prompt di Anaconda, digita nuovamente pip install tclab (include il simulatore).\nScript di prova con simulatore:\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.04 seconds. T1: 20.949499999999997°C\nTime 6.03 seconds. T1: 20.949499999999997°C\nTime 8.06 seconds. T1: 20.949499999999997°C\nTime 10.07 seconds. T1: 20.949499999999997°C\nTime 12.02 seconds. T1: 20.949499999999997°C\nTime 14.03 seconds. T1: 20.949499999999997°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.04 seconds. T1: 20.949499999999997°C\nTime 20.2 seconds. T1: 20.949499999999997°C\nTime 22.01 seconds. T1: 20.949499999999997°C\nTime 24.19 seconds. T1: 20.949499999999997°C\nTime 26.24 seconds. T1: 20.949499999999997°C\nTime 28.16 seconds. T1: 20.949499999999997°C\nTime 30.03 seconds. T1: 20.949499999999997°C\nTime 32.12 seconds. T1: 20.949499999999997°C\nTime 34.2 seconds. T1: 20.6272°C\nTime 36.04 seconds. T1: 20.949499999999997°C\nTime 38.02 seconds. T1: 20.6272°C\nTime 40.21 seconds. T1: 20.949499999999997°C\nTime 42.14 seconds. T1: 20.949499999999997°C\nTime 44.01 seconds. T1: 20.6272°C\nTime 46.3 seconds. T1: 20.949499999999997°C\nTime 48.22 seconds. T1: 20.949499999999997°C\nTime 50.07 seconds. T1: 20.949499999999997°C\nTime 52.27 seconds. T1: 20.949499999999997°C\nTime 54.09 seconds. T1: 20.949499999999997°C\nTime 56.28 seconds. T1: 20.949499999999997°C\nTime 58.19 seconds. T1: 20.949499999999997°C\nTime 60.04 seconds. T1: 20.949499999999997°C\nTime 62.2 seconds. T1: 20.949499999999997°C\nTime 64.11 seconds. T1: 20.949499999999997°C\nTime 66.08 seconds. T1: 20.949499999999997°C\nTime 68.23 seconds. T1: 20.6272°C\nTime 70.13 seconds. T1: 20.949499999999997°C\nTime 72.07 seconds. T1: 20.949499999999997°C\nTime 74.05 seconds. T1: 20.949499999999997°C\nTime 76.1 seconds. T1: 20.6272°C\nTime 78.1 seconds. T1: 20.6272°C\nTime 80.22 seconds. T1: 20.949499999999997°C\nTime 82.28 seconds. T1: 20.949499999999997°C\nTime 84.22 seconds. T1: 20.949499999999997°C\nTime 86.16 seconds. T1: 20.949499999999997°C\nTime 88.23 seconds. T1: 20.949499999999997°C\nTime 90.0 seconds. T1: 20.949499999999997°C\nTime 92.27 seconds. T1: 20.949499999999997°C\nTime 94.0 seconds. T1: 20.949499999999997°C\nTime 96.16 seconds. T1: 20.949499999999997°C\nTime 98.02 seconds. T1: 20.949499999999997°C\nTime 100.1 seconds. T1: 20.949499999999997°C\nTime 102.24 seconds. T1: 20.949499999999997°C\nTime 104.0 seconds. T1: 20.6272°C\nTime 106.18 seconds. T1: 20.949499999999997°C\nTime 108.27 seconds. T1: 20.949499999999997°C\nTime 110.27 seconds. T1: 20.949499999999997°C\nTime 112.1 seconds. T1: 20.949499999999997°C\nTime 114.22 seconds. T1: 20.949499999999997°C\nTime 116.24 seconds. T1: 20.949499999999997°C\nTime 118.18 seconds. T1: 20.949499999999997°C\nTime 120.19 seconds. T1: 20.949499999999997°C\nTime 122.06 seconds. T1: 20.949499999999997°C\nTime 124.22 seconds. T1: 20.6272°C\nTime 126.19 seconds. T1: 20.949499999999997°C\nTime 128.18 seconds. T1: 20.949499999999997°C\nTime 130.25 seconds. T1: 20.949499999999997°C\nTime 132.02 seconds. T1: 20.6272°C\nTime 134.2 seconds. T1: 20.949499999999997°C\nTime 136.27 seconds. T1: 20.949499999999997°C\nTime 138.01 seconds. T1: 20.6272°C\nTime 140.2 seconds. T1: 20.949499999999997°C\nTime 142.18 seconds. T1: 20.949499999999997°C\nTime 144.2 seconds. T1: 20.949499999999997°C\nTime 146.23 seconds. T1: 20.949499999999997°C\nTime 148.24 seconds. T1: 20.949499999999997°C\nTime 150.19 seconds. T1: 20.949499999999997°C\nTime 152.28 seconds. T1: 20.949499999999997°C\nTime 154.25 seconds. T1: 20.949499999999997°C\nTime 156.23 seconds. T1: 20.6272°C\nTime 158.04 seconds. T1: 20.949499999999997°C\nTime 160.11 seconds. T1: 20.949499999999997°C\nTime 162.04 seconds. T1: 20.949499999999997°C\nTime 164.05 seconds. T1: 20.949499999999997°C\nTime 166.01 seconds. T1: 20.949499999999997°C\nTime 168.23 seconds. T1: 20.6272°C\nTime 170.08 seconds. T1: 20.949499999999997°C\nTime 172.01 seconds. T1: 20.949499999999997°C\nTime 174.14 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.22 seconds. T1: 20.949499999999997°C\nTime 180.2 seconds. T1: 20.949499999999997°C\nTime 182.2 seconds. T1: 20.949499999999997°C\nTime 184.21 seconds. T1: 20.949499999999997°C\nTime 186.08 seconds. T1: 20.949499999999997°C\nTime 188.29 seconds. T1: 20.949499999999997°C\nTime 190.24 seconds. T1: 20.949499999999997°C\nTime 192.18 seconds. T1: 20.949499999999997°C\nTime 194.09 seconds. T1: 20.949499999999997°C\nTime 196.22 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.02 seconds. T1: 20.6272°C\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html",
    "href": "compensators_and_root_locus.html",
    "title": "Compensators and the Root Locus",
    "section": "",
    "text": "Welcome to the next phase of our course on Principles of Automatic Control. In this notebook, we will delve into the Root Locus Design.\nLet’s begin by revisiting some of the concepts we have previously discussed and then move on to practical design examples.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html#what-is-a-compensator",
    "href": "compensators_and_root_locus.html#what-is-a-compensator",
    "title": "Compensators and the Root Locus",
    "section": "What is a Compensator?",
    "text": "What is a Compensator?\nA compensator is a type of controller, like PI (Proportional-Integral), PD (Proportional-Derivative), or PID (Proportional-Integral-Derivative), designed to enhance a system’s performance.\nPerformance in control systems is generally categorized into two types:\n\nTransient Performance: How the system responds to changes over time, especially when it’s adjusting to reach its steady state.\nSteady-State Performance: The system’s behavior once it has settled into a consistent pattern over time.\n\nTransient performance is crucial because it determines how quickly and accurately the system reaches its desired state after a disturbance. Steady-state performance, on the other hand, is important for the long-term stability and accuracy of the system.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html#system-structure-with-compensators",
    "href": "compensators_and_root_locus.html#system-structure-with-compensators",
    "title": "Compensators and the Root Locus",
    "section": "System Structure with Compensators",
    "text": "System Structure with Compensators\nLet’s consider a typical control system structure:\n\nThe Plant: The core part of the system being controlled.\nThe Controller/Compensator: A device or algorithm that adjusts the plant’s output based on feedback.\n\n\n\n\n\n\n\n\nIn this setup, the compensator (\\(D(s)\\)) is placed in cascade with the plant. This arrangement can also be modified with minor feedback loops, which can be represented in a similar structural format for design purposes.\nIt’s vital to understand that the choice of compensator affects both the transient and steady-state behaviors of the system. A well-chosen compensator can significantly enhance the system’s response to changes and maintain stability over time.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html#types-of-compensators",
    "href": "compensators_and_root_locus.html#types-of-compensators",
    "title": "Compensators and the Root Locus",
    "section": "Types of Compensators",
    "text": "Types of Compensators\n\nPhase Lead Compensator\nDefinition and Transfer Function\nA phase lead compensator is used to improve transient performance by shifting the root locus to the left, which enhances system stability. The transfer function of a phase lead compensator is given by:\n\\[ D(s) = K_c \\frac{(s + z_c)}{(s + p_c)} \\]\nWhere: - $ K_c $ is the gain. - $ z_c $ is the zero of the compensator. - $ p_c $ is the pole of the compensator.\n\nPhysical Realization: Often realized using an Op-Amp circuit with specific resistor and capacitor values determining $ z_c $, $ p_c $, and $ K_c $.\n\n\n\n\n\n\n\n\nFigure: plot illustrating the pole-zero diagram of a phase lead compensator. The zero is at $ -z_c $ and the pole at $ -p_c $, with the pole farther from the origin than the zero.\n\nCompensator Design Principles\n\nThe zero in the phase lead compensator (at $ s = -z_c $) introduces a derivative action, pulling the root locus plot towards the left half of the plane, thus enhancing stability and transient performance.\nAn additional pole is included for noise attenuation purposes, especially for high-frequency noise, represented by the pole at $ s = -p_c $.\nPlacement of the lead compensator is critical in cases where transient performance needs improvement.\nThe PD controller is a special case of a phase lead compensator that does not include the pole.\n\nPop-up Question: Why is a phase lead compensator used to improve transient performance? Answer: Because it shifts the root locus to the left, enhancing the system’s stability and transient response.\n\n\n\nExample: Phase Lead Compensator\nLet’s apply these concepts to a practical example: the attitude control of a satellite. The system can be modeled as $ $.\n\nScenario: Satellite Attitude Control\nSystem Model:\n\\[ G(s) = \\frac{1}{s^2} \\]\nInput: Torque $ T(t) $\nOutput: Attitude angle $ (t) $\nSystem Type: Type-2 (implies good steady-state performance: zero error for step and ramp inputs, and finite error to acceleration inputs)\nProblem Statement: Addressing instability due to a double integrator at the origin.\n\n\n\n\n\n\n\n\n\nInitial System Design\nWe start considering the simple situation where\n\\[\nD(s) = K\n\\]\nThis corresponds to the situation where \\(D(s)=K\\) is the constant of an actuator tht converts the elctrical signals into a torque \\(T(t)\\) for the thrusters.\nOpen-Loop Transfer Function:\n\\[ G(s) = \\frac{K}{s^2} \\]\nClosed-Loop Behavior:\nWe can analyse it using the root locus as \\(K\\) varies.\n\n\n\n\n\n\n\n\n\n\nUnderstanding the Root Locus Plot\nRemember, the root locus plot is a graphical representation of how the closed-loop poles of a control system vary with changes in a system parameter, typically the gain.\nFor the system $ $, the root locus plot indicates an oscillatory nature. This is because for all values of ‘s’, the roots lie on the imaginary axis of the s-plane, which is characteristic of undamped oscillations.\nWe can plot the root locus using Python in this way:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\nnumerator = [1]\ndenominator = [1, 0, 0]\nG = ctl.TransferFunction(numerator, denominator)\n\n# Plot the root locus\nplt.figure(figsize=(10, 6))\nctl.root_locus(G, plot=True);\nplt.title(f'Root locus of {G}');\n\n\n\n\n\n\n\n\nHere is a Python script that simulates the closed-loop system:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System parameters\nK = 1  # You can modify this gain value as needed\n\n# Transfer function of the system\nnumerator = [K]\ndenominator = [1, 0, 0]  # s^2 term has a coefficient of 1, s term is 0, constant term is 0\nsystem = ctl.tf(numerator, denominator)\n\n# Closed loop transfer function with a unity feedback\n# For a unity feedback system, the feedback transfer function is simply 1\nclosed_loop_system = ctl.feedback(system, 1)\n\n# Time parameters for simulation\nt = np.linspace(0, 100, 1000)  # Simulation from 0 to 10 seconds, with 1000 points\n\n# Step response\nt, y = ctl.step_response(closed_loop_system, t)\n\n# Plotting\nplt.plot(t, y)\nplt.title('Closed-Loop Step Response of the System K/s^2')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Response')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nDecision Making in Compensator Design\n\nChoosing Between Phase Lead and Phase Lag Compensator\n\nPhase Lead Compensator: Ideal for improving transient performance by shifting the root locus to the left, enhancing stability.\nPhase Lag Compensator: Adds another integrator to the system (or something very close to that), making it a type-3 system, which leads to instability. It’s typically used for improving steady-state accuracy. Modify the Python code above or plot the Root Locus for a type-3 system.\n\nIn our current scenario, the primary concern is not steady-state accuracy but transient performance. Therefore, a phase lead compensator is the preferred choice.\n\n\n\nImplementing the Phase Lead Compensator\n\nThe Concept\nThe phase lead compensator is represented by the transfer function:\n\\[ D(s) = K_c \\frac{(s + z_c)}{(s + p_c)} \\]\nwhere $ K_c $, $ z_c $, and $ p_c $ are the parameters we can determine to achieve our requirements.\nNote: The concepts behind the design are more important than the specific design. More than one design can be suitable.\n\n\nThe Design Approach\n\nSystem Representation: The plant’s transfer function is given by $ G(s) = $, where $ K $ is an adjustable gain. We can then take the compensator as $ $.\nImplementation Considerations: Depending on the hardware, the gain $ K $ might be adjusted within the plant or through an external amplification stage in the compensator.\n\nThere are three parameters under our control. How we implement these parameters depend on the hardware.\nWe call $ $ as uncompensated system that in this case includes the design parameter \\(K\\).\nConsider an attitude control system for a satellite: - Uncompensated System: \\[ \\frac{K}{s^2} \\] - Compensator: \\[ D(s) = \\frac{s + z_c}{s + p_c} \\]\n\n\n\nDesigning for Specific Performance Requirements\n\nTranslating Performance into Closed-Loop Pole Locations\nSuppose the design requirements are a damping ratio $ = 0.707 $ and a settling time $ t_s = 2$ seconds. Our goal is to translate these requirements into desired closed-loop pole locations.\nRemember that transient requirements might be given to you in terms of $_n $ (natural frequency), \\(M_p\\) (Overshoot Peak), etc.\nRemember also that we can often go from one specific requirement to another. For example, we can calculate:\n\\[\n\\zeta\\omega_n = \\frac{4}{t_s} = 2\n\\]\nThe closed-loop pole locations can be determined from these values. Below the steps to do it.\nTo calculate the position of the desired closed-loop poles for a control system with a specified damping ratio $ $ and settling time $ t_s $, we use the standard formulas related to the second-order system’s response characteristics.\nThe desired closed-loop poles are generally complex conjugates for underdamped systems, and their position in the s-plane is determined by the damping ratio $ $ and the natural frequency $ _n $.\nGiven: - Damping ratio $ = 0.707 $ - Settling time $ t_s = 2 $ seconds\n\n**Calculate the Natural Frequency ($ _n $)**: The settling time for a second-order system is approximated by $ t_s $. We rearrange this to solve for $ _n $:\n\\[ \\omega_n = \\frac{4}{\\zeta t_s} \\]\nSubstituting the given values:\n\\[ \\omega_n = \\frac{4}{0.7 \\times 2} = \\frac{4}{1.4} \\approx 2.857 \\, \\text{rad/s} \\]\nDetermine the Real and Imaginary Parts of the Poles: The general form of the closed-loop poles for a second-order system is:\n\\[ s = -\\zeta \\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nThe real part (sigma) is given by $ -_n $ and the imaginary part (omega) by $ _n $.\nCalculating these:\n\nReal Part: $ -_n = -0.7 $\nImaginary Part: $ _n = 2.857 $\n\nClosed-loop Pole Locations: Therefore, the closed-loop poles are located at approximately:\n\\[ s = -2 \\pm j2 \\]\n\nThese calculations give you the desired locations for the closed-loop poles in the s-plane to achieve the specified damping ratio and settling time in your control system design.\nWe can plot this on the s-plane:\n\n\n\n\n\n\n\nFigure: Plot of the root locus of the uncompensated system. It is possible to identify where the closed-loop poles should be for the desired performance.\nWe need to modify the behaviour of the root locus to pass through the desired closed-loop poles so that the requirements on the transient accuracy are satisfied.\n\n\n\nDesigning the Phase Lead Compensator: Placing the Zero and the Pole\n\nStep 1: Initial Placement of Zero and Pole on the s-plane\nStart by placing the zero ($ z_c \\() and the pole (\\) p_c $) of the compensator tentatively on the s-plane. This initial placement doesn’t have to be exact; it’s a starting point for fine-tuning.\n\nZero ($ z_c $): Place it closer to the imaginary axis.\nPole ($ p_c $): Place it further left from the zero on the real axis.\n\n\n\nStep 2: Adjusting for Angle Criterion\nTo ensure the system’s closed-loop response meets our requirements, the root locus must pass through the desired closed-loop pole locations. This requires satisfying the angle criterion at these points.\n\nUnderstanding the Angle Criterion:\n\nThe angle criterion states that the sum of phase angles from all poles and zeros to a point on the s-plane must equal an odd multiple of 180 degrees for the point to be on the root locus.\nFor a lead compensator, the important angles are those contributed by the compensator’s zero ($ {z_c} \\() and pole (\\) {p_c} \\(), and the angle from the plant's poles (\\) _1 $).\n\nCalculating the Angle Contributions:\n\nWe need to find the angles $ {z_c} $ and $ {p_c} $ such that they fulfill the equation:\n\\[ \\theta_{z_c} - \\theta_{p_c} - 2\\theta_1 = -180^\\circ \\]\nHere, $ {z_c} $ and $ {p_c} $ are the angles from the compensator’s zero and pole to the desired closed-loop pole location, respectively, and $ 2_1 $ is the contribution from the plant’s poles.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep-by-Step Guide to Compensator Design with Root Locus\n\nUnderstanding the Role of Poles and Angles\n\nStarting Point: We know the plant’s poles, hence we can determine $ _1 $, the angle contribution from these poles to any point in the s-plane.\nDesired Closed-Loop Poles: In our example, they are at $ -2 j2 $. This gives us a reference for determining the necessary angle contributions from the compensator.\n\n\n\nCalculating the Compensator’s Contribution\n\nNet Angle Contribution: The compensator must provide a net angle $ {z_c} - {p_c} $, where $ {z_c} $ and $ {p_c} $ are the angles from the compensator’s zero and pole to the desired closed-loop poles.\nFormula: Given $ _1 = 135^$, we calculate:\n\\[\n\\theta_{z_c} - \\theta_{p_c} = -180^\\circ + 2 \\cdot 135^\\circ = -180^\\circ + 270^\\circ = 90^\\circ\n\\]\n\n\n\nPlacing the Zero and Determining the Pole\n\nGeneral Strategy: Typically, we choose a location for the zero and then calculate where the pole should be to meet the angle condition.\nExample Calculation:\n\nPlace the zero at -1 on the real axis of the s-plane.\nThe resulting root locus shows that the angle condition is met (we have designed it to meet it), and the locus goes through the desired closed-loop poles.\n\n\n\n\n\n\n\n\n\n\n\nEvaluating the Design\n\nDominance Condition: Even though the angle condition is satisfied, we must ensure that the dominance condition is also met. This means the designed system’s behavior should closely match the expected behavior from a second-order system with the given $ $.\nProblem with Third Pole: In our example, the third pole moves close to the zero, potentially affecting the system’s overshoot and not satisfying the dominance condition.\n\n\n\nCalculating the Third Pole and Verifying Dominance\n\nMagnitude Criterion: Use the magnitude criterion to calculate the value of $ K $ corresponding to the desired closed-loop poles. In this case, $ K = 16 $.\nFinding the Third Pole: With $ K = 16 $, locate the third pole and verify if the dominance condition is met.\nSimulation: If the dominance condition is not met, simulate the system’s response to evaluate the influence of the third pole.\n\n\n\nGuidelines for Placing the Zero\n\nPreferred Location: Ideally, place the zero to the left of the desired complex conjugate closed-loop poles. This ensures that the third pole lies to the left of the desired poles, satisfying the dominance condition. This is because the root locus branch will end at that zero.\nExceptions: Sometimes, this ideal placement isn’t possible. In such cases, as with our 90° net angle contribution, we may need to place the zero to the right.\n\n\n\nSolving for \\(K\\)\nTo solve for the gain $ K $ in our control system example, where the zero of the compensator $ z_c $ is at -1 and the pole $ p_c $ is at -6, we follow the steps laid out earlier. We need to calculate $ K $ such that the magnitude condition is satisfied at the desired closed-loop poles $ -2 j2 $.\nGiven:\n\nDesired closed-loop poles: $ -2 j2 $\nZero $ z_c = -1 $\nPole $ p_c = -6 $\n\nThe open-loop transfer function $ G(s) $ is:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} \\]\nSubstituting $ z_c = -1 $ and $ p_c = -6 $ into the transfer function, we get:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + 1)}{s^2 \\cdot (s + 6)} \\]\n\n\nApplying the Magnitude Condition\nNow, we apply the magnitude condition at one of the desired closed-loop poles, say $ s = -2 + j2 $:\n\\[ |G(-2 + j2)| = 1 \\]\n\\[  \\frac{K \\cdot \\left|(-2 + j2) + 1\\right|}{\\left|(-2 + j2)^2\\right| \\cdot \\left|(-2 + j2) + 6\\right|} = 1 \\]\nLet’s simplify this equation:\n\\[ \\frac{K  \\cdot \\left|-1 + j2\\right|}{\\left| (-2 + j2)^2\\right| \\cdot \\left|4 + j2\\right|}  = 1 \\]\n\n\nSolving for $ K $\nFirst, we need to simplify the complex numbers in the equation:\n\nNumerator: $ -3 + j2 $\nDenominator: We simplify $ (-2 + j2)^2 $ and $ (4 + j2) $, then multiply them together.\n\nLet’s do these calculations:\n\n$ |(-2 + j2)^2| = |(-2)^2 + (j2)^2 + 2 (-2) j2 | = |- 8j| = 8 $\n\nThen, calculate the magnitudes:\n\nMagnitude of Numerator: $ = 2.23$\nMagnitude of Denominator: $ = 8$ and $ = 4.47$.\n\nFinally, solve for $ K $ using:\n\\[ \\frac{K \\cdot \\text{Magnitude of Numerator}}{\\text{Magnitude of Denominator}} = \\frac{8(4.47)}{2.23} = 16\\]\n\n\n\nBalancing Angle Conditions and Noise Attenuation in Compensator Design\nIn the design of a compensator, particularly a phase lead compensator, a crucial aspect to consider is the relationship between the compensator’s pole and zero. This relationship is not just a matter of meeting geometric conditions for angle requirements but also plays an important role in noise attenuation, especially for high-frequency signals.\n\nThe Role of Pole-Zero Ratio\n\nGeometric Considerations for Angle Conditions:\n\nThe placement of the pole and zero on the s-plane is initially guided by the need to satisfy the angle condition of the root locus method.\nThis condition ensures that the compensator effectively alters the system’s root locus to achieve desired transient response characteristics.\n\nNoise Filtering Aspect:\n\nApart from meeting angle conditions, the pole in the compensator acts as a filter for high-frequency noise.\nThe location of the pole relative to the zero significantly impacts the compensator’s ability to attenuate high-frequency components.\n\n\n\n\nIdeal Ratio Between Pole and Zero\n\nFactor of 10 for Attenuation:\n\nIt is generally recommended that the ratio between the zero and the pole be around 10. This ratio has been found to provide effective high-frequency attenuation.\nFor instance, if the zero is placed at -1 on the real axis, a corresponding pole at -10 can offer a good balance between angle condition satisfaction and noise reduction.\n\n\n\n\nBalancing Design Objectives\n\nTrade-offs in Design:\n\nOften, control system designers face a trade-off between strictly adhering to the angle conditions for desired transient performance and positioning the pole for optimal high-frequency noise attenuation.\nThis balance is critical in ensuring that the compensator not only improves system response but also maintains robustness against high-frequency disturbances.\n\n\n\n\n\nFinding the third pole\nTo calculate the location of the third pole in a control system where a phase lead compensator has been added, and the gain $ K $ has been determined, we can follow these steps:\n\nOpen-Loop Transfer Function: Recall the open-loop transfer function with the compensator: \\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} \\] where $ z_c $ is the zero and $ p_c $ is the pole of the compensator.\nSubstitute Known Values: Substitute the known values for $ K $, $ z_c $, and $ p_c $ into the open-loop transfer function.\nRoot Locus Method: To find the location of the third pole, you can use the root locus method. This involves plotting the root locus of the open-loop transfer function and identifying where the third pole lies based on the value of $ K $.\nAnalytical Approach: Alternatively, for an analytical approach, you can set up the characteristic equation of the closed-loop system, which is: \\[ 1 + G(s)H(s) = 0 \\] Solving this equation will give you the poles of the closed-loop system.\nSolving the Characteristic Equation: The characteristic equation will be a cubic equation in $ s $ (since the original system is second-order and the compensator adds one order). Solving this cubic equation will give you three solutions, corresponding to the three poles of the closed-loop system.\nIdentifying the Third Pole: Two of these poles will be the desired closed-loop poles (e.g., $ -2 j2 $ in our example). The third solution will be the additional pole introduced by the compensator.\n\n\nPractical Considerations\n\nComputational Tools: Solving the cubic equation analytically can be complex. It’s often more practical to use computational tools like MATLAB or Python, which can efficiently compute the roots of polynomial equations.\nDominance of Poles: Once you find the third pole, you should check its dominance in the system’s response. If it’s far left in the s-plane, its effect on the system’s transient response might be negligible. If it’s closer to the imaginary axis, it might significantly influence the system’s behavior.\n\n\nimport numpy as np\n\n# Coefficients of the cubic equation\ncoefficients = [1, 6, 16, 16]\n\n# Finding the roots\nroots = np.roots(coefficients)\n\n# Display the roots\nprint(\"The poles of the system are:\", roots)\n\nThe poles of the system are: [-2.+2.j -2.-2.j -2.+0.j]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\ndef calculate_settling_time(T, yout, tol=0.02):\n    # Settling time is the time at which the response remains within a certain tolerance\n    settled_value = yout[-1]\n    lower_bound = settled_value * (1 - tol)\n    upper_bound = settled_value * (1 + tol)\n    within_tol = np.where((yout &gt;= lower_bound) & (yout &lt;= upper_bound))[0]\n    if within_tol.size == 0:\n        return np.nan  # Return NaN if the system never settles\n    return T[within_tol[0]]\n\ndef calculate_steady_state_error(system_type, G, K, time_span):\n    G_closed_loop = ctl.feedback(K * G)\n    if system_type == 'step':\n        # Steady-state error for step input (Type 0 system)\n        T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n        steady_state_val = yout[-1]\n        return 1 - steady_state_val\n    elif system_type == 'ramp':\n        # Steady-state error for ramp input (Type 1 system)\n        Kv = ctl.dcgain(G_closed_loop * ctl.TransferFunction([1, 0], [1]))\n        return 1 / Kv if Kv != 0 else np.inf\n    else:\n        return np.nan\n\n# def plot_step_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.step_response(G_closed_loop, T=np.linspace(0, time_span[-1], 500))\n#     plt.plot(T, yout)\n#     settling_time = calculate_settling_time(T, yout)\n#     steady_state_error = calculate_steady_state_error('step', G, K, time_span)\n#     plt.title(f'Step Response for Gain K={K}\\nSettling Time: {settling_time:.2f}, Steady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n# def plot_ramp_response(G, K, time_span):\n#     G_closed_loop = ctl.feedback(K * G)\n#     T, yout = ctl.forced_response(G_closed_loop, T=time_span, U=time_span)\n#     plt.plot(T, yout)\n#     steady_state_error = calculate_steady_state_error('ramp', G, K, time_span)\n#     plt.title(f'Ramp Response for Gain K={K}\\nSteady-State Error: {steady_state_error:.2f}')\n#     plt.xlabel('Time')\n#     plt.ylabel('Amplitude')\n#     plt.grid(True)\n\n\n\ndef plot_root_locus_with_gain(K, numerator, denominator):\n    # Define the transfer function G(s)\n    G = ctl.TransferFunction(numerator, denominator)\n\n    # Calculate the closed-loop transfer function for the given gain\n    G_closed_loop = ctl.feedback(K * G)\n\n    # Find the poles for the specific gain\n    poles = ctl.pole(G_closed_loop)\n\n    # Plot the root locus\n    plt.figure(figsize=(10, 6))\n    ctl.root_locus(G, plot=True)\n\n    # Plot the poles for the specific gain\n    plt.plot(np.real(poles), np.imag(poles), 'ro', markersize=10, label=f'Poles for K={K}')\n\n    # Enhance plot\n    plt.xlabel('Real Axis')\n    plt.ylabel('Imaginary Axis')\n    plt.title(f'Root Locus of G(s) with Poles for Gain K={K}')\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \n    \ndef plot_all(K):\n    # Define the transfer function D(s)G(s)\n    numerator = [1, 1 * zc]     # 16s+16\n    denominator = [1, 6, 0, 0]  # s^3 + 6s^2\n\n    G = ctl.TransferFunction(numerator, denominator)\n    \n    # Time span for the responses\n    time_span = np.linspace(0, 10, 1000)\n\n    # Plot Root Locus\n    plot_root_locus_with_gain(K, numerator, denominator)\n\n#     # Plot Step Response\n#     plt.figure(figsize=(10, 4))\n#     plot_step_response(G, K, time_span)\n#     plt.show()\n\n#     # Plot Ramp Response\n#     plt.figure(figsize=(10, 4))\n#     plot_ramp_response(G, K, time_span)\n#     plt.show()\n    \n\nzc = 1  # Zero of the compensator\n\ninteract(plot_all, \n         K=FloatSlider(value=16, min=0, max=50, step=0.5, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_all(K)&gt;\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define system parameters\nK = 1   # This is one to have K to vary in the plot. We need to click on the value of gain 16.\nzc = 1  # Zero of the compensator\npc = 6  # Pole of the compensator\n\n# Define the transfer function\nnumerator = [K, K * zc] # 16s+16\ndenominator = [1, 6, 0, 0]  # s^3 + 6s^2\nsystem = ctl.tf(numerator, denominator)\n\n# Plot the root locus\nctl.rlocus(system)\nplt.show()\n\n# Use the plot to find the third pole at the specific gain K\n\n\n\n\n\n\n\n\n\n\nInteractive Learning\nConsider designing a phase lead compensator for a system where transient performance is as crucial as noise reduction. The choice of pole and zero locations would need to:\n\nSatisfy Angle Conditions: Ensure that the root locus passes through desired closed-loop pole locations for the required transient response.\nFilter High-Frequency Noise: Position the pole such that it effectively filters out undesirable high-frequency components, without adversely impacting the transient response.\n\nInteractive Exercise: Students can engage in an exercise using a software tool like MATLAB or Python to experiment with different pole-zero ratios. Observing how these adjustments affect both the transient response and noise attenuation will provide practical insights into the trade-offs involved in compensator design.\n\n\nSteady state requirements\nGiven that we have a type-2 system this is not a concern, certainly not for steps and ramps. If acceleration error is to be calculated this can be done from:\n\\[ D(s)G(s) = \\frac{K \\cdot (s + z_c)}{s^2 \\cdot (s + p_c)} =  \\frac{16 \\cdot (s + 1)}{s^2 \\cdot (s + 6)} \\]\nand hence, the acceleration constant is:\n\\[\nK_a = \\frac{16}{6}\n\\]\nand the corresponding acceleration error is:\n\\[\ne_{ss} = \\frac{6}{16} radians\n\\]\nThis is a finite value and most likely acceptable. Following acceleration is difficult and typically we are satisfied with step and ramp inputs.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html#phase-lag-compensation",
    "href": "compensators_and_root_locus.html#phase-lag-compensation",
    "title": "Compensators and the Root Locus",
    "section": "Phase Lag Compensation",
    "text": "Phase Lag Compensation\nIn this part, we’ll delve into the concept of phase lag compensation. Unlike phase lead compensators that are designed to improve transient performance, phase lag compensators are primarily used to enhance steady-state accuracy.\n\nThe Phase Lag Network Model\n\nTransfer Function of Phase Lag Compensator\nThe transfer function for a phase lag compensator is generally given by:\n\\[ D(s) = \\frac{s + z_c}{s + p_c} \\]\nWhere: - $ z_c $ is the zero of the compensator. - $ p_c $ is the pole of the compensator.\n\n\nPole-Zero Configuration\n\nIn a phase lag compensator, the pole is usually placed close to the origin but not necessarily at it. Placing a pole at the origin makes it a Proportional-Integral (PI) controller.\nThe zero ($ z_c \\() is positioned close to the pole (\\) p_c $), which is essential for maintaining system stability. Otherwise, the presence the pole at the origin might destabilise the system.\n\n\n\n\n\n\n\n\n\n\n\nChoosing Between Phase Lag and Phase Lead Compensators\n\nDecision Criteria\n\nTransient Performance Requirements:\n\nIf the uncompensated system, via a gain adjustment, meets the transient performance requirements, then a phase lag compensator can be considered.\nIf not, and you are not able to choose a gain that meets the transient performance requirements, and if there’s a need to pull the root locus to the left, a phase lead compensator is more appropriate.\nThe gain of the uncompensated system is a critical factor. By adjusting this gain, you might meet the transient performance requirements without needing additional compensation.\n\nSteady-State Accuracy:\n\nFor improving steady-state accuracy, particularly in type-1 or type-0 systems, a phase lag compensator is a suitable choice. Using a lag compensator with a type-2 system is very difficult due to the unstabilising effects.\nUsing a lag compensator is similar to adding an integrator to improve the steady state performance. The pole and zero are chosen so that the transient performance are not deteriorated. Having the zero as close as possible to the pole means that we want to reduce the effect that the compensator might have on the transient.\n\n\n\n\n\nExample: Applying Phase Lag Compensation\n\nSystem Model\nLet’s consider a type-1 system represented by:\n\\[ G(s) = \\frac{K}{s(s + 2)} \\]\nThis model could represent a motor servo system for position tracking.\n\n\nPerformance Requirements\n\nDamping Ratio ($ $): 0.45\nVelocity Error Constant ($ K_v $): 20 (for steady-state ramp error)\n\n\n\n\nEvaluating the Uncompensated System\n\nVelocity Error Constant ($ K_v $)\nIn our control system example, let’s begin by assessing the uncompensated system’s performance. A key parameter in this assessment is the velocity error constant, denoted as $ K_v $. For our system, $ K_v $ is calculated as follows:\n\\[ K_v = \\frac{K}{2} \\]\n\n$ K_v $ is a measure of the system’s ability to track ramp inputs. A higher $ K_v $ implies better tracking performance for such inputs.\n\n\n\n\nDesired Closed-Loop Pole Locations\n\nCalculating Pole Locations for Given Damping Ratio\n\nFor a damping ratio ($ $) of 0.45, the closed-loop poles are located at $ -1 2j $.\nThis calculation is based on standard second-order system dynamics where the pole locations are determined by the damping ratio and the natural frequency.\nThe location of these poles in the s-plane directly affects the transient behavior of the system, including aspects like overshoot and settling time.\n\n\n\n\nAssessing System Performance at $ K = 5 $\n\nDetermining When Desired Poles Are Achievable\n\n\n\n\n\n\n\nFigure: root locus plot that shows how varying $ K $ affects the pole locations.\n\nBy examining the root locus plot, we can identify that the desired closed-loop poles at $ -1 2j $ are obtainable when the gain $ K $ is set to 5.\n\n\n\nSteady-State Accuracy\n\nWhen $ K = 5 $, the velocity error constant is:\n\\[ K_v = \\frac{K}{2} = \\frac{5}{2} = 2.5 \\]\nHowever, this value of $ K_v $ is less than the required 20 for adequate steady-state performance.\n\n\n\n\nThe Objective of Phase Lag Compensation\n\nBoosting $ K_v $ to Meet Steady-State Requirements\n\nThe primary goal of introducing a phase lag compensator in this scenario is to increase $ K_v $ to meet the steady-state requirement of 20.\nThis needs to be achieved while ensuring that the compensated root locus plot passes through the desired closed-loop poles at $ -1 2j $.\n\n\n\nBalancing Steady-State and Transient Performance\n\nThe challenge lies in boosting $ K_v $ without adversely affecting the transient performance, which is indicated by the closed-loop pole locations.\n\n\n\n\nMeeting the transient requirements\nTo accomplish our desired outcome, we will position both the zero and the pole of the compensator near the origin. The goal here is to ensure that their combined contribution to the phase angle of the system is minimal, ideally within a range of 1 to 5 degrees. By doing so, we can effectively ensure that these elements have a negligible impact on the system’s original root locus plot. This strategic placement is crucial for maintaining the original characteristics of the system while implementing the phase lag compensator.\n\n\nMeeting the \\(K_v\\) requirement\n\\[ D(s) G(s) = \\frac{K (s+z_c)}{s(s + 2)(s+p_c)} \\]\nand\n\\[\nK_v = \\frac{K z_c}{2p_c} = 20\n\\]\nthis means that we can use the ratio \\(\\frac{z_c}{p_c}\\) to improve our velocity constant.\nMore specifically, for \\(K=5\\) (note that for the same reason why the zero and pole do not disturb the transient, they also do not change much the value of the root locus gain, the boost that we need is \\(\\frac{z_c}{p_c}=8\\).\nThis helps us define the relationship between the zero and the pole of the compensator.\n\nPlacing the pole and zero\n\nWe start from placing the zero at \\(z_c = -0.1\\) (this comes from the dominance condition as we will see soon).\nThe pole hence is located at: \\(p_c = \\frac{-0.1}{8}=0.0125\\)\n\nThe root locus is (this is not too scale to highlight the relationships):\n\n\n\n\n\n\n\n\n\nDominance Condition\nIt is possible to verify that the third pole must be real, and hence very close to the zero. This means that the dominance condition is satisfied (even though it is close to the imaginary axis). If the third pole is not close enough we can make an adjustment to the zero/pole locations to move it closer to the zero. This is typically done using software.\n\n\nSimulations\nFinally through simulation we can verify the full performance (transient and steady-state) of the system.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "compensators_and_root_locus.html#lag-lead-compensation",
    "href": "compensators_and_root_locus.html#lag-lead-compensation",
    "title": "Compensators and the Root Locus",
    "section": "Lag-Lead Compensation",
    "text": "Lag-Lead Compensation\nIn concluding our discussion on control system compensators, let’s consider how to choose between different types of compensators based on the performance of the uncompensated system. Here, by ‘uncompensated,’ we mean a system where only gain adjustments are permissible.\n\nDecision Making for Compensator Type\n\nWhen to Choose a Lag Compensator:\n\nIf the transient performance of the uncompensated system is satisfactory, then a lag compensator is a suitable choice.\nThe primary role of the lag compensator here is to enhance steady-state performance without significantly affecting the transient response.\n\nChoosing a Lead Compensator:\n\nIf the transient performance is unsatisfactory, a lead compensator is the way to go.\nThe lead compensator is designed to improve transient performance. After implementing it, you should re-evaluate to see if steady-state requirements are met.\n\n\n\n\nAddressing Both Transient and Steady-State Performance\n\nScenario: What if, after designing a phase lead compensator, both transient performance is not satisfactory, and steady-state requirements are unmet?\nSolution: In such cases, consider using a lag-lead compensator. This involves first designing a lead compensator to address transient performance and then evaluating steady-state performance.\n\n\n\nThe Standard Final Procedure\n\nEvaluate the Open-Loop System:\n\nCarefully investigate the open-loop system with gain adjustments to assess transient performance.\n\nDesign Process:\n\nIf transient performance is adequate, opt for a lag compensator.\nIf transient performance is inadequate, design a lead compensator to rectify this.\nAfter implementing the lead compensator, check the steady-state error. If it’s satisfactory, your design is complete.\n\nIncorporating Lag Compensator if Necessary:\n\nIf steady-state performance is still lacking, treat the lead-compensated system as ‘uncompensated’ for the purpose of designing a phase lag compensator.\nThe lag compensator, in this case, won’t disturb the transient improvements made by the lead compensator.\n\n\n\n\nFinal Design Choices\n\nYour final design choice can be a lead, lag, or a combination of lead-lag compensators, depending on the system’s requirements.\nOperational Amplifier (Op-Amp) realizations for both lead-lag and lag-lead compensators have been discussed, allowing for practical implementation and parameter adjustments.\n\nConclusion: The design and selection of compensators depend on both the transient and steady-state performance requirements of your system. The decision-making process involves a careful evaluation of the system’s current performance and the objectives you aim to achieve with compensation.\nNote for Instructor: Encourage students to analyze different system scenarios and decide on the type of compensator needed. Practical exercises involving Op-Amp circuit design for lead-lag and lag-lead compensators can be very beneficial for understanding these concepts.",
    "crumbs": [
      "Compensators and the Root Locus"
    ]
  },
  {
    "objectID": "control_system_components.html",
    "href": "control_system_components.html",
    "title": "Control System Components",
    "section": "",
    "text": "Automatic control systems are ubiquitous in various industries and applications. They help maintain desired output conditions by adjusting the input accordingly. One fundamental aspect of understanding these systems is the concept of analogous systems and understanding the components that make up a control system.\nIn automatic control systems, the entire process can be visualized as a sequence of interconnected components. This sequence begins with the plant, which is essentially the system we aim to control. The plant is driven by an actuator, and the power to this actuator is controlled by the controller, which is the brain of our system. The controller makes decisions based on feedback it receives from sensors that monitor the system.\nControl systems consist of various components that work together to achieve a desired output.\nIn our discussion, we primarily focus on mechanical systems, but other systems like thermal or liquid-based systems also exist as we saw.\n\n\n\n\n\n\nComponents of the Control System:\n\nPlant: The primary system that needs to be controlled. This is often a mechanical system in our discussions, but it can also be a thermal system, a liquid system, or any other system that requires control.\nActuator: A device that drives or controls the plant. For mechanical systems, motors are common actuators.\nController: The brain of the system. It decides how to drive the actuator based on the difference between the desired output and the actual output. This can be an operational amplifier circuit (Op-Amp) or even a digital computer in modern systems.\nSensor: A device that measures the actual output of the plant. It often needs noise filters to remove high-frequency noise and amplifiers to boost its signals to usable levels.\n\nThe brain of the control system, the controller, is often electrical in nature. Today, most controllers are either Op-Amp circuits (legacy) or digital computers. Hydraulic or pneumatic controllers were used in the past. The trend is moving toward these controllers because of their versatility and efficiency.\nYour role:\n\nDesigning noise filters to ensure that high-frequency noise from sensors doesn’t interfere with the system.\nAmplifying or conditioning sensor outputs to make them compatible with the standard input signals or to suit the controller hardware. For example, sensor output can be millivolt or milliamper, and require amplification to use them together with the levels of the input signal and with the controller.\nDesigning the controller, which is the most critical part of the system.\n\nLet’s make the diagram more precise:\n\n\n\n\n\n\nThe controller can respond to the error signal in various manners. One approach is to amplify the error, referred to as a Proportional controller. Another method involves controllers that produce a signal based on both the error and its integral. This results in a signal composed of two parts: one directly proportional to the error and another proportional to the accumulated error over time. We talk about Proportional and Integral Controllers in this case.\nIn addition to these, there’s the Proportional-Derivative (PD) controller, which not only responds to the present error but also to the rate of change of this error. By considering the derivative or the rate at which the error is changing, the PD controller can anticipate future errors and act more responsively, making it especially useful in scenarios where swift corrections are essential.\nThen there’s the Proportional-Integral-Derivative (PID) controller, which combines all three strategies. It considers the present error (proportional), the accumulation of past errors (integral), and the rate of change of the error (derivative). By using all three components, the PID controller offers a comprehensive approach to error correction, ensuring steady-state accuracy, quick response, and anticipation of future errors. This makes the PID controller one of the most widely used control strategies in various industries due to its adaptability and efficiency in diverse control scenarios.\n\nProportional (P) Controller: \\[\nu(t) = K_p \\cdot e(t)\n\\]\n\nWhere: - $ u(t) $ is the control output. - $ K_p $ is the proportional gain. - $ e(t) $ is the error signal.\n\nProportional-Integral (PI) Controller: \\[\nu(t) = K_p \\cdot e(t) + K_i \\int e(t) \\, dt\n\\]\n\nWhere: - $ K_i $ is the integral gain.\nThe majority of the industrial controllers are PI controllers.\n\nProportional-Derivative (PD) Controller:\n\n\\[\nu(t) = K_p \\cdot e(t) + K_d \\frac{d e(t)}{dt}\n\\]\nWhere: - $ K_d $ is the derivative gain.\n\nProportional-Integral-Derivative (PID) Controller:\n\n\\[\nu(t) = K_p \\cdot e(t) + K_i \\int e(t) \\, dt + K_d \\frac{d e(t)}{dt}\n\\]\nIn these equations: - $ e(t) $ represents the error signal, which is the difference between the setpoint and the process variable (or the measured output). - The gains $ K_p $, $ K_i $, and $ K_d $ determine the strength of the controller’s response to the error, its accumulation, and its rate of change, respectively. Adjusting these gains allows for tuning the controller’s performance to suit specific applications.\nThese can be easily implemented as analog controllers using Op-Amps.\n\nAnalog Controllers\nOperational amplifiers (Op-Amps) are crucial components in control systems. They can act as amplifiers, integrators, or differentiators, depending on their configuration.\n\nProportional Controller (P):\n\n\nCircuit:\n\n\n\n\n\n\nTransfer function:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=-\\frac{R2}{R1}\n\\]\n\nNote that with two circuits in serie we can get rid of the minus sign.\n\n\nProportional-Integral Controller (PI):\n\n\nCircuit:\n\n\n\n\n\n\nTransfer function:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=-\\frac{R_2+\\frac{1}{sC}}{R_1} = -\\frac{R_2}{R_1} - \\frac{1}{R_1C}\\frac{1}{s}\n\\]\nthat we can write it as:\n\\[\ne_0(t) = -\\frac{R_2}{R_1}e_i(t) - \\frac{1}{R_1C}\\int_{0}^{t}e_i(\\tau)d\\tau\n\\]\n\nProportional-Derivative Controller (PD):\n\n\nCircuit:\n\n\n\n\n\n\nTransfer function:\n\n\\[\n\\frac{E_0(s)}{E_i(s)}=\\frac{\\frac{R_2}{R_1\\frac{1}{sC}}}{R_1+\\frac{1}{sC}}\n\\]\nand with simple manipulations we can obtain the standard structure.\n\nProportional-Integral-Derivative Controller (PID):\n\n\nCircuit:\n\n\n\n\n\n\nTransfer function:\n\n\\[\n\\frac{E_0(s)}{E_i(s)} = -\\frac{Z_2(s)}{Z_1(s)}\n\\]\nwhere\n\\[\nZ_1 = \\frac{R_1}{R_1C_1s+1} \\;\\;\\;\\; Z_2=\\frac{R_2C_2s+1}{C_2s}\n\\]\n\n\nOp-Amps\n\nAn op-amp, short for operational amplifier, is a type of electronic component that amplifies voltage. It’s essentially a device that takes in two voltage inputs, compares them, and outputs the difference between these voltages multiplied by a very high number. The two inputs are known as the inverting input (marked with a minus sign) and the non-inverting input (marked with a plus sign). The output attempts to make the difference between the inputs zero by amplifying the voltage difference.\nOp-amps are fundamental components in electronics, widely used for signal conditioning, filtering, and to perform mathematical operations such as addition, subtraction, integration, and differentiation, hence the name “operational” amplifier. Their capability to amplify the difference between the voltages at their two inputs (the non-inverting “+” and the inverting “-”) is what makes them so useful across various applications. The actual behavior of an op-amp in a circuit depends on how it is configured, including the external components connected to it, which can control its gain and other characteristics.\n\n\n\n\n\n\n\n\n\nThe input voltages \\(v_1, v_2\\) can be DC or AC are often measured with respect to ground which acts as a reference.\nThe output voltage is: \\[\nv_0 = K(v_2-v_1) = -K(v_1-v_2)\n\\]\n\\(K\\) is called (differential) gain and is usually a very large value. It can be as high as \\(1e5\\) or \\(1e6\\) for signal frequencies less than \\(10Hz\\), and decreases for higher frequencies (goes to \\(\\approx 1\\) for frequencies \\(&gt; 1MHz\\)).\nIt is also called differential amplifier because it amplifies the difference between the inputs \\(v_1\\) and \\(v_2\\).\nSince its gain is very high it needs a negative feedback to be stabilised. This negative feedback is hence done on the inverted input (negative).\nIn an ideal op-amp no current flows through the input terminals (input impedence is \\(\\infty\\)).\nThe load has no effect on the output voltage \\(v_o\\) (output impedence is zero).\n\n\n\nInverting Amplifier (P)\nLet’s analyse the proportional controller once again:\n\n\n\n\n\n\n\nFor this circuit we can write:\n\\[\ni_1 = \\frac{e_i - v'}{R_1}\n\\]\n\\[\ni_2 = \\frac{v' - e_0}{R_2}\n\\]\n\nSince no current can flow through the op-amp, \\(i_1 = i_2\\) and hence:\n\n\\[\n\\frac{e_i - v'}{R_1} = \\frac{v' - e_0}{R_2}\n\\]\nGiven that:\n\\[\nv_0 = K(v_2-v_1) = K(0 - v')\n\\]\nand \\(K &gt;&gt; 1\\), \\(v'\\) must be close to zero: \\(v' \\approx 0\\) and hence:\n\\[\n\\frac{e_i}{R_1} = \\frac{- e_0}{R_2} \\Rightarrow \\frac{e_0}{e_i} = \\frac{- R_2}{R_1}\n\\]",
    "crumbs": [
      "Control System Components"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html",
    "href": "compensator_design_using_root_locus.html",
    "title": "Compensator Design",
    "section": "",
    "text": "A compensator is a component of the total control system designed to compensate for deficiencies in the plant. If a control system with a plant, sensor, and feedback loop satisfies your requirements, you do not need compensation. However, if it does not, a compensator is added—a hardware device or software in a digital computer—to improve performance.\nWith reference to the picture below:\n\n\n\n\n\nIf the controller \\(D(s)\\) is not included, the diagram still represents a complete control system. If this satisfies your requirement, no further compensation is needed.\nOur primary objective is to design an effective compensator, represented as $ D(s) $ in transfer function terminology, to ensure our control system adheres to specific performance criteria.\nWe will proceed under the assumption that the fundamental architecture of the system remains constant. This implies that elements like the plant and the sensor will not undergo any modifications. The sole variable open to alteration is the compensator, $ D(s) $. This restriction is based on the relative simplicity of modifying $ D(s) $: it usually involves updating the software in digital controllers or adjusting the operational amplifier (OpAmp) circuitry.\nIn the realm of control systems, a compensator plays a pivotal role. It serves to adjust the system’s behavior to meet targeted specifications, which may include enhanced stability, faster response times, or reduced steady-state errors. Essentially, a compensator fine-tunes the dynamics of the system to achieve our desired outcomes.\nTo illustrate, consider a control system equipped with a basic feedback loop. Should this system fall short of meeting its performance benchmarks, we introduce a compensator. For example, in a scenario where the system’s response is slower than required, a compensator can be engineered specifically to expedite the system’s response time.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#what-is-a-compensator",
    "href": "compensator_design_using_root_locus.html#what-is-a-compensator",
    "title": "Compensator Design",
    "section": "",
    "text": "A compensator is a component of the total control system designed to compensate for deficiencies in the plant. If a control system with a plant, sensor, and feedback loop satisfies your requirements, you do not need compensation. However, if it does not, a compensator is added—a hardware device or software in a digital computer—to improve performance.\nWith reference to the picture below:\n\n\n\n\n\nIf the controller \\(D(s)\\) is not included, the diagram still represents a complete control system. If this satisfies your requirement, no further compensation is needed.\nOur primary objective is to design an effective compensator, represented as $ D(s) $ in transfer function terminology, to ensure our control system adheres to specific performance criteria.\nWe will proceed under the assumption that the fundamental architecture of the system remains constant. This implies that elements like the plant and the sensor will not undergo any modifications. The sole variable open to alteration is the compensator, $ D(s) $. This restriction is based on the relative simplicity of modifying $ D(s) $: it usually involves updating the software in digital controllers or adjusting the operational amplifier (OpAmp) circuitry.\nIn the realm of control systems, a compensator plays a pivotal role. It serves to adjust the system’s behavior to meet targeted specifications, which may include enhanced stability, faster response times, or reduced steady-state errors. Essentially, a compensator fine-tunes the dynamics of the system to achieve our desired outcomes.\nTo illustrate, consider a control system equipped with a basic feedback loop. Should this system fall short of meeting its performance benchmarks, we introduce a compensator. For example, in a scenario where the system’s response is slower than required, a compensator can be engineered specifically to expedite the system’s response time.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#introduction-to-the-root-locus-method",
    "href": "compensator_design_using_root_locus.html#introduction-to-the-root-locus-method",
    "title": "Compensator Design",
    "section": "Introduction to the Root Locus Method",
    "text": "Introduction to the Root Locus Method\nThe root locus method is a graphical approach used in control systems to determine the stability and transient response of a system as a function of a varying parameter, typically a gain.\n\nKey Performance Measures: Translating Performance into Poles\nRecall the key performance measures in control systems:\n\n\\(T_r\\) (Rise Time)\n\\(T_p\\) (Peak Time)\n\\(\\zeta\\) (Damping Ratio)\n\\(\\omega_n\\) (Natural Frequency)\n\\(M_p\\) (Maximum Peak)\nSettling Time\nSteady-State Error\n\nWe’ve observed that performance measures often present conflicts; however, the transient response of the system is primarily governed by two key parameters: \\(\\zeta\\) (damping ratio) and \\(\\omega_n\\) (natural frequency). These parameters influence the system’s performance, as they determine the behavior of the system during transient states - those temporary periods before reaching steady-state.\nConsequently, understanding and controlling the transient response translates into strategically positioning a pair of dominant closed-loop poles in the s-plane. In essence, the parameters \\(\\zeta\\) and \\(\\omega_n\\) are important in shaping the overall performance of a control system.\nThe Root Locus method involves plotting the possible locations (locus) of the closed-loop system poles as a system parameter (usually a gain) varies. This plot helps visualize how the closed-loop poles move in response to changes in this parameter.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#understanding-the-root-locus-plot",
    "href": "compensator_design_using_root_locus.html#understanding-the-root-locus-plot",
    "title": "Compensator Design",
    "section": "Understanding the Root Locus Plot",
    "text": "Understanding the Root Locus Plot\nConsider a system with the open-loop transfer function\n\\[G(s) = \\frac{K}{(s + 1)(s + 2)}\\]\nwhere \\(K\\) is a variable gain.\nThis corresponds to\n\n\n\n\n\nStep 1: Derive the Closed-Loop Transfer Function\nThe closed-loop transfer function is given by:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{K}{s^2 + 3s + 2 + K} \\]\nStep 2: Determine the Pole Locations\nThe root of the characteristic equations are:\n\\[\ns_{1,2} = \\frac{-3}{2} \\pm \\frac{1}{2}\\sqrt{1-4K}\n\\]\nWe can now verify how the system behaves when we change \\(K\\) from 0 to \\(\\infty\\). Afterall this is the total change that we can make.\nFor different values of K, the closed-loop poles, which are the roots of the characteristic equation, change.\n\nInitially, when K = 0, the poles are at the open-loop pole locations, -1 and -2.\nAs K increases, these poles move along specific paths in the s-plane. This movement can be plotted and analyzed.\nFor example, consider \\(K = 1/4\\):\n\n\\[ s_{1,2} = -\\frac{3}{2} \\pm \\frac{1}{2}\\sqrt{1 - 4K} \\] \\[ = -1.5 \\text{ (repeated poles)} \\]\nAs \\(K\\) increases further, the poles become complex conjugate.\n\nVisualising it in Python\nTo illustrate how the poles of a system move as the parameter \\(K\\) changes, we can write a Python script.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, FloatSlider\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    discriminant = 1 - 4 * K\n\n    # Check if the discriminant is negative (complex poles)\n    if discriminant &lt; 0:\n        real_part = -1.5\n        imaginary_part = 0.5 * np.sqrt(-discriminant)\n        poles = [real_part + 1j * imaginary_part, real_part - 1j * imaginary_part]\n    else:\n        # Real poles\n        poles = [-1.5 + 0.5 * np.sqrt(discriminant), -1.5 - 0.5 * np.sqrt(discriminant)]\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'bo')  # Blue dots for poles\n\n    plt.xlim(-3, 1)\n    plt.ylim(-2, 2)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=1, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nWe can graphically visualise it in this way:\n\n\n\n\n\nRemember that the poles are:\n\\[\ns_{1,2} = -\\frac{3}{2} \\pm \\frac{1}{2}\\sqrt{1-4K}.\n\\]\n\nIn the root locus diagram for this system, we see two branches starting at -1 and -2, respectively, on the real axis.\nAs $ K $ increases, these branches would converge towards -1.5.\nBeyond $ K = $, the branches break off into the upper and lower halves of the complex plane, forming a mirror image about the real axis.\nThe branches continue vertically upwards and downwards, respectively, indicating the movement of the complex conjugate poles. The poles must lie on the vertical line because the real part is always \\(-\\frac{3}{2}\\).\nIn a root locus plot, the term “branch” refers to the path that a pole of the closed-loop system takes in the complex plane as a particular parameter (in this case, $ K $) varies.\nFor the given system, there are two branches because it is a second-order system, resulting in two poles. Each branch represents the trajectory of one of these poles.\n\n\nInitial Condition: $ K = 0 $\n\nWhen $ K = 0 $, the poles of the closed-loop system are the same as the open-loop poles.\nThe open-loop transfer function is $ $, and its poles are at $ s = -1 $ and $ s = -2 $.\nThus, at $ K = 0 $, the closed-loop poles start at these open-loop pole locations: one pole at -1 and the other at -2.\n\n\n\nAs $ K $ Increases\n\nAs $ K $ begins to increase from 0, the closed-loop poles start moving from these initial positions.\nWith a slight increase in $ K $, the poles move along specific paths in the s-plane.\n\n\n\nAt $ K = $\n\nWhen $ K $ reaches $ $, a critical change occurs.\nSubstituting $ K = $ into the formula, we find that the discriminant becomes zero, making the poles real and repeated, both located at $ s = -1.5 $.\n\n\n\nVisualization of Pole Movement\n\nOne root moves from -2 towards -1.5, and the other root moves from -1 towards -1.5.\nThese movements can be visualized as two branches of the root locus converging at $ s = -1.5 $.\n\n\n\nBeyond $ K = $\n\nFor $ K &gt; $, the discriminant becomes negative, resulting in complex conjugate poles.\nThe real part of these poles remains constant at $ - $, while the imaginary part increases as $ K $ increases, indicating that the poles move vertically on the s-plane.\nThese poles will always lie on a vertical line in the s-plane with the real part being always $ -1.5 $.\n\n\n\nImplications for System Performance\n\nThe root locus plot visually represents how the system’s dynamic characteristics like rise time, settling time, peak overshoot, and the damping ratio $ $ and natural frequency $ _n $ are influenced by the variation in $ K $.\nCrucially, the system remains stable for all values of $ K $ as the poles never cross the imaginary axis (Jω axis). This is evident from the root locus plot.\n\n\n\n\nRelating Root Locus to System Performance\n\nVisualization of Performance Parameters\n\nThe root locus plot is not just a representation of pole movement; it’s a powerful tool to visualize key performance parameters like rise time, settling time, peak overshoot, damping ratio ($ \\(), and natural frequency (\\) _n $).\nThe position and movement of the poles on this plot directly relate to how these parameters will manifest in the system’s response.\n\n\n\nStability Analysis\n\nOne critical aspect of the root locus plot is its ability to provide quick insights into the system’s stability.\nFor the given system, as long as the poles (represented by the branches) do not cross into the right half of the complex plane (the imaginary axis, or \\(j\\omega\\) axis), the system remains stable.\nSince the poles in this system never cross the imaginary axis for any value of $ K $, we can conclude that the system remains stable for all values of $ K $ from 0 to infinity.\n\n\n\n\nSimplifying Complex Analysis\n\nThe root locus method simplifies the analysis of complex systems. Even in scenarios where the system’s dynamics are more intricate, the root locus plot provides a clear and immediate understanding of how changes in a parameter (like $ K $) will affect the system’s performance and stability.\n\n\n\nUnderstanding and Applying the Root Locus Method in Control System Design\nThe root locus plot provides a comprehensive depiction of a control system’s behavior based on the variation of a single, chosen design parameter. This design parameter could be, for instance, the derivative constant in a Proportional-Derivative (PD) controller, the integral constant in a Proportional-Integral (PI) controller, the gain of an amplifier, or other similar system elements. Initially, you may focus on just one parameter, although in practice, multiple parameters can influence system behavior.\nThe process using the root locus method involves two primary steps:\n\nIdentify the Design Parameter: Determine which parameter in your control system you want to adjust. This parameter is what you’ll use to assess and modify the system’s performance.\nPlot the Root Locus: Create a root locus plot by varying the chosen parameter (typically from 0 to infinity). This plot visually represents how the system’s poles—and hence its behavior—change as the parameter is adjusted.\n\nThe root locus plot serves as a dynamic tool, enabling you to visually correlate variations in your chosen design parameter with changes in the system’s performance. By examining this plot, you can determine the optimal value of the design parameter that aligns with your specific performance requirements, such as response speed, stability, or overshoot.\nThe root locus plot is an essential and complete graphical representation that allows you to understand and optimize a control system’s response based on a key design parameter.\nWe can for example discuss what happens to the damping of the system as we increase \\(K\\):",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#example-2",
    "href": "compensator_design_using_root_locus.html#example-2",
    "title": "Compensator Design",
    "section": "Example 2",
    "text": "Example 2\nConsider a system with the open-loop transfer function\n\\[G(s) = \\frac{K}{s(s + 1)(s + 2)}\\]\nwhere \\(K\\) is a variable gain.\n\n\n\n\n\n\nThe plant has now an integrator.\n\nThe root locus for this case is:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\n# Define the transfer function G(s) = K / (s^3 + 3s^2 + 2s + K)\n# where K is the gain that will be varied.\ndef transfer_function(K):\n    numerator = [K]\n    denominator = [1, 3, 2, K]\n    return ctl.tf(numerator, denominator)\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    \n    if K == 0:\n        poles = np.roots([1, 3, 2, K])\n    else:\n        system = transfer_function(K)\n        poles = ctl.pole(system)\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(poles), np.imag(poles), 'bo')  # Blue dots for poles\n\n    plt.xlim(-3, 1)\n    plt.ylim(-2, 2)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K:.2f}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=20, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nOr:\n\n\n\n\n\n\nInitial Points: The diagram starts with three points on the real axis, representing the open-loop poles at $ K = 0 $.\nBranches: Three lines (branches) emerge from these points, each showing the path of a root as $ K $ increases.\n\nBranch 1 and 2: Two branches might show roots moving towards each other, becoming real and repeated, then splitting into complex conjugate pairs as they approach the imaginary axis.\nBranch 3: The third branch represents the path of the third root, which may move independently of the other two.\n\nDirection Indicators: Arrows along the branches indicate the direction of movement as $ K $ increases.\nCritical Points:\n\nPoints where roots become complex conjugate.\nPoints where the system becomes oscillatory and then unstable.\n\n\n\nInitial conditions\n\nAt $ K = 0 $, the roots of the system are located at the open-loop poles. These are the starting points for the root locus branches.\nAs $ K $ increases from 0, the roots begin to move along distinct paths. For a third-order system, there are three branches in the root locus plot.\n\n\n\nBranches of the Root Locus\n\nEach branch represents the path of one root in the complex plane.\nOne root moves in one direction, the second root in another, and the third root follows a separate path.\nAt a specific value of \\(K\\), the two roots become real and repeated, while the third root is at a different location.\n\n\n\nThe Emergence of Complex Conjugate Roots\n\nWith a further increase in $ K $, the system exhibits complex conjugate roots.\nTwo roots approach the imaginary axis, indicating a trend towards oscillatory behavior and potential instability.\n\n\n\nSignificance of the Third Root\n\nIf this root is sufficiently far from the real part of the complex conjugate roots (by a factor of four to five times), its impact on the system’s dynamics is negligible (dominance condition).\n\n\n\nSystem Stability and Oscillations\n\nAs $ K $ continues to increase, the system moves closer to the imaginary axis.\nA certain value of $ K $ causes the system to become oscillatory. Further increases in $ K $ lead to instability.\n\n\n\nComments\n\nVisibility of System Behavior: The root locus plot clearly illustrates how the system’s behavior changes with $ K $, showcasing stability, oscillatory tendencies, and instability.\nComparison with Routh Stability Criterion: While the Routh Stability Criterion also provides stability ranges, the root locus plot offers a more detailed visualization of the system poles within these ranges. It tells you where the roots are, and this improves our understanding of system dynamics.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#example---adding-a-zero",
    "href": "compensator_design_using_root_locus.html#example---adding-a-zero",
    "title": "Compensator Design",
    "section": "Example - Adding A Zero",
    "text": "Example - Adding A Zero\nIn this section of the notebook, we will explore the concept of root locus analysis focusing on a system with a zero. This is equivalent to having a Proportional-Derivative (PD) control.\nConsider a control system represented by the transfer function:\n\\[ G(s) = \\frac{K (s + 5)}{(s + 1)(s + 2)} \\]\nHere, $ K $ is the gain, and the system includes a zero at $ s = -5 $, resembling the addition of a PD controller. This system is a type-0 system with PD control. It could represent various real-world systems like temperature control or liquid level control.\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\n# Define the transfer function G(s) = K (s+5)/ (s^2 + 3s +  Ks + 2 + 5K)\n# where K is the gain that will be varied.\ndef transfer_function(K):\n    numerator = [K, 5*K]\n    denominator = [1, 3 + K, 2 + 5*K]\n    return ctl.tf(numerator, denominator)\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    \n    if K == 0:\n        poles = np.roots([1, 3 + K, 2 + 5*K])\n    else:\n        system = transfer_function(K)\n        poles = ctl.pole(system)\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'bo')  # Blue dots for poles\n\n    # Plot the zero at s = -5\n    plt.plot(-5, 0, 'rx')  # Red 'x' for zero\n\n    plt.xlim(-12, 1)\n    plt.ylim(-5, 5)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K:.2f}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=20, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nAnd the resulting Root Locus Diagram is:\n\n\n\n\n\n\nRoot Locus Sketch\n\nIdentifying Poles and Zeros\n\nPoles: $ s = -1, -2 $\nZero: $ s = -5 $\n\n\n\nCharacteristic Equation\nWith $ K $ as a running parameter, the characteristic equation is:\n\\[ 1 + K \\cdot \\frac{1}{(s + 5)(s + 1)(s + 2)} = 0 \\]\n\n\n\nAnalysis of Root Locus\n\nInitial Condition at $ K = 0 $\n\nStart with open-loop poles at $ s = -1 $ and $ s = -2 $.\nAt $ K = 0 $, the system behaves purely based on these open-loop poles.\n\n\n\nAs $ K $ Increases\n\nTwo branches emerge from the open-loop poles.\nBranch 1: Moves from $ s = -1 $ towards the right.\nBranch 2: Moves from $ s = -2 $ towards the right.\n\n\n\nAnalysis at Critical Points\n\nAs $ K $ increases further, the roots become complex conjugate.\nThe point where the roots are real and repeated is critical, indicating a transition in system dynamics.\nNote that there are two values of \\(K\\) for which the roots are real and repeated.\nAt $ K = $, observe the behavior of the roots.\n\n\n\n\nImpact of PD Control on System Stability\n\nAddition of a zero (PD control) shifts the root locus towards the left, which implies better stability.\nThe system’s stability can be visualized through the root locus plot, where the roots move towards or away from the imaginary axis.\nCompare this with what happened when we added the integrator that instead pull the branches towards the RHP.\n\n\n\nUnderstanding System Dynamics\n\nIn the provided diagram, as $ K $ is incrementally increased, the two poles shift towards the left on the real axis, indicating an increase in their negative real components. Concurrently, there is an observable increase in the imaginary parts of these poles, though this effect is less pronounced compared to the changes in the real parts.\nThe real component of the poles, represented by $ _n $, is directly linked to the system’s settling time, which can be mathematically expressed as $ t_s = $.\nWith the increase in $ K $, there is a notable rise in the real part $ _n $ of the poles. This leads to a reduction in the settling time, thereby making the system respond more quickly.\n\nPop-up Question: How does the addition of a PD controller influence the system’s overshoot and settling time?\nAnswer: The PD controller’s zero typically reduces overshoot and improves settling time by shifting the root locus to the left, thus increasing the damping ratio $ $.\n\n\nTranslating Performance Specifications into Pole Locations\n\nThe Root Locus Sketch and System Performance\n\nRoot locus analysis translates key performance measures like rise time (\\(t_r\\)), settling time (\\(t_s\\)), peak time (\\(t_p\\)), and maximum overshoot (\\(M_p\\)) into specific closed-loop pole locations in the s-plane.\nThese performance measures are essential in determining how quickly and accurately a system responds to changes or disturbances.\n\n\n\nDesign Objectives\n\nThe core objective in this design process is to determine where the closed-loop poles should be located to meet the desired system performance.\nOnce these optimal pole positions are identified, the corresponding value of the parameter $ K $ can be calculated. This step essentially ‘designs’ the system parameter $ K $.\n\n\n\n\nGoing Back to the example: Considering the Zero at $ s = -5 $\n\nThe system includes a zero at $ s = -5 $, which is both an open-loop and a closed-loop zero.\nThe location of this zero relative to the pole locations significantly impacts the system’s response.\n\n\nImpact of the Zero on System Dynamics\n\nThe zero at $ s = -5 $ introduces a peaking effect in the system response. This effect manifests as an early peak and potentially larger overshoot in the system’s output.\nTo mitigate this peaking effect, the design should aim for a larger damping ratio ($ $). A higher $ $ value usually corresponds to less oscillatory response and reduced overshoot.\n\n\n\nDesign Strategy for Damping Ratio\n\nAdjusting Pole Locations\n\nIf the zero at $ s = -5 $ is close to the closed-loop poles, it significantly influences the system response.\nTo counterbalance the effect of this zero, the design should ‘pull’ the closed-loop poles towards a position that increases $ $.\nIncreasing $ $ means moving the poles further into the left half of the s-plane.\n\n\n\nPractical Design Implications\n\nIn this example, the exact positioning of the closed-loop poles for an optimal response depends on the relative significance of the zero at $ s = -5 $.\nIf the effect of the zero is substantial, poles should be placed further right compared to a scenario where the zero’s influence is less pronounced. This is because the peaking pull of the zero will compensate this action.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#constructing-and-analyzing-root-locus-plots",
    "href": "compensator_design_using_root_locus.html#constructing-and-analyzing-root-locus-plots",
    "title": "Compensator Design",
    "section": "Constructing and Analyzing Root Locus Plots",
    "text": "Constructing and Analyzing Root Locus Plots\nThis chapter explores the construction and analysis of root locus plots in control systems, focusing on how they can be used to assess and design system responses.\nConsider a general control system with a feedback loop. The closed-loop transfer function is represented as:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)H(s)} \\]\nHere, $ G(s) $ is the forward path transfer function, and $ H(s) $ is the feedback path transfer function.\n\n\n\n\n\n\nDefining Loop or Open-Loop Transfer Function\nThe transfer function $ G(s)H(s) $ can be interpreted as the product of the forward path and feedback path transfer functions when the feedback loop is open:\n\\[\n\\frac{B(s)}{R(s)} = G(s)H(s)\n\\]\nThis transfer function is called: open-loop or loop transfer function.\nIt correspond to the following:\n\n\n\n\n\n\nIf we break the loop after the sensor, the signal \\(B\\) is the output of the sensor and the transfer function between the input and the output of the sensor is the loop transfer function: \\(G(s)H(s)\\).\nFor a unity-feedback system, where $ H(s) = 1 $, the open-loop transfer function simplifies to the forward path transfer function $ G(s) $.\n\n\n\nCharacteristic Equation of the System\nThe characteristic equation, crucial for determining the system’s stability, is given by:\n\\[ 1 + G(s)H(s) = 0 \\]\nwhere $ G(s)H(s) $ is the open-loop transfer function.\nWe are interested into the roots of this equation. They are the closed-loop poles and they are going to give us the transient behaviour of the system.\n\n\nFactorizing the Open-Loop Transfer Function\nAn open-loop transfer function can generally be expressed in the form (which turns out more convenient to plot the Root Locus):\n\\[ G(s)H(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\\]\nHere, $ K $ is the gain, $ z_i $ are the zeros, and $ p_j $ are the poles of the transfer function. Obviously, $ z_i, p_j $ are positive if they lie in the LHP, and negative otherwise.\nNote that we are not ruling out that poles can be in the RHP. An open loop system can be unstable, in which case the feedback loop will need to make it stable.\nThe key concept to emphasize here is the distinction between the permissible locations of poles in open-loop and closed-loop systems:\n\nClosed-Loop Poles: For a system to be stable, its closed-loop poles must reside in the left-half of the complex plane. This is a fundamental requirement because poles in the right-half plane would indicate an unstable system response in closed-loop operation.\nOpen-Loop Poles: In contrast, the open-loop system, which is the system without the feedback loop engaged, can have poles in the right-half plane. This does not necessarily imply that the overall system is unstable. The design process often involves taking an open-loop system that may be unstable (or less stable than desired) and applying feedback control to achieve stability in the closed-loop system.\n\nThe distinction is critical in control system design: while we can tolerate and work with right-half plane poles in an open-loop context, ensuring stability in the closed-loop system requires all poles to be in the left-half plane.\n\n\nUnderstanding Root Locus Plots\nWe now call:\n\\[ F(s) = G(s)H(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\\]\nand the characteristic equation becomes:\n\\[\n1 + F(s) = 0\n\\]\n\nConstructing the Root Locus Plot: Scanning the Entire S-Plane\n\nThe root locus method involves scanning the entire s-plane, which comprises all possible values of $ s = + j$, where $ $ is the real part and $ $ is the imaginary part.\nThis scanning process identifies those points in the s-plane where the characteristic equation $ 1 + F(s) = 0 $ is satisfied.\nOnce these points are identified, they are joined to create the root locus plot.\nThis plot represents the trajectory of the system’s poles as a specific parameter (often the gain $ K $) varies from 0 to infinity.\n\n\n\n\nMathematical Conditions for Root Locus\n\nCriterion for Root Locus Points\n\n\n\n\n\n\nA point on the s-plane is a part of the root locus if it satisfies the condition $ 1 + F(s) = 0 $. This can be rephrased as $ F(s) = -1 $.\nMathematically, this translates to two conditions:\n\nMagnitude Condition: $ |F(s)| = 1 $\nAngle Condition: The angle of $ F(s) $ must be an odd multiple of 180 degrees. Formally, $ F(s) = (2q + 1) ^$, where $ q =0,1,2,…$\n\n\n\n\nCriterion for Root Locus\nSince we have taken:\n\\[ F(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\\]\nA point in the s-plane is part of the root locus if it satisfies both the magnitude and angle conditions:\n\nMagnitude Condition:\n\n\\[ \\frac{K \\prod_{i=1}^{m} |s + z_i| }{ \\prod_{j=1}^{n} |s + p_j| } = 1 \\]\n\nAngle Condition:\n\n\\[ \\sum_{i=1}^{m} \\angle (s + z_i) - \\sum_{j=1}^{n} \\angle (s + p_j) = \\pm (2q + 1)180^\\circ \\]\nwhere $ q $ is an integer.\nAny point that satisfy these two conditions is a point in the Root Locus plot.\n\n\n\nExploring Magnitude and Angle Conditions in Root Locus\nThis part discusses how to determine the points on the s-plane that satisfy the magnitude and angle conditions of a given transfer function. We’ll use a simplified and graphical approach to make it easier to grasp.\n\nTransfer Function\nConsider the transfer function:\n\\[\nF(s) = \\frac{K}{s(s+1)(s+2)}\n\\]\nHere, $ F(s) $ is a function of the complex variable $ s $, and $ K $ is a gain factor.\n\n\nMagnitude Condition\nThe magnitude condition for the root locus can be expressed as:\n\\[\n\\frac{K}{|s||s+1||s+2|} = 1\n\\]\nWhat this means is that for any point $ {s} = {} + j{} $ on the s-plane, if we multiply the distances from $ {s} $ to each of the poles (at $ s=0 $, $ s=-1 $, and $ s=-2 $) and adjust $ K $ such that this product equals 1, the point satisfies the magnitude condition.\n\n\n\n\n\n\n\nVisualizing the Magnitude Condition\n\nTo visualize this on a graph, imagine drawing lines from your point $ {s} $ to each of the poles.\nThe length of each line represents the magnitude (distance) to each pole.\nGraphically, if you can adjust $ K $ such that the product of these lengths equals 1, then $ {s} $ satisfies the magnitude condition.\n\n\n\n\n\n\n\n\nAngle Condition\nThe angle condition is given by:\n\\[\n-\\angle{s}-\\angle{s+1}-\\angle{s+2} = \\pm(2q+1)180^o\n\\]\nThis implies that the sum of the angles made by lines from $ {s} $ to each pole, with respect to the positive real axis, should sum up to an odd multiple of 180 degrees.\n\n\n\n\n\n\n\nGraphical Interpretation of the Angle Condition\n\nTo calculate these angles, imagine drawing lines from your point $ {s} $ to each pole.\nThe angle each line makes with the positive real axis is what we need.\nThese angles can be calculated using trigonometry (specifically, tangent inverse).\nIf the sum of these angles (considering their signs) equals an odd multiple of 180 degrees, then $ {s} $ satisfies the angle condition.\n\n\n\n\nPutting It All Together\nBy combining these two conditions, we can determine points on the s-plane that belong to the root locus of the system. These points help us understand how the system will behave for different values of $ K $, especially in terms of stability and response time.\nIn upcoming sections, we’ll apply these principles to specific examples, reinforcing the concepts and demonstrating their practical application in control system design.\n\n\nTitle: Understanding Root Locus: Magnitude and Angle Conditions\n\nExplaining the Magnitude Condition\nLet’s delve into the root locus method and understand how it helps us in control system analysis. The root locus method involves analyzing how the poles of the system’s transfer function move in the s-plane as we vary a parameter, typically the gain $ K $.\nConsider the general form of a transfer function:\n\\[\nF(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\n\\]\nwhere $ z_i $ are the zeros and $ p_j $ are the poles of the function.\nThe Magnitude Condition: - For any point $ s $ on the s-plane, we can find a particular value of $ K $ that satisfies the magnitude condition. Specifically, $ K $ needs to be the inverse of the magnitude that the transfer function $ F(s) $ takes at that point. - However, satisfying the magnitude condition alone doesn’t guarantee that the point $ s $ is on the root locus of the system.\n\n\nThe Angle Condition: Key to Root Locus\nWhy Not Every Point Satisfies the Root Locus Criteria: - The root locus plot is not just about satisfying the magnitude condition. It also crucially depends on the angle condition. - Not every point in the s-plane satisfies the angle condition, which is why we cannot assume that every point is part of the root locus.\nCalculating the Root Locus: - To construct the root locus plot, we focus primarily on the angle condition. We scan the entire s-plane, identifying points where the angle condition is met. - Once we find these points, we can be assured that the magnitude condition will also be satisfied for some value of $ K $, thus confirming their place on the root locus. - This scanning leads to a plot because $ K $ varies from 0 to infinity, allowing us to trace the path of the poles across the s-plane as $ K $ changes.\n\n\nConclusion\nThe root locus is constructed by considering both magnitude and angle conditions, and the angle condition is particularly important.\nWith reference to the plot below\n\n\n\n\n\n\nAll the points on the red lines satisfy the angle criteria. Any other point does not satisfy it.\n\n\n\n\nExercise on Root Locus Analysis\n\nQuestion:\nGiven a transfer function $ G(s) = $, determine the radius and center of the root locus plot.\n\n\nAnswer:\nAs an exercise, you can prove that the root locus plot in this case will have a center at \\(( -b, 0 )\\) and a radius determined by $ $.\n\nWe will now delve deeper into the root locus plot method. We’ll focus on sketching the root locus and leave its interpretation for later.\n\n\n\nUnderstanding the Root Locus Equation\nLet’s revisit the root locus equation:\n\\[1 + F(s) = 0\\]\nWhere $ F(s) $ can be represented as:\n\\[\nF(s) = K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)}\n\\]\nHere, $ K $ is the root locus gain, $ z_i $ are the zeros, and $ p_j $ are the poles.\n\nExample: The Plant Model\nConsider a plant with a transfer function defined as:\n\\[\nG(s) = \\frac{1}{(s+1)(s+2)}\n\\]\nIn this context, $ G(s) $ models the behavior of our system. Let’s explore what happens when we incorporate an amplifier into this system. The amplifier is characterized by a gain, denoted as $ K $.\nWhen this amplifier with gain $ K $ is introduced, the system becomes a closed-loop system. The characteristic equation of this closed-loop system is then represented as follows:\n\\[\n1 + \\frac{K}{(s+1)(s+2)} = 0\n\\]\nIn this equation, $ F(s) $ is defined by the expression:\n\\[\nF(s) = \\frac{K}{(s+1)(s+2)}\n\\]\nHere, $ F(s) $ captures the combined effect of the plant and the amplifier. The term “root locus gain” in this context refers to the amplifier gain $ K $.\nLet’s delve into the concept of open-loop poles. The open-loop poles of a system are the values of $ s $ where the open-loop transfer function, in this case $ F(s) $, goes to infinity. For our function $ F(s) $, these poles are located at the values where the denominator equals zero. Therefore, for $ F(s) $, the open-loop poles are:\n\n$ s_1 = -1 $\n$ s_2 = -2 $\n\nIt’s important to note that in this example, $ F(s) $ aligns perfectly with the general form we discussed earlier for root locus plots. This alignment allows us to apply the root locus technique effectively to analyze how changes in the amplifier gain $ K $ affect the system’s behavior, particularly its stability.\n\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the transfer function G(s)\nnumerator = [1]  # Coefficients of the numerator\ndenominator = [1, 3, 2]  # Coefficients of the denominator (s^2 + 3s + 2)\nG_s = ctl.TransferFunction(numerator, denominator)\n\n# Get poles from the transfer function\npoles = ctl.pole(G_s)\n\n# Plotting\nplt.figure()\nplt.scatter(poles.real, poles.imag, marker='x', color='r')  # Plot poles as red 'x'\nplt.axhline(y=0, color='k', linestyle='-')  # x-axis\nplt.axvline(x=0, color='k', linestyle='-')  # y-axis\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Pole-Zero Plot on the s-plane')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nExample: Tachometric Feedback\nConsider a control system with a specific plant. This plant is characterized by its transfer function:\n\\[\n\\frac{25}{(s+1)(s+2)}\n\\]\n\n\n\n\n\nIn this system, we also have a feedback loop. This loop is characterized by a parameter $ s $, and this type of feedback is known as tachometric feedback. Tachometric feedback is commonly used in position control systems to improve performance and stability.\nIn addition to the tachometric feedback, the system includes a main feedback loop, known as unity feedback. The complete configuration of this system can be visualized through the diagram provided (please refer to the image linked in the original text for a visual representation).\nWhen we analyze this system, we pay special attention to the minor feedback loop that includes the tachometric feedback. By simplifying this part of the system, we can represent its dynamics with the following expression:\n\\[\n\\frac{25}{s^2 + 3s + 2 + 25\\alpha s}\n\\]\nThis expression is a result of combining the plant’s transfer function with the tachometric feedback parameter $ $.\nTo understand the stability and behavior of the closed-loop system, we look at its characteristic equation:\n\\[\ns^2 + 3s + 2 + 25\\alpha s + 25 = 0\n\\]\nIn this equation, the variable $ $, representing the tachometric constant, is key. Changing $ $ will affect the system’s stability and how it responds to inputs.\nFor root locus analysis, which is a method used to study system stability, we need to rewrite this characteristic equation in a standard form. This standard form is $ 1 + F(s) = 0 $. Here, $ F(s) $ represents a ratio of polynomials derived from the system’s dynamics, including the transfer function and the feedback parameter $ $. For our system, the reformulation looks like this:\n\\[\n1 + \\frac{25\\alpha s}{s^2 + 3s + 27} = 0\n\\]\nIt’s important to understand that $ F(s) $ is generally represented as:\n\\[\nF(s) = K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)}\n\\]\nIn our specific case, we can express $ F(s) $ as:\n\\[\nF(s) = 1+\\frac{K(s+z_1)}{(s+p_1)(s+p_2)}\n\\]\nHere, $ z_1 = 0 $ (indicating a zero at the origin), and the poles $ p_1 $ and $ p_2 $ are the roots of the denominator $ s^2 + 3s + 27 $. It’s crucial to note that the poles and zeros of $ F(s) $ may differ from those of the open-loop system.\nIn this reformulated equation, the root locus gain, denoted as $ K $, is equivalent to $ 25$. This formulation aligns with the standard root locus form and is essential for applying the root locus method in our analysis.\n\n\nComments on the Root Locus Gain\nWhen studying a control system using the root locus method, a key aspect to consider is the parameter you wish to analyze. The important thing to remember is that your system’s characteristic equation needs to be reformulated. In this reformulated equation, the parameter of interest should be introduced as a multiplier. This specific parameter, which we introduce as a multiplier, is known as the ‘root locus gain’.\nAs we move forward with examples and design applications, keep in mind an important distinction regarding poles and zeros. When we talk about poles and zeros in the context of the root locus method, it’s essential to understand that they may not always correspond to the poles and zeros of the system’s open-loop transfer function. Although in many practical situations, they do align, there are cases where they differ.\nThese differences arise because we sometimes need to manipulate the poles and zeros to reformat the original characteristic equation into a specific format suitable for root locus analysis. This manipulation is done to bring the parameter of interest (our root locus gain) into the equation in a way that allows us to apply the root locus method effectively.\nFor instance, when we explored design examples involving the tachometric constant, we saw how this principle applied. The tachometric constant was part of the root locus gain, and we observed how it influenced the system’s behavior through the root locus plot.\nThe key takeaway here is that while the poles and zeros in the root locus method are crucial for analysis, they should be understood in the context of how the characteristic equation is reformulated for this specific method of analysis.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#guidelines-for-sketching-root-locus",
    "href": "compensator_design_using_root_locus.html#guidelines-for-sketching-root-locus",
    "title": "Compensator Design",
    "section": "Guidelines for Sketching Root Locus",
    "text": "Guidelines for Sketching Root Locus\n\nIntroduction\nOur primary equation is:\n\\[\n1 + F(s) = 0\n\\]\nor in expanded form:\n\\[\n1+ K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)} = 0\n\\]\nwhere:\n\n\\(K\\) is the root locus gain (not necessarily the system gain).\nThe focus is on \\(K \\ge 0\\) due to its common occurrence in control systems.\nRealizability requires that \\(m \\le n\\). This ensures that the system described by \\(F(s)\\) is physically realizable.\n\n\nMagnitude Criterion:\n\nThe magnitude condition is given by:\n\n\\[\nK \\frac{\\prod_{i=1}^{m} \\left|s + z_i\\right|}{\\prod_{j=1}^{n} \\left|s + p_j\\right|} = 1\n\\]\nAngle Criterion:\n\nThe angle condition is:\n\n\\[\n\\sum_{i=1}^{m} \\angle(s + z_i) - \\sum_{j=1}^{n} \\angle(s + p_j) = \\pm (2q + 1)180^\\circ, \\quad q = 0, 1, 2, \\ldots\n\\]\n\n\n\nScanning the s-plane\n\nIdentifying Points Satisfying the Angle Condition:\nScan the entire s-plane to locate points satisfying the angle condition.\nConstructing the Root Locus:\nConnect these points to form the root locus branches. The points that satisfy the angle condition, when joined together, form the root locus branches.\nUse the Magnitude Calculation:\nFor each point on these branches, there exists a value of \\(K\\) such that both the magnitude and angle conditions are satisfied.\n\nPop-up Question: Why is it important to consider both magnitude and angle conditions in root locus analysis?\nAnswer: Both conditions must be satisfied to ensure that the points on the root locus represent valid system responses as $ K $ varies. The magnitude condition ensures the correct amplification, while the angle condition ensures phase stability.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#guidelines-for-sketching-root-locus-1",
    "href": "compensator_design_using_root_locus.html#guidelines-for-sketching-root-locus-1",
    "title": "Compensator Design",
    "section": "Guidelines for Sketching Root Locus",
    "text": "Guidelines for Sketching Root Locus\nIn this section, we’ll explore the root locus method. While your textbooks offers detailed proofs, our focus here will be more on practical application.\nHere’s how we’ll proceed:\n\nUnderstanding the Rules: This part presents the rules for constructing a root locus plot. We won’t delve into the mathematical proofs, but rather apply these rules through examples, particularly focusing on satisfying the angle condition.\nScanning the s-plane: The method involves scanning the entire s-plane to find points that satisfy the angle condition. Imagine the s-plane filled with points, each representing a potential part of the root locus.\nThe Brute Force Method: This method is straightforward but labor-intensive. For each point on the s-plane (let’s call it $ s_0 $), we measure the angles formed by drawing vectors from all the open-loop poles and zeros of the function $ F(s) $ to $ s_0 $. By adding up these angles, we determine if the total is an odd multiple of -180 degrees, which indicates that $ s_0 $ is a point on the root locus.\n\n\n\n\n\n\n\n\n\n\n\n\nComputer-Aided Graphing: While the brute force method is effective, it’s also time-consuming. Fortunately, computer-aided design tools can automate this process, quickly generating a root locus plot. These tools can handle the complex calculations and graphical representations, making the design process much more efficient.\nUsing Guidelines: There are certain guidelines that can help us quickly identify potential points on the s-plane for the angle criterion. These guidelines won’t give you the complete root locus plot instantly but will guide you close to the actual points. This approach, combined with rough sketches, can be very informative for initial design considerations.\nThe Role of Computers in Design: Modern software has greatly simplified these processes. By inputting different values of system parameters like $ $ or $ K $, the software can instantly provide a root locus plot. This visualization aids significantly in making informed design decisions.\n\nWhile understanding the theory behind root locus plots is important, today’s computer tools greatly assist in the practical aspects of design. Our goal is to blend theoretical knowledge with practical skills to efficiently design control systems.\nShould you encounter any challenges with the calculations, remember that they can be extensive and are not expected to be done manually, especially in an examination setting. We have access to computers that can perform these complex calculations for us. Our goal here is to grasp the qualitative aspects of design methods in control engineering.\nHere’s the key point: this notebook provide the basic guidelines to create a rough sketch of the root locus. This sketch, even though approximate, is very useful. It helps you make fundamental decisions about the control system design without delving into complex calculations. For instance, based on this rough sketch, you can decide whether to use a Proportional-Integral (PI) controller, a Proportional-Derivative (PD) controller, or a Proportional-Integral-Derivative (PID) controller, among other options. This initial decision-making, guided by a basic understanding of the root locus plot, can be done even before you use a computer for detailed analysis.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#how-to-sketch-the-root-locus-drawing-rules",
    "href": "compensator_design_using_root_locus.html#how-to-sketch-the-root-locus-drawing-rules",
    "title": "Compensator Design",
    "section": "How to sketch the Root Locus: Drawing Rules",
    "text": "How to sketch the Root Locus: Drawing Rules\n\nRule 1: Symmetry Rule\nThe root locus plot must be symmetrical with respect to the real axis. This symmetry is due to the fact that in any real system, complex roots occur in conjugate pairs, resulting in real coefficients for the characteristic equation.\nIf you accurately construct one half of the root locus (above the real axis), the other half (below the real axis) is its mirror image. This symmetry simplifies the plotting process.\n\n\nRule 2: Root Locus Branches\nThe root locus branches start at the open-loop poles of the function $ F(s) $ (where $ K = 0 $) and end at the open-loop zeros of $ F(s) $ or at infinity (where \\(K = \\infty\\)).\nThe number of root locus branches equals \\(n\\), the number of open-loop poles of $ F(s) $. Terminal points of these branches are either the zeros of $ F(s) $ or points at infinity.\nThis means that \\(m\\) branches end at the zeros of \\(F(s)\\), and \\((n-m)\\) terminate at infinity.\n\n\nRule 3: Real Axis Segments\nTo determine if a segment on the real axis is part of the root locus, count the number of poles and zeros to the right of any point on that segment. If the count is odd, the segment is part of the root locus.\nThis rule helps quickly identify segments of the real axis that belong to the root locus. For example, if there’s one pole to the right of a point and no zeros, the segment to the left of this point is part of the root locus.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStarting Points: In this example, we begin with three points where $ K = 0 $. These points are the starting points of our root locus branches. Remember, the root locus starts at the open-loop poles of the system, which are represented by these points.\nTerminal Points: For each branch, there’s a terminal point where $ K $ approaches infinity. In our sketch, there are three such terminal points corresponding to each branch.\nUnderstanding Branches: One of the branches in this plot extends from a starting point (where $ K = 0 $) to a terminal point (where $ K = $). This shows a complete root locus branch. However, it’s important to note that this segment of the plot represents just one branch of the entire root locus.\nSegment on the Root Locus: While the left most segment of this root locus is part of the root locus plot, it doesn’t necessarily constitute a single, independent branch. The root locus plot is a combination of all such segments, and each segment is defined by where it starts and ends in terms of the gain $ K $.\nCompleteness of the Branch: The completion of this branch from $ K = 0 $ to $ K = $ suggests that it’s a full representation of how one of the system’s poles moves in the complex plane as $ K $ varies. However, to fully validate this branch, we would apply additional rules of the root locus method, which will be discussed later.\n\nWe will see how complete the diagram as we go through the rest of the rules.\n\n\nRule 4: Asymptote Directions\n\nUnderstanding Asymptote Directions\nFor a system with $ n $ poles and $ m $ zeros, $ n - m $ branches of the root locus go to infinity. The directions in which these branches approach infinity are determined by a specific formula.\n\n\nThe Formula\nThe formula for the direction of asymptotes is given by:\n\\[\n\\Phi_A = (2q + 1) \\times \\frac{180^\\circ}{n - m}\n\\]\nwhere $ q = 0, 1, 2, …, n - m - 1 $.\nThis formula provides the angles at which the root locus branches approach infinity. It helps in sketching the asymptotic behavior of the root locus plot.\n\n\n\nRule 5: Centroid of Asymptotes\nThe centroid of asymptotes is a crucial point on the real axis from which the asymptotes’ directions are measured. It’s calculated as:\n\\[\n\\sigma_A = \\frac{\\sum \\text{real parts of poles} - \\sum \\text{real parts of zeros}}{n - m}\n\\]\nThis is the point on the real axis where all asymptotes come together.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#applying-the-rules-an-example",
    "href": "compensator_design_using_root_locus.html#applying-the-rules-an-example",
    "title": "Compensator Design",
    "section": "Applying the Rules: An Example",
    "text": "Applying the Rules: An Example\nLet’s apply these rules to the transfer function\n\\[ F(s) = \\frac{K}{s(s+1)(s+2)} \\]\nHere, $ n = 3 $ and $ m = 0 $.\nNo finite zeros, so all branches will go to infinity.\n\nAsymptote Angles and Centroid\n\nCalculating Asymptote Angles:\nApplying the formula for $ n - m = 3$ directions:\n\\[\n\\Phi_A = (2q + 1) \\times \\frac{180^\\circ}{n - m}\n\\]\nwhere $ q = 0, 1, 2$.\nWe find angles at \\(\\Phi_A=\\) 60°, 180°, and 240°.\nDetermining the Centroid:\nThe centroid $ _A $ is calculated as:\n\\[\n\\sigma_A = \\frac{\\sum \\text{real parts of poles} - \\sum \\text{real parts of zeros}}{n - m} = \\frac{0-1-2}{3} = -1\n\\]\n\nUsing the information we have for now, we can start sketching the root locus:\n\n\n\n\n\n\n\n\n\nRule 6: Breakaway point\n\nConcept of Breakaway Points\nBreakaway points on the root locus are critical locations where multiple root branches converge or diverge on the real axis.\n\n\nDefining the Breakaway Point\nAt a breakaway point on the real axis, the value of the control gain \\(K\\) is at its maximum relative to that segment (see for example, the plot above). As \\(K\\) increases beyond this point, the roots become complex conjugates.\n\n\nCalculating Breakaway Points\nUsing this intruitive understanding of a breakaway point that maximises the value of \\(K\\), to find a breakaway point, we use the condition:\n\\[\n\\frac{dK}{ds} = 0\n\\]\nThis condition represents the extremization of $ K $ with respect to $ s $.\nThis process involves differentiating $ K $ as a function of $ s $, obtained from the characteristic equation of the system. We then solve for $ s $ where this derivative equals zero.\nWe use the expression of \\(K\\) from the equation:\n\\[\n1+ K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)} = 0\n\\]\n\n\nApplying the Concept\nConsider again our example:\n\\[ 1+F(s) = 1+\\frac{K}{s(s+1)(s+2)} = 0\\]\nWe’ll derive $ K $ as a function of $ s $ and find its derivative:\n\\[\nK = -\\Big(s^3+3s^2+2s\\Big)\n\\]\nand\n\\[\n\\frac{dK}{ds} = -\\Big( 3s^2 + 6s + 2 \\Big)=0\n\\]\nSolving the quadratic equation from \\(\\frac{dK}{ds} = 0\\) gives potential breakaway points.\n\\[\ns_1 = -0.423,\\;\\;\\; s_2 = -1.577\n\\]\nHowever, not all solutions are valid; they must satisfy the angle criterion to be considered actual breakaway points.\nThis is shown in the diagram below:\n\n\n\n\n\n\n\n\n\n\nMore complex conditions\nConsider the function\n\\[ 1+ F(s) = 1 + \\frac{K}{s(s+4)(s^2 + 4s + 20)} \\]\nThe root locus starts at the poles $ s = 0, -4 $ and the complex conjugate poles are \\(s = -2\\pm j4\\).\n\nFinding Breakaway Points\n\nIdentifying Candidates: Solve $ = 0 $ for the given $ F(s) $ to identify potential breakaway points.\nValidating Candidates: Check each candidate against the angle criterion to confirm if it’s a valid breakaway point.\n\n\n\n\n\n\n\n\nThis example shows that breakaway points are not always on the real axis. Complex breakaway points occur, especially in systems with complex poles or zeros.\nOften, breakaway points exhibit symmetry, especially in systems with symmetric pole-zero configurations.\nAnother, simpler, example with breakaway points is:\n\\[\n1 + F(s) = 1 + \\frac{Ks}{s^2 + 2s + 2}\n\\]\n\n\n\n\n\n\n\nAgain, the breakaway point satisfies \\(\\frac{dK}{ds} = 0\\) and the angle condition.\nNote: breakway points are called breakin points when the roots are coming together.\n\n\n\nRoots Breakaway Angles\nWhen analyzing root locus plots, an important concept is the angle at which roots break away from the real axis. This angle, denoted as $ $, is determined by the formula:\n\\[\n\\phi = \\frac{180^\\circ}{r}\n\\]\nHere, $ r $ represents the number of branches meeting at the breakaway point. For instance, if two branches meet, the breakaway angle is $ 90^$.\n\n\nExample Analysis:\nConsider the transfer function given by:\n\\[\n1 + F(s) = 1 + \\frac{K}{s (s + 4) (s^2 + 4s + 8)}\n\\]\nTo find the breakaway points, we solve the equation derived from setting the derivative of $ K $ with respect to $ s $ to zero, i.e., $ = 0 $. Among the solutions, only those that satisfy the angle condition are considered valid breakaway points.\nIn our case, we find:\n\\[\n\\phi = \\frac{180^\\circ}{4} = 45^\\circ\n\\]\nThis implies that, for this particular transfer function, the roots break away at an angle of $ 45^$.\n\n\nRoot Locus Plot\nThe following script can be used to visualize the root locus plot for this transfer function, illustrating the breakaway points and their corresponding angles.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\ns = ctl.tf('s')\n\nG_modified = 1 / (s * (s + 4) * (s**2 + 4*s + 8))\n\n# Plot root locus for the modified transfer function\nplt.figure()\nctl.root_locus(G_modified, plot=True)\nplt.title(\"Root Locus of Modified Transfer Function\")\n\nplt.show()\n\n\n# Go deeper and see what happens when you \n# modify the transfer function to change the root locus once more.\n\n# Original transfer function\n# s = ctl.tf('s')\n# G_original = 1 / (s * (s + 4) * (s**2 + 4*s + 20))\n\n# # Plot root locus for the original transfer function\n# plt.figure()\n# ctl.root_locus(G_original, Plot=True)\n# plt.title(\"Root Locus of Original Transfer Function\")\n\n# Let's change the quadratic term to s^2 + 6s + 25\n# G_modified = 1 / (s * (s + 4) * (s**2 + 6*s + 25))",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#questions",
    "href": "compensator_design_using_root_locus.html#questions",
    "title": "Compensator Design",
    "section": "Questions",
    "text": "Questions\nPop-up Question: Why is the root locus plot symmetrical about the real axis?\nAnswer: The symmetry is due to the complex conjugate nature of roots in real systems. For every complex pole or zero, there is a conjugate counterpart, resulting in symmetric plots.\nPop-up Question: How does the number of poles and zeros affect the number of branches in the root locus plot?\nAnswer: The number of branches in the root locus plot is equal to the number of open-loop poles of the system. The branches start at these poles and move towards the zeros or towards infinity.\nPop-up Question: Why do we need to know the asymptote directions in root locus analysis?\nAnswer: Knowing the asymptote directions helps predict how the root locus branches behave as they move towards infinity, which is crucial for understanding system stability and design.\nPop-up Question: How does the centroid location affect the root locus plot?\nAnswer: The centroid is the starting point for the asymptotes on the real axis. Its position influences how the root locus branches diverge towards infinity, impacting the overall shape of the plot.\nPop-up Question: How do breakaway points affect the stability of a control system?\nAnswer: Breakaway points indicate where roots of the system (poles of the closed-loop transfer function) transition from real to complex or vice versa, affecting the system’s stability and oscillatory behavior.\nPop-up Question: Can breakaway points occur off the real axis?\nAnswer: Yes, especially in systems with complex poles or zeros, breakaway points can occur off the real axis, indicating a transition in the root trajectory.\nPop-up Question: Why is the maximum value of $ K $ significant at breakaway points?\nAnswer: The maximum value of $ K $ at a breakaway point signifies the transition from real to complex conjugate roots (or vice versa), marking a critical change in system dynamics.\nPop-up Question: How do we determine which solutions for breakaway points are valid?\nAnswer: After calculating potential breakaway points, we must check each one against the angle criterion. Only those satisfying this criterion are valid breakaway points.\n\nSummary\nHere’s a summary of the root locus rules covered so far:\n\nSymmetry Rule: The root locus plot is always symmetrical about the real axis. This symmetry arises because complex poles or zeros in polynomial equations with real coefficients occur in conjugate pairs.\nRoot Locus Branches - Starting and Ending Points:\n\nRoot locus branches start at the open-loop poles (where the gain $ K = 0 $).\nThey end at the open-loop zeros or go to infinity if there are fewer zeros than poles.\n\nReal Axis Segmentss: A segment on the real axis is a part of the root locus if the total number of poles and zeros to the right of any point on that segment is odd.\nAsymptote Directions: When the number of poles is greater than the number of zeros, root locus branches go to infinity along asymptotes. The directions of these asymptotes are given by $ = (2q + 1) $, where $ q $ varies from 0 to $ n - m - 1 $.\nCentroid of Asymptotes: The point on the real axis from which asymptotes emanate (the centroid) is calculated using the formula: $ _A = $.\nBreakaway and Break-in Points: These points on the root locus are where branches diverge from or converge to the real axis. They can be found by solving $ = 0 $ for $ s $ and selecting the points that satisfy the angle criterion.\n\nBreakaway Angles: The angle at which branches break away from or converge to the real axis is $ = $, where $ r $ is the number of branches meeting at the point.\n\n\n\n\nRule 7: The Angle of Departure and Arrival\nThe angle of departure from a complex pole and the angle of arrival at a complex zero are important to understand how the root locus branches behave near these points.\n\nAngle of Departure from a Complex Pole\nRule for Angle of Departure: The angle at which a root locus departs from a complex pole is determined by the sum of angle contributions from all other poles and zeros to this pole, minus 180 degrees multiplied by (2q + 1), where q is an integer.\nExample Explanation: Consider a system with two poles and one zero. The root locus sketch shows the trajectory of the system poles as the gain \\(K\\) varies. As \\(K\\) increases from 0, the poles move along the root locus path, eventually breaking away from the real axis. The direction in which they break away (the angle of departure) is essential for understanding system behavior.\n\n\n\n\n\n\n\nSteps for Angle of Departure: 1. Identify the complex pole of interest. 2. Calculate the angle contribution, \\(\\theta_1\\), due to the zero and \\(\\theta_2\\) due to the other pole. 3. The net angle contribution at this pole is \\(\\theta_1 - \\theta_2\\) (zero contribution is positive, and of poles is negative). 4. The angle of departure \\(\\phi_p\\) is given by the formula: \\(\\phi_p = \\pm 180^\\circ \\times (2q + 1) + \\phi\\), where \\(\\phi_p\\) is the net angle contribution.\nFor example, in the case below, look at the departure angle due to the contribution of all zeros and poles:\n\n\n\n\n\n\n\n\n\nAngle of Arrival at a Complex Zero\nRule for Angle of Arrival: The angle at which a root locus arrives at a complex zero is determined similarly, considering the sum of angle contributions from all other poles and zeros to this zero.\nSteps for Angle of Arrival: 1. Identify the complex zero of interest. 2. Calculate the total angle contribution, \\(\\phi_z\\), from all poles and zeros to this zero. 3. The angle of arrival is given by \\(\\phi_z = \\pm 180^\\circ \\times (2q + 1) - \\phi\\).\nFor example:\n\n\n\n\n\n\n\nAnd the angle of approach to the zero is \\(\\phi_z = 180^\\circ - (\\theta_2 - 2\\theta_1)\\)\n\n\n\nRule 8: Routh-Hurwitz Criterion and Imaginary Axis Intersection\nLet’s consider once again:\n\\[ 1+F(s) = 1+\\frac{K}{s(s+1)(s+2)} = 0\\]\nWe determined the following root locus plot:\n\n\n\n\n\n\n\nThe last rule we will discuss involves using the Routh-Hurwitz criterion to determine the point at which the root locus intersects the imaginary axis.\nSteps to Use Routh-Hurwitz Criterion: 1. Form the characteristic equation of the system. 2. Construct the Routh array. 3. Identify the condition for which a row of the Routh array becomes zero. 4. Use this condition to find the value of \\(K\\) at which the root locus intersects the imaginary axis.\nExample:\nConsider a system with the characteristic equation \\[ G(s) = \\frac{K}{s(s+1)(s+2)} \\]\nThe characteristic equation is:\n\\[s^3 +3s^2 +2s+K=0\\]\nTo construct the Routh array for the equation $ s^3 + 3s^2 + 2s + K = 0 $, we need to organize the coefficients of the polynomial in a tabular format. The Routh array helps us determine the number of roots with positive real parts, which makes it possible to understand the stability of the system.\nHere’s how to construct the Routh array for the given polynomial:\n\nArrange the Coefficients: Start by writing down the coefficients of the polynomial in descending powers of $ s $.\nFirst Two Rows: Place the coefficients of even powers of $ s $ in the first row and those of odd powers of $ s $ in the second row.\nSubsequent Rows: Compute each element of the lower rows using the formula: \\[\nR_{i,j} = -\\frac{1}{R_{i-1,1}} \\left( R_{i-1,1}R_{i-2,j+1} - R_{i-2,1}R_{i-1,j+1} \\right)\n\\] where $ R_{i,j} $ is the element in the $ i $-th row and $ j $-th column.\nCompleting the Array: Continue this process until you have filled the array. If any row starts with zero, special techniques like polynomial division or using a small positive number (ε) are used to proceed.\n\nFor the given polynomial $ s^3 + 3s^2 + 2s + K = 0 $, the Routh array will be:\n\n\n\n$ s^3 $\n\\(1\\)\n\\(2\\)\n\n\n$ s^2 $\n\\(3\\)\n\\(K\\)\n\n\n$ s^1 $\n$ $\n\\(0\\)\n\n\n$ s^0 $\n\\(K\\)\n\n\n\n\n\nThe first column of the Routh array indicates the number of roots with positive real parts. If there’s a sign change in this column, it indicates a root with a positive real part, implying instability in the system.\nThe stability of the system depends on the value of $ K $. For the system to be stable, all elements in the first column must be positive. Therefore, the conditions for stability can be derived by ensuring positive values in this column.\n\n\n\nDetermining Stability Conditions\nFrom the third row, we have $ $. For stability, this term must be positive, leading to the condition:\n\\[ K &lt; 6 \\]\nAnd from the last row, since it’s just $ K $, for stability, we must also have:\n\\[ K &gt; 0 \\]\nTherefore, the system is stable for:\n\\[ 0 &lt; K &lt; 6 \\]\nWhen the gain factor $ K $ is set to 6, we encounter a special situation in the Routh array. Specifically, the row corresponding to $ s^1 $ becomes all zeros. This occurrence is significant because it indicates a certain condition in control systems analysis.\n\n\nUnderstanding the Auxiliary Polynomial\nThe concept of an auxiliary polynomial comes into play here. It is derived from the row just above the all-zero row in the Routh array. In our case, since the $ s^1 $ row is all zeros, we look at the $ s^2 $ row.\nFrom the $ s^2 $ row, the auxiliary polynomial is formed as follows:\n\\[ 3s^2 + K \\]\nSetting $ K = 6 $, as per our special case, the polynomial becomes:\n\\[ 3s^2 + 6 = 0 \\]\n\n\nFinding the Roots\nThe roots of this auxiliary polynomial are also the roots of the original characteristic equation at $ K = 6 $. Let’s solve this equation:\nStarting with:\n\\[ 3s^2 + 6 = 0 \\]\nWe simplify it to:\n\\[ s^2 + 2 = 0 \\]\nTo find the roots $ s_{1,2} $, we solve for $ s $:\n\\[ s_{1,2} = \\pm j\\sqrt{2} \\]\nThese are complex roots, where $ j $ represents the imaginary unit.\n\n\nVisualizing on the Root Locus Diagram\nWith these roots, we can now update our root locus diagram. These points, $ j $, represent the intersections of the root locus with the imaginary axis. Adding these intersections allows us to complete the rough sketch of the root locus diagram.\n\n\n\n\n\n\n\nDiagram showing the root locus plot with the intersections at $ j $.\nThis step is important in control system design as it helps us visualize how the system poles move in the complex plane, especially as the gain $ K $ changes. The intersection points with the imaginary axis provide valuable insights into system stability at specific gain values.",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#example-1",
    "href": "compensator_design_using_root_locus.html#example-1",
    "title": "Compensator Design",
    "section": "Example 1",
    "text": "Example 1\nIn this part, we focus on a comprehensive example to understand the application of the root locus method.\nConsider a unity-feedback system with an open-loop transfer function given by:\n\\[ G(s) =  K \\cdot \\frac{1}{s(s+3)(s^2+2s+2)} \\]\nOur objective is to apply the root locus rules to this transfer function and analyze the resulting root locus plot.\n\nStep 1: Identifying Open-Loop Poles and Zeros\nFirst, we need to identify the open-loop poles and zeros of the system. For our given transfer function, the poles are at:\n\n$ s = 0 $\n$ s = -3 $\nThe roots of $ s^2 + 2s + 2 $, which are complex: $ s = -1 j $\n\n\n\nStep 2: Sketching the Pole-Zero Diagram\nNext, we plot these poles and zeros on the complex $ s $-plane. This helps us visualize the starting points of our root locus.\n\n\n\n\n\n\n\nWe can obtain the diagram above in python:\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_pole_zero_diagram(poles, zeros):\n    \"\"\"\n    Plots the pole-zero diagram.\n    \n    Parameters:\n    poles (list): List of complex numbers representing poles.\n    zeros (list): List of complex numbers representing zeros.\n    \"\"\"\n\n    # Setting up the plot\n    plt.figure(figsize=(8, 6))\n    plt.axhline(y=0, color='k')  # Horizontal axis\n    plt.axvline(x=0, color='k')  # Vertical axis\n    plt.grid(True, which='both')\n\n    # Plot poles as 'x' and zeros as 'o'\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'rx', markersize=10)  # Poles\n    for zero in zeros:\n        plt.plot(np.real(zero), np.imag(zero), 'bo', markersize=10)  # Zeros\n\n    plt.title('Pole-Zero Diagram')\n    plt.xlabel('Real')\n    plt.ylabel('Imaginary')\n    plt.show()\n\n# Define poles and zeros for the example transfer function\npoles = [0, -3, complex(-1, 1), complex(-1, -1)]  # s=0, s=-3, s=-1±j\nzeros = []  # No zeros in this example\n\n# Call the function to plot the diagram\nplot_pole_zero_diagram(poles, zeros)\n\n\n\n\n\n\n\n\n\n\nStep 3: Determining the Root Locus Branches\nSince there are four poles and no zeros, we expect four root locus branches starting at each pole. The branches will originate from these poles as the gain $ K $ varies from 0 to infinity.\nPop-up Question: Why do we expect four root locus branches in this case?\nAnswer: The number of root locus branches equals the number of open-loop poles. Here, we have four poles, hence four branches.\n\n\nStep 4: Calculating the Departure Angles (\\(\\phi_p\\))\nThe direction in which the root locus departs from complex poles is important. This is determined by the angle of departure, calculated using the formula:\n\\[ \\phi_p = \\pm 180^\\circ - (\\text{sum of angles due to other poles and zeros}) \\]\nExample Calculation: For our complex poles at $ s = -1 j $, we calculate the angles due to other poles and apply the formula to find $ _p $.\nand hence:\n\\[ \\phi_p = \\pm 180^\\circ - \\theta_1 - \\theta_2 - \\theta_3 = -71.6^o\\]\nTo calculate the angle of departure \\(\\phi_p\\) for the pole at \\(-1 + j\\) for our example transfer function, we need to follow these steps:\n\nIdentify the Pole and Other Elements: We are focusing on the pole at \\(-1 + j\\). The other elements in the system include the poles at \\(0\\), \\(-3\\), and \\(-1 - j\\). There are no zeros in this system.\nCalculate Angle Contributions: The angle contribution of each pole/zero to the pole at \\(-1 + j\\) is calculated by the angle of the vector from each pole/zero to the pole at \\(-1 + j\\).\nSum the Angles: Sum these angle contributions, keeping in mind that the angles due to poles are subtracted (as they are in the denominator of the transfer function).\nApply the Formula: Use the formula \\(\\phi_p = \\pm 180^\\circ - (\\text{sum of angles due to other poles and zeros})\\).\n\nLet’s calculate this step by step:\n\n\nStep 1: Identifying Poles\n\nPoles: \\(0, -3, -1 - j\\)\nPole of Interest: \\(-1 + j\\)\n\n\n\nStep 2: Calculating Angle Contributions\nFor each pole \\(s_i\\), the angle \\(\\theta_i\\) made with the pole of interest \\(-1 + j\\) is calculated as follows:\n\nFrom pole at \\(0\\):\n\\[\\theta_{0} = \\angle(-1 + j - 0) = \\tan^{-1}\\left(\\frac{\\text{Imaginary Part}}{\\text{Real Part}}\\right) = \\tan^{-1}\\left(\\frac{1}{-1}\\right) = -135^\\circ\\]\nFrom pole at \\(-3\\):\n\\[\\theta_{-3} = \\angle(-1 + j - (-3)) = \\tan^{-1}\\left(\\frac{1}{2}\\right) \\approx 26.57^\\circ\\]\nFrom pole at \\(-1 - j\\):\n\\[\\theta_{-1-j} = \\angle(-1 + j - (-1 - j)) = \\tan^{-1}\\left(\\frac{2}{0}\\right) = 90^\\circ\\]\n\n\n\nStep 3: Applying the Formula\nFinally, apply the formula for \\(\\phi_p\\): $$ _p = ^- 135^- 26.57^- 90^ $\nThis yields two possible values for \\(\\phi_p\\):\n\n\\(\\phi_{p1} = 180^\\circ - 251.56^\\circ = -71.57^\\circ\\)\n\\(\\phi_{p2} = -180^\\circ - 251.56^\\circ = 288.43^\\circ\\)\n\nSo, both calculations lead to the same angle of departure, \\(-71.57^\\circ\\). This is the angle at which the root locus will depart from the complex pole at \\(-1 + j\\).\n\n\n\n\n\n\n\n\n\nStep 5: Asymptotes and Centroid\nThe asymptotes provide a rough idea of the directions in which the root locus branches will tend. We calculate the angles of asymptotes (φA) and the centroid (σA) using:\n\\[ \\phi_A = \\frac{(2q+1) \\times 180^\\circ}{n-m} = 45, 135, 225, 315\\]\n\\[ \\sigma_A = \\frac{\\text{sum of real parts of poles - sum of real parts of zeros}}{n-m} = -1.25 \\]\nWhere $ n $ is the number of poles, $ m $ the number of zeros, and $ q $ varies from 0 to $ n-m-1 = 3$.\n\n\n\n\n\n\n\nPop-up Question: What does the centroid represent in the root locus plot?\nAnswer: The centroid represents the average location of the asymptotes on the real axis, providing a central reference point for the direction of the root locus branches.\n\n\nStep 6: Breakaway Points\nBreakaway points are where root locus branches move away from the real axis. We calculate these using the condition:\n\\[ \\frac{dK}{ds} = 0 \\]\nWhere $ K $ is the open-loop gain.\n\nFind the Open-Loop Transfer Function:\n\nThe given open-loop transfer function is $ 1+F(s) = 1+ $.\n\nExpress $ K $ in terms of $ s $:\n\nRewrite $ F(s) $ so that $ K = -s(s+3)(s^2+2s+2) = -(s4+5s3+8s^2+6s)$.\n\nDifferentiate $ K $ with Respect to $ s $:\n\nCalculate $ $. This gives:\n\\[\n   \\frac{dK}{ds} = -4(s^3+3.75s^2+4s+1.5)\n   \\]\n\nSolve for $ s $ where $ = 0 $:\n\nThis step requires finding the roots of the derivative equation.\nSolving this equation will give us the potential breakaway points.\nThis is a cubic polynomial in $ s $, and its roots can be the potential breakaway points. Solving this equation analytically can be complex, so it’s often solved using numerical methods or computational tools like MATLAB or Python.\n\nnp.roots(np.dot(-4,[1, 3.75, 4, 1.5]))\n\narray([-2.28858435+0.j        , -0.73070783+0.34855858j,\n       -0.73070783-0.34855858j])\n\n\n\nFinding an approximate solution\nWe can also attempt to find the solution manually, using the initial sketch of the root locus. From that sketch we see that a breakaway point must lie between 0 and -3 on the real axis. By trial-and-error procedure, we can find that \\(s=-2.3\\) satisfies the equation to a reasonable accuracy.\n\n\n\nIdentifying Valid Breakaway Points:\nAfter solving the cubic equation, not all roots will be valid breakaway points. The valid breakaway points must: - Lie on the real axis. - Be within the range of the open-loop poles and zeros on the real axis. - Satisfy the angle criterion of the root locus.\n\n\nIntersections with the imaginary axis\nThe points where the root locus intersects the imaginary axis are critical in understanding the system’s oscillatory behavior. These can be determined using the Routh-Hurwitz criterion.\nApplying Routh-Hurwitz Criterion: For this system, the intersection points are found to be at \\(\\pm 1.1\\) and the corresponding gain value \\(K = 8.16\\).\n\n\n\n\n\n\n\n\n\nUnderstanding the Root Locus Sketch\nWhen analyzing control systems using the root locus method, it’s important to distinguish between qualitative and quantitative analysis. This distinction is crucial for both creating and interpreting root locus plots.\n\n\nQualitative Analysis of Root Locus\nThe root locus sketch we create initially is a qualitative representation. It gives us a visual understanding of how the system’s poles move in the complex plane as the gain, \\(K\\), varies. This qualitative sketch is valuable for grasping the general behavior of the system, such as:\n\nIdentifying the paths along which poles move.\nUnderstanding the system’s stability changes with varying gain.\nObserving the tendency of poles to converge or diverge.\n\nNote: Remember, this sketch is qualitative. It provides a visual guide to the system’s behavior but does not offer precise numerical values or exact locations of the poles, except for those few points we have explicitly calculated.\n\n\nImportance of Quantitative Information\nWhile a qualitative sketch is helpful for a general understanding, obtaining quantitative information is crucial for detailed analysis and design. This involves:\n\nPrecise pole locations for specific gain values.\nExact values of gain where system behavior changes (like crossing the imaginary axis).\nDetailed stability margins and performance criteria.\n\n\n\nThe Role of the Angle Condition\nTo derive quantitative information, we rely on the angle condition, a fundamental part of the root locus method. The angle condition helps us determine:\n\nThe exact points on the root locus that satisfy the angle criterion, providing us with specific pole locations for given gain values.\nThe verification of whether a point lies on the root locus or not.\n\nApplying the angle condition involves calculating the sum of phase angles contributed by all poles and zeros to a point in the complex plane and ensuring that this sum equals an odd multiple of 180 degrees.\n\n\nDesign Problem - Adjusting Gain for Desired Damping\nA common design problem in control systems is adjusting the gain, $ K $, to achieve a desired level of damping, denoted as $ $. Let’s say we aim for a damping ratio of 0.5.\n\nDrawing the Damping Line: We draw a line corresponding to $ = 0.5 $ in the $ s $-plane to find where it intersects the root locus.\n\n\\[\n\\theta = \\cos^{-1}(\\zeta) = 60^o\n\\]\n\n\n\n\n\n\n\n\nFinding the Suitable Gain Value: Once we find the intersection point, we apply the angle criterion to confirm it lies on the root locus. Then, we calculate the corresponding gain, $ K $, using the magnitude criterion.\n\nIf the point we try based on our rough sketch does not satisfy the angle condition we try more points to adjust our plot. Keep in mind that only points on the desired damping line are of interest in this case.\n\nAngle Criterion: To confirm if a candidate point is indeed on the root locus, check if the total phase angle contribution from all poles and zeros to this point is an odd multiple of 180 degrees.\nVerification: If the angle criterion is satisfied, the point is on the root locus. If not, adjust the sketch to find a valid intersection point along the damping line.\n\nDoing the calculation we obtain an intersection point of:\n\\[\ns = -0.4\\pm j0.7\n\\]\nThese are the desired closed loop poles of the system.\n\nCalculating the Gain $ K $\n\nMagnitude Criterion: Once a valid intersection point is confirmed, calculate the corresponding gain $ K $ using the magnitude criterion:\n\n\\[ K = \\left| \\frac{\\text{Product of distances from selected point to zeros}}{\\text{Product of distances from selected point to poles}} \\right| \\]\nand more formally:\n\\[\nK = \\frac{\\left| \\prod_{j=1}^{m} (s + p_j) \\right| }{ \\left| \\prod_{i=1}^{n} (s + z_i) \\right|}\n\\]\nFor the point $s = -0.4 j0.7 $, we measure the distances to each pole (say $ p_1, p_2, p_3 $) and calculate $ K $:\n\\[ K = |(-0.4 \\pm j0.7 + p_1)(-0.4 \\pm j0.7 + p_2)(-0.4 \\pm j0.7 + p_3)| \\]\nAssuming we’ve measured these distances and calculated them, $ K $ turns out to be 2.91. Thus, $ K = 2.91 $ is the gain at which the system achieves a damping ratio of 0.5.\nNote that you can also calculate the corresponding \\(K\\) graphically, measuring the distances from the points to the zeros and poles to have a rough number. Divide the product of distances to zeros by the product of distances to poles to find $ K $. Since there are no zeros in this example, the denominator becomes 1.\n\n\n\nAdditional considerations\nWe will now focus on finding the remaining closed-loop poles in our fourth-order control system.\nWe have already identified two poles, but to complete our analysis, we need to locate the other two. This step is crucial for understanding the system’s overall behavior, especially its stability and response characteristics.\nThe design that we have made only makes sense if the poles that we have identified are dominant, and the other two poles are negligible.\nOnly in this case in fact, the dominant poles at $s = -0.4 j0.7 $ are representative system’s behavior and hence correspond to having a damping ratio $ = 0.5 $ .\nOur goal now is to find these remaining poles to ensure they are indeed non-dominant.\nUsing the Gain Value: - We have a specific gain value of interest, $ K = 2.91 $, which corresponds to our dominant poles. - Our task is to find points on the other root locus branches that correspond to this same gain value.\n\n\nMethodology for Locating Poles\n\nGraphical Approach:\n\nBy graphically plotting the root locus, we can estimate the location of the poles at $ K = 2.91 $.\nThis method involves trial and error, adjusting points on the root locus until the magnitude criterion confirms $ K = 2.91 $.\nWe try a point on the other branches of the plot and we apply the magnitude condition to calculate the value of \\(K\\) until we find one point that roughly gives us the correct gain.\n\nMagnitude Criterion:\n\nThis criterion is used to verify if a point on the root locus corresponds to the desired gain value.\nFormula:\n\n\\[ K = \\frac{ \\left| \\prod_{j=1}^{n} (s + p_j) \\right| }{ \\left| \\prod_{i=1}^{m} (s + z_i) \\right| } \\]\n\nApplying these considerations we will that the other two roots when $ K = 2.91 $ are at $ s_3 = -1.4 $ and $ s_4 = -2.85 $ and they are on the real axis.\nNote that in this case the dominance condition is not verified because the ratio between 0.4 and 1.4 is about 3 times only (and we want 4 or 5 times).\nThe actual overshoot will be more than that corresponding to \\(\\zeta=0.5\\). This is due to the fact that the influence of the other poles is not negligible.\nWe will need to do simulations to understand how the system behaves.\n\n\n\n\n\n\n\n\n\n\nFigure: Left: trial and error until we find the desired value of gain. Right: Final poles obtained as black squares.\nAnd the final closed-loop transfer function is:\n\\[\nF(s) = \\frac{2.91}{(s + 1.4)(s + 2.85)(s + 0.4 + j0.7)(s + 0.4 - j0.7)}\n\\]\n\n\nPlotting the root locus with Python\nTo plot the root locus for the system described, we can use Python along with the matplotlib library for plotting and the control library, which provides functions specifically for control systems analysis, including root locus plots.\nBelow is a Python script to plot the root locus for the given system.\nThis script sets up the transfer function of your system and then uses the root_locus function from the control library to plot the root locus. The root locus plot will show how the poles of the closed-loop system move in the complex plane as the gain \\(K\\) varies.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the transfer function\nnumerator = [1]\ndenominator = [1, 5, 8, 6, 0]  # s^4 + 5s^3 + 8s^2 + 6s\nsystem = ctl.TransferFunction(numerator, denominator)\n\n# Plot the root locus\nfig, ax = plt.subplots()\nrl, k = ctl.root_locus(system, plot=True, ax=ax)\n\n# Improve plot aesthetics\nax.set_title('Root Locus Plot')\nax.set_xlabel('Real Axis')\nax.set_ylabel('Imaginary Axis')\nax.axhline(y=0, color='k', lw=1)\nax.axvline(x=0, color='k', lw=1)\nax.grid(True, which='both', ls='--', lw=0.5)\n\n# Adjust plot limits if necessary\nax.set_xlim([-4, 1])\nax.set_ylim([-3, 3])\n\nplt.show()",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#example-2-1",
    "href": "compensator_design_using_root_locus.html#example-2-1",
    "title": "Compensator Design",
    "section": "Example 2",
    "text": "Example 2\nIn this example, we delve into the application of root locus analysis for designing control systems with multiple parameters. We focus on a specific example involving a position control system with tachometric feedback.\n\nUnderstanding the System Configuration\nConsider a system with an open-loop transfer function of the form:\n\\[ G(s) = K_A \\cdot \\frac{s}{s(s+2)} \\]\nWhere $ K_A $ is the amplifier gain. We aim to design this system for a specified value of the damping ratio $ $.\n\n\n\n\n\n\n\n\n\nResolving into a Single Loop Configuration\nThe first thing we want to do is to convert the system into a single loop configuration:\n\\[ F(s) = \\frac{K_A}{s^2 + (2 + K_A K_T) s} \\]\nWhere $ K_t $ represents the tachometric constant.\n\n\n\n\n\n\n\n\nDetermining the Characteristic Equation\nThe characteristic equation for this system is:\n\\[ s^2 + (2 + K_A K_T) s + K_A = 0 \\]\nAs we discussed poles and zeros of the system might be different from the open-loop ones.\n\n\nStep 1: Formulating the Root Locus Function\nWe express the characteristic equation in a form suitable for root locus analysis:\nTo do this, we can re-write the characteristic equation in this form:\n\\[ s^2 + 2s + K_A + K_AK_T s = 0 \\]\n\\[ K_A + K_AK_T s = -s^2 - 2s \\]\n\\[ K_AK_T s = -s^2 - 2s -K_A\\]\nand finally we can write the root locus equation:\n\\[ 1 +  \\frac{K_A K_Ts}{s^2 + 2s + K_A} = 0 \\]\nHere, $ K = K_A K_T $ acts as the root locus gain. If for example I want to understand how \\(K_T\\) affects my performance I have to have the equation is a way that \\(K_T\\) is my root locus gain:\n\\[\n1 + KF(s) = 0, \\;\\;\\; K = K_A K_T\n\\]\n\n\n\nDesign Problem: Specifying Damping Ratio\nSuppose we are given \\(K_A=60\\) and we want to design \\(K_T\\) so that the system has a damping ratio $ = 0.5 $.\nThis specialises our equation:\n\\[ 1 +  \\frac{60 K_Ts}{s^2 + 2s + 60} = 0 \\]\n\nStep 1: Sketching the Root Locus\n\nThe root locus plot helps us visualize how the system poles move as $ K $ varies.\nWe identify poles, zeros, and the breakaway points on the root locus.\n\n\n\nStep 2: Calculating $ K_T $ for Desired Damping\n\nWe draw a line in the s-plane corresponding to $ = 0.5 $.\nFind the intersection of this line with the root locus to identify the corresponding value of $ K $.\nCalculate $ K_T $ from $ K $ using $ K_T = $.\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Root Contours\nRoot contours represent the root locus plots for various values of one parameter while keeping the other constant. This concept is crucial for systems with multiple varying parameters.\n\nRoot Contours for varying $ K_A $\n\nPlotting Root Contours: For each value of $ K_A $, plot the corresponding root locus.\nAnalysis: Observe how the root locus branches change with different values of $ K_A $.\n\n\n\n\n\n\n\n\nIn fact the vertical dashed line in the diagram above is the root locus of the equation:\n\\[\ns^2 + 2s + K_A = 0\n\\]\nIf you have multiple parameters like we had before:\n\\[ 1 +  \\frac{K_A K_Ts}{s^2 + 2s + K_A} = 0 \\]\n\nConcentrate on the denominator, which is a function of only one parameter. The roots of the denominator are the open-loop poles of the total function.\n\n\nFirst of all study: \\(s^2 + 2s + K_A=0\\), including if necessary (and it might be for a complex function) put it in the root locus form:\n\n\\[\n1 + \\frac{K_A}{s(s+2)}\n\\]\nand plot the root locus (which is a vertical line between 0 and -2).\n\nThis root locus gives you the open loop poles for the complete function. This means that you can take any two points on this root locus and they represent your open loop poles (for a specific value of your \\(K_A\\) parameter).\nDraw the root locus for the other parameter (\\(K_T\\) in our case).",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_root_locus.html#root-locus-analysis-for-systems-with-dead-time",
    "href": "compensator_design_using_root_locus.html#root-locus-analysis-for-systems-with-dead-time",
    "title": "Compensator Design",
    "section": "Root Locus Analysis for Systems with Dead Time",
    "text": "Root Locus Analysis for Systems with Dead Time\nWe deal now with the root locus analysis of control systems that include dead time, a common scenario in real-world applications. We will use the Pade approximation to simplify the dead time element and analyze its impact on the root locus plot.\n\nUnderstanding Dead Time in Control Systems\nDead time in control systems refers to a delay between the input and output response. It is often represented by a term like $ e^{-s_D} $ in the transfer function, where $ _D $ is the dead time.\n\nExample: Transfer Function with Dead Time\nConsider a transfer function with dead time:\n\\[ G(s) = \\frac{K \\cdot e^{-s\\tau_D} }{ s }\\]\n\n\n\nApproximating Dead Time: Pade’s Approximation\nDead time can be approximated using Pade’s approximation, which converts the exponential delay into a rational function. The approximation for a first-order Pade is:\n\\[ e^{-s\\tau_D} \\approx \\frac{1 - \\frac{\\tau_D}{2} s}{1 + \\frac{\\tau_D}{2} s} \\]\n\n\nTransforming the Transfer Function\nApplying Pade’s approximation to $ G(s) $, the transfer function becomes:\n\\[ G(s) = \\frac{K}{s} \\frac{1 - \\frac{\\tau_D}{2} s}{1 + \\frac{\\tau_D}{2} s}  = -K \\cdot \\frac{s - \\frac{2}{\\tau_D}}{s(s + \\frac{2}{\\tau_D})} \\]\nNotice the negative sign that comes from the approximation.\nThis corresponds to the equation:\n\\[\n1-G(s) = 0\n\\]\n\nAngle and Magnitude Criteria\n\nMagnitude Criterion: Remains unchanged; $ |G(s)| = 1 $.\nAngle Criterion: Modifies due to the negative sign. The criterion changes from an odd multiple of 180 degrees to an even multiple: \\[ \\angle G(s) = \\pm 2q \\times 180^\\circ \\]\nThis is because the equation is now \\(G(s)=1\\) (earlier it was \\(G(s)=-1\\)).\n\n\n\nConstructing the Root Locus\n\nIdentify Poles and Zeros:\n\nPole at $ s = 0 $\nZero at $ s = $\nAdditional pole at $ s = - $ due to Pade’s approximation.\n\nPlotting the Root Locus:\n\nWith respect to the rules we saw, there are only two changes: - The real axis segments that are part of the root locus change because of the negative sign. - Use the modified angle criterion to determine which segments of the real axis belong to the root locus.\n\n\n\nPlotting the root locus with python\nThis code generates the root locus plot for a system with dead time, considering the modifications required due to the Pade approximation. It provides a visual representation of how the poles of the system move in the complex plane as the gain \\(K\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\n\n# Define the system parameters\nK = -1  # Gain\ntau_D = 1  # Dead time\n\n# Transfer function with Pade's approximation for dead time\nnumerator = [1, -tau_D/2]\ndenominator = [1, tau_D/2, 0]\n\nG_s = ctrl.TransferFunction(K * np.array(numerator), np.array(denominator))\n\n# Plotting the root locus\nplt.figure(figsize=(8, 6))\nrlist, klist = ctrl.root_locus(G_s, plot=True)\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Root Locus of System with Dead Time (Pade Approximation)')\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "Compensator Design"
    ]
  },
  {
    "objectID": "compensator_design_using_frequency_response_plots.html",
    "href": "compensator_design_using_frequency_response_plots.html",
    "title": "Principles of Automatic Control: Lead and Lag Compensation",
    "section": "",
    "text": "After gaining a thorough understanding of feedback performance characteristics, it’s time to address the design aspects of control systems. An efficient way to delve into this topic is through the exploration of lead and lag compensators, employing examples for a comprehensive understanding. Previously, you have been introduced to the root locus method, which serves as a foundational concept for this discussion.\n\n\nLead and lag compensators are integral to modifying the dynamic response of control systems. They are characterized by a pole-zero configuration. In a lead compensator, a zero precedes a pole, enhancing the system’s transient response by introducing a phase lead. Conversely, in a lag compensator, a pole precedes a zero, primarily used to improve steady-state accuracy without significantly affecting the transient response.\n\n\nA lead compensator consists of a zero followed by a pole, particularly in the left-half plane, to ensure system stability. The general transfer function of a lead compensator, denoted as (D(s)), can be expressed as:\n\\[D(s) = \\frac{s + \\frac{1}{\\tau}}{s + \\frac{1}{\\alpha \\tau}}\\]\nwhere \\(\\tau &gt; 0\\) is the time constant of the zero, and \\(\\alpha\\) is a constant less than 1 (\\(\\alpha &lt; 1\\)), dictating the distance between the pole and the zero. The closer \\(\\alpha\\) is to zero, the further apart the pole and zero are, which enhances the compensator’s phase-lead characteristics.\n\n\n\n\n\n\n\n\n\n\nLet’s consider the design process for a lead compensator, where our goal is to adjust transient performance criteria such as settling time and overshoot. The design revolves around the strategic placement of the zero and pole to achieve a desired phase margin or equivalently, to ensure certain frequency domain specifications like bandwidth (\\(\\omega_b\\)) and phase margin (\\(M_r\\)) are met.\nDesign Parameters and Flexibility\nIn addition to \\(\\tau\\) and \\(\\alpha\\), the gain \\(K_c\\) plays a pivotal role in the compensator’s effectiveness. This introduces three degrees of freedom in the design process: \\(K_c\\), \\(\\tau\\), and \\(\\alpha\\). For simplicity, during the initial design stages, \\(K_c\\) is often merged with the gain of the uncompensated system (and we call it \\(K\\)).\n\n\n\n\nThe effectiveness of a lead compensator is predominantly evaluated through its frequency response. The transfer function in the frequency domain, \\(D(j\\omega)\\), is given by:\n\\[D(j\\omega) = K_c \\cdot \\frac{\\tau j\\omega + 1}{\\alpha \\tau j\\omega + 1}\\]\nTo understand the impact of the compensator on the system’s frequency response, let’s examine the Bode plot characteristics of \\(D(j\\omega)\\).\n\n\n\n\n\n\n\nI want to find the values of \\(K\\), \\(\\tau\\), and \\(\\alpha\\) so that the requirements on phase margin, bandwidth and velocity constant (or any other constant) are satisfied.\n\n\nLet’s start from the compensator in the frequency domain; we would like to understand what contribution it gives to the Bode plot of the uncompensated system.\n\\[D(j\\omega) = \\frac{\\tau j\\omega + 1}{\\alpha \\tau j\\omega + 1}\\]\nThe magnitude plot of a lead compensator showcases a key feature: it starts at 0 dB, increases at +20 dB/decade after the zero’s corner frequency (\\(\\frac{1}{\\tau}\\)), and flattens after the pole’s corner frequency (\\(\\frac{1}{\\alpha \\tau}\\)). This characteristic is important for increasing the system’s gain margin and phase margin.\nThe phase plot reveals the compensator’s ability to add a leading phase to the system. The maximum phase lead occurs between the zero and the pole’s corner frequencies, providing a valuable tool for shaping the system’s response to meet design specifications.\nWe can plot the Bode Plots of the Lead Compensator.\nNote that the phase is\n\\[\n\\Phi = \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau)\n\\]\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom ipywidgets import interact, FloatSlider\n\n# Function to plot the Bode plot of the lead compensator with annotations\ndef plot_lead_compensator_with_annotations(tau=1.0, alpha=0.5):\n    # Define the transfer function of the lead compensator\n    numerator = [tau, 1]\n    denominator = [alpha*tau, 1]\n    system = signal.TransferFunction(numerator, denominator)\n    \n    # Generate Bode plot data\n    frequencies = np.logspace(-2, 2, 400)\n    w, mag, phase = signal.bode(system, w=frequencies)\n    \n    # Calculate corner frequencies\n    corner_freq_zero = 1/tau\n    corner_freq_pole = 1/(alpha*tau)\n    \n    # Plotting\n    plt.figure(figsize=(14, 6))\n    \n    ## Magnitude plot\n    plt.subplot(1, 2, 1)\n    plt.semilogx(w, mag) # Bode magnitude plot\n    plt.title('Magnitude Plot')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Magnitude [dB]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for magnitude plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(mag), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(mag), r'$\\frac{1}{\\alpha\\tau}$', horizontalalignment='right', color='green')\n    \n    ## Phase plot\n    plt.subplot(1, 2, 2)\n    plt.semilogx(w, phase) # Bode phase plot\n    plt.title('Phase Plot')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Phase [degrees]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for phase plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(phase), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(phase), r'$\\frac{1}{\\alpha\\tau}$', horizontalalignment='right', color='green')\n    \n    plt.show()\n\n# Interactive widget\ninteract(plot_lead_compensator_with_annotations, \n         tau=FloatSlider(value=7.5, min=0.1, max=10.0, step=0.1, description='Tau (τ)'),\n         alpha=FloatSlider(value=0.01, min=0.01, max=1.0, step=0.05, description='Alpha (α)'));\n\n\n\n\nCalculating Maximum Phase Lead in Compensator Design\nA critical step in the design process involves determining the frequency (\\(\\omega_m\\)) at which the maximum phase lead (\\(\\phi_m\\)) occurs. This is achieved by differentiating the phase angle with respect to \\(\\omega\\) and setting the derivative to zero.\n\\[\\frac{d\\phi}{d\\omega} = 0\\]\nThe phase lead \\(\\phi\\) of a compensator is given by the difference between the phase angles due to its zero and its pole:\n\\[\\phi = \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau)\\]\nwhere: - \\(\\omega\\) is the frequency, - \\(\\tau\\) is the time constant associated with the zero, - \\(\\alpha\\tau\\) (with \\(\\alpha &lt; 1\\)) is the time constant associated with the pole.\nCalculating \\(\\omega_m\\)\n\\[\n\\tan(\\phi) = \\tan\\left( \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau) \\right)\n\\]\nThe phase angle \\(\\phi\\) for the lead compensator is the difference between the arctan of the zero’s frequency response (\\(\\tan^{-1}(\\omega\\tau)\\)) and the pole’s frequency response (\\(\\tan^{-1}(\\omega\\alpha\\tau)\\)).\nTo simplify this expression, we use the identity for the tangent of a difference, \\(\\tan(a - b)\\), which is given by:\n\\[\n\\tan(a - b) = \\frac{\\tan(a) - \\tan(b)}{1 + \\tan(a)\\tan(b)}\n\\]\nApplying this identity to our problem where \\(a = \\tan^{-1}(\\omega\\tau)\\) and \\(b = \\tan^{-1}(\\omega\\alpha\\tau)\\), we get:\n\\[\n\\tan(\\phi) = \\frac{\\omega\\tau - \\omega\\alpha\\tau}{1 + \\omega^2\\tau^2\\alpha}\n\\]\nHere, \\(\\tan(a) = \\omega\\tau\\) and \\(\\tan(b) = \\omega\\alpha\\tau\\) are the tangents of the arctan expressions, simplifying to \\(\\omega\\tau\\) and \\(\\omega\\alpha\\tau\\), respectively. The denominator reflects the product of the tangents.\nThus, the final expression becomes:\n\\[\n\\tan(\\phi) = \\frac{\\omega\\tau(1 - \\alpha)}{1 + \\omega^2\\tau^2\\alpha}\n\\]\nThis formula calculates the tangent of the phase difference introduced by the lead compensator. It reflects how the phase difference varies with frequency (\\(\\omega\\)), the time constant (\\(\\tau\\)), and the ratio (\\(\\alpha\\)) between the pole and zero time constants.\nSolving this equation, we find that:\n\\[\\omega_m = \\sqrt{\\frac{1}{\\tau}\\cdot\\frac{1}{ \\alpha \\tau}}\\]\nThis shows that \\(\\omega_m\\) is the geometric mean of the inverse of the time constants of the pole and zero.\n\n\n\n\nSubstituting \\(\\omega_m\\) back into the equation for \\(\\phi\\) gives us \\(\\phi_m\\), the maximum phase lead. By rearranging the terms, we find that:\n\\[\\sin(\\phi_m) = \\frac{1-\\alpha}{1+\\alpha}\\]\nFrom this, we can calculate \\(\\alpha\\) given a desired \\(\\phi_m\\), using the formula:\n\\[\\alpha = \\frac{1 - \\sin(\\phi_m)}{1 + \\sin(\\phi_m)}\\]\nThis equation is important for designing our compensator, as it directly relates the maximum phase lead we aim to achieve to the parameter \\(\\alpha\\) of our compensator.\n\n\n\nFor the design process, it’s also useful to know the compensator’s magnitude at the frequency \\(\\omega_m\\).\nFor a lead compensator, the magnitude (in dB) due to a factor like \\(1 + j\\omega\\tau\\) can be calculated using the formula:\n\\[ \\text{Magnitude (dB)} = 20 \\log \\left| 1 + j\\omega\\tau \\right| = 20 \\log \\sqrt{1+\\omega^2\\tau^2}\\]\nThis involves calculating the magnitude of the complex number \\(1 + j\\omega\\tau\\) and then converting it to decibels (dB) using \\(20 \\log_{10}(\\cdot)\\).\n\n\n\nAs the frequency \\(\\omega\\) increases, the term \\(j\\omega\\tau\\) becomes much larger than 1, especially when \\(\\omega\\tau &gt; 1\\). In this scenario, the ‘1’ can be neglected for an asymptotic approximation, simplifying our magnitude formula to:\n\\[ \\text{Magnitude (dB)} \\approx 20 \\log \\left| j\\omega\\tau \\right| = 20 \\log (\\omega\\tau) \\]\nThis approximation simplifies calculations and is often used in asymptotic Bode plot sketches.\n\n\n\nWhen analyzing at a specific frequency related to the compensator’s pole, say \\(\\omega = \\frac{1}{\\alpha\\tau}\\), we substitute this into our magnitude formula. Let’s see how this plays out:\n\nInitial Formula: \\(20 \\log (\\omega\\tau)\\)\nSubstitute \\(\\omega = \\frac{1}{\\alpha\\tau}\\): This leads to \\(20 \\log \\left( \\frac{1}{\\alpha\\tau} \\cdot \\tau \\right) = 20 \\log \\left( \\frac{1}{\\alpha} \\right)\\)\n\nThis calculation gives us the magnitude in dB at the specific frequency where the compensator’s effect is analyzed (\\(\\omega = \\frac{1}{\\alpha\\tau}\\)).\nThe magnitude at the frequency of maximum phase lead (\\(\\omega_m\\)) can then be calculated. Assuming \\(\\omega_m\\) corresponds to the geometric mean of the zero and pole frequencies (as previously derived in discussions of \\(\\omega_m\\)), and substituting \\(\\omega_m\\) back into the magnitude formula we obtain the magnitude at \\(\\omega_m\\), which simplifies to: \\[10 \\log (1/\\alpha)\\]",
    "crumbs": [
      "Principles of Automatic Control: Lead and Lag Compensation"
    ]
  },
  {
    "objectID": "compensator_design_using_frequency_response_plots.html#introduction-to-compensator-design",
    "href": "compensator_design_using_frequency_response_plots.html#introduction-to-compensator-design",
    "title": "Principles of Automatic Control: Lead and Lag Compensation",
    "section": "",
    "text": "After gaining a thorough understanding of feedback performance characteristics, it’s time to address the design aspects of control systems. An efficient way to delve into this topic is through the exploration of lead and lag compensators, employing examples for a comprehensive understanding. Previously, you have been introduced to the root locus method, which serves as a foundational concept for this discussion.\n\n\nLead and lag compensators are integral to modifying the dynamic response of control systems. They are characterized by a pole-zero configuration. In a lead compensator, a zero precedes a pole, enhancing the system’s transient response by introducing a phase lead. Conversely, in a lag compensator, a pole precedes a zero, primarily used to improve steady-state accuracy without significantly affecting the transient response.\n\n\nA lead compensator consists of a zero followed by a pole, particularly in the left-half plane, to ensure system stability. The general transfer function of a lead compensator, denoted as (D(s)), can be expressed as:\n\\[D(s) = \\frac{s + \\frac{1}{\\tau}}{s + \\frac{1}{\\alpha \\tau}}\\]\nwhere \\(\\tau &gt; 0\\) is the time constant of the zero, and \\(\\alpha\\) is a constant less than 1 (\\(\\alpha &lt; 1\\)), dictating the distance between the pole and the zero. The closer \\(\\alpha\\) is to zero, the further apart the pole and zero are, which enhances the compensator’s phase-lead characteristics.\n\n\n\n\n\n\n\n\n\n\nLet’s consider the design process for a lead compensator, where our goal is to adjust transient performance criteria such as settling time and overshoot. The design revolves around the strategic placement of the zero and pole to achieve a desired phase margin or equivalently, to ensure certain frequency domain specifications like bandwidth (\\(\\omega_b\\)) and phase margin (\\(M_r\\)) are met.\nDesign Parameters and Flexibility\nIn addition to \\(\\tau\\) and \\(\\alpha\\), the gain \\(K_c\\) plays a pivotal role in the compensator’s effectiveness. This introduces three degrees of freedom in the design process: \\(K_c\\), \\(\\tau\\), and \\(\\alpha\\). For simplicity, during the initial design stages, \\(K_c\\) is often merged with the gain of the uncompensated system (and we call it \\(K\\)).\n\n\n\n\nThe effectiveness of a lead compensator is predominantly evaluated through its frequency response. The transfer function in the frequency domain, \\(D(j\\omega)\\), is given by:\n\\[D(j\\omega) = K_c \\cdot \\frac{\\tau j\\omega + 1}{\\alpha \\tau j\\omega + 1}\\]\nTo understand the impact of the compensator on the system’s frequency response, let’s examine the Bode plot characteristics of \\(D(j\\omega)\\).\n\n\n\n\n\n\n\nI want to find the values of \\(K\\), \\(\\tau\\), and \\(\\alpha\\) so that the requirements on phase margin, bandwidth and velocity constant (or any other constant) are satisfied.\n\n\nLet’s start from the compensator in the frequency domain; we would like to understand what contribution it gives to the Bode plot of the uncompensated system.\n\\[D(j\\omega) = \\frac{\\tau j\\omega + 1}{\\alpha \\tau j\\omega + 1}\\]\nThe magnitude plot of a lead compensator showcases a key feature: it starts at 0 dB, increases at +20 dB/decade after the zero’s corner frequency (\\(\\frac{1}{\\tau}\\)), and flattens after the pole’s corner frequency (\\(\\frac{1}{\\alpha \\tau}\\)). This characteristic is important for increasing the system’s gain margin and phase margin.\nThe phase plot reveals the compensator’s ability to add a leading phase to the system. The maximum phase lead occurs between the zero and the pole’s corner frequencies, providing a valuable tool for shaping the system’s response to meet design specifications.\nWe can plot the Bode Plots of the Lead Compensator.\nNote that the phase is\n\\[\n\\Phi = \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau)\n\\]\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom ipywidgets import interact, FloatSlider\n\n# Function to plot the Bode plot of the lead compensator with annotations\ndef plot_lead_compensator_with_annotations(tau=1.0, alpha=0.5):\n    # Define the transfer function of the lead compensator\n    numerator = [tau, 1]\n    denominator = [alpha*tau, 1]\n    system = signal.TransferFunction(numerator, denominator)\n    \n    # Generate Bode plot data\n    frequencies = np.logspace(-2, 2, 400)\n    w, mag, phase = signal.bode(system, w=frequencies)\n    \n    # Calculate corner frequencies\n    corner_freq_zero = 1/tau\n    corner_freq_pole = 1/(alpha*tau)\n    \n    # Plotting\n    plt.figure(figsize=(14, 6))\n    \n    ## Magnitude plot\n    plt.subplot(1, 2, 1)\n    plt.semilogx(w, mag) # Bode magnitude plot\n    plt.title('Magnitude Plot')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Magnitude [dB]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for magnitude plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(mag), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(mag), r'$\\frac{1}{\\alpha\\tau}$', horizontalalignment='right', color='green')\n    \n    ## Phase plot\n    plt.subplot(1, 2, 2)\n    plt.semilogx(w, phase) # Bode phase plot\n    plt.title('Phase Plot')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Phase [degrees]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for phase plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(phase), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(phase), r'$\\frac{1}{\\alpha\\tau}$', horizontalalignment='right', color='green')\n    \n    plt.show()\n\n# Interactive widget\ninteract(plot_lead_compensator_with_annotations, \n         tau=FloatSlider(value=7.5, min=0.1, max=10.0, step=0.1, description='Tau (τ)'),\n         alpha=FloatSlider(value=0.01, min=0.01, max=1.0, step=0.05, description='Alpha (α)'));\n\n\n\n\nCalculating Maximum Phase Lead in Compensator Design\nA critical step in the design process involves determining the frequency (\\(\\omega_m\\)) at which the maximum phase lead (\\(\\phi_m\\)) occurs. This is achieved by differentiating the phase angle with respect to \\(\\omega\\) and setting the derivative to zero.\n\\[\\frac{d\\phi}{d\\omega} = 0\\]\nThe phase lead \\(\\phi\\) of a compensator is given by the difference between the phase angles due to its zero and its pole:\n\\[\\phi = \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau)\\]\nwhere: - \\(\\omega\\) is the frequency, - \\(\\tau\\) is the time constant associated with the zero, - \\(\\alpha\\tau\\) (with \\(\\alpha &lt; 1\\)) is the time constant associated with the pole.\nCalculating \\(\\omega_m\\)\n\\[\n\\tan(\\phi) = \\tan\\left( \\tan^{-1}(\\omega\\tau) - \\tan^{-1}(\\omega\\alpha\\tau) \\right)\n\\]\nThe phase angle \\(\\phi\\) for the lead compensator is the difference between the arctan of the zero’s frequency response (\\(\\tan^{-1}(\\omega\\tau)\\)) and the pole’s frequency response (\\(\\tan^{-1}(\\omega\\alpha\\tau)\\)).\nTo simplify this expression, we use the identity for the tangent of a difference, \\(\\tan(a - b)\\), which is given by:\n\\[\n\\tan(a - b) = \\frac{\\tan(a) - \\tan(b)}{1 + \\tan(a)\\tan(b)}\n\\]\nApplying this identity to our problem where \\(a = \\tan^{-1}(\\omega\\tau)\\) and \\(b = \\tan^{-1}(\\omega\\alpha\\tau)\\), we get:\n\\[\n\\tan(\\phi) = \\frac{\\omega\\tau - \\omega\\alpha\\tau}{1 + \\omega^2\\tau^2\\alpha}\n\\]\nHere, \\(\\tan(a) = \\omega\\tau\\) and \\(\\tan(b) = \\omega\\alpha\\tau\\) are the tangents of the arctan expressions, simplifying to \\(\\omega\\tau\\) and \\(\\omega\\alpha\\tau\\), respectively. The denominator reflects the product of the tangents.\nThus, the final expression becomes:\n\\[\n\\tan(\\phi) = \\frac{\\omega\\tau(1 - \\alpha)}{1 + \\omega^2\\tau^2\\alpha}\n\\]\nThis formula calculates the tangent of the phase difference introduced by the lead compensator. It reflects how the phase difference varies with frequency (\\(\\omega\\)), the time constant (\\(\\tau\\)), and the ratio (\\(\\alpha\\)) between the pole and zero time constants.\nSolving this equation, we find that:\n\\[\\omega_m = \\sqrt{\\frac{1}{\\tau}\\cdot\\frac{1}{ \\alpha \\tau}}\\]\nThis shows that \\(\\omega_m\\) is the geometric mean of the inverse of the time constants of the pole and zero.\n\n\n\n\nSubstituting \\(\\omega_m\\) back into the equation for \\(\\phi\\) gives us \\(\\phi_m\\), the maximum phase lead. By rearranging the terms, we find that:\n\\[\\sin(\\phi_m) = \\frac{1-\\alpha}{1+\\alpha}\\]\nFrom this, we can calculate \\(\\alpha\\) given a desired \\(\\phi_m\\), using the formula:\n\\[\\alpha = \\frac{1 - \\sin(\\phi_m)}{1 + \\sin(\\phi_m)}\\]\nThis equation is important for designing our compensator, as it directly relates the maximum phase lead we aim to achieve to the parameter \\(\\alpha\\) of our compensator.\n\n\n\nFor the design process, it’s also useful to know the compensator’s magnitude at the frequency \\(\\omega_m\\).\nFor a lead compensator, the magnitude (in dB) due to a factor like \\(1 + j\\omega\\tau\\) can be calculated using the formula:\n\\[ \\text{Magnitude (dB)} = 20 \\log \\left| 1 + j\\omega\\tau \\right| = 20 \\log \\sqrt{1+\\omega^2\\tau^2}\\]\nThis involves calculating the magnitude of the complex number \\(1 + j\\omega\\tau\\) and then converting it to decibels (dB) using \\(20 \\log_{10}(\\cdot)\\).\n\n\n\nAs the frequency \\(\\omega\\) increases, the term \\(j\\omega\\tau\\) becomes much larger than 1, especially when \\(\\omega\\tau &gt; 1\\). In this scenario, the ‘1’ can be neglected for an asymptotic approximation, simplifying our magnitude formula to:\n\\[ \\text{Magnitude (dB)} \\approx 20 \\log \\left| j\\omega\\tau \\right| = 20 \\log (\\omega\\tau) \\]\nThis approximation simplifies calculations and is often used in asymptotic Bode plot sketches.\n\n\n\nWhen analyzing at a specific frequency related to the compensator’s pole, say \\(\\omega = \\frac{1}{\\alpha\\tau}\\), we substitute this into our magnitude formula. Let’s see how this plays out:\n\nInitial Formula: \\(20 \\log (\\omega\\tau)\\)\nSubstitute \\(\\omega = \\frac{1}{\\alpha\\tau}\\): This leads to \\(20 \\log \\left( \\frac{1}{\\alpha\\tau} \\cdot \\tau \\right) = 20 \\log \\left( \\frac{1}{\\alpha} \\right)\\)\n\nThis calculation gives us the magnitude in dB at the specific frequency where the compensator’s effect is analyzed (\\(\\omega = \\frac{1}{\\alpha\\tau}\\)).\nThe magnitude at the frequency of maximum phase lead (\\(\\omega_m\\)) can then be calculated. Assuming \\(\\omega_m\\) corresponds to the geometric mean of the zero and pole frequencies (as previously derived in discussions of \\(\\omega_m\\)), and substituting \\(\\omega_m\\) back into the magnitude formula we obtain the magnitude at \\(\\omega_m\\), which simplifies to: \\[10 \\log (1/\\alpha)\\]",
    "crumbs": [
      "Principles of Automatic Control: Lead and Lag Compensation"
    ]
  },
  {
    "objectID": "compensator_design_using_frequency_response_plots.html#designing-with-specific-requirements",
    "href": "compensator_design_using_frequency_response_plots.html#designing-with-specific-requirements",
    "title": "Principles of Automatic Control: Lead and Lag Compensation",
    "section": "Designing with Specific Requirements",
    "text": "Designing with Specific Requirements\nLet’s now focus on a design scenario where we aim to meet certain specifications with our control system. Imagine an uncompensated system represented by b \\[G(s) = \\frac{K}{s(s+1)}\\]\nwith design requirements of a velocity error constant \\(K_v = 12\\) and a phase margin \\(\\phi_{pm}=40^\\circ\\).\n\nStep One: Determine \\(K\\) to satisfy \\(K_v\\). For \\(K_v = 12\\), we deduce \\(K\\) must also equal 12, given the direct relationship in this system setup:\n\nFor a given system with a transfer function \\(G(s)\\), the velocity error constant \\(K_v\\) is defined as:\n\\[ K_v = \\lim_{s \\to 0} sG(s) \\]\nand we can substitute \\(G(s)\\) into the formula for \\(K_v\\):\n\\[ K_v = \\lim_{s \\to 0} s \\left( \\frac{K}{s(s+1)} \\right) = \\lim_{s \\to 0} \\frac{K}{s+1} \\]\nAs \\(s\\) approaches 0, the expression simplifies to:\n\\[ K_v = \\frac{K}{0+1} = K = 12 \\]\n\nStep Two: Incorporate \\(D(s)\\), ensuring it does not alter \\(K_v\\). The compensator \\(D(s) = \\frac{\\tau s + 1}{\\alpha \\tau s + 1}\\) is structured to enhance phase margin without affecting \\(K_v\\).\n\nWith \\(K_v\\) now established, we turn our attention to the system’s phase margin.\nTo do this, we need to understand the uncompensated system first.\nConsider our system represented by the transfer function in the frequency domain:\n\\[ G(j\\omega) = \\frac{12}{j\\omega(j\\omega + 1)} \\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# Define the transfer function G(s) = 12 / (s*(s + 1))\nnumerator = [12]\ndenominator = [1, 1, 0]\nG_s = control.TransferFunction(numerator, denominator)\n\n# Generate Bode plot with margins\nmag, phase, omega = control.bode(G_s, dB=True, Plot=False)\n\n# Calculate margins for annotation\ngm, pm, sm, gc = control.margin(G_s)\npm_deg = pm if pm &gt; 0 else pm + 360  # Ensure phase margin is positive for display\n\n# Convert magnitude from absolute to dB\nmag_dB = 20 * np.log10(mag)\n\n# Plotting magnitude\nplt.figure()\nplt.semilogx(omega, mag_dB)\nplt.axhline(y=0, color='g', linestyle='--')  # 0 dB line\nplt.axvline(x=gc, color='r', linestyle='--')  # Gain crossover frequency line\nplt.title('Magnitude Plot with 0 dB Crossover')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Magnitude (dB)')\nplt.grid(True)\n\n# Plotting phase\nplt.figure()\nplt.semilogx(omega, phase * (180/np.pi))  # Convert phase from radians to degrees\nplt.axvline(x=gc, color='r', linestyle='--')  # Gain crossover frequency line\nplt.axhline(y = -180 + pm_deg, color = 'g', linestyle = '--')  # Phase Margin line\nplt.text(gc, -180 + pm_deg, f'PM = {pm_deg:.2f}° at ω = {gc:.2f} rad/s', va='bottom')\nplt.title('Phase Plot with Phase Margin')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Phase (degrees)')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo grasp the system’s behavior, we sketch the Bode plot, focusing first on the magnitude plot. The term \\(\\frac{12}{j\\omega}\\) indicates a slope of \\(-20\\) dB per decade starting from the origin, representing the system’s initial roll-off due to the single integrator term.\nThe additional term, \\(j\\omega + 1\\), introduces a pole at \\(\\omega = 1\\), further steepening the slope to \\(-40\\) dB per decade beyond this corner frequency.\nFor the phase angle plot, our system exhibits characteristic shifts due to its pole at \\(\\omega = 1\\). Initially, the phase begins at \\(-90^\\circ\\) (due to the integrator), and the introduction of the pole at \\(\\omega = 1\\) further decreases the phase, approaching \\(-180^\\circ\\).\nThis behavior is typical of a Type-1 system, which shows a phase transition from \\(-90^\\circ\\) to \\(-180^\\circ\\) as the frequency increases.\nUpon analyzing the system’s phase behavior, we note that our current setup yields a phase margin of approximately \\(15^\\circ\\).\nHowever, our design specification requires a phase margin of \\(40^\\circ\\), indicating that we are currently \\(25^\\circ\\) short of our target. This discrepancy highlights the need for compensatory measures to enhance the system’s phase margin to the desired level.\n\n\nAdding the Controller\nWhen you cascade (or combine) two systems, such as adding a lead compensator to an existing system, the resulting Bode plot is effectively the sum of the individual Bode plots of those systems. This additive property is particularly useful in the logarithmic scale used in Bode plots, where the multiplication of transfer functions (as in cascading systems) translates into the addition of their magnitudes and phases.\n\n\nStrategic Placement of Maximum Phase Lead (\\(\\omega_m\\))\nWe can then leverage the lead compensator to achieve a desired phase margin. The phase lead provided by the compensator peaks at a specific frequency, denoted \\(\\omega_m\\).\nBy aligning this peak phase lead (\\(\\phi_m\\)) with the critical point on the system’s frequency response where we want to enhance the phase margin, the compensator can effectively improve the system’s stability.\n\nPhase Lead Placement: The goal is to position the phase lead (\\(\\phi_m\\)) provided by the lead compensator at a frequency where it can most effectively increase the system’s phase margin. This involves adjusting the compensator’s parameters so that \\(\\omega_m\\) aligns with the frequency at which the system needs increased phase support.\nAchieving Desired Phase Margin: The phase margin (\\(\\phi_{pm}\\)) of a system is a measure of its stability, with larger margins generally indicating greater stability. By adding the lead compensator and correctly positioning its \\(\\omega_m\\), we can ensure that the system achieves a specific target phase margin, in this case, \\(25^\\circ\\), thereby enhancing the system’s robustness against oscillations and ensuring better performance.\n\n\n\nThe Challenge of Achieving the Desired Phase Margin\nIn our control system design, we aim to achieve a specific phase margin through the strategic use of a lead compensator. We’ve decided that the compensator should provide a phase lead (\\(\\phi_m\\)) of 25 degrees to meet our phase margin requirements. However, careful consideration reveals potential challenges with this approach.\nBy integrating a lead compensator to add a phase lead of 25 degrees at a particular frequency (\\(\\omega_m\\)), we intend to increase the system’s phase margin to 40 degrees. But, there’s a catch. When we add the lead compensator, not only does it contribute to the phase, but it also affects the system’s gain. This interaction can inadvertently shift the gain crossover frequency towards higher frequencies.\n\n\nThe Problem Explained\n\nGain and Phase Addition: Introducing a lead compensator influences both the phase and gain of the system. Ideally, we want to place the maximum phase lead exactly where it’s needed. However, this addition also brings an increase in gain at the corresponding frequency.\nShift in Crossover Frequency: The increased gain at the target frequency might push the gain crossover frequency to the right (towards higher frequencies). This shift is crucial because it can alter the phase margin we aim to achieve.\nImpact on Phase Margin: Suppose the original system provided a phase of 15 degrees at the gain crossover frequency, and we anticipated that adding 25 degrees of phase lead would suffice. Due to the shift in crossover frequency, the actual contribution from the original system may decrease, potentially leaving us short of the desired 40 degrees of phase margin.\n\n\n\nSolution: Adjusting for Safety Margin\nTo counteract this potential shortfall, we introduce a safety margin by adjusting our target phase lead upwards. Instead of aiming for 25 degrees, we target a higher phase lead (\\(\\phi_m\\)) of 30 degrees, accounting for 5 degrees of safety margin. This adjustment helps ensure that even with the shift in crossover frequency, we can still achieve or surpass our desired phase margin of 40 degrees.\n\n\nCalculating Compensator Parameters\nWith this revised target, the required phase lead \\(\\phi_m\\) is not just based on the desired phase margin (\\(\\phi_{pm}\\)) but also includes a buffer (\\(\\epsilon\\)), resulting from potential phase reduction due to the gain crossover shift.\nHence, we calculate \\(\\phi_m\\) (the required phase lead) as:\n\\[ \\phi_m = \\phi_{pm} - \\phi_{uncompensated} + \\epsilon \\]\nGiven \\(\\phi_{pm} = 40^\\circ\\), \\(\\phi_{uncompensated} = 15^\\circ\\), and \\(\\epsilon = 5^\\circ\\), we find \\(\\phi_m = 30^\\circ\\). This calculation guides us in setting the compensator parameters, specifically \\(\\alpha\\), to achieve the necessary phase lead.\nIn thi case:\n\\[\n\\alpha = \\frac{1-\\sin(30)}{1+\\sin(30)} = 0.334\n\\]\n\n\nComments\n\nThis approach underlines the iterative nature of control system design, blending theoretical calculations with practical considerations to navigate the complexities of achieving desired system behavior.\nThe example illustrates the importance of flexibility and adjustment in design parameters to meet specific performance criteria, showcasing the adaptability required in effective control system design.\n\n\n\nDetermining the Time Constant (\\(\\tau\\))\nAfter deciding on the phase lead (\\(\\phi_m\\)) provided by the compensator, the next step is to determine the appropriate time constant (\\(\\tau\\)) for the compensator. This is crucial because \\(\\tau\\) influences the frequency (\\(\\omega_m\\)) at which the compensator provides the maximum phase lead.\n\n\nThe Concept of Gain Crossover Frequency\nThe gain crossover frequency (\\(\\omega_{gc}\\)) is the frequency at which the system’s gain crosses the 0 dB line. Ideally, after adding the lead compensator, \\(\\omega_m\\) should align with a new gain crossover frequency, enhancing the system’s phase margin to the desired level.\nHowever, an important consideration is how the addition of gain from the compensator affects the system’s gain crossover frequency, potentially shifting it. This shift is important because it directly impacts the system’s phase margin.\n\n\nAdjusting for the New Gain Crossover Frequency\nIn the scenario where we aim for a phase margin increase, it’s noted that the compensator will also add gain at \\(\\omega_m\\).\nSpecifically, the compensator adds a magnitude of \\(4.8\\) dB at \\(\\omega_m\\), calculated as \\(10 \\log \\frac{1}{\\alpha}\\) (see picture above).\nTo accommodate this, we anticipate that the new gain crossover frequency (\\(\\omega_{gc}'\\)) will be where the original, uncompensated system’s gain is \\(-4.8\\) dB.\nThis adjustment ensures that when the compensator’s gain is added, the total system gain at \\(\\omega_{gc}'\\) will cross the 0 dB threshold, achieving the new gain crossover frequency.\n\n\nCalculating \\(\\tau\\)\nTo find \\(\\tau\\), we consider that \\(\\omega_m\\) (where we place the compensator’s maximum phase lead) should ideally be at \\(\\omega_{gc}'\\). Given the relationship between \\(\\omega_m\\) and \\(\\tau\\), and knowing the desired new crossover frequency from our adjustments, we can solve for \\(\\tau\\).\nGiven a gain adjustment of \\(4.8\\) db, the new the new crossover frequency is determined to be \\(4.6\\) radians per second.\nFinally, we use the formula relating \\(\\omega_m\\) and \\(\\tau\\) to calculate the exact value of \\(\\tau\\):\n\\[\\omega_m = \\sqrt{\\frac{1}{\\tau} \\frac{1}{\\alpha \\tau}} = 4.6\\]\n\n\n\n\n\n\n\nand the controller is:\n\\[\nD(s) = \\frac{0.376s+1}{0.128s+1}\n\\]\n\n\nOptimization and Verification\nIt is important to verify that the compensator meets the phase margin requirement without unduly sacrificing system bandwidth.\nOptimizing the control system design is an iterative process. After implementing the compensator, we need to re-evaluate the system’s phase margin and gain crossover frequency.\nIf the phase margin achieved is slightly above or below the target, minor adjustments might be necessary. This iterative refinement ensures the system meets design specifications while maintaining a balance between performance and stability.\nThe system we need to verify is now the open-loop transfer function of the compensated system:\n\\[\nKG(s)D(s) = \\frac{12}{s(s+1)}\\frac{0.376s+1}{0.128s+1}\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control.matlab as control\n\n# Define the transfer function G(s) = 12 / (s(s + 1))\nnumerator_G = [12]\ndenominator_G = [1, 1, 0]\nG_s = control.TransferFunction(numerator_G, denominator_G)\n\n# Define the transfer function D(s) = (0.376s + 1) / (0.128s + 1)\nnumerator_D = [0.376, 1]\ndenominator_D = [0.128, 1]\nD_s = control.TransferFunction(numerator_D, denominator_D)\n\n# Combine G(s) and D(s) to get the overall open-loop transfer function KG(s)D(s)\nKGD_s = G_s * D_s\n\n# Generate Bode plot with margins\n# Generate Bode plot with margins for the combined transfer function\n# mag, phase, omega = control.bode(KGD_s, dB=True)\nmag, phase, omega = control.bode(KGD_s, dB=True, Plot=False)\n\n# Calculate margins for annotation\ngm, pm, sm, gc = control.margin(KGD_s)\npm_deg = pm if pm &gt; 0 else pm + 360  # Ensure phase margin is positive for display\n\n# Convert magnitude from absolute to dB\nmag_dB = 20 * np.log10(mag)\n\n# Plotting magnitude\nplt.figure()\nplt.semilogx(omega, mag_dB)\nplt.axhline(y=0, color='g', linestyle='--')  # 0 dB line\nplt.axvline(x=gc, color='r', linestyle='--')  # Gain crossover frequency line\nplt.title('Magnitude Plot with 0 dB Crossover')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Magnitude (dB)')\nplt.grid(True)\n\n# Plotting phase\nplt.figure()\nplt.semilogx(omega, phase * (180/np.pi))  # Convert phase from radians to degrees\nplt.axvline(x=gc, color='r', linestyle='--')  # Gain crossover frequency line\nplt.axhline(y = -180 + pm_deg, color = 'g', linestyle = '--')  # Phase Margin line\nplt.text(gc, -180 + pm_deg, f'PM = {pm_deg:.2f}° at ω = {gc:.2f} rad/s', va='bottom')\nplt.title('Phase Plot with Phase Margin')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Phase (degrees)')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportance of Verification\nOnce you’ve calculated the compensator’s parameters, including the time constant (\\(\\tau\\)) and adjusted for the new gain crossover frequency (\\(\\omega_{gc}'\\)), a thorough check of the system’s performance is necessary. This step is to validate whether the adjustments have indeed realized the target phase margin.\n\n\nAdjusting for Safety Margin (\\(\\epsilon\\))\nDuring the design, a safety margin (\\(\\epsilon\\)) is considered to account for uncertainties or approximations in calculations. If, upon verification, the actual phase margin achieved deviates from the target, adjustments may be needed.\n\nIf the phase margin is higher than the target (for example, achieving 42 or 43 degrees when the target is 40 degrees), this is generally acceptable. It indicates the system is potentially more stable than initially required, which is often beneficial.\nIf the phase margin is slightly lower (say, 38 or 39 degrees instead of 40 degrees), while not ideal, it might still be acceptable depending on the system’s overall performance and stability requirements.\n\nThis flexibility in the design process acknowledges that while we strive to meet specific targets, practical considerations and the inherent complexity of dynamic systems may lead to slight deviations from these ideals.\n\n\nIterative Design Process\nThe design and optimization of a control system, especially when integrating components like lead compensators, is inherently iterative. After initial calculations and system adjustments:\n\nPerform simulations or generate Bode plots to assess how the compensator influences the system’s phase margin and bandwidth.\nEvaluate the results against the desired specifications. If the system’s phase margin is within a reasonable range of the target, consider whether further adjustments are necessary.\nConsider adjusting \\(\\epsilon\\), the safety margin, if initial results are not satisfactory. Increasing \\(\\epsilon\\) may provide additional buffer to achieve the desired phase margin, especially if initial assumptions were too conservative or if the system response varies from theoretical predictions.\n\n\n\nComment\n\nIf a phase margin of 40 degrees is required, why not aim for a larger margin, like 50 or 60 degrees, to increase system stability?\n\n\nUnderstanding Phase Margin and Its Impact\nThe phase margin is a measure of system stability, with a higher phase margin generally indicating a more stable system. However, increasing the phase margin beyond certain limits comes with trade-offs:\n\nShift in Crossover Frequency: Increasing the phase margin typically involves shifting the gain crossover frequency ((_{gc})). The gain crossover frequency is a critical parameter that influences the system’s bandwidth. As the phase margin increases, the crossover frequency tends to decrease, which can reduce the system’s bandwidth.\nBandwidth Limitations: The system’s bandwidth determines how quickly it can respond to changes. A larger bandwidth allows for faster response but can also introduce more noise into the system, potentially affecting performance. There’s often a practical limit to how much bandwidth is beneficial or necessary for a given application.\nNoise Filtering Considerations: High-bandwidth systems are more susceptible to noise, necessitating additional noise filtering measures. This can complicate the system design and potentially introduce more points of failure or inefficiency.\nTrade-offs with Other Requirements: Designing a control system involves balancing various requirements, including stability, responsiveness, and noise immunity. Increasing the phase margin significantly may compromise other aspects of system performance, such as responsiveness or noise handling.\n\n\n\nDesign Philosophy: Meeting Specifications on the Boundary\n\nIn practice, when design specifications are given, the goal is usually to meet these specifications as closely as possible without exceeding them unnecessarily. This approach ensures that the system is optimized for the intended application without over-engineering for stability at the expense of other performance metrics. By designing to meet specifications on the boundary, engineers can provide adequate safety margins for stability while preserving system performance and efficiency.\nWhile aiming for a higher phase margin than required might seem like an effective way to ensure system stability, it’s essential to consider the associated trade-offs. The optimal design balances stability with performance, ensuring the system meets its intended function efficiently and effectively without unnecessary compromises. In cases where stability and bandwidth are both critical, a nuanced approach to system design is necessary to achieve the best overall performance.\n\n\n\nUnderstanding Bandwidth from Bode and Nichols Charts\nBandwidth and Bode Plot: The Bode plot is a fundamental tool in control system analysis, offering insights into how the system responds across different frequencies. While the gain crossover frequency (where the gain crosses the 0 dB line) hints at the system’s bandwidth, it doesn’t provide a complete picture. Bandwidth, which is the range of frequencies over which the system effectively operates, is influenced by how quickly the gain drops off beyond the crossover point.\nNichols Chart for Detailed Bandwidth Analysis: For a more precise determination of bandwidth, the Nichols chart is invaluable. It plots the system’s gain and phase together, allowing you to identify the -3 dB contour. The intersection of the system’s response curve with this -3 dB line gives a clear indication of the bandwidth. This method is particularly useful because it considers both gain and phase, offering a comprehensive view of the system’s frequency response.\n\n\n\nThe Design Cycle and Adjustments\nDesigning a control system, such as incorporating a lead compensator, is an iterative process. It involves making initial calculations, implementing changes, and then verifying if those adjustments meet the design requirements.\n\nInitial Adjustments and Verifications: After setting the compensator parameters, you should first verify if the phase margin meets the design goals. The phase margin is critical because it indicates the system’s stability margin. If it’s around the target value (e.g., 40 degrees), even if slightly higher or lower, the system is generally considered stable.\nNichols Chart for Bandwidth Verification: If the design also specifies a bandwidth requirement, translating the compensated system’s data onto the Nichols chart helps verify if the design meets this criterion. If the actual bandwidth differs from the requirement, you might need to adjust the compensator’s parameters.\n\n\n\nIterative Refinements Based on Outcomes\n\nAdjusting Safety Margin (\\(\\epsilon\\)): The safety margin in the design accounts for uncertainties. If the phase margin or bandwidth isn’t satisfactory, consider adjusting this margin. For instance, increasing \\(\\epsilon\\) might provide a larger buffer to achieve the desired phase margin, but it’s essential to balance this against potential impacts on bandwidth.\nBalancing Stability and Performance: It’s important to balance achieving a high phase margin with maintaining adequate bandwidth. A very high phase margin could unnecessarily restrict bandwidth, affecting the system’s responsiveness. Thus, aiming for specifications that meet the system’s operational requirements without excessive conservatism is key.\nFeedback and Next Steps: Should the design not meet all requirements after initial adjustments, the process entails revisiting the design parameters. This might involve a more nuanced adjustment of the compensator parameters or even considering additional compensatory measures, like a lag compensator, to satisfy all criteria.\n\n\n\n\nSIDEBAR - Bandwidth and Bode Plots\nUsing the Bode plot of the open-loop transfer function to determine the bandwidth of a control system can be misleading due to the fundamental differences between open-loop and closed-loop behaviors. Here’s why the open-loop Bode plot isn’t typically used to determine bandwidth:\n\n\n1. Definition of Bandwidth:\nBandwidth is conventionally defined as the range of frequencies over which the closed-loop system maintains a certain level of performance, often measured as the frequency range within which the system’s gain stays within 3 dB of its low-frequency value. This concept inherently applies to how the system responds when it’s operating in a closed-loop configuration because it’s about the system’s ability to follow its input.\n\n\n2. Feedback Effects:\nFeedback significantly alters the system’s frequency response. An open-loop system might show a certain gain and phase characteristic that changes drastically once feedback is applied. The closed-loop response can exhibit reduced gain at high frequencies, improved stability margins, and altered resonance characteristics, none of which are apparent in the open-loop Bode plot.\n\n\n3. Stability and Performance:\nClosed-loop stability and performance metrics such as phase margin and gain margin are directly visible and measurable on the closed-loop Bode plot. These metrics are critical for understanding the system’s robustness and its ability to reject disturbances or handle variations in system dynamics. The open-loop Bode plot provides some predictive insight into these metrics, but it doesn’t show the actual closed-loop behavior.\n\n\n4. Real-world Relevance:\nThe closed-loop configuration is what is actually implemented in most control systems to achieve desired performance and stability. Therefore, analyzing the Bode plot of the closed-loop system gives a more accurate and relevant depiction of how the system will perform in real-world conditions, including its bandwidth.\n\n\n5. Misinterpretation Risk:\nRelying solely on the open-loop Bode plot might lead to misinterpretations about the system’s ability to process signals across different frequencies. For example, an open-loop system might appear to have a wide bandwidth because of high gain at higher frequencies. However, once feedback is considered, the effective bandwidth (where the system accurately follows the input) might be significantly narrower due to the gain reduction introduced by feedback.\n\n\nConclusion:\nWhile the open-loop Bode plot is valuable for designing and understanding certain aspects of control systems, such as potential stability and the general shape of the frequency response, it cannot accurately determine closed-loop bandwidth. Closed-loop analysis is essential for an accurate representation of system performance, making the closed-loop Bode plot the preferred tool for bandwidth determination and overall system analysis.\n— END OF SIDEBAR\n\n\n\nQuestions for Reinforcement\n\nPop-up Question: What is the primary purpose of a lead compensator in control system design?\n\nAnswer: To improve the transient response of a system by introducing a phase lead, which can help meet desired performance specifications such as reduced overshoot and improved settling time.\n\nPop-up Question: How does the parameter \\(\\alpha\\) affect the performance of a lead compensator?\n\nAnswer: The parameter \\(\\alpha\\) controls the separation between the pole and zero of the compensator. A smaller \\(\\alpha\\) value increases the distance between the pole and zero, enhancing the compensator’s phase-lead characteristic and its impact on system performance.",
    "crumbs": [
      "Principles of Automatic Control: Lead and Lag Compensation"
    ]
  },
  {
    "objectID": "compensator_design_using_frequency_response_plots.html#chapter-on-lag-compensators",
    "href": "compensator_design_using_frequency_response_plots.html#chapter-on-lag-compensators",
    "title": "Principles of Automatic Control: Lead and Lag Compensation",
    "section": "Chapter on Lag Compensators",
    "text": "Chapter on Lag Compensators\nAfter having discussed the lead compensators, we now turn our attention to their counterparts: lag compensators. While lead compensators are designed to improve the transient response by adding phase lead, lag compensators serve a different purpose. They are primarily used to enhance the steady-state accuracy of a control system without significantly degrading its transient performance.",
    "crumbs": [
      "Principles of Automatic Control: Lead and Lag Compensation"
    ]
  },
  {
    "objectID": "compensator_design_using_frequency_response_plots.html#the-principle-of-lag-compensation",
    "href": "compensator_design_using_frequency_response_plots.html#the-principle-of-lag-compensation",
    "title": "Principles of Automatic Control: Lead and Lag Compensation",
    "section": "The Principle of Lag Compensation",
    "text": "The Principle of Lag Compensation\nLag compensators are characterized by a transfer function that introduces a phase lag over a specific frequency range. This is achieved by adding a pole-zero pair to the system, where the pole is placed closer to the origin on the s-plane than the zero. The general form of a lag compensator’s transfer function can be represented as:\n\\[ D(s) = \\frac{\\tau s + 1}{\\beta \\tau s + 1} \\]\nwhere \\(\\tau &gt; 0\\) and \\(\\beta &gt; 1\\). The factor \\(\\beta\\) determines the distance between the pole and the zero, with larger values indicating a greater separation.\n\n\n\n\n\n\n\n\nFrequency Domain Analysis of Lag Compensators\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom ipywidgets import interact, FloatSlider\n\n# Function to plot the Bode plot of the lag compensator with annotations\ndef plot_lag_compensator_with_annotations(tau=1.0, beta=2.0):\n    # Define the transfer function of the lag compensator\n    numerator = [tau, 1]\n    denominator = [tau*beta, 1]\n    system = signal.TransferFunction(numerator, denominator)\n    \n    # Generate Bode plot data\n    frequencies = np.logspace(-2, 2, 400)\n    w, mag, phase = signal.bode(system, w=frequencies)\n    \n    # Calculate corner frequencies\n    corner_freq_zero = 1/tau\n    corner_freq_pole = 1/(tau*beta)\n    \n    # Plotting\n    plt.figure(figsize=(14, 6))\n    \n    ## Magnitude plot\n    plt.subplot(1, 2, 1)\n    plt.semilogx(w, mag) # Bode magnitude plot\n    plt.title('Magnitude Plot of Lag Compensator')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Magnitude [dB]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for magnitude plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(mag), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(mag), r'$\\frac{1}{\\beta\\tau}$', horizontalalignment='right', color='green')\n    \n    ## Phase plot\n    plt.subplot(1, 2, 2)\n    plt.semilogx(w, phase) # Bode phase plot\n    plt.title('Phase Plot of Lag Compensator')\n    plt.xlabel('Frequency [rad/s]')\n    plt.ylabel('Phase [degrees]')\n    plt.grid(which='both', axis='both')\n    \n    # Annotations for phase plot\n    plt.axvline(x=corner_freq_zero, color='r', linestyle='--')\n    plt.axvline(x=corner_freq_pole, color='g', linestyle='--')\n    plt.text(corner_freq_zero, min(phase), r'$\\frac{1}{\\tau}$', horizontalalignment='right', color='red')\n    plt.text(corner_freq_pole, min(phase), r'$\\frac{1}{\\beta\\tau}$', horizontalalignment='right', color='green')\n    \n    plt.show()\n\n# Interactive widget\ninteract(plot_lag_compensator_with_annotations, \n         tau=FloatSlider(value=1.0, min=0.1, max=10.0, step=0.1, description='Tau (τ)'),\n         beta=FloatSlider(value=2.0, min=1.01, max=10.0, step=0.05, description='Beta (β)'));\n\n\n\n\n\nMagnitude Response\nThe Bode plot for a lag compensator reveals how it affects the system’s frequency response.\nThe first corner frequency occurs at \\(\\omega = \\frac{1}{\\beta \\tau}\\), corresponding to the pole, and results in a decrease in magnitude.\nThe second corner frequency, at \\(\\omega = \\frac{1}{\\tau}\\), corresponds to the zero, partially compensating for the decrease. However, the net effect over the entire frequency range is minimal, except for the phase lag introduced.\n\n\nPhase Response\nThe phase plot of a lag compensator showcases its primary characteristic: the introduction of phase lag within a certain frequency range. This lagging effect is most pronounced between the pole and zero frequencies, after which the system’s phase response begins to normalize.\nPop-up Question: What is the main use of a lag compensator in control systems? - Answer: A lag compensator is mainly used to improve the steady-state error of a control system without significantly affecting its transient response. It introduces a phase lag that is carefully managed to avoid negative impacts on the system’s overall performance.\n\n\n\nDesign Considerations and Application\nWhen designing a lag compensator, one must carefully select the values of \\(\\tau\\) and \\(\\beta\\) to achieve the desired steady-state performance without compromising the system’s stability or responsiveness. The goal is to enhance the system’s gain at low frequencies (for improved steady-state accuracy) while maintaining an acceptable phase margin.\nIn practice this means that we will not be using the lag part to be important for our compensation. For this reason, we do not need to understand exactly when the maximum lag will occur.\n\n\nDesign Example: Enhancing Phase Margin and Bandwidth\nConsider a system with a transfer function\n\\[G(s) = \\frac{K}{s(s+1)(s+4)}\\]\nthat we can re-write as:\n\\[G(j\\omega) = \\frac{K/4}{j\\omega(j\\omega + 1)(0.25j\\omega + 1)}\\]\nwhere the design objectives include a phase margin of \\(\\phi_{pm}=43^\\circ\\), a bandwidth of \\(\\omega_b=1.02\\) radians per second, and a velocity error constant \\(K_v \\geq 5\\).\nStep 1: Satisfying \\(K_v\\) Requirement\nThe first step involves adjusting the system gain \\(K\\) to meet the \\(K_v\\) requirement. For instance, if \\(K_v = 5\\) dictates \\(K = 20\\), the modified transfer function becomes:\n\\[G(j\\omega) = \\frac{5}{j\\omega(j\\omega + 1)(0.25j\\omega + 1)}\\]\nStep 2: Asymptotic Sketch and Phase Margin Adjustment\nAn asymptotic sketch of the uncompensated system helps visualize the necessary adjustments.\nIt is easy to draw the Bode plots (corner frequencies are \\(\\omega=1\\) and \\(\\omega=4\\).\n\nimport numpy as np\n\n# Define the polynomials as sequences of coefficients\n# For s, the polynomial is s, represented as [1, 0]\n# For s + 1, the polynomial is represented as [1, 1]\n# For 0.25s + 1, the polynomial is represented as [0.25, 1]\n\n# Perform polynomial multiplication\nresult_poly = np.polymul([1, 0], [1, 1])  # Multiply s and (s + 1)\nresult_poly = np.polymul(result_poly, [0.25, 1])  # Multiply the result by (0.25s + 1)\n\n# Print the resulting polynomial\nprint(\"The resulting polynomial coefficients are:\", result_poly)\n\nThe resulting polynomial coefficients are: [0.25 1.25 1.   0.  ]\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n# Define the transfer function G(s) = 5 / (s(s + 1)(0.25s + 1))\nnumerator = [5]\ndenominator = [0.25, 1.25, 1.,   0.]  # Corresponds to 0.25s^3 + 1.25s^2 + s\nG_s = control.TransferFunction(numerator, denominator)\n\n# Generate Bode plot with margins\nmag, phase, omega = control.bode(G_s, dB=True, Plot=False)\n\n# Calculate margins for annotation\ngm, pm, sm, gc = control.margin(G_s)\npm_deg = pm if pm &gt; 0 else pm + 360  # Ensure phase margin is positive for display\n\n# Plotting\nplt.figure(figsize=(14, 7))\n\n## Magnitude plot\nplt.subplot(1, 2, 1)\nplt.semilogx(omega, 20*np.log10(mag))\nplt.title('Magnitude Plot')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Magnitude (dB)')\nplt.grid(True)\n\n## Phase plot\nplt.subplot(1, 2, 2)\nplt.semilogx(omega, np.rad2deg(phase))\nplt.title('Phase Plot')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Phase (degrees)')\nplt.grid(True)\n\n# Display the phase margin on the plot\nplt.axhline(y = -180 + pm_deg, color = 'r', linestyle = '--')\nplt.text(gc, -180 + pm_deg + 5, f'Phase Margin: {pm_deg:.2f}° at ω = {gc:.2f} rad/s', color = 'red')\n\nplt.tight_layout()\nplt.show()\n\n# Print the phase margin value\nprint(f\"Phase Margin: {pm_deg:.2f}° at ω = {gc:.2f} rad/s\")\n\n\n\n\n\n\n\n\nPhase Margin: 0.00° at ω = 2.00 rad/s\n\n\nwhere the phase angle curve is:\n\\[\n\\phi = -90 - tan^{-1}(\\omega) - tan^{-1}(0.25\\omega)\n\\]\nTo increase the phase margin to the required \\(43^\\circ\\), one might consider shifting the low-frequency region of the Bode plot downwards. This approach hints at utilizing a lag compensator to pull the gain crossover frequency to the left, thereby increasing the phase margin.\nPop-up Question: Why is it preferable to place the maximum attenuation of a lag compensator at the low-frequency region? - Answer: Placing the maximum attenuation at the low frequency ensures that the steady-state gain of the system is increased without significantly affecting the high-frequency gain. This strategy improves the system’s phase margin by ensuring that the gain crossover frequency shifts leftward, aligning with the desired phase margin improvement.\nNote that the phase margin means that the system, with the selected \\(K\\), has become unstable.\n\n\nStep 3. Incorporating the Lag Compensator\nThe crux of lag compensation lies in strategically introducing phase lag at low frequencies without excessively diminishing the bandwidth.\nThis is accomplished by ensuring the compensator’s corner frequency is positioned judiciously relative to the desired phase margin frequency.\nThe crossover frequency is where the system’s gain crosses a certain threshold, typically the 0 dB line. This frequency is a cornerstone in determining the system’s phase margin and bandwidth.\n\nLag Compensator: Reducing Bandwidth\nA lag compensator is employed to improve the system’s steady-state error without significantly degrading its transient response. However, it introduces a phase lag and decreases the system’s gain at higher frequencies. This decrease in gain at higher frequencies causes the gain crossover frequency to shift left (towards lower frequencies), inherently reducing the system’s bandwidth.\nKey Points: - Phase Lag: Lag compensators introduce a phase lag, predominantly affecting lower frequency ranges. - Decrease in Bandwidth: By pulling down the low-frequency region of the gain plot, the gain crossover frequency decreases, leading to a reduction in bandwidth. This also makes it possible to improve the phase margin.\n\n\nLead Compensator: Increasing Bandwidth\nConversely, a lead compensator aims to improve the transient response by introducing a phase lead. This compensator increases the system’s gain at higher frequencies, causing the gain crossover frequency to shift right (towards higher frequencies), effectively increasing the system’s bandwidth.\nKey Points: - Phase Lead: Lead compensators introduce a phase lead, beneficial for improving system stability. - Increase in Bandwidth: Elevating the gain in the high-frequency region shifts the crossover frequency rightward, enhancing the bandwidth.\n\n\nA General Guideline to Choose the Compensators\nWhen faced with a design problem, choosing between a lag or lead compensator depends on the existing system characteristics and the desired outcomes:\n\nEvaluating the Uncompensated System: Begin by analyzing the uncompensated system’s bandwidth. If it’s significantly higher or lower than required, this analysis will guide the choice between adding a lag or lead compensator.\nBalancing Phase Margin and Bandwidth: In scenarios where both the phase margin and bandwidth do not meet the design criteria, a dual approach is adopted—first employing a lag compensator to adjust the phase margin, followed by a lead compensator to rectify the bandwidth.\n\n\nA Dual-Compensator Approach\nFor comprehensive system tuning, it’s feasible to divide the phase margin requirement into two segments—addressed by both lag and lead compensators. This dual-compensator approach allows for a nuanced tuning process, ensuring both stability (through phase margin adjustment) and responsiveness (through bandwidth optimization) are achieved.\nIn this case: - We start from the design of the lag compensator, which meets the phase margin requirements - Add lead section to increase the bandwidth\n\nSplit Phase Margin Requirement: If a total phase margin of 60 degrees is needed, you might use a lag compensator to achieve the first 30 degrees, adjusting the gain crossover frequency and slightly impacting the bandwidth. Subsequently, a lead compensator can be employed to attain the remaining 30 degrees, ideally restoring or enhancing the bandwidth to meet the system requirements.\n\n\n\n\n\nSelecting the Corner Frequency\n\n\n\n\n\n\n\n\nWe want to new crossover frequency where the lag compensator provides the maximum attentuation (it is possible to verify that the maximum attenuation is: \\(20\\log{\\beta})\\).\nThe region of maximum attenuator however extends from \\(\\frac{1}{\\tau}\\) to infinity. So what point should we take?\n\nLag compensators inherently introduce a phase lag, particularly noticeable at the corner frequency where the compensator’s effect transitions from minimal to significant. This phase lag can detract from the system’s overall phase margin, leading to less stability than intended. For example, aiming directly for a 43-degree phase margin without accounting for this phase lag could result in an actual margin lower than anticipated, such as 35 degrees, due to the negative contribution of the compensator.\n\n\nStrategy for Addressing Phase Lag\nTo counteract the unexpected reduction in phase margin due to the compensator’s phase lag, the design process involves considering an additional safety margin (denoted as epsilon, \\(\\epsilon\\)) on top of the desired phase margin. This approach means aiming for a higher phase margin during the design phase to ensure that, even after accounting for the phase lag introduced by the compensator, the system achieves the intended phase margin.\n\nExample Implementation\nIn the given scenario, to achieve an effective phase margin of 43 degrees, the designer considers a safety margin of 12 degrees, leading to a target phase margin of 55 degrees before compensator effects. This adjusted target compensates for the phase lag introduced by the compensator, ensuring the final design meets the original stability requirements.\n\n\n\nPractical Considerations\n\nRealization Challenges: Additionally there are practical challenge of realizing specific compensator values, particularly \\(1/\\tau\\) and \\(1/\\beta\\tau\\), using real components (like resistors and capacitors). Extreme values for these parameters could complicate the physical implementation of the compensator and this limits in practice their maximum value.\n\n\n\nChoosing the Corner Frequency\nA strategic decision involves setting the corner frequency for the compensator’s effect.\nThe guideline is to place this frequency approximately two octaves below the frequency associated with the desired phase margin, based on a qualitative assessment rather than a strict formula. This rule of thumb helps balance between achieving the necessary phase margin adjustment and maintaining practical component values for the compensator.\nThe guideline suggests positioning this frequency approximately two octaves below the frequency where a phase margin of \\(43^\\circ + \\epsilon\\) is desired (each octave provides a frequency ratio of 2:1), with \\(\\epsilon\\) representing a safety margin to account for the inherent phase lag introduced by the compensator.\nIn our example, aiming for a phase margin of \\(55^\\circ\\) (i.e., \\(43^\\circ + 12^\\circ\\)) leads to identifying \\(0.52\\) radians per second as the critical frequency. Consequently, the corner frequency is set to \\(\\frac{1}{\\tau} = \\frac{0.52}{4} = 0.13\\) radians per second, fulfilling our qualitative guideline.\nTrial and error might be required.\n\nChoosing \\(\\beta\\)\nWith the corner frequency established, the next step involves calculating the compensator’s parameters, \\(\\tau\\) and \\(\\beta\\), to achieve the desired attenuation at the specified frequency. In this context, achieving a \\(20\\) dB attenuation dictates that \\(\\beta = 10\\):\n\nThe second parameter of the compensator comes from the maximum attenuation: \\(20\\log{\\beta}\\).\nWe want that at point \\(0.13\\) the gain plot attenuates approximately \\(20\\) db\n\n\\[20\\log{\\beta} = 20 \\rightarrow \\beta = 10\\]\n\n\n\n\n\n\n\nAnd hence the compensator parameters are:\n\n\\(\\tau = 1/0.13=7.7\\)\n\\(\\beta\\tau = 10 \\cdot 7.7 = 77\\)\n\n\\[D(s) = \\frac{7.7s + 1}{77s + 1}\\]\n\n\nStep 4. Validation and Iteration\nThe final design phase entails validating the compensator’s effectiveness by integrating \\(D(s)\\) with the original system and analyzing the combined system’s Bode plot. This step verifies whether the adjusted phase margin and bandwidth meet the design specifications.\n\nEvaluating the Impact of Phase Lag\n\nAssessing Phase Margin: A key outcome of this analysis is observing the effect of the lag compensator on the system’s phase margin. The phase lag introduced by \\(D(s)\\) can potentially reduce the phase margin, which is critical for system stability. An adequate safety margin (\\(\\epsilon\\)) is considered to ensure that the desired phase margin (e.g., 43 degrees) is achieved despite the inherent phase lag of the lag compensator.\nAdjusting \\(\\epsilon\\): The value of \\(\\epsilon\\) is finely tuned based on the Bode plot analysis to ensure that the actual phase margin closely aligns with the target phase margin. This process might require iterative adjustments based on observed outcomes.\n\n\n\n\n\nBandwidth Considerations\n\nAnalyzing Bandwidth: Another significant aspect checked after incorporating \\(D(s)\\) is the system’s bandwidth, particularly how it’s affected by the lag compensator. The gain crossover frequency, where the system’s gain crosses 0 dB, helps determine the bandwidth.\nMaking Adjustments: If the resulting bandwidth slightly deviates from the desired bandwidth, minor adjustments to \\(\\epsilon\\) or other compensator parameters might suffice to align the bandwidth with the requirements.\nAddressing Significant Discrepancies: A substantial gap between the achieved and desired bandwidth may indicate the need for additional compensatory measures. This scenario suggests that the system, even with \\(D(s)\\) incorporated, might still lack the required performance, prompting the design to be treated as if it were “uncompensated” or in need of further compensation.\n\n\n\nIntegrating a Lead Compensator\n\nExpanding the Compensatory Approach: For cases where the lag compensator alone doesn’t meet all performance criteria, particularly bandwidth, introducing a lead compensator might be necessary. This addition aims to complement the lag compensator by enhancing the system’s bandwidth, thus achieving a balanced performance that meets both phase margin and bandwidth requirements.\n\nPop-up Question: Why is it crucial to add a safety margin (\\(\\epsilon\\)) when designing a lag compensator? - Answer: The safety margin accounts for uncertainties and non-idealities in the system’s response, ensuring the compensator achieves the desired phase margin even when unforeseen variations occur.",
    "crumbs": [
      "Principles of Automatic Control: Lead and Lag Compensation"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "",
    "text": "Instructors: - Andrea Munafo (andrea.munafo@unipi.it) - Riccardo Costanzi (riccardo.costanzi@unipi.it)",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#learning-outcomes",
    "href": "syllabus.html#learning-outcomes",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nUnderstand the fundamental principles of automatic control, including concepts such as feedback control, stability, and controllability.\nAnalyze and design control systems using mathematical models and tools, including Laplace transforms, transfer functions, and block diagrams.\nApply control strategies to various real-world engineering problems, such as temperature control, speed control, etc.\nEvaluate the performance of control systems and identify ways to improve them, including adjusting control parameters and modifying system components.\nDevelop critical thinking and problem-solving skills by applying control principles to novel and complex engineering problems, and communicating their findings effectively.\n\nYou will be well-prepared to apply the principles of automatic control to a variety of engineering fields, such as robotics, aerospace, and manufacturing, etc.",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces the design of feedback control systems. Topics include:\n\n\n\n\n\nA bit on Python/Jupyter notebook\n\n\nOpen loop vs Closed Loop\n\n\nTransfer functions and Laplace transform\n\n\nBlock Diagrams\n\n\nReponse of a system\n\n\nFrequency response and Bode plots\n\n\nFinal Value Theorem and Steady State\n\n\n\n\n\n\nSystem Stability and Control\n\n\nThe Root Locus Method\n\n\nPID controllers\n\n\nGain and phase margins\n\n\nSensitivity Functions\n\n\nLead/Lag compensators\n\n\nState space analysis",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#tutorials-and-tclab",
    "href": "syllabus.html#tutorials-and-tclab",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "Tutorials and TCLab",
    "text": "Tutorials and TCLab\nThe practical component of our course involves using the Temperature Control Lab (TCLab). This hands-on approach enhances understanding of control problems.\n\n\n\n\n\n\n\n\nYou can purchase TCLab on amazon.com for about $50, but purchasing it is not mandatory for this course. I will provide a limited number of boards, and TCLab offers simulators, which are usually sufficient for grasping the course concepts.\nGuidelines for Using TCLab: - Only one board at any time. - Schedule your TCLab time using the course Teams channel spreadsheet. When returning the board, ensure to check out. Responsibility for the board rests with the last person listed as having it on the spreadsheet.\nWeek 1: Introduction and Basics - Notebooks: - Introduction (01_intro) - Basics of Feedback Control (02_basics_of_feedback_control) - Objectives: - Understanding Control Systems and their importance in modern technology. Discussions on basic terminologies and concepts in control systems. Distinction between Open-Loop and Closed-Loop control systems. Exploring the structure and challenges of Feedback Control Systems. Design approaches for Feedback Control Systems. Historical context and evolution of control systems.\n\nTCLab Integration: Familiarization with the lab and basic setup.\n\nNotebooks: 00_Spacecraft_Thermal_Control_Systems, 01_TCLab, 01_Understanding_TCLab\nLab: 02_TCLab_Lab_1_Coding_a_relay_controller\n\nActivities: Group discussions on real-world applications of control systems.\nAssignment:\n\nInstall Python. Python is a general-purpose programming language. It is used in this course for process dynamics and control.\nInstall TCLab Libraries\n\n\nWeek 2: Mathematical Modeling - Notebooks: - Mathematical Models (03_introduction_to_control_problem), - Laplace Transforms and Transfer Functions (04_dynamic_systems), - System Response and The Final Value Theorem; Characteristics of First-Order and Second-Order systems (05_dynamic_response)\n\nObjectives:\n\nUnderstanding mathematical models and transfer functions in control systems. Real-world examples of control systems: Water Level Control, Automobile Driving System, Hydraulic Power Steering Mechanism, Residential Heating System. Introduction to Multi-Input Multi-Output (MIMO) systems. Analysis of complex control systems and their components. Block Diagram of Basic Feedback Structure.\n\nTCLab Integration: Modeling Identification\n\nNotebooks: 03_System_Model_and_Identification_TCLab, 04_Step_Testing_TCLab, 05_Fitting_Step_Test_Data_to_Empirical_Models, (optional: 05b_First-Order-Model-for-a-Single-Heater)\nLab: 06_TCLab_Lab_2_Model_Identification\n\nActivities: Problem-solving sessions to apply mathematical models to theoretical scenarios.\nAssignment: TCLab Simulate Step Response. Description: Dynamic Temperature Response of a Heater and Temperature Sensor with an Arduino\n\nWeek 3: System Response and Feedback - Notebooks:\n- Inverse Laplace Transform (06_inverse_laplace_transform) - Modeling Dynamic Systems: mechanical and thermal modeling (07_modeling_dynamic_systems) - Components of a controller (08_control_system_components) - Models of Control Devices and Systes (09_Models_of_Control_Devices_and_Systems) - Hardware and some case studies (10_hardware_and_case_studies, 11_AC_hardware_and_case_studies)\n\nObjectives:\n\nExplore system response to various inputs and the role of feedback in control systems. Time-domain analysis of systems, introduction to modelling of physical systems. Understanding hardware and exemplar case studies for practical understanding. Application of inverse Laplace transform in control systems. Methods of partial fraction decomposition for complex functions.\n\nTCLab Integration: Given the data from an identification experiment, the next task is to find one or more models that accurately reproduce the process response to changes in the manipulated variable. This notebook demonsrates a practical approach to fitting low-order models to step response data.\n\nNotebooks: -\nLab: 07_CLab_Lab_2_Fitting\n\nActivities: Interactive simulations to demonstrate the impact of feedback on system stability.\nAssignment: TCLab Convective Heat Transfer. Description: Convective Heat Transfer Prediction with a Transistor Heater. !!!\n\nWeek 4: Stability and Controllers - Notebooks: - A first complete application, temperature control system (12_A_First_Complete_Application) - Feedback Control (13_Principles_of_Feedback_Control, 14_Feedback_systems_and_their_effects) - Diving deeper on control systems: PID Controllers (Introduction to Control Systems) - Stability Analysis in Control Systems (16_Stability, 17_Stability_and_Routh_Criterion)\n\nObjectives:\n\nApplying theoretical knowledge to a complete control system application. Detailed study of feedback control principles and their applications. Analyzing the effects of feedback mechanisms in control systems. Revisiting the fundamental concepts in control systems. Study the concepts of stability in systems and feedback systems, and the basics of PID controllers. Detailed study of the Routh criterion and its application in assessing stability.\n\nTCLab Integration: Implement controllers using TCLab.\n\nNotebooks: 08_Relay_Control, 09_PID_Control\nLabs: 10_Lab-Assignment-PID-Control, 11_Lab-Assignment-PI-Control\n\nActivities: Group exercises to design basic PID controllers for given specifications.\nResources: TCLab FOPDT Model. Description: Linear Dynamic Temperature Response Model of a Heater and Temperature Sensor with an Arduino\n\nWeek 5: Advanced Control Strategies - Notebooks: - Performance of Feedback Systems (18_Performance_of_Feedback_Systems) - Design of Feedback Control: Second Order Systems (19_Design_of_feedback_control, 20_Design_of_feedback_control_continued) - Steady-state accuracy and a complete design example (21_Steady_State_Accuracy_And_Design_Principles)\n\nObjectives:\n\nStudy the concepts of performance in feedback systems. Evaluating and enhancing the performance of feedback control systems. Introduction to steady-state accuracy. Initial discussions on strategies and methodologies for designing effective feedback control systems.\n\nTCLab Integration: Continue with implementation of simple PID controllers using TCLab.\n\nWeek 6: Advanced Control Strategies: Root Locus - Notebooks: - Root Locus (22_Compensator_Design_Using_Root_Locus, 23_Design_with_the_root_locus, 24_Compensators_and_Root_Locus)\n\nObjectives:\n\nUnderstanding the Root Locus and how to use it to design control systems.\n\nTCLab Integration: TBC\nActivities: Case studies of different control strategies in computing systems.\nAssignment: Graphical Method: FOPDT to Step Test. Description: A first-order linear system with time delay is a common empirical description of many dynamic processes. Python source code demonstrates how to simulate a step test and compare with an FOPDT approximation.\n\nTCLab FOPDT Regression. Description: Linear Dynamic Temperature Response Model of a Heater and Temperature Sensor with an Arduino\nWeek 7: Advanced Control Strategies: Frequency Response - Notebooks: - Frequency Response and the Nyquist’s Criterion (25_Introduction_to_Frequency_Domain_Analysis_in_Control_Systems) - Application of the Nyquist’s Criterion (26_Application_of_Nyquist_Stability_Criterion) - Relative Stability (27_The_Nyquist_Stability_Criterion_and_Relative_Stability) - Objectives: - Understanding the Frequency Response, the Nyquist Criterion and the concept of relative stability.\n\nTCLab Integration: Design and implement a controller using TCLab.\nActivities: Case studies of different control strategies in computing systems.\nAssignment: TCLab Controller Design. Description: Design a controller for automation of temperature regulation to a setpoint. The controller adjusts a heater to regulate the temperature.\n\nWeek 8: Bode Plots, Control and Final Comments - Notebooks: - Bode Plots (28_Body_Plots) - System performance in the frequency domain (29_Feedback_system_performance_based_on_frequency_response) - Loop shaping (30_Loop_Shaping)\n\nObjectives:\n\nUnderstanding Bode Plots. Analysis of performance in the frequency domain. Loop shaping as a control strategy. Review of key concepts and preparation for the final exam.\n\nTCLab Integration: State-space modeling with TCLab.\nActivities: Q&A sessions, mock tests, and group discussions.\nAssignement:\n\nTCLab Proportional-only Control. Description: TCLab with proportional-only control has offset between the setpoint and measured temperature. The purpose of this lab activity is to quantify and verify the offset.\nTCLab PI Control. Description: TCLab with proportional integral (PI) control eliminates offset between the setpoint and measured temperature\nTCLab PID Control. Description: TCLab with proportional integral derivative (PID) control. Use IMC and ITAE tuning and compare the response",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#textbooks",
    "href": "syllabus.html#textbooks",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "Textbooks",
    "text": "Textbooks\nItalian - Bolzern, Scattolini, Schiavoni. Fondamenti di Controlli Automatici, 2nd ed. McGraw-Hill.\n\nOgata, Katsuhiko. Modern Control Engineering. 4th ed. Prentice Hall, 2002.\n\nEnglish - Ogata, Katsuhiko. Modern Control Engineering. 4th ed. Prentice Hall, 2002.\n\nM. Gopal, Control Systems Principles and Design, McGraw-Hill (3rd edition).\nRichard C. Dorf and Robert H. Bishop IE, Modern Control Systems (13th Edition).\n\nOther texts which might be helpful:\n\nG. Marro, Controlli Automatici, Zanichelli\nFranklin, Gene, J. David Powell, and Abbas Emami-Naeini. Feedback Control of Dynamic Systems. 6th ed. Prentice Hall, 2009. ISBN: 9780136019695.\nVan de Vegte, John. Feedback Control Systems. 3rd ed. Prentice Hall, 1994. ISBN: 9780002085069.\nKuo, Benjamin. Automatic Control Systems. 8th ed. John Wiley & Sons, 2003. ISBN: 9780471381488.\nOgata, Katsuhiko. Solving Control Engineering Problems with MATLAB. Prentice Hall, 1993. ISBN: 9780130459077.",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#the-role-of-software-in-the-study-of-feedback-systems",
    "href": "syllabus.html#the-role-of-software-in-the-study-of-feedback-systems",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "The Role of Software in the Study of Feedback Systems",
    "text": "The Role of Software in the Study of Feedback Systems\n\nUsing a software package like Python or MATLAB is very helpful in the study of Feedback Systems.\nThe software can best be used initially to check work that is first done traditionally with pencil and paper.\nThis is particularly helpful when verifying polar plots (Nyquist plots), Bode diagrams and root loci when first attempting to sketch these functions.\nStep responses in the time domain can be examined in order to build an intuitive sense of the relations between time and frequency domain behavior.\nSimplifying approximations that are often made when carrying out preliminary designs can be checked for validity using Python.\nMore complex problems can be studied with a computer-aided design package without the enormous burden of doing extensive computations.\nWe suggest that everyone become familiar with the use of Python or MATLAB.\nRemember that the computer is to aid in achieving understanding and should be used intelligently as an engineering tool.\nThe goal is for you to come away with an understanding of feedback theory in some depth.",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "syllabus.html#frequently-asked-questions-faq",
    "href": "syllabus.html#frequently-asked-questions-faq",
    "title": "Syllabus for “Principles of Automatic Control”",
    "section": "Frequently Asked Questions (FAQ)",
    "text": "Frequently Asked Questions (FAQ)\n\nsee notebook 00_FAQ.ipynb",
    "crumbs": [
      "Syllabus for \"Principles of Automatic Control\""
    ]
  },
  {
    "objectID": "bode_plots.html",
    "href": "bode_plots.html",
    "title": "Bode Plot Analysis",
    "section": "",
    "text": "Under the framework of the Nyquist stability criterion, a significant aspect that needs attention is the application of Bode plots for analyzing gain margin, phase margin, and overall system stability.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#the-nyquist-plot-and-its-computational-intensity",
    "href": "bode_plots.html#the-nyquist-plot-and-its-computational-intensity",
    "title": "Bode Plot Analysis",
    "section": "The Nyquist Plot and Its Computational Intensity",
    "text": "The Nyquist Plot and Its Computational Intensity\nThe Nyquist plot, an essential tool in control theory, visualizes the frequency response of a system by plotting\n\\[ G(j\\omega)H(j\\omega) \\]\nwhich encompasses both the magnitude and phase angle of the transfer function over a range of frequencies.\nConstructing a Nyquist plot requires the calculation of these components for a continuum of frequencies, typically from 0 to infinity. This process, as you might imagine, involves extensive computational efforts.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#bodes-simplification-method",
    "href": "bode_plots.html#bodes-simplification-method",
    "title": "Bode Plot Analysis",
    "section": "Bode’s Simplification Method",
    "text": "Bode’s Simplification Method\nTo alleviate the computational burden associated with Nyquist plots, Hendrik W. Bode introduced a more efficient method. Bode’s approach simplifies the display of frequency response data by transforming the complex plots into straightforward asymptotic lines. This transformation is achieved through logarithmic scaling of the magnitude and phase of the transfer function.\nThis semplification makes it possible to do the Fequency Design on the Bode’s Plots and not on the Nyquist Plos.\n\nThe Essence of Bode Plot Analysis\nLet’s take a generic form for a Transfer Function:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{K(1 + j\\omega T_1)...}{j\\omega(1 + j\\omega T_2)...}\n\\]\nThis is a type-1 system but we can easily generalise it to n-th order.\nTo analyze this function using Bode plots, we first take the logarithm of both sides:\n\\[ \\log_{10}(G(j\\omega)H(j\\omega)) = \\log_{10}K + \\log_{10}(1 + j\\omega T_1) - \\log_{10}j\\omega - \\log_{10}(1 + j\\omega T_2) ... \\]\nThis approach breaks down the transfer function into simpler additive components.\n\nLogarithmic Representation: By taking the logarithm of the transfer function’s components, the multiplicative terms in $ G(j)H(j) $ become additive. This facilitates the creation of Bode plots with minimal calculations.\nLogarithmic Scale and Straight Lines: Bode’s method employs logarithmic scales on both axes of the plot. This choice results in individual components of the transfer function, when plotted, appearing as (almost) straight lines. The addition of these linear segments provides a clear and comprehensive visualization of the system’s frequency response.\n\nIn Bode plots, the frequency axis is represented on a logarithmic scale, which is essential for analyzing control systems. On such a scale, the notion of ‘zero frequency’ is undefined, and thus, frequencies typically range from a low (but non-zero) value to a high value. This characteristic of the Bode plot offers a significant advantage for control system analysis.\nControl systems often function as low-pass filters, meaning they are primarily concerned with signals in the low-frequency range. However, it’s equally important to consider the impact of high-frequency noise. The logarithmic nature of the Bode plot’s frequency axis allows for an effective representation of both these aspects.\nIn a linear frequency scale, such as that used in Nyquist plots, accommodating a wide range of frequencies can lead to a compressed representation of the low-frequency range, where the performance characteristics of a system are most relevant. Conversely, the high-frequency range, which is crucial for understanding disturbance rejection, might not be adequately represented due to space limitations on the graph.\nThe logarithmic scale used in Bode plots elegantly addresses these issues. It elongates the low-frequency region, allowing for a more detailed analysis of the system’s behavior in this crucial range. Simultaneously, it also accommodates the high-frequency range effectively. This dual capability enables a comprehensive view of the system’s performance across a wide frequency spectrum, which is particularly beneficial for the analysis and design of control systems.\n\n\nMagnitude and Phase Calculations\n\nMagnitude: Consider the logarithm of the magnitude of each term.\n\n\\[\n\\left|G(j\\omega)H(j\\omega)\\right| = \\frac{K\\left|1 + j\\omega T_1\\right|...}{\\left|j\\omega\\right|\\left|1 + j\\omega T_2\\right|...}\n\\]\n\\[\nlog_{10} \\left|G(j\\omega)H(j\\omega)\\right| = \\log_{10}K + \\log_{10}\\left|1 + j\\omega T_1\\right| - \\log_{10}{\\left|j\\omega\\right|} - \\log_{10}{\\left|1 + j\\omega T_2\\right|} ...\n\\]\nWe can convert this to dB (see below):\n\\[\n20log_{10} \\left|G(j\\omega)H(j\\omega)\\right| = 20\\log_{10}K + 20\\log_{10}\\left|1 + j\\omega T_1\\right| - 20\\log_{10}{\\left|j\\omega\\right|} - 20\\log_{10}{\\left|1 + j\\omega T_2\\right|} ...\n\\]\n\nPhase: Sum the phase contributions from each term in the transfer function.\n\n\\[\n\\angle{G(j\\omega)H(j\\omega)} = \\tan^{-1}{\\omega T_1} - 90^\\circ - \\tan^{-1}{\\omega T_2} ....\n\\]",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#sidebar---decibels-in-control-systems",
    "href": "bode_plots.html#sidebar---decibels-in-control-systems",
    "title": "Bode Plot Analysis",
    "section": "SIDEBAR - Decibels in Control Systems",
    "text": "SIDEBAR - Decibels in Control Systems\n\nUnit of Magnitude: In control systems, the magnitude of a transfer function is often expressed in decibels (dB). The formula for converting a unit-less magnitude $ M $ to decibels is $ 20 _{10}(M) $.\nRationale for Using Decibels: The decibel unit, originating from communication engineering, provides a standardized and practical scale for magnitude representation. Although one could argue for using the natural logarithm or a simple logarithmic scale, the decibel unit’s ubiquity and compatibility with Bode’s method make it the preferred choice.\n\n–\n\nDefinition: A logarithmic unit used to express the magnitude of a frequency response.\nFormula: \\(20 \\log{10}M\\) dB, where M is the magnitude.\nSignificance: Provides a standardized scale for comparing magnitudes in control systems.\n\n– END OF SIDEBAR",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#the-structure-of-bode-plots",
    "href": "bode_plots.html#the-structure-of-bode-plots",
    "title": "Bode Plot Analysis",
    "section": "The Structure of Bode Plots",
    "text": "The Structure of Bode Plots\nBode plots consist of two separate plots: 1. Magnitude Plot: This plot has frequency (\\(\\omega\\)) on the x-axis and magnitude in decibels on the y-axis. The magnitude plot shows how the gain of the system changes with frequency. 2. Phase Plot: This plot also has frequency (\\(\\omega\\)) on the x-axis, but the phase angle (\\(\\phi\\)) on the y-axis. It demonstrates how the phase of the system changes with frequency.\n\n\n\n\n\n\n\n\nThe Significance of Logarithmic Scaling\nUsing a logarithmic scale for the frequency axis (\\(\\log \\omega\\)) is crucial because it converts the complex frequency response of each term into straight lines, as opposed to curved lines that would be seen on a linear scale. This transformation significantly simplifies the analysis.\nIf we did not have \\(\\log \\omega\\) Bode’s plot would not be as convenient.\n\n\nLinear and Logarithmic Scales in Bode Plots\n\nMagnitude Axis: The magnitude axis in a Bode plot is linear, as the logarithmic operation is already incorporated in the decibel calculation.\nFrequency Axis: The frequency axis is logarithmic, which simplifies the representation of the frequency response.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#building-blocks-of-bode-plots",
    "href": "bode_plots.html#building-blocks-of-bode-plots",
    "title": "Bode Plot Analysis",
    "section": "Building Blocks of Bode Plots",
    "text": "Building Blocks of Bode Plots\nTo construct a Bode plot, we consider the following building blocks of a transfer function:\n\nConstant gain factor $ K $.\nZero or Pole at the origin $ (j)^{N} $.\nFirst-order-like factors $ (1 jT)^{m} $;\nSecond-order-like factors $ ( s^2 + s + 1)^{r} $.\nTime delay factor $ e^{-j_D} $.\nOther factors representing zeros and poles in both the left and right half of the s-plane.\n\nNote that we have taken the Time Constant Form of the factors.\nNote also that case 3), includes:\n$ (1 - jT) $ (RHP zero) and $ $ (RHP pole)\nThese elements are combined to form the complete Bode plot, with each factor contributing linearly to the overall response.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#bode-plot",
    "href": "bode_plots.html#bode-plot",
    "title": "Bode Plot Analysis",
    "section": "Bode Plot",
    "text": "Bode Plot\nThe Bode plot consists of two graphs:\n\nMagnitude Plot: This plot has the frequency on a logarithmic scale (x-axis) and the magnitude of the system response in decibels (y-axis).\nPhase Plot: This plot also has the frequency on a logarithmic scale (x-axis), but the y-axis represents the phase angle in degrees.\n\n\nFrequency Range in Bode Plots\n\nFrequency Spectrum: Bode plots cover a wide range of frequencies, from very low (approaching zero) to very high frequencies.\nSignificance: This broad range allows for comprehensive analysis of system dynamics under various conditions.\n\nThis was not the case with Nyquist where the low frequency range was compressed to allow plotting up to infinity.\n\n\nBasic Building Blocks of Bode Plots\nBode plots are constructed by analyzing the basic building blocks of a transfer function and then combining them. Let’s start with the simplest building block.\n\nBuilding Block 1: Gain $ K $\nThe gain $ K $ in a transfer function can be represented in a Bode plot as:\n\nMagnitude: $ 20 (K) $ dB. This value is constant across all frequencies.\nPhase: $ 0^$, as the gain doesn’t affect the phase.\n\nGraphically, on a semi-log paper, the magnitude plot is a horizontal line at $ 20 (K) $ dB, while the phase plot remains at $ 0^$.\n\nConsiderations for Gain $ K $\n\nIf $ K &gt; 1 $, the magnitude line is above the 0 dB axis.\nIf $ K &lt; 1 $, the magnitude line is below the 0 dB axis.\n\n\n\n\n\n\n\n\n\n\n\nBuilding Block 2: Zero or Pole at the origin $ (j)^{N} $\nWe start evaluating how $ $ affects the Bode plot and then we generalise it:\n\nMagnitude: $ -20 () $ dB.\nPhase: $ -90^$ for all frequencies.\n\n\nMagnitude Analysis\nThe magnitude plot is a straight line with a slope of $ -20 $ dB/decade. This slope is determined by the fact that a change in frequency by a factor of 10 (a decade) results in a $ -20 $ dB change in magnitude.\nNote that if you took the Magnitude with respect to \\(\\omega\\) it would be a non-linear function (there is the log).\n\n\nDecade and dB per Decade\n\nDecade: A decade refers to a tenfold increase in frequency. For example, moving from 1 Hz to 10 Hz is one decade.\ndB per Decade: This term describes how the magnitude (in decibels) changes over a decade. A line with a slope of “-20 dB per decade” implies a decrease of 20 dB with every tenfold increase in frequency.\n\n\n\nPlotting dB per Decade\n\nConstructing the Slope: To illustrate a slope of -20 dB per decade, select a reference frequency and decrease the magnitude by 20 dB for the next decade.\nExample: If starting at 0.1 Hz, draw a straight line decreasing by -20 dB at 1 Hz, representing -20 dB per decade.\n\n\n\n\nExample: Plot for One Pole at the Origin\nConsider a frequency range from $ 0.1 $ to $ 10 $ rad/s. On a semi-log graph: - At $ = 0.1 $ rad/s, the magnitude is $ -20 (0.1) = 20 $ dB. - At $ = 1 $ rad/s, the magnitude is $ -20 (1) = 0 $ dB. - At $ = 10 $ rad/s, the magnitude is $ -20 (10) = -20 $ dB. - Connect these points to form a straight line, representing the magnitude plot.\n\n\n\n\n\n\n\nWe can now generalise and consider $ $:\n\nMagnitude: $ -40 () $ dB (i.e., straight line with slope of $ -40 $ dB/decade.\nPhase: $ -180^$ for all frequencies.\n\n\n\n\n\n\n\n\n\nMagnitude Change: For each additional lag term, the slope of the magnitude plot doubles. For \\(1/j\\omega^2\\), the slope is -40 dB per decade.\nPlotting: Begin at \\(\\omega\\) = 1 with a specific dB level and extend the line with a slope of -40 dB per decade.\n\nAnd if we have a zero (or multiple zeros at the origin) the shape is the same but the slope becomes positive.\n\n\nCombination of Gain and Pole at the Origin \\(\\left( \\frac{K}{s} \\right)\\)\n\\[\nG(s) = \\frac{K}{s}\n\\]\nThe Bode Plot is obtained summing up the plot for \\(K\\) and the plot for \\(\\frac{1}{s}\\).\n\nCombined Effects: When combining a gain factor (\\(K\\)) with a term (\\(1/j\\omega\\)), the magnitude plot shifts. The phase is -90.\nMagnitude Equation: For \\(G(j\\omega) = \\frac{K}{j\\omega}\\), the magnitude in dB is \\(-20 log(\\omega) + 20 log(K)\\).\n\nThis is a straight line of the form: \\(y = mx + c\\).\n\n\n\n\n\n\n\nTwo poles at the origin:\n\\[\nG(s) = \\frac{K}{s^2}\n\\]\nThe Magnitude equation is \\(dB = -40 log(\\omega) + 20 log(K)\\).\n\n\n\n\n\n\n\n\n\nIdentifying the Type of System from Bode Plot\nIn the low frequency region, the Bode Plot will tell you the type of your system:\n\nType-0 System: Characterized by a horizontal line in the low-frequency region, indicating a constant gain.\nType-1 System: Exhibits a line with a slope of -20 dB per decade, indicative of a first-order system.\nType-2 System: A slope of -40 dB per decade in the low-frequency region signals a second-order system.\n\n\n\n\n\n\n\n\n\n\n\nBuilding Block: First-Order Lag with Time Constant\n\nSimple Pole or Simple Lag (1/(1 + jωT))\n\nMagnitude and Phase:\n\nFor \\(G(s) = \\frac{1}{1 + j\\omega T}\\), the Magnitude can be expressed as:\n\\[\n|G(s)| = \\frac{1}{\\sqrt{1 + \\omega^2 T^2}}  \\Rightarrow -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\nand the Phase as:\n\\[\n\\angle{G(s)} = -\\tan^{-1}(\\omega T)\n\\]\n\nPlotting the First-Order Lag\nFrequency Ranges: We divide the frequency spectrum into two ranges based on the product \\(\\omega T\\): - Case 1: \\(\\omega T &lt;&lt; 1\\) (Low-frequency range): In this range, the term \\(\\omega^2T^2\\) is negligible, simplifying the equation to \\(dB ≈ 0\\). Thus, the plot remains at 0 dB for low frequencies.\n\nCase 2: \\(\\omega T &gt;&gt; 1\\) (High-frequency range): Here, the \\(1\\) in the equation becomes negligible, simplifying it to \\(dB = -20 log(\\omega T)\\). This results in a straight line with a slope of -20 dB per decade.\n\n\n\nCorner Frequency and Transition\n\nCorner Frequency: The frequency at which \\(\\omega T = 1\\) is known as the corner frequency. It represents a critical transition point in the plot.\nMagnitude Plot: The plot transitions from a flat line (0 dB) at low frequencies to a line with a slope of -20 dB per decade beyond the corner frequency.\n\nWe can then plot the Magnitude plot:\n\n\n\n\n\n\n\nLet’s consider the equation again:\n\\[\n|G(s)|  = \\Rightarrow -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\n\nCase 1: \\(|G(s)| = 0\\)\nCase 2: \\(|G(s)| = -20\\log(\\omega) - 20\\log(T)\\)\nCase 3: At \\(\\omega T = 1\\): The magnitude equation becomes \\(dB = -10 log \\sqrt{2} = -3\\) dB. In this case, the phase is \\(tan^{-1}\\left(1\\right) = -45^\\circ\\)\n\nWe can verify the difference between the real function and the approximation.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nT = 1  # You can change T as per your requirements\ncorner_frequency = 1 / T\n\n# Frequency range from 0.1 to 100\nomega = np.logspace(-1, 2, 500)  # 500 points between 10^-1 and 10^2\n\n# Calculating dB values for the actual plot\ndB_actual = -10 * np.log10(1 + omega**2 * T**2)\n\n# Asymptotic approximation\ndB_asymptotic = np.zeros_like(omega)\nfor i, w in enumerate(omega):\n    if w &lt; corner_frequency:\n        dB_asymptotic[i] = 0\n    else:\n        dB_asymptotic[i] = -10 * np.log10(w**2 * T**2)  # Slope of -20 dB/decade\n\n# Plotting the Bode plot and its asymptotic approximation\nplt.figure()\nplt.semilogx(omega, dB_actual, label='Actual Plot')\nplt.semilogx(omega, dB_asymptotic, label='Asymptotic Approximation', linestyle='--')\nplt.title('Bode Plot with Asymptotic Approximation')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Magnitude (dB)')\nplt.grid(which='both', axis='both')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nError Analysis in Bode Plots\n\\[\n|G(s)|  = -10\\log{\\left(1 + \\omega^2 T^2\\right)}\n\\]\nIn Bode plot analysis, the use of asymptotic approximations simplifies the plotting process. However, this approach can introduce errors, especially near the corner frequencies. To enhance the accuracy of the plot, we can add more points and calculate the errors at these points.\n\nError Calculations: Errors in the Bode plot are algebraically added at specific frequencies to create a more accurate representation. For instance, at the corner frequency, the typical error might be -3 dB. Additionally, we can calculate errors at points one octave above and below the corner frequency. An octave in this context refers to a doubling or halving of the frequency.\n\nFor a more accurate representation, we can take additional points at frequencies \\(\\omega = \\frac{1}{2T}\\) and \\(\\omega = \\frac{2}{T}\\). The errors at these points can be calculated as follows:\n\nAt \\(\\omega = \\frac{1}{2T}\\):\n\\[\nerr_{dB} = −10\\log(1) - \\left (-10\\log{\\left(1 + \\left(\\frac{1}{2T}\\right)^2 T^2\\right)} \\right) \\approx -1 \\text{ dB}\n\\]\nAt \\(\\omega = \\frac{2}{T}\\):\n\\[\nerr_{dB} = -10\\log{\\left(\\left(\\frac{2}{T}\\right)^2 T^2\\right)} - \\left (-10\\log{\\left(1 + \\left(\\frac{2}{T}\\right)^2 T^2\\right)} \\right) \\approx -1 \\text{ dB}\n\\]\n\nThese error calculations help refine the Bode plot, making it a closer match to the actual frequency response of the system.\nCommon practice includes adjusting the plot at ω = 1/(2T) and ω = 2/T by a certain dB level to closely match the actual plot.\n\n\nPhase Plot Analysis\nThe primary equation for the phase plot in Bode analysis is given by:\n\\[\n\\angle G(j\\omega) = -\\tan^{-1}(\\omega T)\n\\]\nThis equation implies:\n\nAt \\(\\omega = 0\\), \\(\\angle G(j\\omega) = 0^\\circ\\), indicating the phase starts at 0 degrees at low frequencies.\nAs \\(\\omega \\rightarrow \\infty\\), \\(\\angle G(j\\omega) \\rightarrow -90^\\circ\\), showing the phase approaches -90 degrees at high frequencies.\nAt the specific frequency \\(\\omega = \\frac{1}{T}\\), \\(\\angle G(j\\omega) = -45^\\circ\\), which is the midpoint in the phase transition.\n\n\n\n\n\n\n\n\n\n\nConstruction of the Phase Plot\n\nActual Phase Plot: The actual phase plot for a simple pole smoothly transitions from 0 degrees at low frequencies to -90 degrees at high frequencies. While certain frequency ranges might allow for constant phase approximations, the true plot exhibits a gradual, continuous change.\nApproximation Method: A practical approximation for the phase plot uses a straight line extending from \\(\\omega = \\frac{1}{10T}\\) to \\(\\omega = \\frac{10}{T}\\). This approximation simplifies the plot but can introduce an error of up to approximately \\(6^\\circ\\). Such an error becomes significant when calculating the phase margin, where precision is crucial for assessing system stability.\n\n\n\nVisualization\nThe phase plots, both approximated and actual, can be visualized as shown below. The figures illustrate the distinction between the actual phase behavior and its asymptotic approximation, highlighting the simplicity and potential errors involved in the latter approach.\n\nAsymptotic Approximation: (Image showing the straight-line approximation from \\(\\frac{1}{10T}\\) to \\(\\frac{10}{T}\\))\n\n\n\n\n\n\n\n\nFigure: The asymptotic approximation is depicted using a straight line for ease of analysis.\n\nActual Phase Plot:\n\nFigure: Image representing the smooth transition from 0 to -90 degrees. This is shown using the Python Script Below.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Constants\nT = 1  # Time constant, you can change this as needed\n\n# Frequency range from 0.01 to 1000\nomega = np.logspace(-2, 3, 500)  # 500 points between 10^-2 and 10^3\n\n# Calculating the actual phase\nphase_actual = -np.arctan(omega * T) * (180 / np.pi)  # Convert to degrees\n\n# Straight-line approximation\nphase_approx = np.zeros_like(omega)\nfor i, w in enumerate(omega):\n    if w &lt; 1 / (10 * T):\n        phase_approx[i] = 0\n    elif w &gt; 10 / T:\n        phase_approx[i] = -90\n    else:\n        # Linear interpolation between -45 at 1/T and -90 at 10/T\n        phase_approx[i] = np.interp(np.log10(w), [np.log10(1 / (10 * T)), np.log10(10 / T)], [0, -90])\n\n# Plotting the phase plots\nplt.figure()\nplt.semilogx(omega, phase_actual, label='Actual Phase')\nplt.semilogx(omega, phase_approx, label='Straight-line Approximation', linestyle='--')\nplt.title('Phase Plot for a Simple Pole')\nplt.xlabel('Frequency (rad/s)')\nplt.ylabel('Phase (degrees)')\nplt.grid(which='both', axis='both')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nSummary - Simple Pole or Simple Lag (1/(1 + jωT))\n\\[G(s) = \\frac{1}{1 + j\\omega T}\\]\n\n\n\n\n\n\n\n\n\n\n\nSimple Zero (1 + jωT)\n\\[\nG(s) = 1+j\\omega T\n\\]\n\nAsymptotic Plot: For a zero, the asymptotic Bode plot starts with an increasing slope of +20 dB per decade at the corner frequency (1/T).\nAdjusting for Accuracy: To create a more accurate plot, adjust the asymptotic plot at specific frequencies (such as ω = 1/(2T) and ω = 2/T) by adding dB levels.\n\n\n\n\n\n\n\n\n\n\nBode Plot for a Double Pole (1/(1 + jωT)²)\n\\[\nG(s) = \\frac{1}{(1+j\\omega T)^2}\n\\]\n\nSlope of the Line: For a double pole, the line in the Bode plot has a slope of -40 dB per decade, with adjustments for errors around this frequency.\nCorner Frequency: The corner frequency, where ωT = 1, is the point where the slope change occurs.\n\n\nError Analysis in Bode Plots\n\nError Calculations: Errors in the Bode plot are algebraically added at specific frequencies to create a more accurate representation. For example, at the corner frequency, the error is -6 dB, with additional errors of -2 dB one octave above and below the corner frequency.\n\n\n\n\nSecond-Order Factors\n\\[\nG(s) = \\frac{1}{\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1}\n\\]",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#phase-margin-and-gain-margin-in-bode-plots",
    "href": "bode_plots.html#phase-margin-and-gain-margin-in-bode-plots",
    "title": "Bode Plot Analysis",
    "section": "Phase Margin and Gain Margin in Bode Plots",
    "text": "Phase Margin and Gain Margin in Bode Plots\n\nGain Crossover Frequency: This is the frequency at which the magnitude of the system’s response equals 1 (or 0 dB). It is crucial for stability analysis.\nPhase Margin: The phase margin is the additional phase shift required to bring the system to the brink of instability. It is calculated from the phase plot at the gain crossover frequency.\nPhase Margin Analysis:\n\nThe phase margin represents the additional phase angle that can be added to the system before it reaches a phase angle of -180 degrees.\nPositive Phase Margin: If the plot is above the -180-degree line at the gain crossover frequency, the phase margin is positive, indicating a stable system.\nNegative Phase Margin: Conversely, if the plot is below the -180-degree line, it’s a negative phase margin, suggesting potential instability.\n\nDefining Phase Crossover Frequency: The phase crossover frequency is where the phase angle of the system’s response becomes -180 degrees. This frequency is critical in determining the stability of the system.\n\n\nGain Margin Analysis\n\nCalculating Gain Margin: Gain margin is the additional gain that can be added to the system before it becomes unstable. It is measured in decibels (dB).\nDetermining Gain Margin: To find the gain margin, locate the phase crossover frequency on the magnitude plot. The distance (in dB) from this point to the 0 dB line represents the gain margin.\n\n\n\n\nConstructing Bode Plots for Specific Transfer Functions\n\nExample:\n\\[\nG(s) = \\frac{k}{s(1 + sT_1)(1 + sT_2)}\n\\]\n\nMagnitude Plot Construction: Start by plotting the low-frequency plot for K = 10. Then, add plots for each factor (1/s, 1 + sT1, 1 + sT2) and adjust the slope at each corner frequency.\nApproach: At each corner frequency, add or subtract dB levels based on the net change in slope. For example, at a corner frequency where the slope decreases, subtract dB levels to correct the plot.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "bode_plots.html#check-your-understanding",
    "href": "bode_plots.html#check-your-understanding",
    "title": "Bode Plot Analysis",
    "section": "Check your understanding",
    "text": "Check your understanding\nPop-up Question: Why are Bode plots preferred over Nyquist plots for certain analyses in automatic control?\nAnswer: Bode plots simplify the visualization and interpretation of a system’s frequency response by converting complex polar plots into straightforward logarithmic plots. This simplification is especially useful for understanding the system’s gain and phase margins.\nPop-Up Question: Why are decibels used in Bode plot analysis?\nAnswer: Decibels provide a logarithmic scale that simplifies the comparison of different magnitudes, making it easier to analyze and design control systems.\nPop-Up Question: What does a positive gain margin indicate about a system’s stability?\nAnswer: A positive gain margin indicates that a system can withstand an increase in gain without becoming unstable.\nPop-up Question: Why are Decades Used in Bode Plots?\nAnswer: Decades are used because they provide a logarithmic scale for frequency. This allows a wide range of frequencies to be represented compactly, facilitating the analysis of system behavior across different frequency bands.\nPop-up Question: Why is the Corner Frequency Important in Bode Plots?\nAnswer: The corner frequency marks the transition point where the behavior of the system changes significantly. It is where the approximation of the system’s frequency response shifts from one regime to another, such as from a flat response to a sloped one.\nPop-up Question: What is the Significance of the Gain and Phase Margins in Control Systems?\nAnswer: Gain and phase margins are critical indicators of system stability. A positive phase margin and a substantial gain margin imply that the system can tolerate a certain level of gain increase or phase shift before becoming unstable.",
    "crumbs": [
      "Bode Plot Analysis"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html",
    "href": "stability_and_routh_criterion.html",
    "title": "Stability Analysis in Control Systems",
    "section": "",
    "text": "We continue our journey into the world of control systems by delving deeper into stability analysis. Let’s build upon the conclusions we arrived at last time.\nConsider a closed-loop system characterized by its transfer function. For simplicity, we assume a unity-feedback system where $ G(s) $ is the open-loop transfer function, $ R $ is the input, and $ Y $ is the output.\nThe closed-loop transfer function is given by:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)}\n\\]\nThe characteristic equation of our system is $ 1 + G(s) = 0 $. The roots of this equation, also known as the closed-loop poles, dictate the system’s stability.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html#determining-stability",
    "href": "stability_and_routh_criterion.html#determining-stability",
    "title": "Stability Analysis in Control Systems",
    "section": "Determining Stability",
    "text": "Determining Stability\nLet’s now progress to determine stability. The characteristic equation can generally be represented as an nth-order polynomial:\n\\[\n\\Delta(s) = a_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\n\nThis equation is derived from $ 1 + G(s) = 0 $ and represents the poles of our closed-loop system.\nWe would like to know if the zeros of this characeterist equations are stable or not.\n\nNote: The zeros of the closed-loop system are not considered in stability analysis, as they affect only the magnitude, not the mode, of the response.\n\nControllability, Observability, and Zeros\nA crucial assumption in our analysis is that zeros do not cancel poles, a condition typically met in controllable and observable systems. If a zero cancels an unstable pole, it can lead to incorrect stability assessments.\nThis is the point of convergence for both asymptotic stability and Bounded Input Bounded Output (BIBO) stability. In scenarios where these conditions aren’t met, the two types of stability diverge in their interpretations. Specifically, in BIBO stability, the cancellation of a pole by a zero does not manifest in the system’s behavior. However, when considering internal stability, which is analyzed using a state variable model, the impact of such a cancelled pole becomes evident in the overall stability of the system.\nThe presumption that a system is both controllable and observable generally holds true for the majority of real-world systems.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html#routh-stability-criterion",
    "href": "stability_and_routh_criterion.html#routh-stability-criterion",
    "title": "Stability Analysis in Control Systems",
    "section": "Routh Stability Criterion",
    "text": "Routh Stability Criterion\nWe now turn our attention to the Routh stability criterion, an invaluable method in the realm of stability analysis. While modern numerical tools can effortlessly compute the roots of an equation, the Routh criterion helps beyond these numerical methods, especially in design-oriented contexts. It enables us to both assess stability and identify design parameters that ensure a stable system configuration.\nConsider our characteristic equation: \\(a_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\\). The coefficients of this equation are intrinsically linked to the physical attributes of the system. A common inquiry might involve determining the permissible ranges for these coefficients that guarantee system stability. In such instances, relying solely on numerical tools may prove inadequate, as they typically require predefined numerical values for the coefficients, which isn’t always feasible in design scenarios. The Routh stability criterion addresses this gap, providing insights into the stability implications of varying system parameters.\n\nConstructing the Routh Array\nWe start with our characteristic equation:\n\\[\na_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\n\nEnsure $ a_n $ to avoid trivial roots at $ s = 0 $.\n$ a_0 &gt; 0 $. If $ a_0 $ is not positive we can simply multiply by \\(-1\\) and this does not change the analysis.\n\n🤔 Pop-up Question: Why is it important for the leading coefficient $ a_0 $ to be positive in the Routh stability analysis?\nAnswer: A positive $ a_0 $ ensures that the Routh array starts with a positive value, which is crucial for correctly determining the number of sign changes and, consequently, the system’s stability.\n\n\nNecessary conditions\n\nAll Coefficients Must Be Positive: For a system to be stable, every coefficient in the characteristic polynomial must be positive and non-zero. A zero or negative coefficient is a red flag, indicating potential instability.\n\nNote that if we did not have $ a_0 &gt; 0 $ then this condition becomes: all coefficients must be of the same sign.\n\n\nSufficient conditions: Constructing the Routh Array\nGiven the characteristic equation:\n\\[\na_0 s^n + a_1 s^{n-1} + \\dots + a_{n-1} s + a_n = 0\n\\]\nNow, let’s construct the Routh array, a structured method to analyze the stability of a polynomial equation. The Routh array is built row by row, using the coefficients of the characteristic polynomial.\n\nFirst Two Rows: The first two rows are directly derived from the polynomial. For a polynomial of degree $ n $, the first row contains coefficients of even powers of $ s $ (e.g., $ a_0, a_2, a_4, $), while the second row contains coefficients of odd powers of $ s $ (e.g., $ a_1, a_3, a_5, $).\nSubsequent Rows: Each element of the subsequent rows is calculated using a specific formula. For the third row (corresponding to $ s^{n-2} $), each element is calculated as follows:\n\nThe first element of the third row is given by $ $.\nThe second element is $ $, and so on.\n\nNote: If any coefficient is missing (i.e., the power of $ s $ does not appear in the polynomial), treat it as zero in these calculations.\nIndexing Rows: The indexing of rows (e.g., $ s^{n-1}, s^{n-2}, $) serves as a guide but does not correspond to the powers of $ s $ in the original polynomial after the first two rows.\n\nHere’s an example of what the Routh table structure would look like for a generic $ n $-th order polynomial:\n\n\n\n\n\n\n\n\n\n\n\nOrder of \\(s\\)\nColumn 1\nColumn 2\nColumn 3\n…\nColumn \\(\\frac{n}{2}+1\\)\n\n\n\n\n\\(s^n\\)\n\\(a_0\\)\n\\(a_2\\)\n\\(a_4\\)\n…\n\\(a_{2k}\\) or 0\n\n\n\\(s^{n-1}\\)\n\\(a_1\\)\n\\(a_3\\)\n\\(a_5\\)\n…\n\\(a_{2k+1}\\) or 0\n\n\n\\(s^{n-2}\\)\n\\(b_1 = \\frac{a_1 a_2 - a_0 a_3}{a_1}\\)\n\\(b_2 = \\frac{a_1 a_4 - a_0 a_5}{a_1}\\)\n\n…\n\n\n\n\\(s^{n-3}\\)\n\n\n\n…\n\n\n\n…\n\n\n\n…\n\n\n\n\\(s^1\\)\n\n\n\n…\n\n\n\n\\(s^0\\)\n\n\n\n…\n\n\n\n\n\n$ k $ is the integer part of $ $.\nA missing cofficient is 0.\n\n\n\nIllustrative Example\nLet’s illustrate this with a specific 4th order polynomial:\n\\[\ns^4 + 8 s^3 + 18 s^2 + 16 s + 5 = 0\n\\]\n\nFirst Two Rows:\n\nRow for $ s^4 $: $ 1 $ (coefficient of $ s^4 $), $ 18 $ (coefficient of $ s^2 $), $ 5 $ (constant term).\nRow for $ s^3 $: $ 8 $ (coefficient of $ s^3 $), $ 16 $ (coefficient of $ s^1 $), $ 0 $ (since there is no $ s^{-1} $ term).\n\nRow for $ s^2 $:\n\nFirst element: $ = = 16 $.\nSecond element: $ = = 5 $.\nThird element is zero (as there are no more elements to use in the calculation).\n\nRow for $ s^1 $:\n\nFirst element: $ = = 13.5 $.\nSecond element is zero (as the corresponding elements above are zero or do not exist).\n\nRow for $ s^0 $:\n\nOnly the first element is needed, which is the same as the second element of the previous row: $ 5 $.\n\n\nHere is the Routh array:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n1\n18\n5\n\n\n$ s^3 $\n8\n16\n0\n\n\n$ s^2 $\n16\n5\n0\n\n\n$ s^1 $\n13.5\n0\n\n\n\n$ s^0 $\n5\n\n\n\n\n\nSince there are no sign changes in the first column of the Routh array, this system is stable. The Routh stability criterion tells us that all roots of the characteristic equation are in the left half of the complex plane, indicating stability.\n\n\nAnalyzing Stability with the Routh Array\nAfter constructing the Routh array, we examine the first column’s signs to draw conclusions about the system’s stability.\n\nIf there are no sign changes in the first colum of the Routh array, then the system is stable.\nIf there are sign changes, the system is not stable and the number of roots in the RHP is equal to the number of sign changes. The criteria hence provides information on the number of unstable roots, but does not give you the location of the roots.\n\n\nimport numpy as np\n\ndef routh_array(coefficients):\n    n = len(coefficients)\n    routh = []\n\n    # First two rows\n    r1 = [coefficients[i] for i in range(0, n, 2)]\n    r2 = [coefficients[i] for i in range(1, n, 2)]\n    \n    routh.append(r1)\n    routh.append(r2 + [0] * (len(r1) - len(r2)))  # Padding zeros\n\n    # Other rows\n    for i in range(2, n):\n        row = []\n        for j in range(len(r1) - 1):\n            # Calculate element\n            first = routh[i-1][0]\n            upper = routh[i-2][j+1]\n            left = routh[i-1][j+1] if j+1 &lt; len(routh[i-1]) else 0\n            element = ((upper * first) - left * routh[i-2][0]) / first\n            row.append(element)\n        routh.append(row + [0] * (len(r1) - len(row)))  # Padding zeros\n\n        # Check for row of zeros\n        if all(r == 0 for r in row):\n            print(\"Row of zeros detected. Special procedure needed.\")\n            return routh\n\n    return routh\n\n# Example usage\ncoeffs = [1, 8, 18, 16, 5]\nrouth = routh_array(coeffs)\n\n# Printing the Routh array\nfor row in routh:\n    print(row)\n\n[1, 18, 5]\n[8, 16, 0]\n[16.0, 5.0, 0]\n[13.5, 0.0, 0]\n[5.0, 0.0, 0]\n\n\n\n\nIllustrative example 2\nTo calculate the Routh array for the polynomial $ 3s^4 + 10s^3 + 5s^2 + 5s + 2 = 0 $, we can use the same method as before.\nLet’s perform the calculations step by step:\n\nFirst Two Rows:\n\nRow for $ s^4 $: $ 3 $ (coefficient of $ s^4 $), $ 5 $ (coefficient of $ s^2 $), $ 2 $ (constant term).\nRow for $ s^3 $: $ 10 $ (coefficient of $ s^3 $), $ 5 $ (coefficient of $ s^1 $), $ 0 $ (since there is no $ s^{-1} $ term).\n\nRow for $ s^2 $:\n\nFirst element: $ = = 3.5 $.\nSecond element: $ = = 2 $.\nThird element is zero (as there are no more elements to use in the calculation).\n\nRow for $ s^1 $:\n\nFirst element: $ = = -0.71 $.\nSecond element is zero (as the corresponding elements above are zero or do not exist).\n\nRow for $ s^0 $:\n\nOnly the first element is needed, which is the same as the first element of the previous row: $ 2 $.\n\n\nHere is the completed Routh array:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n3\n5\n2\n\n\n$ s^3 $\n10\n5\n0\n\n\n$ s^2 $\n3.5\n2\n0\n\n\n$ s^1 $\n-0.71\n0\n\n\n\n$ s^0 $\n2\n\n\n\n\n\nSince there are two sign changes in the first column of the Routh array (from positive to negative between $ s^2 $ and $ s^1 $ and one from negative to positive between $ s^1 $ and $ s^0 $ ), this system is unstable.\nThe Routh stability criterion indicates that there are two roots of the characteristic equation is in the right half of the complex plane, leading to the conclusion of instability.\nNote that in this case, given that the second row is divisible by 5, we could also have written the following table:\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^4 $\n3\n5\n2\n\n\n$ s^3 $\n2\n1\n0\n\n\n$ s^2 $\n3.5\n2\n0\n\n\n$ s^1 $\n\\(-\\frac{1}{7}\\)\n0\n\n\n\n$ s^0 $\n2\n\n\n\n\n\nAnd finally we can try out our routh_array function:\n\nrouth_array([3, 10, 5, 5, 2])\n\n[[3, 5, 2],\n [10, 5, 0],\n [3.5, 2.0, 0],\n [-0.7142857142857143, 0.0, 0],\n [2.0, 0.0, 0]]",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html#routh-stability-criterion-handling-roots-on-the-imaginary-axis",
    "href": "stability_and_routh_criterion.html#routh-stability-criterion-handling-roots-on-the-imaginary-axis",
    "title": "Stability Analysis in Control Systems",
    "section": "Routh Stability Criterion: Handling Roots on the Imaginary Axis",
    "text": "Routh Stability Criterion: Handling Roots on the Imaginary Axis\nWe delve into more intricate scenarios where the roots of the characteristic equation may lie on the imaginary axis (jω axis). This discussion will lead us through the process of dealing with such special cases.\n\nIllustrative example 3\nConsider a system represented by the characteristic equation\n\\[\n\\Delta(s) = s^5 + s^4 + 4s^3 + 24s^2 + 3s + 63 = 0\n\\]\nWhen applying the Routh stability criterion to this system, we encounter a specific situation. In this case, a complete row in the Routh array may turn out to be all zeros, indicating the possibility of roots on the jω axis. This is a significant indicator, as it implies that the system might exhibit marginal stability or instability.\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^5 $\n1\n4\n3\n\n\n$ s^4 $\n1\n24\n63\n\n\n$ s^3 $\n\\(\\cancel{-20} \\rightarrow -1\\)\n\\(\\cancel{-60} \\rightarrow -3\\)\n\n\n\n$ s^2 $\n\\(\\cancel{21} \\rightarrow  1\\)\n$ $\n0\n\n\n$ s^1 $\n\\(0\\)\n0\n\n\n\n$ s^0 $\n\n\n\n\n\n\n\n\nUnderstanding the All-Zero Row\n\nIf we encounter an all-zero row at any step, the coefficient of the subsequent row is undefined and we need to construct an auxiliary polynomial from the row immediately above the all-zero row and use its derivative to continue the Routh array construction.\nThis indicates the potential presence of roots on the jω axis.\nAll-Zero Row Implication: When an all-zero row is encountered in the Routh array, it suggests that the characteristic equation may have symmetrical roots about the imaginary axis. This could mean a pair of roots lying exactly on the jω axis or complex conjugate pairs symmetrical across this axis.\nStability Uncertainty: The presence of an all-zero row does not immediately classify the system as stable or unstable. Instead, it indicates that further analysis is needed to determine the system’s stability.\n\n\n\n\n\n\n\nWhen a row is all zeros, we cannot conclude on the stability of the system, and further investigation is needed.\nNote that the system cannot be stable.\nDue to symmetry, an all zero row will always be associated with and odd power of s.\n\n\nConstructing the Auxiliary Polynomial\n\nTo address the all-zero row, we construct an auxiliary polynomial from the coefficients of the row just above the all-zero row. For instance, if the all-zero row is at $ s^2 $, we look at the $ s^3 $ row for these coefficients, if the all-zero row is at $ s^1 $ (as in our previous case), we look at the $ s^2 $.\n\nWith reference to our example above, the auxiliary polynomial is:\n\\[ A(s) = s^2 + 3 \\]\n\nNote that the \\(s^2\\) comes from the order of row just above the all-zero row (in our case \\(s^2\\)).\nThe auxiliary polynomial is a factor of the original characteristic equation \\(\\Delta(s)\\).\nSince in this case, the roots of the auxiliary polynomial are imaginary, we can conclude that the roots of the characteristic equation are also on the imaginary axis (and we are in the middle case above), and the system is marginally stable or unstable in the case we have multiple imaginary poles. In fact to conclude about the stability we must also conclude about the remaining roots of the characteristic equation (those of the auxiliary polynomial are a subset).\n\n\n\nConcluding about the stability\nOnce we have the auxiliary polynomial there are two ways to conclude about the stability:\n\nWe divide the total characteristic equation by the auxiliary polynomial, we obtain the remainder polynomial and we apply the Routh criterion to the remainder polynomial\nWe take the derivative of the auxiliary polynomial \\(\\frac{dA}{ds}\\) and replace the all-zero row with the coefficients of this derivative. This modification allows us to continue with the Routh array construction.\n\nIn our case:\n\\[\\frac{dA}{ds} = 2s + 0\\]\nand we can finish the Routh array:\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^5 $\n1\n4\n3\n\n\n$ s^4 $\n1\n24\n63\n\n\n$ s^3 $\n\\(\\cancel{-20} \\rightarrow -1\\)\n\\(\\cancel{-60} \\rightarrow -3\\)\n\n\n\n$ s^2 $\n\\(\\cancel{21} \\rightarrow  1\\)\n$ $\n0\n\n\n$ s^1 $\n2\n0\n\n\n\n$ s^0 $\n3\n\n\n\n\n\n\nAfter replacing the all-zero row and completing the Routh array, we reassess the first column for sign changes. The number of sign changes now gives us information about the stability of the system, considering the roots on the imaginary axis.\nIn our case there are two sign changes. We conclude that the original polynomial has:\n\ntwo roots in the RHP (from the Routh array)\ntwo roots on the imaginary axis (from the auxiliary polynomial)\none root in the LHP (the remaining one)\n\n\nThe system is unstable.\n\n\nSpecial Case of \\(s_0\\) Row Being All Zeros?\n\nInfeasibility of All-Zero \\(s_0\\) Row: An all-zero row at the \\(s_0\\) level (the last row of the Routh array) is practically not feasible. If it were to occur, it would imply a single root at the origin, which contradicts the all-zero row situation since a single root does not create this scenario.\nSymmetry Consideration: The symmetry involved in the root distribution of the characteristic equation implies that an all-zero row will correspond to an even power of \\(s_0\\). Thus, the roots associated with an all-zero row will always have some symmetry about the imaginary axis.\n\n\nThe Routh stability criterion is a pivotal analytical tool used in control engineering to assess the stability of linear systems. Here’s a summary of its key points that we have see so far:\n\nPurpose: The Routh criterion is used to determine whether a system is stable, unstable, or marginally stable without explicitly calculating the roots of its characteristic equation.\nCharacteristic Equation: Stability is analyzed based on the characteristic equation of the system’s transfer function, typically represented as a polynomial in $ s $ (the Laplace variable).\nConstruction of Routh Array: The criterion involves constructing a tabular array, known as the Routh array, using the coefficients of the characteristic equation. The array is formed row by row, with the first two rows filled with the coefficients of the polynomial, alternating between even and odd powers of $ s $.\nStability Analysis:\n\nIf all elements in the first column of the Routh array are positive, the system is stable (no poles in the right-half of the s-plane).\nThe presence of sign changes in the first column indicates instability. The number of sign changes corresponds to the number of poles in the right-half of the s-plane.\nIf a row is composed entirely of zeros, it indicates symmetrical roots about the imaginary axis and requires further analysis.\n\nHandling Special Cases:\n\nAll-Zero Row: When a row in the Routh array is all zeros, it suggests symmetrical roots about the imaginary axis. An auxiliary polynomial is formed from the row above the all-zero row, and its derivative is used to continue the Routh array construction.\nMarginal Stability: An all-zero row can indicate marginal stability, where roots lie on the imaginary axis. However, further investigation is needed to confirm this.\n\nAuxiliary Polynomial: This polynomial is derived from the row above the all-zero row. The derivative of the auxiliary polynomial is used to replace the all-zero row and continue the Routh array construction.\nLimitations: While the Routh criterion can indicate the number and location (left-half or right-half plane) of the roots, it does not provide the exact values of these roots.\n\n\n\n\nIllustrative Example 3\nConsider the system characterized by the polynomial\n\\[\ns^6 + 2s^5 + 8s^4 + 12s^3 + 20s^2 + 16s + 16 = 0\n\\]\nAs we construct the Routh array, we encounter an all-zero row at $ s^3 $.\n\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\nColumn 4\n\n\n\n\n$ s^6 $\n1\n8\n20\n16\n\n\n$ s^5 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^4 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^3 $\n0\n0\n\n\n\n\n$ s^2 $\n…\n…\n\n\n\n\n$ s^1 $\n…\n\n\n\n\n\n$ s^0 $\n…\n\n\n\n\n\n\nThe Routh array needs to be completed with further calculations starting from the modified $ s^3 $ row. This process will provide the necessary information to assess the system’s stability.\nIn this case, we form an auxiliary polynomial from the $ s^4 $ row, which turns out to be:\n\\[ A(s) = s^4 + 6s^2 + 8 \\]\nThe next step involves taking the derivative of this auxiliary polynomial:\n\\[ \\frac{dA}{ds} = 4s^3 + 12s + 0 \\]\n\n\n\n\n\n\n\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\nColumn 4\n\n\n\n\n$ s^6 $\n1\n8\n20\n16\n\n\n$ s^5 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^4 $\n\\(\\cancel{2} \\rightarrow 1\\)\n\\(\\cancel{12} \\rightarrow 6\\)\n\\(\\cancel{16} \\rightarrow 8\\)\n0\n\n\n$ s^3 $\n$ $\n\\(\\cancel{12} \\rightarrow 3\\)\n\n\n\n\n$ s^2 $\n3\n8\n\n\n\n\n$ s^1 $\n\\(\\frac{1}{3}\\)\n\n\n\n\n\n$ s^0 $\n8\n\n\n\n\n\n\nConclusions\n\nThe first column of the Routh array are all positive (no sign changes). This means that the polynomial \\(\\frac{\\Delta(s)}{A(s)}\\) has no roots in the RHP.\nWhen we look at the auxiliary polynomial: $ A(s) = s^4 + 6s^2 + 8 $, we can solve for its roots:\n\nset $s^2=z A(s) = z^2 + 6z + 8 $ with roots: \\(s=\\pm j\\sqrt{2};\\;\\;\\;s=\\pm j2\\)\nthe auxiliary polynomial has imaginary only roots (middle case in the diagram we drew above)\n\nThe system is hence marginally stable, oscillating at a frequency \\(\\sqrt{2}\\;\\;rad/s\\) and at \\(2\\;\\;rad/s\\) (the output remains bounded). We will use this point during the design phase.\n\n\n\nSituation: Zero Pivot Element in a Row\nA special situation arises when only the pivot element (the first element) of a row in the Routh array is zero, while at least one of the subsequent elements in the same row is non-zero. This scenario requires a distinct approach for continuation of the Routh array construction. Here are the details:\n\nThe pivot element in a Routh array refers to the first element of any row. A zero pivot element with at least one non-zero element in the same row presents a unique case in the array formulation.\nA zero pivot element makes it impossible to use the standard Routh array formula for the subsequent row, as it involves division by the pivot element.\nThe presence of a zero pivot element does not immediately suggest symmetrical roots or roots on the imaginary axis, unlike an all-zero row. Instead, it represents a numerical condition resulting from the specific coefficients of the characteristic equation.\n\n\nHandling the Zero Pivot Element\n\nApproach: To continue the Routh array construction, we typically replace the zero pivot element with a small positive number, denoted as $ $. This substitution allows the calculation to proceed without the indeterminacy caused by division by zero.\nSignificance of $ $: The value of $ $ is considered infinitesimally small, effectively tending towards zero. This substitution is a mathematical technique to overcome the computational hurdle and does not change the fundamental nature of the system being analyzed.\n\n🤔 Pop-up Question: What does the substitution of $ $ in place of a zero pivot element represent in the Routh array?\nAnswer: The substitution of $ $ represents a method to circumvent the computational issue of dividing by zero. It allows for the continuation of the Routh array construction and aids in drawing conclusions about the system’s stability.\nLet’s analyse this scenario through an example:\nConsider the system characterized by the polynomial\n\\[\ns^5 + 3s^4 + 2s^3 + 6s^2 + 6s + 9 = 0\n\\]\n\n\n\nOrder of $ s $\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\n$ s^5 $\n1\n2\n6\n\n\n$ s^4 $\n3\n6\n9\n\n\n$ s^3 $\n0\n3\n\n\n\n$ s^2 $\n\n\n\n\n\n$ s^1 $\n\n\n\n\n\n$ s^0 $\n\n\n\n\n\n\nWe cannot make any stability assessment. The presence of a 0 as a pivot element represents a numerical condition resulting from the specific coefficients of the characteristic equation.\nIn this case, we replace the zero pivot in the row with \\(\\epsilon\\) and continue constructing the array. This corresponds to perturbing the coefficients of the polynomial.\n\n\n\nPerturbation of the Characteristic Equation’s Coefficients\n\nStability of Roots: The roots of a polynomial in the left or right half-plane are unlikely to ‘jump’ from one side of the complex plane to the other with a small perturbation in the coefficients. This stability of roots’ locations in the complex plane forms the basis of this approach.\nEffect of Small Changes: If the coefficients of the characteristic polynomial are slightly altered (say by 1% or less), the physical locations of the roots in the complex plane are expected to shift only slightly. This implies that roots originally in the left half-plane will likely remain there, and similarly for those in the right half-plane.\nConcern with Roots on the Imaginary Axis: The risk in this perturbation method arises if the original characteristic equation has roots exactly on the imaginary axis (jω axis). A small change in coefficients might shift these roots into the right or left half-plane, altering the stability conclusion. If this was the case, you will not know if these imaginery roots have moved to the left or to the right.\nAssumption of No Roots on the Imaginary Axis: If it is known beforehand that there are no roots on the imaginary axis, then perturbing the coefficients slightly should not significantly affect the conclusions about the system’s overall stability.\n\nNote that an all-zero row will indicate if there might be roots on the imaginary axis\n\nHandling a Zero Pivot in the Routh Array: In practice, if a row in the Routh array has a zero pivot element, this problem can often be addressed by replacing the zero with a small positive number, $ $. This approach is effectively equivalent to a minor perturbation of the characteristic equation’s coefficients.\nImportance of All-Zero Row: If there’s an all-zero row in the Routh array, it usually indicates roots on the imaginary axis. Thus, in cases without an all-zero row, we can be more confident that perturbing the coefficients (as with the $ $ substitution) won’t lead to incorrect conclusions regarding stability.\nPractical Application: This technique is particularly useful in automated calculations or algorithms where dealing with a zero pivot element is computationally problematic. By introducing $ $, the Routh array can be completed, and stability can be assessed.\nRisk Assessment: The key point here is the assessment of risk when applying this perturbation. If there is a chance of roots being on the imaginary axis, one needs to be cautious, as perturbation could lead to incorrect stability conclusions.\n\nFor now we will assume that there are no roots on the imaginary axis and we perturbe the coefficients of the polynomial.\nIn this case, we replace the zero pivot in the row with \\(\\epsilon\\) and continue constructing the array.\nAfter replacing the zero pivot with \\(\\epsilon\\), we reassess the first column for sign changes. The conclusions drawn from this modified Routh array help in assessing the stability of the system.\nConsideration of ( ) in Limit Analysis: It is important to note that the use of $ $ in the context of a limiting process, where it tends towards zero, renders its sign (positive or negative) inconsequential. This is because, in cases where the system’s characteristic equation does not have roots on the imaginary axis, the specific sign of the small perturbation introduced by $ $ does not significantly impact the analysis of stability.\n\n\n\n\n\nWe then complete the Routh array:\n\n\n\n\n\nConcluding on the stability: We can now conlcude on the stability. Given that we have chosen $ &gt; 0 $ then we have two sign changes which means that the system has two roots on the RHP, and hence they system is unstable.\nSignificance of an All-Zero Row: If, in the process of letting $ $ approach zero, we encounter a row that becomes entirely zeros, this suggests the potential existence of roots on the imaginary axis. In such scenarios, any stability conclusions derived based on the limit $ $ should be approached with caution, as they may not accurately reflect the system’s behavior. It is crucial to consider the direction from which $ $) approaches zero (whether from the positive or negative side) in this context. The sign of $ $ becomes important because, depending on whether $ $ tends to zero from the positive or negative direction, it can affect the analysis of roots that lie close to the imaginary axis. This sensitivity to the sign of $ $ is particularly relevant when dealing with roots that may cross the imaginary axis due to such small perturbations, thereby altering the stability characteristics of the system. Therefore, in cases with an all-zero row, the stability assessment should include a careful examination of how these small changes in $ $ influence the location of roots in relation to the imaginary axis.\nIn such cases, we formulate an auxiliary polynomial using the row immediately above the all-zero row. This auxiliary polynomial aids in further analyzing the system’s behavior.\nThe next step involves dividing the original characteristic polynomial by this auxiliary polynomial to isolate the remaining roots. The Routh stability criterion is then reapplied to this remainder polynomial.\n\n\nIllustrative Example\nConsider the polynomial:\n\\[\n\\Delta(s) = s^6 + s^5 +3s^4 + 3s^3 + 3s^2 + 2s+ 1\n\\]\n\n\n\n\n\nAs $ $ approaches zero, the elements in the $ s^1 $-row of the Routh array converge to zero. This situation suggests a potential presence of roots on the imaginary axis in the s-plane. To address this, a closer inspection of the auxiliary polynomial is necessary. In cases where no roots are found on the imaginary axis, we typically proceed by substituting the all-zero row with the coefficients derived from the derivative of the auxiliary polynomial. However, if roots on the imaginary axis are indeed present, we take a different approach: the original characteristic polynomial is divided by the auxiliary polynomial, and the Routh stability criterion is then applied to this resultant remainder polynomial.\nIn the specific example being analyzed, when considering the limit of $ $ approaching zero in the $ s^2 $-row, the auxiliary polynomial is formulated as $ A(s) = s^2 + 1 = 0 $.\n\nRoots of Auxiliary Polynomial:\n\nThe auxiliary polynomial $ A(s) = s^2 + 1 = 0 $ has roots at $ s = j $, indicating the presence of roots on the imaginary axis in the s-plane. These roots are symmetrically located about the real axis.\n\nDivision of Original Polynomial:\n\nGiven the presence of imaginary-axis roots, the original characteristic polynomial should be divided by the auxiliary polynomial. This division isolates the remaining part of the polynomial, which excludes the roots already identified by the auxiliary polynomial. This division will yield a new polynomial representing the part of the system not accounted for by the auxiliary polynomial.\n\n\\[\n\\frac{\\Delta(s)}{A(s)} = s^4 + s^3 + 2s^2 + 2s + 1\n\\]\nApplication of Routh Stability Criterion to Remainder Polynomial:\n\nOnce the original polynomial is divided by $ A(s) = s^2 + 1 $, the resulting polynomial is subjected to the Routh stability criterion. This analysis will reveal the stability of the system concerning the roots that are not on the imaginary axis.\n\n\n\n\n\n\n\n\nInterpret the Results:\n\nIf all the elements in the first column of the new Routh array are positive, it indicates that the remaining roots (excluding those on the imaginary axis) are in the left half-plane, suggesting stability for this part of the system.\nIf there are sign changes in the first column, it indicates instability due to roots being in the right half-plane.\n\n\nIn this case, when \\(\\epsilon \\rightarrow 0\\), there are two sign changes in the first column of the array. There are hence two roots in the RHP.\nThe original polynomial \\(\\Delta(s)\\) therefore has two roots in the RHP and two roots on the imaginary axis.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html#extending-the-routh-criterion-beyond-absolute-stability",
    "href": "stability_and_routh_criterion.html#extending-the-routh-criterion-beyond-absolute-stability",
    "title": "Stability Analysis in Control Systems",
    "section": "Extending the Routh Criterion Beyond Absolute Stability",
    "text": "Extending the Routh Criterion Beyond Absolute Stability\n\nRelative Stability\nThe Routh stability criterion is employed to confirm the absolute stability of a system, verifying that all roots of its characteristic equation are located in the left half of the s-plane. Upon establishing that a system is absolutely stable, with all its characteristic roots in the left half-plane, the next step is to assess its relative stability. Relative stability focuses on understanding the characteristics of the system’s transient response.\nIn other words, relative stability refers to the degree of system stability, indicating how quickly a system’s response settles to its steady state or how resilient it is to oscillations and perturbations.\n\nSignificance of Root Locations: In the s-plane, the location of the system’s poles (roots of the characteristic equation) determines its relative stability. Poles that are farther to the left in the s-plane indicate a faster decay of transients, implying greater relative stability.\nTime Constant and Response: The transient response of a mode in a system can be represented as $ e^{-pt} $, where $ p $ is the pole and $ t $ is time. This can be rewritten as $ e^{-} $, where $ $, the time constant, is the inverse of the real part of the pole. A smaller $ $ means a faster response.\nUsing the Routh Stability Criterion: The Routh stability criterion can be extended to assess relative stability by examining how close the roots are to the imaginary axis. The criterion can ascertain if the roots lie to the left of a specified vertical line in the s-plane (e.g., $ s = -$), which represents a boundary of desired damping (see diagram below). You will know if your poles are faster than $ e^{-t} $\n\n\n\n\n\n\n🤔 Pop-up Question: How does the location of poles in the s-plane relate to relative stability?\nAnswer: The further to the left the poles are located in the s-plane, the quicker the transient response of the system decays, indicating higher relative stability. Poles closer to the imaginary axis suggest a slower decay of transients, implying lower relative stability.\n\n\nIllustrative Example 4\nLet’s consider the polynomial:\n\\[\ns^3 + 7s^2 + 25s + 39 = 0\n\\]\n\nExtending Routh Criterion for Relative Stability:\n\nTo analyze relative stability, we can modify the Routh criterion to assess if the poles lie to the left of a specific line in the s-plane, for instance, $ s = -$.\nBy substituting $ s = - $ into the characteristic equation, we shift the analysis to a new plane ($ $-plane). Here, $ $ is a pre-defined value representing the desired level of damping or speed of response.\n\n\nFor example, for \\(\\sigma=1\\), we can change the coordinate into $ s = - 1 $ and re-write the characteristic equation as:\n\\[\n\\hat{s}^3 + 4\\hat{s}^2 + 14\\hat{s} + 20 = 0\n\\]\nand we apply the Routh criterion to this new polynomial.\nWe can then verify that, in this case, there are no sign changes in the first column of the Routh array. This means that the original polynomial has no roots to the right of the line \\(s=-1\\).\n\nThe Routh array is establishing if the new polynomial has no roots to the right of \\(\\hat{s}=0\\).\nIf you set \\(\\hat{s}=0\\) into $ s = - 1 $, this will give us: \\(s=-1\\)\n\n🤔 Pop-up Question: How does the choice of $ $ affect relative stability analysis?\nAnswer: The choice of $ $ sets a benchmark for the desired speed of response or damping in the system. By analyzing the root locations relative to $ s = -$, we can determine whether the system’s response is faster or slower than this benchmark, thereby assessing its relative stability.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "stability_and_routh_criterion.html#parameter-sensitivity-and-stability-analysis",
    "href": "stability_and_routh_criterion.html#parameter-sensitivity-and-stability-analysis",
    "title": "Stability Analysis in Control Systems",
    "section": "Parameter Sensitivity and Stability Analysis",
    "text": "Parameter Sensitivity and Stability Analysis\nIn our ongoing exploration of control systems, delve let’s delve into an important aspect: the sensitivity of system stability to parameter variations. We’ll focus on a feedback system characterized by a parameter $ K $. Our goal is to determine the range of $ K $ that ensures system stability.\n\nThe Characteristic Equation and Routh Array\nConsider a feedback system where:\n\\[ G(s) = \\frac{K}{s(s^2+s+1)(s+4)} \\]\nand $ K $ is our design parameter, and we would like to choose it in such a way that the system remains stable.\nThe stability of the system is governed by the characteristic equation $ 1 + G(s) = 0 $. For this system, the characteristic equation becomes a function of $ K $:\n\\[\ns^4 + 5s^3 + 5s^2 + 4s + K = 0\n\\]\nLet’s construct the Routh array for this system, keeping in mind that it will be a function of $ K $:\n\\[\\begin{array}{c|ccc}\ns^4 & 1 & 5 & K\\\\\ns^3 & 5 & 4 & \\\\\ns^2 & \\frac{21}{5} & K & \\\\\ns^1 & \\frac{84/5 - 5K}{\\frac{21}{5}} & 0 \\\\\ns^0 & K &  \\\\\n\\end{array}\\]\n\nStability Constraints on Parameter $K $\nThe Routh array analysis reveals the constraints on $K $.\nTo ensure stability:\n\n$K $ must be greater than zero. This aligns with physical systems where, typically, amplifier gain ($K $) is positive.\nFurther constraints arise from the Routh array. For instance, the first column element corresponding to $s^1 $ should be positive, yielding the condition $K &lt; $.\n\nThus, for system stability, $K $ must lie within the range $0 &lt; K &lt; $.\n\n\nDesign Implications\n\nRange of Stability: The range $0 &lt; K &lt; $ becomes critical in system design. Any performance specifications must be met within this range to avoid instability.\nPole Movement with Varying $K $: As $K $ increases within this range, the closed-loop poles drift towards the right half-plane. A $K $ value of $ $ brings the poles to the \\(j\\omega\\) axis, indicating a marginally stable system. In the case where \\(K = \\frac{84}{25}\\) we would obtain an all-zero row in the Routh array. The corresponding roots would be on the \\(j\\omega\\) axis (more specifically they would be \\(\\pm j \\omega_0\\)).\nSystem Behavior Beyond the Stability Range: For $K &gt; $, the system becomes unstable, oscillating with a frequency of \\(\\omega_0\\) radians per second.\n\n🤔 Pop-up Question: What happens to the stability of a system as the parameter $K $ exceeds its upper stability limit?\nAnswer: When $K $ exceeds its upper stability limit (in this case, $ $), the system transitions from a marginally stable to an unstable state, characterized by oscillations at a specific frequency determined by the system’s poles.\n\n\nExtending the Analysis: Considering Delay Elements\nLastly, let’s extend our analysis to a more complex system where:\n\\[G(s) = \\frac{K}{s(s+1)} \\]\nand \\[H(s) = e^{-s\\tau_D} \\]\nwhere we are introducing a delay element $_D $.\n\n\n\n\n\nThe characteristic equation is:\n\\[\n1+G(s)H(s) = 1 + \\frac{Ke^{-s\\tau_D}}{s(s+1)} = 0\n\\]\n\nThe presence of delay makes the characteristic equation non-polynomial.\nHowever, by approximating the delay term $e^{-s_D} $ using Padé’s first-order approximation, we can revert to polynomial form, enabling the application of the Routh criterion.\nMore specifically, a rough approximation of \\(e^{-s\\tau_D}\\) is:\n\n\\[\ne^{-s\\tau_D} \\approx 1 - s\\tau_D\n\\]\nor a better one:\n\\[\ne^{-s\\tau_D} \\approx \\frac{1 - s\\frac{\\tau_D}{2}}{1 + s\\frac{\\tau_D}{2}} = \\frac{1 - sT}{1 + sT}\n\\]\nWe now have two unknown parameters: $K $ and \\(T\\).\nExercise: Apply the Routh stability criterion to the approximated characteristic equation involving $K $ and \\(T\\). Determine the stability range for these parameters.\n\\[\nTs^3 + (1+T)s^2 + (1-KT)s + K = 0\n\\]\n\\[\\begin{array}{c|cc}\ns^3 & T & 1-KT \\\\\ns^2 & 1+T & K \\\\\ns^1 & \\frac{1+T-2KT-KT^2}{1+T} & 0 \\\\\ns^0 & K &  \\\\\n\\end{array}\\]\nFor the system to be stable:\n\n\\(T&gt;0\\) (physically makes sense)\n\\(K&gt;0\\)\n\\(\\frac{1+T-2KT-KT^2}{1+T} &gt;0\\) \\(\\Rightarrow\\) \\(1+T-KT(T+2)&gt;0\\) \\(\\Rightarrow\\) \\(KT = \\frac{T+2}{T+1}\\) (marginal case).\n\nWe can plot this:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the range of T, avoiding T = 0 and T = -1 to prevent division by zero\nT = np.linspace(0, 1, 400)\nT = T[np.logical_and(T != 0, T != -1)]\n\n# Calculate K as a function of T\nK = (T + 2) / (T * (T + 1))\n\n# Plotting\nplt.plot(T, K, label='K(T) = (T + 2) / (T * (T + 1))')\nplt.fill_between(T, 1, K, color='lightblue', alpha=0.5, label='Stable Range (below curve)')\n\nplt.xlabel('T')\nplt.ylabel('K')\nplt.title('Plot of K(T) = (T + 2) / (T * (T + 1))')\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nNote on Delay and Stability: - This example illustrates how increased delay (\\(\\tau_D\\)) reduces the stability margin, highlighting the destabilizing effect of delay in control systems. - The system will be stable for a lower value of \\(K\\). - Dead time causes instability in the system, and should be reduced as much as possible. - Any pair \\((K, T)\\) must lie in the stable range.",
    "crumbs": [
      "Stability Analysis in Control Systems"
    ]
  },
  {
    "objectID": "20_Design_of_feedback_control_continued.html",
    "href": "20_Design_of_feedback_control_continued.html",
    "title": "Understanding the Standard Second-Order System: Recap",
    "section": "",
    "text": "We first summarize our previous discussion on the various transient response and steady-state response measures with respect to a standard second-order system. Recall the model of the standard second-order system:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_ns + \\omega_n^2}\n\\]\nHere, $ Y(s) $ is the output in the Laplace domain, and $ _n $ and $ $ represent the natural frequency and damping ratio, respectively.",
    "crumbs": [
      "Understanding the Standard Second-Order System: Recap"
    ]
  },
  {
    "objectID": "20_Design_of_feedback_control_continued.html#system-performance-specification",
    "href": "20_Design_of_feedback_control_continued.html#system-performance-specification",
    "title": "Understanding the Standard Second-Order System: Recap",
    "section": "System Performance Specification",
    "text": "System Performance Specification\n\nHigh Natural Frequency ($ _n $):\nThe natural frequency, $ _n $, plays a pivotal role in determining the speed of response of a system. A higher $ _n $ leads to an improved speed of response, characterized by a lower rise time ($ t_r \\() and reduced peak time (\\) t_p $). Additionally, a higher $ n $ contributes to enhanced steady-state accuracy, denoted as $ e{ss} $. However, it’s important to note that the value of $ _n $ is subject to limitations imposed by system bandwidth and hardware constraints. For instance, achieving a high $ _n $ may necessitate a significantly high amplifier gain, which can, in turn, lead to saturation issues. This highlights the necessity for careful hardware design, including the implementation of filters that can mitigate issues related to noise and hardware limitations.\n\n\nRegulating Damping Ratio ($ $):\nThe damping ratio, $ $, is the other critical parameter to consider after $ _n $ has been decided. $ $ exerts a significant influence on the system’s rise time, overshoot, and steady-state error. A lower value of $ $ generally results in a faster rise time, although the impact might not be very pronounced within the range of values typically considered for $ $. Additionally, a lower $ $ leads to a reduced peak time and improves the steady-state error in response to ramp inputs. However, it’s crucial to recognize that a lower $ $ also results in a higher peak overshoot and brings the system closer to instability.\nThe relationship between $ $ and the normalized settling time ($ _n t_s $) is complex and non-linear. The minimum $ _n t_s $ is achieved at $ = 0.68 $ for a 5% tolerance band, and $ = 0.8 $ for a 2% tolerance band. We observed that decreasing $ $ can lead to an increase in settling time. It’s essential to understand that rise time alone does not fully define the speed of response; the settling time is also a crucial factor. The trade-off between these parameters must be resolved based on the specific requirements of the application. It’s noteworthy that increasing $ $ beyond 0.68 for a 5% tolerance band, or beyond 0.8 for a 2% tolerance band, does not yield benefits, as it only results in a more sluggish system with reduced performance in both settling time and rise time. For a detailed analysis, refer to the ’Normalized Settling Time ($ _n t_s \\() vs Damping Ratio (\\) $)’ plot in the notebook titled ‘19_Design_of_feedback_control’ and reported below.\n\n\n\n\n\n\n\nSummary\n\nHigh Natural Frequency (\\(\\omega_n\\)):\n\nLeads to faster response speed.\nReduces rise time (\\(t_r\\)) and peak time (\\(t_p\\)).\nImproves steady-state accuracy (\\(e_{ss}\\)).\nLimited by:\n\nBandwidth considerations.\nHardware capabilities.\n\nChallenges:\n\nHigh \\(\\omega_n\\) might require high amplifier gain.\nPotential issues: saturation problems.\n\nSolutions:\n\nAppropriate hardware design.\nUse of filters to mitigate noise and hardware limitations.\n\n\nRegulating Damping Ratio (\\(\\zeta\\)):\n\nAffects rise time, overshoot, and steady-state error.\nLower \\(\\zeta\\) leads to:\n\nFaster rise time (though not significantly over typical \\(\\zeta\\) ranges).\nLower peak time.\nImproved steady-state error for ramp inputs.\nHigher peak overshoot and closer proximity to instability.\n\nComplex relationship with \\(\\omega_n t_s\\) (settling time):\n\nMinimum \\(\\omega_n t_s\\) observed at:\n\n\\(\\zeta = 0.68\\) for 5% tolerance band.\n\\(\\zeta = 0.8\\) for 2% tolerance band.\n\n\nSettling time considerations:\n\nDecreasing \\(\\zeta\\) can increase settling time.\nRise time is not the sole determinant of response speed; settling time is also crucial.\n\nApplication-specific conflict resolution:\n\nChoose \\(\\zeta\\) based on the application’s need to balance rise time and settling time.\n\nBeyond certain points (\\(\\zeta &gt; 0.68\\) for 5% tolerance, \\(\\zeta &gt; 0.8\\) for 2% tolerance):\n\nLeads to a sluggish system.\nNegatively impacts both settling time and rise time.\nRefer to the ‘Normalized Settling Time (\\(\\omega_n t_n\\)) vs Damping Ratio (\\(\\zeta\\))’ plot in notebook ‘19_Design_of_feedback_control’ for detailed insights.\n\n\n\n\n\nDamping Ratio (\\(\\zeta\\)) Range and Key Considerations\n\nIndustry Norms for $ $:\n\nGeneral Range: In standard industry practices, $ $ is usually set between 0.4 and 0.7, particularly when no specific quantitative performance criteria are provided by the user.\n\n\n\nTailoring for High Static Accuracy:\n\nSteady-State Error Relationship: Considering the equation $ e_{ss} = $, achieving high static accuracy involves:\n\n**Maximizing $ _n $**: A higher $ _n $ is preferable, which may necessitate incorporating specialized hardware to handle the higher performance requirements.\nMinimizing $ $: A smaller $ $ is desired. In certain specific applications, a value as low as $ = 0.1 $ may be considered acceptable. Although this leads to a system with high oscillations and poorer transient performance, it offers enhanced static accuracy. However, it’s crucial to note that such low values of $ $ edge the system closer to instability, making it more sensitive to parameter variations and affecting its robustness.\n\n\n\n\nSpecialized Applications:\n\nExample - Robotic Arm Control Systems: In applications like robotic arms, a higher $ $ value, approaching 1, might be more suitable. This ensures a slower but more controlled movement, preventing oscillations that could disrupt the arm’s path in its operating environment.\n\n\n\nTypical $ $ Values for General Applications:\n\nPreferred Range: For most applications, the focus remains within the range $ 0.4 &lt; &lt; 0.7 $, though there can be slight deviations from these limits based on specific requirements.\n\n\n\nNatural Frequency ($ _n $) Considerations:\n\nDependence on System Hardware: The feasible range for $ _n $ is highly dependent on the system’s hardware and its configuration. Unlike $ $, there’s no standard range for $ _n $ as it varies significantly based on the physical and operational characteristics of the system.",
    "crumbs": [
      "Understanding the Standard Second-Order System: Recap"
    ]
  },
  {
    "objectID": "20_Design_of_feedback_control_continued.html#translating-performance-specifications",
    "href": "20_Design_of_feedback_control_continued.html#translating-performance-specifications",
    "title": "Understanding the Standard Second-Order System: Recap",
    "section": "Translating Performance Specifications",
    "text": "Translating Performance Specifications\nTranslating performance specifications into closed-loop pole requirements is a critical step in control system design. This process involves determining where the poles of the closed-loop transfer function should be placed in the complex plane to meet the desired performance criteria like overshoot, rise time, settling time, and steady-state error.\nThe closed-loop transfer function for a standard second-order system is given by:\n\\[ T(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nwhere $ $ is the damping ratio and $ _n $) is the natural frequency.\nThe poles of this transfer function are solutions to the characteristic equation:\n\\[ s^2 + 2\\zeta\\omega_n s + \\omega_n^2 = 0 \\]\nwhich are:\n\\[ s_{1,2} = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1} \\]\n\n\n\n\n\nPop-up Question: What is the region in the s-plane for the closed loop poles given the requirements for \\(\\omega_n\\) and \\(\\zeta\\) that we have specified?\nAnswer:\nTo determine the ideal region in the s-plane for closed-loop poles based on specified values of natural frequency ($ _n \\() and damping ratio (\\) $), we need to consider both these parameters and how they influence the system’s response. Here’s a breakdown of the argument using the provided text:\n\n1. Establishing a Range for Natural Frequency ($ _n $):\n\n**Minimum $ _n $**: There should be a minimum value for $ _n $ to prevent the rise time from becoming too large. This can be visualized as a circle in the s-plane with a radius equal to this minimum $ _n $ value, denoted as $ _n^1 $.\n**Maximum $ _n $**: The upper limit of $ _n $ is constrained by hardware capabilities and noise considerations. This can be represented by another circle with a radius of $ _n^2 $.\n\n\n\n2. Considering Damping Ratio ($ $):\n\nRange of $ $: In this case, we consider $ $ values of 0.4 and 0.7. These values dictate the angle made by the line from the origin to the pole with the negative real axis. The angles can be calculated as $ ^{-1}(0.4) $ and $ ^{-1}(0.7) $.\n\n\n\n3. Ideal Region for Closed-Loop Poles:\n\n**Combining $ _n $ and $ $**: The ideal region for the closed-loop poles is where these two considerations intersect. Specifically, the poles should lie within a sector defined by the angles corresponding to $ = 0.4 $ and $ = 0.7 $ and between the circles representing the minimum and maximum $ _n $ values.\nSymmetry in S-Plane: Given the symmetric nature of the s-plane, a corresponding point reflecting the pole position would exist in the lower half of the plane.\nRegion Characteristics: This region, bounded by the red curves (representing the natural frequency considerations) and the green curves (representing the damping considerations), is where the system’s closed-loop poles should ideally be located for a standard system with two poles.\n\nTo summarise, for general applications, the closed-loop poles of a system should ideally be located within a specific region in the s-plane. This region is defined by the minimum and maximum values of the natural frequency ($ _n \\() and within the angular bounds set by the specified damping ratios (\\) $). This placement ensures a balanced system response, considering both the speed of response (influenced by $ _n $) and the level of overshoot and stability (influenced by $ $). This is shown in the picture below.",
    "crumbs": [
      "Understanding the Standard Second-Order System: Recap"
    ]
  },
  {
    "objectID": "20_Design_of_feedback_control_continued.html#handling-non-standard-systems-in-control-engineering",
    "href": "20_Design_of_feedback_control_continued.html#handling-non-standard-systems-in-control-engineering",
    "title": "Understanding the Standard Second-Order System: Recap",
    "section": "Handling Non-Standard Systems in Control Engineering",
    "text": "Handling Non-Standard Systems in Control Engineering\nSo far, our discussion has been focused on a standard second-order system, represented by the transfer function:\n\\[ Y(s) / R(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nHowever, real-world systems often deviate from this standard model. They may have more than two poles, introduce zeros, or have other complexities. The next part of our course will explore how to handle these variations.\n\nHandling Systems with a Zero\n\n1. Introduction of a Zero in the System\n\nIn some systems, particularly those employing Proportional-Derivative (PD) control, a zero is introduced into the system dynamics.\nFor instance, applying PD control to a second-order system adds a zero to the transfer function.\n\n\n\n2. Modified Transfer Function\n\nThe new transfer function, in the presence of a zero, can be represented as: \\[ \\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2 (s + z)}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\] where $ s=-z $ is the zero of the system.\nWe want to understand the effects of the zero on the transient of the reponse.\n\n\n\n3. Normalizing the Transfer Function\n\nTo facilitate analysis, we normalize the transfer function so the steady-state value of $ Y $ for a step input becomes 1. This is achieved by multiplying the transfer function by a factor of $ 1/z $. This does not affect the dynamics which we want to study.\nThe normalized transfer function becomes: \\[ \\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{z} \\cdot \\frac{(s + z)}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nwe can re-write this as: \\[ Y(s) =  \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}R(s) + \\frac{1}{z} \\cdot \\frac{s\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}R(s) \\]\nWe we write the transfer function in this way, we notice:\n\nthe left part is the standard second-order transfer function\nthe right part is the derivative of the second-order transfer function (multiplied by a scaling factor)\n\n\n\n\n4. Effect on Transient Response\n\nThe introduction of a zero affects the transient response of the system.\nInitially, the derivative component (due to the zero) is large, significantly impacting the early part of the response.\nThe overall effect is dependent on the position of the zero. A zero closer to the origin has a more pronounced effect compared to one further in the left-half plane.\n\nTo illustrate the effect of adding a zero on the transient response of a control system, and to compare it with the standard second-order system response, we can use Python’s control systems library. Below is a Python code snippet that accomplishes this task. The code generates a plot showing the response of a standard second-order system and the modified system with an additional zero, both subjected to a unit step input.\n\n\"\"\"\n- 'omega_n' and 'zeta' are the natural frequency and damping ratio of the system, respectively.\n- 'zero_position' is the position of the additional zero in the s-plane.\n- 'system_standard' represents the standard second-order system.\n- 'system_zero_added' is the system with an additional zero.\n- The step responses of both systems are computed using ctl.step_response.\n- The responses are then plotted for comparison.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System Parameters\nomega_n = 1  # Natural frequency\nzeta = 0.3   # Damping ratio\n\n# Position of the zero - change this to see the effects of the zero on the response\nzero_position = -0.5  \n\n# Define the standard second-order system\nnum_standard = [omega_n**2]\nden_standard = [1, 2*zeta*omega_n, omega_n**2]\nsystem_standard = ctl.TransferFunction(num_standard, den_standard)\nprint(system_standard)\n\n# Define the system with an additional zero\nnum_zero_added = [1, -zero_position]\nden_zero_added = 1\nsystem_zero_added = 1/(-zero_position)*ctl.TransferFunction(num_zero_added, den_zero_added) * system_standard\nprint(system_zero_added)\n\n# Time range for the response\nt = np.linspace(0, 20, 500)\n\n# Compute the step responses\nt_standard, y_standard = ctl.step_response(system_standard, T=t)\nt_zero_added, y_zero_added = ctl.step_response(system_zero_added, T=t)\n\n# Unit Step Reference (Constant value of 1 across the time range)\nunit_step = np.ones_like(t_standard)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_standard, y_standard, label='Standard Second-Order System')\nplt.plot(t_zero_added, y_zero_added, label='System with Zero Added', linestyle='--')\nplt.plot(t, unit_step, label='Unit Step Input', color='red', linestyle='-', linewidth=3)\n\nplt.title('Comparison of Step Response with Unit Step Input')\n\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n       1\n---------------\ns^2 + 0.6 s + 1\n\n\n    2 s + 1\n---------------\ns^2 + 0.6 s + 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Transient Response with an Added Zero:\n\nStandard Second-Order System Response:\n\nThe transient response of a standard second-order system (without a zero) typically shows a certain rise time, overshoot, and settling time, depending on its damping ratio ($ \\() and natural frequency (\\) _n $).\n\nEffect of Adding a Derivative Component (Zero):\n\nAdding a zero to the system effectively adds a derivative component to the response.\nInitially, when the response is changing rapidly, the derivative of the response (slope) is large. This leads to a significant effect on the initial part of the transient response due to the zero.\nAs the response starts settling and the changes become less drastic, the derivative (slope) becomes smaller. Therefore, the influence of the zero diminishes in the later part of the response.\n\nVisualizing the Effect of the Zero:\n\nThe transient response curve of the modified system gets ‘lifted up’ or altered primarily in the initial phase due to the significant derivative at the beginning.\nThe scale factor $ 1/z $ (where $ z $ is the position of the zero) influences the magnitude of this effect. A zero closer to the origin (small $ z $) has a more pronounced impact, while a zero further into the left-half plane (large $ z $) has a negligible effect.\n\nImpact of Zero on Decay of Response:\n\nThe decay of the response is primarily governed by the real part of the system’s poles, specifically by $ e^{-_n t} $.\nThe added zero does not significantly change the decay rate dictated by the poles but alters the initial response dynamics.\n\n\n\n\nParameters to Show the Effect of Zero:\nTo better illustrate the impact of adding a zero, consider adjusting these parameters in the simulation above:\n\nPosition of the Zero ($ z $):\n\nVarying the position of the zero closer or further from the origin will demonstrate its impact on the initial response.\n\nDamping Ratio ($ $):\n\nAltering $ $ can show how the system’s inherent damping interacts with the effects introduced by the zero.\n\n**Natural Frequency ($ _n $)**:\n\nChanging $ _n $ can help visualize how the system’s speed of response is affected by the zero.\n\n\nBy adjusting these parameters in a simulation environment, you can vividly see how the presence of a zero in the system’s transfer function modifies its transient response, especially in the initial phase following a step input. This is essential for understanding the design implications of such modifications in control systems.\n\n\nGuideline on the Influence of a Zero\n\nRelative Position of Zero and Complex Conjugate Poles:\n\nThe effect of a zero on the transient response of a control system is significantly related to its position relative to the system’s complex conjugate poles.\nIf a zero is approximately five times further away from the origin than the complex conjugate poles, its impact on the transient response is negligible.\n\n\n\n\nDesign Implications\n\nNegligible Impact of Distant Zero:\n\nWhen the zero is sufficiently far from the complex conjugate poles (five times further), you can design the system as if the zero doesn’t exist. This means the standard performance measures (like rise time, settling time, peak overshoot) applicable to a second-order system without a zero can still be used.\n\nAdjusting Design Parameters:\n\nIf the zero is closer and significantly affects the response, adjustments in the system’s design parameters, particularly the damping ratio ($ $), may be necessary.\nFor instance, if a system designed for a damping ratio of 0.4 experiences increased overshoot due to the zero, the designer might opt for a slightly higher damping ratio (like 0.5) to compensate for this effect.\n\nDesign Verification through Simulation:\n\nThe actual impact of the zero and the efficacy of any compensatory design changes should be verified through simulation.\nThe simulation will confirm whether the chosen damping ratio achieves the desired performance, particularly in terms of peak overshoot.\n\n\n\n\nRe-Entering the Design Cycle\n\nIterative Design Process:\n\nThe design process is iterative. If the initial design (with the adjusted damping ratio) does not meet the requirements, further adjustments and simulations are necessary.\nThis iterative process continues until the design achieves the desired transient response characteristics.\n\nExample Scenario:\n\nIf a design for $ = 0.4 $ leads to an overshoot of 25% due to the presence of a zero, the designer might increase $ $ to 0.5 to reduce the overshoot. However, this change is then tested through simulation to ensure it meets the overall system performance criteria.\n\n\nIn summary, the text provides a practical guideline for control system designers on how to account for the presence of a zero in the system’s transfer function, particularly when it impacts transient response. The key takeaway is to assess the zero’s influence based on its relative position to the dominant poles and to adjust design parameters accordingly, verifying these changes through simulation to ensure they meet the desired system performance.\n\n\nRight Half Plane Zeros and System Dead Times\nLet’s now discuss the implications of having a zero in the right-half of the s-plane in a control system’s transfer function, particularly in relation to stability and system response.\n\nZeros in the Right-Half Plane\n\nImpact on Stability:\n\nA zero in the right-half plane (RHP) does not directly affect the stability of a system. Stability is generally determined by the poles of the system, not the zeros. A system remains stable as long as all its poles are in the left-half plane (LHP).\n\nPhysical Occurrence:\n\nIn most physical systems, zeros in the RHP are uncommon. However, they can appear in certain scenarios, particularly in systems with dead time.\n\n\n\n\nDead Time and Its Representation\n\nModeling Dead Time:\n\nDead time in a system is a delay between the input and the output response. It is often denoted as $ e^{-s_D} $ in the Laplace domain, where $ _D $ is the dead time.\nA common approximation for dead time is $ e^{-s_D} $. This approximation introduces a zero in the RHP (at $ s = 2/_D $) and a pole in the LHP (at $ s = -2/_D $).\n\n\n\n\nEffects of a Zero in the RHP\n\nInfluence on System Response:\n\nA zero in the RHP can significantly alter the system’s response. Unlike a zero in the LHP, which typically enhances the system’s ability to track rapid changes in input (due to the derivative-like effect), a RHP zero can lead to undesirable characteristics in the response.\n\nReduced Overshoot and Increased Sluggishness:\n\nThe presence of a RHP zero tends to reduce peak overshoot in the system’s response. This is because the effect of the zero counteracts the rising action of the system’s response, akin to subtracting the derivative component rather than adding it.\nMore significantly, a RHP zero can make the system response more sluggish. This means slower response times and potentially poorer performance in tracking inputs or recovering from disturbances.\n\nPractical Consideration in Process Control:\n\nIn process control systems where dead time is common, dealing with the effects of a RHP zero is a practical challenge. Engineers must design controllers that can compensate for the delay and sluggishness introduced by the dead time, ensuring the system can still meet its performance requirements.\n\n\nIn summary, while a zero in the RHP does not affect the stability of a control system, it can have a marked impact on the system’s transient response, often making it less responsive and reducing overshoot. These characteristics need to be carefully considered and addressed in control system design, especially in process control applications where dead time is a factor. Understanding and managing the effects of RHP zeros is crucial in ensuring that the system operates effectively despite these inherent challenges.\n\n\"\"\"\n- 'omega_n' and 'zeta' are the natural frequency and damping ratio of the system, respectively.\n- 'zero_position' is the position of the additional zero in the s-plane.\n- 'system_standard' represents the standard second-order system.\n- 'system_zero_added' is the system with an additional zero.\n- The step responses of both systems are computed using ctl.step_response.\n- The responses are then plotted for comparison.\n\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# System Parameters\nomega_n = 1  # Natural frequency\nzeta = 0.3   # Damping ratio\n\n# Position of the zero - change this to see the effects of the zero on the response\nzero_position = 1  \n\n# Define the standard second-order system\nnum_standard = [omega_n**2]\nden_standard = [1, 2*zeta*omega_n, omega_n**2]\nsystem_standard = ctl.TransferFunction(num_standard, den_standard)\nprint(system_standard)\n\n# Define the system with an additional zero\nnum_zero_added = [1, -zero_position]\nden_zero_added = 1\nsystem_zero_added = 1/(-zero_position)*ctl.TransferFunction(num_zero_added, den_zero_added) * system_standard\nprint(system_zero_added)\n\n# Time range for the response\nt = np.linspace(0, 20, 500)\n\n# Compute the step responses\nt_standard, y_standard = ctl.step_response(system_standard, T=t)\nt_zero_added, y_zero_added = ctl.step_response(system_zero_added, T=t)\n\n# Unit Step Reference (Constant value of 1 across the time range)\nunit_step = np.ones_like(t_standard)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_standard, y_standard, label='Standard Second-Order System')\nplt.plot(t_zero_added, y_zero_added, label='System with Zero Added', linestyle='--')\nplt.plot(t, unit_step, label='Unit Step Input', color='red', linestyle='-', linewidth=3)\n\nplt.title('Comparison of Step Response with Unit Step Input')\n\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n       1\n---------------\ns^2 + 0.6 s + 1\n\n\n    -s + 1\n---------------\ns^2 + 0.6 s + 1",
    "crumbs": [
      "Understanding the Standard Second-Order System: Recap"
    ]
  },
  {
    "objectID": "20_Design_of_feedback_control_continued.html#handling-higher-order-systems",
    "href": "20_Design_of_feedback_control_continued.html#handling-higher-order-systems",
    "title": "Understanding the Standard Second-Order System: Recap",
    "section": "Handling Higher Order Systems",
    "text": "Handling Higher Order Systems\nWe are now ready to discuss the complexities involved in designing higher-order control systems and to introduce the concept of the “dominance condition.”\nA standard second-order model, while useful, is often an oversimplification for real-world systems. In practice, systems are usually of higher order.\nA standard second-order system can be represented by the transfer function:\n\\[ Y(s) / R(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nA real-system, of order higher than second might look like:\n\\[ Y(s) / R(s) = \\frac{p}{s+p}\\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2} \\]\nwhere the \\(p\\) at the numerator normalised the response to 1.\n\nUnderstanding the System’s Modes\nIn this third-order system, the system’s response is dictated by two modes:\n\nMode Associated with the Original Second-Order System:\n\nThis mode follows the form $ e^{-_nt} $, which is characteristic of the original second-order system.\nAgain, the residue at the system’s poles dictates the magnitude of this mode.\n\nMode Associated with the Pole:\n\nThis mode is represented by $ e^{-pt} $, where $ p $ is the position of the added pole in the system (if any).\nThe residue at this pole will influence how much this mode contributes to the overall system response.\n\n\n\n\nDesigning a Higher-Order System: Dominance Condition\nThe concept of “dominance condition” implies that for a higher-order system, the transient response is primarily influenced by two poles closest to the imaginary axis if the other poles are sufficiently far away.\nThis allows us to use the design principles of a second-order system for higher-order systems under certain conditions.\n\nDominance Condition:\n\nThe dominance condition is introduced as an important concept to deal with high-order systems. It states that in a higher-order system, if certain poles (typically the ones closest to the imaginary axis in the s-plane) are dominant, the system’s transient response can be approximated by considering only these dominant poles.\nIf other poles are sufficiently far into the left half-plane (more than five times farther from the origin than the dominant poles), their contribution to the transient response can be considered negligible.\n\nImplication of Dominance Condition:\n\nWhen the dominance condition is satisfied, the design and analysis of the higher-order system can be simplified to focus on the dominant poles. The parameters $ $ (damping ratio) and $ _n $ (natural frequency), which are only relevant for second-order systems, become relevant gain in this scenario.\n\n\nIn a higher-order system, such as a tenth-order system, the design may have multiple poles. The dominance condition becomes critical here:\n\nIf the non-dominant poles are significantly far from the dominant poles (say, more than five times the real part of the dominant poles), their contribution to the transient response is minor.\nThis allows the designer to focus on the dominant poles (typically the ones closest to the imaginary axis) for designing the system’s transient response.\nRemember that \\(\\zeta\\) and \\(\\omega_n\\) are meaningless unless we are dealing with a second order system. It is our responsibility to verify that the dominance condition is satisfied.\nIn cases where the dominance condition is not met, the design becomes more complex. The system may need to be analyzed and designed using a more detailed approach, considering the effects of all poles and zeros. In this case, an iterative design process, including simulation, is necessary to validate the system’s performance against the desired specifications. Adjustments are made based on simulation results until the system meets its performance criteria (trial and error design).\n\n\n\nExample: Pole-Zero Cancellation\nConsider a scenario where the system has a problematic pole configuration that determine performance.\n\n\n\n\n\nFor this system, the performance are not driven by \\(\\zeta\\) and \\(\\omega_n\\). Note that in this case, there are no dominant poles and the system must be evaluated as a complete third order system.\nThe requirements are still expressed in terms of peak overshoot, rise time, etc. but we cannot simply use the approach we used so far.\nA method to minimize the impact of an undesirable pole is to introduce a zero near it, effectively canceling its impact. This is known as the pole-zero cancellation method.\n\nPole-Zero Cancellation: If a zero is placed exactly at the location of a pole, it cancels the pole’s effect (the residue at that pole becomes zero). We can design a PD controller that places the zero where we need it.\nFor a third-order system, if this cancellation occurs, the system’s response might be effectively dictated by the remaining two poles, simplifying the design process.\nIn mathematical terms, the pole-zero cancellation changes the residues at the canceled pole, thereby altering the system’s response. This can be particularly useful for managing complex poles or poles that adversely affect system performance.\nNote that this does not need to be a precise cancellation, placing the zero sufficiently close reduces the effect of the unwanted pole.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Change this to simulate parameter noise in the placement of the zero\n# You can try 0 (no noise), 1e-2, etc.\nDelta = 0 #1e-2\n\n# System parameters\nomega_n = 1  # Natural frequency for complex conjugate poles\nzeta = 0.5   # Damping ratio for complex conjugate poles\nreal_pole = -2  # Location of the real pole\n\n# Transfer function of the original third-order system\n# Two complex conjugate poles and one real pole\nnum_original = [-real_pole*omega_n**2]\n# (s^2 + 2*zeta*omega_n s + omega_n**2)(s+real_pole)\nden_original = [1, \n                -real_pole + 2 * zeta * omega_n, \n                2 * zeta * omega_n * -real_pole + omega_n**2, \n                omega_n**2 * -real_pole] \n\nsystem_original = ctl.TransferFunction(num_original, den_original)\n\n# Add a zero to cancel the real pole\n# The zero is located at the position of the real pole\nnum_modified = [1, -real_pole+Delta]\nsystem_modified = ctl.TransferFunction(num_modified, den_original)\n\n# Standard second-order system\nnum_second_order = [omega_n**2]\nden_second_oder = [1, 2*zeta*omega_n, omega_n**2]\n\nsystem_second_order = ctl.TransferFunction(num_second_order, den_second_oder)\n\n# Time range for the response\nt = np.linspace(0, 10, 500)\n\n# Compute the step responses\nt_original, y_original = ctl.step_response(system_original, T=t)\nt_modified, y_modified = ctl.step_response(system_modified, T=t)\nt_second_order, y_second_order = ctl.step_response(system_second_order, T=t)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t_original, y_original, label='Original System (Third-Order)')\nplt.plot(t_modified, y_modified, label='System with Zero Canceling Real Pole', linestyle='--', linewidth=3)\nplt.plot(t_second_order, y_second_order, label='Second-Order System', color='green', linestyle=':', linewidth=3)\nplt.title('Comparison of Step Response: Original vs Modified System vs Second-Order')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nConclusion\nIn conclusion, transitioning from a standard second-order system to higher-order systems in control design involves careful consideration of poles and zeros’ contributions. Techniques like normalization and pole-zero cancellation become essential in managing the system’s transient response effectively.",
    "crumbs": [
      "Understanding the Standard Second-Order System: Recap"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html",
    "href": "introduction_to_control_systems.html",
    "title": "Introduction to Control Systems",
    "section": "",
    "text": "In this notebook, we will explore the fundamental concepts of control systems and the various modes of control, including proportional control, integral control, and derivative control.\nIn a control system, we have a basic feedback structure consisting of several components:\nFor simplicity we are considering a unity-feedback system, and hence we focus on the system error $e$ directly.\nNotes: - Unity feedback so \\(e = r-y\\), whereas if it was through a sensor we would have had \\(\\hat{e}\\).\nHistorically there were hardware limitations (controllers had to be hydraulic, pneumatic or electrical).\nWith the advent of digital technology, virtually any function can be realized through a digital computer, removing the limitations of hardware-based control systems.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#proportional-control-p-control",
    "href": "introduction_to_control_systems.html#proportional-control-p-control",
    "title": "Introduction to Control Systems",
    "section": "Proportional Control (P-Control)",
    "text": "Proportional Control (P-Control)\nProportional control is one of the simplest control modes. The control signal $u$ in proportional control is given by:\n\\[\nu = K_c \\cdot e\n\\]\nWhere \\(K_c\\) is the controller gain.\nIn the Laplace domain:\n\\[\nU(s) = K_c \\cdot E(s)\n\\]",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#proportional---integral-control-pi-control",
    "href": "introduction_to_control_systems.html#proportional---integral-control-pi-control",
    "title": "Introduction to Control Systems",
    "section": "Proportional - Integral Control (PI-Control)",
    "text": "Proportional - Integral Control (PI-Control)\nProportional-Integral control, often known as PI control, introduces integral action to improve control performance.\nThe control signal \\(u\\) in integral control is given by:\n\\[\nu = K_c \\cdot \\big( e + \\frac{1}{T_I} \\int e dt \\big)\n\\]\nIt is composed of two components, one which is proportional to the error, and one that is proportional to the integral of the error.\nIn the Laplace domain:\n\\[\nu = K_c \\cdot \\big( 1 + \\frac{1}{T_I s}\\big)E(s)\n\\]\nSometime also written as:\n\\[\nu = \\big( K_c + \\frac{K_I}{s}\\big)E(s)\n\\]\nWhere: - \\(K_I\\) is called integral gain - \\(K_c\\) is called controller gain - \\(T_I\\) is the integral time or reset time.\nWe’ll explore the benefits of integral control and its application in control systems.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#proportional-derivative-control-pd-control",
    "href": "introduction_to_control_systems.html#proportional-derivative-control-pd-control",
    "title": "Introduction to Control Systems",
    "section": "Proportional-Derivative Control (PD-Control)",
    "text": "Proportional-Derivative Control (PD-Control)\nProportional-Derivative control, often known as PD control, introduces derivative action to control systems.\nThe control signal \\(u\\) in derivative control is given by:\n\\[\nu = K_c \\big(e + T_D \\dot{e}\\big )\n\\]\nIn the Laplace domain:\n\\[\nU(s) = K_c \\big(1 + T_D s\\big )E(s)\n\\]\nWhere \\(T_D\\) is the derivative time or rate time.\nSometime also written as:\n\\[\nu = \\big( K_c + K_D s\\big)E(s)\n\\]\nWhere \\(K_D\\) is called derivative gain.\nWe’ll examine the role of derivative control and its impact on control system performance.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#pid-control",
    "href": "introduction_to_control_systems.html#pid-control",
    "title": "Introduction to Control Systems",
    "section": "PID Control",
    "text": "PID Control\nPID control combines proportional, integral, and derivative actions in a single controller. The control signal \\(u\\) in PID control is given by:\n\\[\nu = K_c \\cdot (e + \\frac{1}{T_I} \\int e dt + T_D \\cdot \\frac{de}{dt})\n\\]\n\\[\nU(s) = K_c \\big(1+\\frac{1}{T_I s} + T_Ds\\big)E(s)\n\\]\nSometime written also as:\n\\[\nU(s) =  \\big(K_c+\\frac{K_I}{s} + K_Ds\\big)E(s)\n\\]\nOften used as first attempt before attemping different methods if the PID does not work.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#example-temperature-control-system",
    "href": "introduction_to_control_systems.html#example-temperature-control-system",
    "title": "Introduction to Control Systems",
    "section": "Example: Temperature Control System",
    "text": "Example: Temperature Control System\nConsider a temperature control system designed to maintain a chamber’s temperature at a prescribed level. This system serves as an excellent illustration of proportional control.\n\nSystem Description: We consider a temperature control system, which is a chamber where the temperature needs to be maintained at a specific level \\(\\theta_r\\). The disturbance variable (ambient temperature) in this system is denoted as \\(\\theta_a\\), and \\(\\theta\\) represente the temperature of the chamber.\nApplication Context: This system can be likened to a testing chamber for electronic equipment, where the temperature needs to be regulated for testing the components under different thermal conditions.\n\n\n\n\n\n\nSystem Components: - Chamber Temperature (\\(\\theta\\)): The primary variable to be regulated. - Disturbance Variable (\\(\\theta_a\\)): External factors influencing the chamber temperature, such as ambient temperature. - Thermocouple: A sensor used to measure the chamber’s temperature. - Electropneumatic Transducer: Converts the electrical signal to a pressure signal. - Valve Positioner: Adjusts a valve to control steam flow, thereby regulating the chamber’s temperature. - Heat Exchanger: Facilitates the heating of the air inside the chamber.\nOperation: -The desired temperature (\\(\\theta_r\\)) is set and compared with the actual temperature (θ). - The thermocouple generates an electrical signal proportional to the temperature difference. - This signal is amplified and used to adjust the valve position, controlling the steam flow and, consequently, the temperature.\nControl Requirements\n\nObjective: Maintain the chamber temperature at a regulated value, \\(\\theta_r\\).\nSensing the Temperature: A thermocouple is used as a sensor to measure the chamber’s temperature.\nError Calculation: The sensor output, denoted as \\(e_t\\), is compared with a reference value \\(e_r\\) (proportional to \\(\\theta_r\\)) to calculate the error signal \\(e\\).\n\nContoller and actuators\n\nAmplifier as Controller: The output of the amplifier, based on the error signal, is used to control the Electropneumatic transducer, which in turn generates a pressure signal.\nValve Positioner: This device adjusts the valve based on the pressure signal, controlling the steam flow and thus the temperature in the chamber.\n\nDisturbances\n\nSources of Disturbance: Changes in environmental temperature or command signal variations are the primary disturbances.\nSystem’s Response: The control system adjusts the steam flow rate to restore equilibrium in response to disturbances.\n\n\nUsing a Proportional Proportional\nWe analyze how effective proportional control is in maintaining the desired temperature in the presence of disturbances.\n🤔 Popup Question: What happens to the error signal \\(e\\) when the chamber temperature \\(\\theta\\) is equal to the setpoint \\(\\theta_r\\)?\nAnswer: The error signal \\(e\\) becomes zero, indicating no discrepancy between the desired and actual temperature.\n\n\n\n\n\nIn the state of equilibrium, both the error signal and the control signal are null. The initial adjustment of the Electropneumatic transducer within the valve positioner upholds the heat equilibrium. This adjustment additionally compensates for any heat loss to the surroundings, provided that the ambient temperature remains constant.\nWhat happens if there are disturbances?\nPerturbations from the equilibrium position can be created by - Change in the environment - Change in the command signal\nWhen this happens, we have an error signal \\(e\\) and a corresponding control signal \\(u\\) that needs to readjust the steam flow rate to get to a new equilibrium.\n\n\nModeling the Temperature Control System\n\nMathematical Model: We can model the chamber as a first-order system with a transfer function\n\n\\[ \\frac{K_p}{\\tau_p s + 1} \\]\nwhere \\(K_p\\) is the process gain and \\(\\tau_p\\) is the time constant.\n\nDisturbance: Changes in the environmental temperature (\\(\\theta_a\\)) can perturb the system from its equilibrium.\n\nWe can hence model the disturbance influence as a first-order system with a transfer function\n\\[ \\frac{1}{\\tau_p s + 1} \\]\nSetting \\(K\\) as 1 implies that we are assuming a direct, one-to-one impact of $ _a $ on $ $ at the steady state. If an experimental assessment reveals a variance from this assumption, an appropriate constant can be introduced to account for the difference.\nWhen we consider dynamical models we always consider with respect to the steady state. The total ambient temperature is not \\(\\theta_a\\), which is the perturbation of the ambient temperature from the point of equilibrium.\n\n\n\n\n\n\n\nBlock Diagram\nWe can then write the block diagram of the temperature control system, illustrating the relationship between the control signal, the plant, and the output.\n\n\n\n\n\nIn the example of the temperature control system, we are looking at a Proportional (P) controller where various gains are multiplied together. Let’s break down these gains and their units to understand the overall unit of the proportional controller in this context.\n\n\nBreakdown of the Gains and Their Units\n\nAmplifier Gain (\\(K_A\\)): This gain typically has the unit of volts per volt (V/V), as it relates the output voltage to the input voltage of the amplifier.\nElectropneumatic Transducer Gain (\\(K_e\\)): This gain converts the electrical signal (voltage) to a pneumatic signal (pressure).\nValve Positioner Gain (\\(K_x\\)): This relates the pneumatic pressure signal to the mechanical position of the valve. Its unit could be dimensionless, representing the ratio of the valve stem displacement to the input pressure signal (e.g., mm/psi or mm/bar).\nControl Valve Gain (\\(K_v\\)): This gain describes how the position of the valve affects the flow rate of the steam. The unit could be in terms of steam flow rate per unit displacement, such as cubic meters per hour per millimeter (m³/h/mm).\n\n\n\nCalculation of Proportional Controller’s Overall Gain\nWhen these gains are multiplied together, the resulting unit of the proportional controller’s overall gain (\\(K\\)) will be a composite of all these individual units. In the given scenario, the units would multiply as follows:\n\\[ K = K_A \\times K_e \\times K_x \\times K_v \\]\nSo, for example, the unit of \\(K\\) would be:\n\\[ \\text{V/V} \\times \\text{psi/V} \\times \\text{(mm/psi)} \\times \\text{(m³/h/mm)} \\]\nWhen simplified, this gives us:\n\\[ \\text{m³/h/V} \\]\n\n\nInterpretation\nThe resulting unit of m³/h/V indicates that the controller’s output, in terms of steam flow rate (m³/h), is proportional to the voltage input to the system. This reflects the essence of a proportional controller, where the output is directly proportional to the error signal, which, in this case, is represented in voltage.\nThis detailed understanding of units is crucial for designing and tuning control systems, ensuring that the controller operates within the desired range and effectively manages the plant it is controlling.\n\n\nComponents as zero-order systems\nWe have simplified our model by treating all these components as zero-order systems, disregarding their inherent dynamics. It’s important to remember that these components do possess dynamic characteristics.\nCharacterizing them as zero-order systems implies an assumption of instantaneous response, which is not possible for any physical system. Nonetheless, this simplification is made because the time constants of these individual components are considerably small compared to the plant’s time constant, $ _p $.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#understanding-the-impact-of-disturbance-theta_a",
    "href": "introduction_to_control_systems.html#understanding-the-impact-of-disturbance-theta_a",
    "title": "Introduction to Control Systems",
    "section": "Understanding the Impact of Disturbance (\\(\\theta_a\\))",
    "text": "Understanding the Impact of Disturbance (\\(\\theta_a\\))\nWith reference to the physical drawing shown above, consider an increase in the ambient temperature (\\(\\theta_a\\)). Intuitively, if the external temperature rises, the outflow of heat from the system will reduce, leading to an increase in the chamber’s temperature.\nGiven this understanding, we’ll consider the effect of the disturbance \\(\\theta_a\\) on the system \\(\\theta\\) as positive (see summation point in the block diagram).",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#effects-of-amplifier-gain",
    "href": "introduction_to_control_systems.html#effects-of-amplifier-gain",
    "title": "Introduction to Control Systems",
    "section": "Effects of Amplifier Gain",
    "text": "Effects of Amplifier Gain\nWe aim to study the effect of the amplifier gain (\\(K_A\\)) on various performance metrics like steady-state error, transient response, and sensitivity to disturbances.\n\nDeveloping the System Equation\n\nDescribing Equations\n\nError Signal: The error is represented by\n\n\\[e = K_t \\theta_r(s) - K_t \\theta(s)\\]\nwhere \\(K_t\\) is the thermocouple constant, \\(\\theta_r\\) is the reference temperature, and \\(\\theta\\) is the actual temperature.\n\nControl Signal: The error signal gets multiplied by the product of the gains\n\n\\[K_A K_e K_x K_v\\]\nresulting in the manipulated variable.\n\nOverall System Dynamics: Incorporating the plant dynamics, represented by \\(\\frac{K_p}{\\tau_p s + 1}\\), and the disturbance \\(\\theta_a\\), we get a comprehensive equation describing the system:\n\n\\[\\Big[ (K_t \\theta_r(s) - K_t \\theta(s))K_A K_e K_x K_v \\Big] \\frac{K_p}{\\tau_p s + 1}\\]\n\nIncluding the disturbance:\n\n\\[\\Big[ (K_t \\theta_r(s) - K_t \\theta(s))K_A K_e K_x K_v \\Big] \\frac{K_p}{\\tau_p s + 1} + \\frac{1}{\\tau_p s + 1}\\theta_a(s) = \\theta\\]\n\n\nManipulating the Equation\n\nObjective: To express the system’s output \\(\\theta(s)\\) in terms of the reference input \\(\\theta_r(s)\\) and the disturbance \\(\\theta_a(s)\\).\n\n\\[ (\\tau_p s + 1)\\theta(s) + K_tK_A K_e K_x K_vK_p\\theta(s) = (K_tK_A K_e K_x K_vK_p)\\theta_r + \\theta_a \\]\n\nLoop Gain (\\(K\\)): By combining the constants, we define\n\n\\[K = K_t K_A K_e K_x K_v K_p\\]\ntermed as the loop gain.\nThis gain, particularly \\(K_A\\) (the amplifier gain), directly influences the system’s response.\n\n\n\nFinal Equation\nUsing the loop gain \\(K\\), we can now obtain:\n\\[ (\\tau_p s + 1 + K )\\theta(s) = K \\theta_r(s) + \\theta_a(s) \\]\nInterpretation: This equation links the output temperature \\(\\theta(s)\\) with the reference temperature \\(\\theta_r(s)\\) and the ambient temperature disturbance \\(\\theta_a(s)\\).\n\n\nKey Points to Note\n\nProportional Control Constant: The loop gain \\(K\\) can be regarded as a proportional control constant, reflecting the effectiveness of the proportional controller in maintaining the desired temperature in the presence of disturbances.\nAttention to Detail: Care must be taken in the derivation of this equation. Any mistake in the manipulation can lead to incorrect conclusions about the system’s behavior.\n\nSo in this case the final equation is:\n\\[ \\theta(s) = \\frac{K}{\\tau_p s + 1 + K} \\theta_r(s) + \\frac{1}{\\tau_p s + 1 + K} \\theta_a(s) \\]\nWe have the relationship between the output \\(\\theta(s)\\) and the command \\(\\theta_r(s)\\) and between the output \\(\\theta(s)\\) and the disturbance \\(\\theta_a(s)\\).\n\nFeedback Impact on Time Constant\nRewriting the system’s expression as\n\\[ \\theta(s) = \\frac{K}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\theta_r(s) + \\frac{1}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\theta_a(s) \\]\nwe observe that the time constant of the feedback system, $ $, is:\n\\[\\tau =  \\frac{\\tau_p}{1 + K} \\]\n\nHere, $ _p $ is the plant’s original time constant without feedback.\nFeedback reduces the time constant ($ $) since $ K &gt; 0 $.\nImplication: A reduction in the time constant implies a faster system response. The transients decay more quickly, and the system reaches steady state sooner after a disturbance.\n\n\n\nSteady State Error Analysis\nLet’s now analyse the steady state error. For this we separate the effect of the input \\(\\theta_r\\) and that of the disturbance \\(\\theta_a\\) (we can apply superposition given that we are talking about linear systems).\nMore specifically, let’s analyze the system’s response to a unit step input to determine the steady state value:\n\\[\\theta_r = \\frac{1}{s}\\]\nand the output is:\n\\[ \\theta(s) = \\frac{K}{1 + K} \\cdot \\frac{1}{\\tau s + 1} \\frac{1}{s} \\]\nSteady State Value for Unit Step Input:\n\\[ \\theta_{ss} = \\lim_{s \\to 0} s \\theta(s) = \\frac{K}{1 + K} \\]\nLet’s now examime the system’s response to a unit step disturbance.\n\\[\\theta_a = \\frac{1}{s}\\]\nSteady State Value for Disturbance:\n\\[ \\theta_{ss}|_{dist} = \\frac{1}{1 + K} \\]\n\n\nComments and results\nCommand Signal: - \\(\\theta_r(s)\\) is the command signal. We want \\(\\theta_{ss}\\) to be equal to 1 (we are tracking a unit step input). - As $ K $ increases, $ _{ss} $ approaches 1, reducing the steady-state error for constant command signals. - As $ K $ increases, the steady state error in response to a command signal decreases.\nDisturbance Rejection: - Higher $ K $ values improve disturbance rejection, pushing \\(\\theta_{ss}|_{dist}\\) towards zero, and hence filtering out the disturbance.\n\nImprovement with High $ K $: Both transient and steady state performance improve with a higher $ K $.\nIdeal Scenario: Theoretically, with $ K $, the system would have instant response and zero steady-state error.\n\n\n\nThe Trade-off Between Performance and Stability\n\nImprovement vs. Stability:\n\nHigher $ K $ values improve both transient and steady-state performance.\nTheoretically, an infinite $ K $ would result in an instantaneous system with zero steady-state error.\nHowever, this leads to a conflict between performance improvement and system stability.\n\n\n\n\nConsiderations for System Dynamics:\n\nRevisiting Component Dynamics:\n\nOur initial model used zero-order approximations for components like the amplifier and the valve positioner (their time constants are negligible with respect to the time constant \\(\\tau_p\\) of the plant).\nWhen we operate in feedback however the time costant is \\(\\tau=\\frac{\\tau_p}{1+K}\\)\nAs $ K $ increases, and the effective time constant ($ $) decreases, these approximations become invalid (the time constants of the components are not negligible anymore).\n\nImplications of High $ K $ Values:\n\nA high $ K $ transforms the first-order system (see initinal block diagram above) into a higher-order system, potentially fifth-order (see block diagram below).\nHigh-order systems (&gt; third order) can become unstable with large $ K $ values (we will see why this later when we study stability analysis tools).\nThe system hence does not behave the way we want.\nThis instability introduces a trade-off between the performance of the system (steady state accuracy) and its stability requirements.\n\nNon-linearity and Saturation: High values of \\(K\\) can drive components into saturation, leading to non-linear behavior and potential instability.\n\n\n\n\n\n\nTo make the point clearer, let’s take an example\n\n\n\n\n\nThe closed loop transfer function becomes:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{\\frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1)}}{1+\\frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1)}} = \\frac{K_cK_vK_p}{(\\tau_cs+1)(\\tau_vs+1)(\\tau_ps+1) + K_cK_vK_p}\n\\]\nThe original expression for the system without the first-order dynamics of the individual components was:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s + 1 + K}\n\\]\nIn this latter case, the characteristic equation is:\n\\[\n\\tau_p s + 1 + K = 0\n\\]\nand its root (the pole of the closed loop system) is:\n\\[\ns = -\\frac{1+K}{\\tau_p}\n\\]\nWe have not discussed stability in details, but intuitively (this of the differential equations and its solutions), if the poles are in the Left Half Place (LHP) the system is stable.\nIn the case where \\(s = -\\frac{1+K}{\\tau_p}\\), for all values of \\(K\\), \\(s\\) is always negative.\nWhen we consider time constants for each component, the characteristic equation becomes that of a third order system:\n\\[ a_1 s^3 + a_2 s^2 + a_3 s + a_4 = 0 \\]\nThis equation has three poles in the s-plane (three roots which you can calculate as an exercise). For high values of \\(K\\) some of the poles are driven to the Right Half Plane (RHP) leading to an unstable system.\nThe poles of this higher-order system, influenced by \\(K\\), determine its stability.\n\n\n\nComments:\n\nOnce the system is unstable everything else does not matter! There is not point to study time constants, etc.\nIn open-loop, the individual dynamic modes are stable, but in a closed-loop, their interaction can lead to instability.\nThe feedback loop which is helping improving robusteness and sensitivity, is also creating stability problems.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#integral-control-and-steady-state-error",
    "href": "introduction_to_control_systems.html#integral-control-and-steady-state-error",
    "title": "Introduction to Control Systems",
    "section": "Integral Control and Steady State Error",
    "text": "Integral Control and Steady State Error\nAddressing Steady State Error with Integral Control\n\nProportional Control Limitation: In proportional control, a persistent error is necessary to maintain system equilibrium. If the error is zero, the control action is zero (see diagram below).\n\n\n\n\n\n\nIn proportional control, the error provides the energy needed to sustain a new equilibrium. The new equilibrium is obtained using new energy that is only available if the error signal is present. If the error is zero, you go back to the original equilibrium position. However this is not possible because the system is driven to the new situation.\n\nRole of Integral Control: The integral controller accumulates the error over time, allowing the error to reduce to zero while still providing the necessary control action.\n\n\n\n\n\n\nIntegral control uses the accumulation of past errors to achieve this, allowing the error to eventually reduce to zero. This is always possible for the type of systems we are considering.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#revisiting-the-temperature-control-system",
    "href": "introduction_to_control_systems.html#revisiting-the-temperature-control-system",
    "title": "Introduction to Control Systems",
    "section": "Revisiting the Temperature Control System",
    "text": "Revisiting the Temperature Control System\nWe will now revisit the temperature control process discussed previously, focusing on the system’s dynamics, particularly the role of integral control in enhancing system performance.\n\nSystem Overview\n\n\n\n\n\n\nBlock Diagram Description\n\nReference Temperature: Denoted as \\(\\theta_r\\), the desired temperature setting.\nSensor and Error Signal: A thermocouple sensor converts \\(\\theta_r\\) into a voltage signal. This voltage is compared with the actual temperature voltage to generate an error signal.\nAmplifier and Transducer: The error signal is amplified (gain \\(K_A\\)) and then sent to an electropneumatic transducer (constant \\(K_e\\)).\nValve Positioner and Gain: The transducer signal controls a valve positioner (constant (K_x)) to regulate flow rate, influenced by valve gain \\(K_v\\).\nProcess Transfer Function: Represented as \\(\\frac{K_p}{\\tau_p s + 1}\\).\nDisturbance Effect: Modeled as \\(\\frac{1}{\\tau_p s + 1}\\), where \\(\\theta_a\\) is the ambient temperature disturbance.\n\n\n\n\nSystem Dynamics and Stability\nWhen we assumed that the plant was a first-order system and that the various components can be approximated as zero-order: - Transient Performance: Larger loop gain (\\(K\\)) improves transient performance by reducing the system’s time constant. - Steady State Error: Larger \\(K\\) also reduces steady state error. - Constraints on Gain: High gain \\(K\\) can lead to component saturation and nonlinear behavior, limiting the system’s linear response range. Additionally, the dynamics of the various components cannot be neglected leading to potential instability.\n\n\nIntegral Control in Temperature Systems\n\nAddressing Command Signal Changes\n\nScenario: Consider a requirement to increase the chamber temperature by 10 degrees.\nCommand Change: This necessitates a change in \\(\\theta_r\\) by the same amount.\n\n\n\nIntegral Control Mechanism\n\nError Signal Dynamics: With integral control, the system can handle changes in command signal while maintaining stability and performance.\n\nMathematical Expression:\n\\[ u(t) = K_I \\int e(t) \\, dt \\]\nComments: - Role in System Stability: Integral control enables the system to automatically adjust to new equilibriums without compromising stability.\n\nSystem Adaptability: The integral controller adjusts the control action over time based on accumulated error, leading to a zero steady-state error even with command changes.\nSystem Adaptability: The integral controller adjusts the control action over time based on accumulated error, leading to a zero steady-state error even with command changes.\n\nThere will be a price to pay: integral control might lead to instability even more than the usage of a simple proportional controller.\n\n\n\nImplementing Integral Control in Temperature Systems\nLet’s replace the amplifier \\(K_A\\) with an integral controller \\(K_I/s\\).\nSystem Dynamics: The system now includes the integral controller, the Electropneumatic transducer (\\(K_e\\)), valve positioner (\\(K_x\\)), and valve gain (\\(K_v\\)).\n\n\n\n\n\nBased on this block diagram we can then write the mathematical equations:\n\\[\n(K_t\\theta_r - K_t\\theta)\\cdot \\Big(\\frac{K_I}{s}K_eK_xK_v \\Big) \\Big(\\frac{K_p}{\\tau_ps+1} \\Big) + \\frac{1}{\\tau_ps+1} \\theta_a = \\theta\n\\]\nWe can then rearrange the equation to isolate \\(\\theta(s)\\) on one side.:\n\\[\n(\\tau_p s + 1)\\theta(s)  + \\frac{K}{s} \\theta(s) = \\frac{K}{s} \\theta_r(s) + \\theta_a(s)\n\\]\nwhere \\(K = K_tK_IK_eK_xK_vK_p\\).\nAnd hence:\n\\[\n\\Big(\\tau_p s + 1 + \\frac{K}{s}\\Big) \\theta(s) = \\frac{K}{s} \\theta_r(s) + \\theta_a(s)\n\\]\nor equivalently:\n\\[\n\\Big(\\tau_p s^2 + s + K \\Big) \\theta(s) = K \\theta_r(s) + s\\theta_a(s)\n\\]\n\n\nSteady State Performance with Integral Control\nWe would like now to calculate the steady state for a step input in command and in disturbance\n\nCommand Input Response: For a step input command, the steady-state output \\(\\theta_{ss}\\) is equal to 1, irrespective of \\(K\\), indicating zero steady-state error.\n\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s^2 + s + K}\n\\]\nApplying \\(\\theta_r(s)=\\frac{1}{s}\\), we can calculate \\(\\theta_{ss}\\):\n\\[ \\theta_{ss} = \\lim_{s \\to 0} s \\theta(s) = s \\frac{K}{\\tau_p s^2 + s + K} \\frac{1}{s} = 1\\]\nThis is true for all possible values of \\(K\\) and the steady state error is zero.\n\nDisturbance Response: In response to a step disturbance \\(\\theta_a(s)=\\frac{1}{s}\\), the steady-state output \\(\\theta_{ss}\\) becomes zero, effectively rejecting the disturbance:\n\n\\[\n\\frac{\\theta(s)}{\\theta_a(s)} = \\frac{s}{\\tau_p s^2 + s + K}\n\\]\n\\[\n\\theta_{ss}|_{dist} = 0\n\\]\n\n\nTransient Performance with Integral Control\nLet’s get back to the response to the input:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s^2 + s + K}\n\\]\n\nComments:\n\nThe addition of integral control changes the system from first-order to second-order.\n\nRemember that with a proportional controller the system was a first-order system with form \\(\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K}{\\tau_p s + 1 + K}\\)\nFor this first-order system the pole is:\n\\[\ns= \\frac{-(1+K)}{\\tau_p}\n\\]\nWhen we increase \\(K\\) the pole remains on the left-hand plane and moves from \\(s=\\frac{-1}{\\tau_p}\\) (when \\(K=0\\)) to the left and its response gets faster and faster.\nFor the second-order system, the poles are the roots of:\n\\[ \\tau_p s^2 + s + K = 0 \\]\nWhen \\(K=0\\), the roots are \\(s=0\\), and \\(s=\\frac{-1}{\\tau_p}\\).\nNote that if there is a pole at the origin the transiet will never decay.\nAs we increase the gain \\(K\\) the two poles will move closer together, until at some point they will become complex conjugate.\n\n\nLimitations in Improvement\n\nLimit on Transient Performance: Integral control imposes a limit on the improvement of transient performance, as poles can only be driven to a certain point (see root locus plot below).\nOscillatory Response: Increasing (K) can lead to oscillatory behavior, a direct consequence of integral control.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom control import tf, root_locus\n\n# System parameters\ntau_p = 1  # For example, let's take tau_p as 1\n\n# Define the characteristic equation of the system with integral control\n# The characteristic equation is tau_p * s^2 + s + K = 0\n\n# For the root locus, we consider the open-loop transfer function G(s)H(s)\n# G(s)H(s) = K / (tau_p * s^2 + s)\n# This is equivalent to a system with a numerator [K] and a denominator [tau_p, 1, 0]\n\nnumerator = [1]  # Coefficient for K\ndenominator = [tau_p, 1, 0]  # Coefficients of s^2, s, and constant term for the denominator\n\n# Create the transfer function for the system\nsystem = tf(numerator, denominator)\n\n# Plot the root locus\nfig, ax = plt.subplots()\nroot_locus_data = root_locus(system, Plot=True, ax=ax)\n\n# Add labels and title for clarity\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Root Locus with Integral Control')\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nInfluence of Poles on System Response\n\nPoles: In control theory, the poles of a system are the roots of its characteristic equation. They are crucial in determining the system’s behavior over time, particularly its stability and transient response.\nComplex Plane Representation: Poles are represented in the complex plane, where the horizontal axis is the real axis and the vertical axis is the imaginary axis (jω axis).\nLocation of Poles: The location of poles in the complex plane significantly impacts how the system responds to inputs.\nReal Axis Proximity: Poles closer to the jω axis (imaginary axis) have a smaller real part. This small real part implies a slower decay rate of the system’s transient response.\nDominant Poles: Poles that are closer to the jω axis are often referred to as “dominant poles” because they have a more pronounced effect on the system’s transient behavior. Their slower decay rate means that they dictate the overall response of the system, especially in the transient phase.\n\n\nDesign Considerations\n\nWith referect to the root locus above, the dominant pole cannot be moved further left, hence limiting the dynamic response we can obtain.\nWhen designing control systems, engineers often aim to position the dominant poles in a way that achieves a desired balance between quick response and stability. Poles that are too close to the jω axis may result in slow response times, while poles too far into the left-half plane may cause the system to respond too quickly, potentially leading to overshoot and instability.\nTransient vs. Steady-State Response: The dominant poles primarily affect the transient response of the system. Once the transient effects have decayed, the steady-state behavior is determined by other factors, such as the system’s steady-state gain and the type of controller used (e.g., proportional, integral, derivative).\n\nIn this case, the poles do not move to the right (become unstable). However, if one of the time constant of our components start to have an effect that might easily lead the system to instability (the system becomes at least of third order which might have poles going to RHP for high K).",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#introduction-to-derivative-control",
    "href": "introduction_to_control_systems.html#introduction-to-derivative-control",
    "title": "Introduction to Control Systems",
    "section": "Introduction to Derivative Control",
    "text": "Introduction to Derivative Control\nLet’s now consider the following error:\n\n\n\n\n\nAt times $ t_1 $ and $ t_2 $, a proportional controller would exhibit identical control actions since the magnitude of the error is the same at both instances. Nonetheless, the scenarios at $ t_1 $ and $ t_2 $ are distinctly different: at $ t_1 $, the error is increasing, whereas at $ t_2 $, the error is on a decreasing trend.\nIntuitively, we would prefer varied control actions in these situations. Specifically, at $ t_1 $, a more aggressive control action might be desirable to prevent the error from escalating. By considering the error’s rate of change, or its slope, we can distinguish between these scenarios. This slope effectively informs the controller about potential future errors, enabling a more predictive and adaptive response.\nThis is what a derivative control does: it introduces a signal that is not only proportional to the magnitude of the error (proportional control), but on the derivative of that signal.\n\nDerivative Control Concept\n\nPredictive Nature of Derivative Control\n\nPrediction through Derivative: Derivative control predicts future errors (through the slope of the error signal) and adjusts the control action accordingly, providing more damping during transients.\n\nEquation:\n\\[ U(s) = K_c (1 + T_D s) E(s) \\]\n\nEffectiveness: Derivative control is effective during transient periods but has no impact on steady-state error.\n\nIf the steady error becomes constant, i.e., when you reach steady state, the derivative is zero and the effect of derivative control is zero (see error plot above).\nAt steady state the derivati control loses its role and it only proportional and integral control that can support it.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_control_systems.html#implementing-derivative-control-in-control-systems",
    "href": "introduction_to_control_systems.html#implementing-derivative-control-in-control-systems",
    "title": "Introduction to Control Systems",
    "section": "Implementing Derivative Control in Control Systems",
    "text": "Implementing Derivative Control in Control Systems\nWe now shift our focus to the practical aspects of implementing derivative control in control systems. We’ll discuss the challenges and alternatives in employing derivative control, particularly in the context of a position control system.\nWe have the following control action:\n\\[ U(s) = K_c (1 + T_D s) E(s) \\]\n\nNoise Amplification Issue\n\nDerivative of High-Frequency Noise: Derivative control can amplify high-frequency noise signals, potentially disrupting the system’s performance.\nExample Scenario: Consider a noise signal \\(0.01 \\sin(10^3 t)\\). The amplitude of this signal is very small, and it is high frequency. In proportional control, most likely we do not need to consider this explicitely because the system itself is a low pass filter.\n\nIn derivative control, the derivative of this signal is $10^3 (10^3 t) = 10 (10^3 t) $, which significantly amplifies the noise.\nThe derivative action $ T_D s $ applied to a noise signal can lead to a large magnitude signal that may overshadow the actual error signal.\nFor this reason the derivative control described above is only theoretical and never implemented in practise. You always apply a suitable low pass filter for the implementation (we will see this later).\nFor the purpose of this notebook it is assumed that high frequency noise are not part of the problem or they have been filtered out appropriately.\n\n\nAlternatives to Standard Derivative Control\nLet’s see what alternatives we can have using a position control system. For this we will revisit the Position Control System we analysed in a previous notebook and reported below.\nNote that we have made a few simplifications: - Plant is inertial only. - Inductance is neglected.\n\n\n\n\n\nFrom this we can calculate the equation (note that the sign of the disturbance torque \\(T_W\\) is not important):\n\\[\n\\Big[ \\Big(K_p\\theta_r - K_p\\theta\\Big) K_c \\Big(1+T_Ds\\Big)\\frac{K_T}{R_f} + T_W \\big] \\frac{1}{Js^s} = \\theta\n\\]\nwhich can be written as:\n\\[\nJs^s\\theta + K_pK_C\\frac{K_T}{R_f}\\Big(1+T_Ds\\Big)\\theta =  K_pK_C\\frac{K_T}{R_f}\\Big(1+T_Ds\\Big)\\theta_r + T_W\n\\]\nwe can set: \\(K = K_pK_C\\frac{K_T}{R_f}\\) and obtain:\n\\[\n\\Big(Js^2 + K T_D s + K\\Big)\\theta(s) = K(1+T_Ds)\\theta_r + T_W\n\\]\nand finally we can write the Transfer Function:\n\\[\n\\frac{\\theta(s)}{\\theta_r(s)} = \\frac{K (1 + T_D s)}{Js^2 + K T_D s + K}\n\\]\nAnd the “personality parameters” of the systems are:\n\\[\n\\omega_n = \\sqrt{\\frac{K}{J}}\n\\]\n\\[\n2\\zeta\\omega_n = \\frac{KT_D}{J} \\rightarrow \\zeta=\\frac{T_D}{2}\\sqrt{\\frac{K}{J}}\n\\]\nThe effect of the derivative control on the transient is visibile through \\(\\zeta\\). You can increase the damping increasing \\(T_D\\).\n\nAdditional comments:\nIf we look at the transfer function we notice: - The denominator is a second-order system - The numerator has one zero\nWhen a step change is introduced in the command signal (\\(\\theta_r\\)), such as \\(\\theta_r = \\frac{1}{s}\\) in the Laplace domain, and this signal interacts with a derivative control element characterized by \\(T_Ds\\) (see numerator of the transfer function above), it results in the generation of an impulse, or a spike.\nThis phenomenon occurs because differentiating a step function, which essentially remains constant after the initial change, produces an impulse:\n\\[\nT_Ds \\cdot \\frac{1}{s} \\rightarrow T_D \\cdot \\delta(t)\n\\]\nThis implies that in response to a step change, a derivative controller produces an exceptionally high initial output, commonly referred to as a spike. This behavior can be interpreted as the control system’s immediate effort to counter a sudden and significant change in the error.\nHowever, such a spike in the controller’s output is not always desirable. While it represents an immediate response to the error change, it can be likened to introducing a disturbance into the system only to subsequently correct it. This could potentially lead to issues such as system instability or excessive overshoot, especially in systems sensitive to rapid changes.\nSmoothing the controller’s response:\nTo address this issue, control systems are often equipped with additional filtering mechanisms. Alternatively, a modified approach to derivative control is employed, one that does not react as intensely to high-frequency components of the error signal. These design strategies help in smoothing out the controller’s response, preventing the abrupt spike and ensuring a more stable system behavior.\n\n\n\n\n\nAnd the presence of the Tachogenerator is equivalent to:\n\n\n\n\n\nRather than computing the derivative of the output signal, one can employ a tachogenerator to generate a feedback signal that is proportionate to the output’s rate of change.\nThis method circumvents the challenges typically encountered when differentiating the input command, specifically the issues of noise amplification and the creation of spikes when there are sudden changes in the command signal.\nIn the actual implementation of this system, no derivative operation is conducted. While the model includes a derivative term (\\(sK_t\\)), this differentiation does not occur in practice.\nIt’s important to note, however, that this approach is not universally applicable. For instance, in temperature control systems, there isn’t an inherent signal within the system that directly represents the derivative of the variable being controlled.\nIn motion control, this is possible, in process control this is generally not possible. In this case, we add suitable filters to avoid spikes.\nInstead of directly calculating the derivative of the output signal, a tachogenerator can be utilized to produce a feedback signal that correlates with the rate of change of the output. This strategy effectively addresses typical issues associated with direct differentiation of the input command. These issues include the amplification of noise and the generation of spikes, especially when the command signal undergoes abrupt changes.\nIn practical implementations of such a system, an actual derivative calculation is not performed. The system’s model might include a derivative term represented as $ sK_t $, but in reality, this differentiation process is not carried out. The tachogenerator inherently provides a signal that reflects the derivative, thus bypassing the need for explicit differentiation.\nHowever, it is crucial to recognize that this method is not universally applicable across all types of control systems. For example, in temperature control systems, there typically isn’t a readily available signal that inherently represents the derivative of the temperature. Such systems lack an equivalent to the tachogenerator used in motion control systems, where the derivative feedback is naturally integrated.\nIn contexts like process control, where directly obtaining a derivative signal is not feasible, alternative strategies must be employed. These often involve adding suitable filters to the control system. These filters are designed to mitigate or eliminate the unwanted effects, such as spikes, that can occur when using derivative control. This approach ensures smoother system performance and reduces the risk of instability or excessive response to high-frequency disturbances.",
    "crumbs": [
      "Introduction to Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "",
    "text": "Concept 1: Understanding the Shift in Perspective\n\nTime Domain Analysis: Previously, we’ve discussed the root locus method, which is primarily focused on the time domain. This method is intuitive for visualizing transient performance through closed-loop poles.\nFrequency Domain Analysis: Now, we will shift our focus to frequency domain analysis. This approach offers a different perspective, emphasizing the steady-state response of control systems to sinusoidal inputs.\n\n\n\n\nHistorical Context: Historically, frequency domain methods were developed before the root locus, but for pedagogical reasons, we started with the latter.\nTransient vs. Steady-State Performance: In frequency domain analysis, understanding transient performance is less direct compared to the root locus method. Understanding the transient in terms of zeros and poles is very straightforward.\n\nIn frequency domain analysis, understanding the results requires a more abstract approach, as the method presents an indirect way of interpreting system behavior. This contrasts with the root locus method, where the interpretation of system performance is more straightforward and direct, primarily because it visually represents system dynamics in the time domain.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#transition-from-time-domain-to-frequency-domain-analysis",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#transition-from-time-domain-to-frequency-domain-analysis",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "",
    "text": "Concept 1: Understanding the Shift in Perspective\n\nTime Domain Analysis: Previously, we’ve discussed the root locus method, which is primarily focused on the time domain. This method is intuitive for visualizing transient performance through closed-loop poles.\nFrequency Domain Analysis: Now, we will shift our focus to frequency domain analysis. This approach offers a different perspective, emphasizing the steady-state response of control systems to sinusoidal inputs.\n\n\n\n\nHistorical Context: Historically, frequency domain methods were developed before the root locus, but for pedagogical reasons, we started with the latter.\nTransient vs. Steady-State Performance: In frequency domain analysis, understanding transient performance is less direct compared to the root locus method. Understanding the transient in terms of zeros and poles is very straightforward.\n\nIn frequency domain analysis, understanding the results requires a more abstract approach, as the method presents an indirect way of interpreting system behavior. This contrasts with the root locus method, where the interpretation of system performance is more straightforward and direct, primarily because it visually represents system dynamics in the time domain.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#frequency-domain-formalism",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#frequency-domain-formalism",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Frequency Domain Formalism",
    "text": "Frequency Domain Formalism\nConcept 2: Foundations of Frequency Domain Analysis\n\nRobustness of Frequency Domain Methods: One significant advantage of frequency domain analysis is its robustness, which means less dependency on the accuracy of the system model. This is crucial as obtaining an accurate model can be challenging. This is one of the main reasons why it is probably the most used method in control.\nEase of Analysis and Design: Another advantage is the relative ease of analysis and design in the frequency domain.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#frequency-response-of-linear-systems",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#frequency-response-of-linear-systems",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Frequency Response of Linear Systems",
    "text": "Frequency Response of Linear Systems\nConcept 3: Sinusoidal Input and Steady-State Response\n\nSystem Response to Sinusoidal Input:\n\nConsider a linear system described by a transfer function $ G(s) $. When this system is subjected to a sinusoidal input $ r(t) = R_0 (t) $, the output will have both transient and steady-state components.\n\nStable System Assumption: For a stable system, transient components die out, leaving only the steady-state response. The steady-state output can be represented as $ y(t) = Y_0 (t + ) $.\n\nThe steady-state response of a linear system is also sinusoidal, the only change is in the amplitude and in the phase angle.\nThis implies that by understanding the amplitude ratio \\(\\frac{Y_0}{R_0}\\) and the phase angle \\(\\phi\\), we can completely describe the input-output relationship for the system’s steady-state response. Specifically, the key to this understanding lies in observing how \\(\\frac{Y_0}{R_0}\\) and \\(\\phi\\) change as a function of frequency.\n\n\n\n\n\n\n\n\nMathematical Representation\n\nAmplitude and Phase Change: The steady-state response to a sinusoidal input is also sinusoidal, with changes in amplitude and phase.\n\n\\[ \\text{Amplitude Ratio} = \\frac{Y_0}{R_0} \\]\n\\[ \\text{Phase Angle} = \\phi \\]\n\n\nFrequency Response Definition\nWe can now define formally define the Frequency response.\nConcept 4: Defining Frequency Response\n\nFrequency Response Components: The frequency response of a system can be characterized by how these parameters (amplitude ratio and phase angle) vary with the frequency \\(\\omega\\).\n\n\\[ \\text{Frequency Response} = \\left\\{ \\frac{Y_0}{R_0}(\\omega), \\phi(\\omega) \\right\\} \\]\n\nRelating to Transfer Function\n\nLink to Transfer Function:\n\nThe amplitude ratio $ $ is the magnitude of the transfer function $ G(s) $ evaluated at $ s = j$, and $ $ is the phase angle of $ G(j) $:\n\\[\n\\frac{Y_0}{R_0} = |G(s)|\\Big|_{s=j\\omega} = |G(j\\omega)|\n\\]\nand\n\\[\n\\phi = \\angle{G(j\\omega)}\n\\]\nwhich means that the frequency response is completely contained in the mathematical model of the system.\nFrequency response definition\nthe Magnitude \\(|G(j\\omega)|\\) and the \\(\\angle{G(j\\omega)}\\) constitude the frequency response of the system\nFrequency response plots\nWhen we plot \\(|G(j\\omega)|\\) and the \\(\\angle{G(j\\omega)}\\) with respect to \\(\\omega\\) we obtain the Frequency response plots.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#complete-system-characterization",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#complete-system-characterization",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Complete System Characterization",
    "text": "Complete System Characterization\nConcept 5: Frequency Response as a Complete System Characterization\n\nBeyond Steady-State Analysis: While frequency response is derived from steady-state sinusoidal response, it encapsulates the entire system behavior, including transient response. This is due to the Fourier transform’s ability to link frequency response to time-domain behavior.\nExperimental Advantages: Frequency response plots can be experimentally obtained, providing a complete characterization of the system, even when a mathematical model isn’t available.\n\nIn our analysis, we examine two key relationships: the magnitude of the transfer function, denoted as $ G(j) $, as it varies with frequency \\(\\omega\\), and the phase angle of $ G(j) $ as it also changes with frequency. These relationships can be graphically represented, giving us what are known as frequency response plots. These plots visually depict how the system responds to different frequencies.\nInitially, it might seem that these frequency response plots only describe the system’s behavior in a steady-state scenario — that is, how the system performs after it has settled following any initial disturbances. However, there’s more to it than meets the eye.\nIn reality, these frequency response plots offer a complete characterization of the system, encompassing both steady-state and transient (temporary) responses. This comprehensive understanding is possible because of a powerful mathematical tool known as the Fourier transform. The Fourier transform allows us to relate the frequency response back to the system’s time response. Essentially, this means that from the frequency response data, we can predict how the system will react to any given input over time. To do this for different types of input signals, we use the Fourier series for periodic (repeating) signals, or the Fourier transform for non-periodic (one-time) signals. This way, we get a full picture of the system’s behavior in both the frequency and time domains.\nAs we progress, our focus will shift primarily to examining frequency response plots.\nIt’s important to understand that these plots, whether derived experimentally or through other means from the system’s sinusoidal response in a steady-state condition, actually represent the entire mathematical behavior of the system. This includes both the transient (short-term) and steady-state (long-term) responses.\nThe key to this comprehensive understanding lies in the Fourier transform. The Fourier transform serves as a crucial link, connecting the transient response of the system with its steady-state frequency response. This connection allows us to use the frequency response plots as a complete representation of the system’s behavior, encompassing all aspects of its response over time.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#practical-implications",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#practical-implications",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Practical Implications",
    "text": "Practical Implications\nConcept 6: Practical Applications and Advantages\n\nModel Independence: The frequency domain approach is less reliant on a precise mathematical model, which is beneficial when such models are hard to obtain or uncertain.\nExperimental Accessibility: Frequency response can be directly measured, bypassing the need for a detailed system model. This is especially useful for systems where the model is unknown or complex.\n\nConsider a situation where you have access to the physical hardware of a system, but its mathematical model is unknown. Under these circumstances, you can’t directly use the root locus method for analysis or design, because the root locus requires a known mathematical model of the system. This model typically takes the form of a transfer function, or a pole-zero model.\nHowever, if we switch to frequency domain analysis, the process becomes more straightforward. In this approach, you can start with sinusoidal testing of the system. This involves applying sinusoidal inputs to the hardware and measuring the system’s output in terms of magnitude and phase angle. By doing this, you gather frequency response data directly from the hardware.\nOnce you have this frequency response data, you can plot frequency response graphs. These graphs provide a complete characterization of the system’s behavior, capturing both its steady-state and transient responses. The advantage here is that you don’t need a pre-established mathematical model, like a transfer function, for analysis and design. This aspect is particularly significant because creating an accurate mathematical model of a system can be a challenging task.\nLet’s say you still want to use the root locus method, but all you have is frequency response data. To proceed, you would need to fit this data into a pole-zero model, which can then be used for root locus design. However, it’s important to recognize that this fitting process is approximate. It’s nearly impossible to achieve a perfect match between the experimental frequency response data and the theoretical pole-zero model. As a result, the model you end up with for the root locus method is an approximation.\nIn contrast, frequency domain analysis does not require this intermediate fitting step. You work directly with the raw data obtained from your sinusoidal tests. This direct use of experimental data in frequency domain analysis simplifies the process and avoids the approximations and potential errors involved in fitting data to a pole-zero model.\nI hope it’s clear why the frequency domain approach is so vital for control engineers. This approach isn’t just important, it’s essential. Interestingly, some of the system performance concepts we use in control engineering are also common in communication theory. Communication engineers often deal with sinusoidal inputs or a combination of sinusoidal signals, which aligns well with their focus on sinusoidal transfer functions.\nHowever, for control engineers, the situation is a bit different. We don’t always work with sinusoidal inputs. In fact, in many cases, the systems we design and analyze may never encounter sinusoidal inputs. Yet, we still prefer the frequency domain formalism due to its numerous advantages.\nOne of these advantages is a clearer understanding of a system’s noise characteristics. The frequency domain approach allows us to analyze and interpret the noise filtering characteristics of a system more effectively than we could by looking solely at time-domain effects. For example, concepts like bandwidth are more intuitively understood in the frequency domain. Bandwidth relates to how a system filters out noise, which isn’t as clearly represented by time-domain metrics like rise time.\nIn summary, the frequency domain approach offers several key benefits:\n\nNoise Characteristics: It provides a clearer view of the system’s noise filtering behavior.\nFlexibility with System Models: This method can work with less accurate mathematical models or even experimental models.\nEase of Analysis and Design: Frequency domain methods often offer simpler and more straightforward techniques for system analysis and design.\n\nSo, while the root locus method is advantageous for directly visualizing transient responses through closed-loop poles, the frequency domain approach excels in other critical areas, particularly in analyzing noise characteristics and offering flexibility with system models.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#root-locus-vs.-frequency-domain-formalism",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#root-locus-vs.-frequency-domain-formalism",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Root Locus vs. Frequency Domain Formalism",
    "text": "Root Locus vs. Frequency Domain Formalism\n\nRoot Locus Method\n\nThe root locus method requires a detailed mathematical model of the system, typically a transfer function or a pole-zero model.\nThis method is intuitive for visualizing the transient response in terms of closed-loop poles.\n\n\n\nFrequency Domain Formalism\n\nIn frequency domain analysis, direct mathematical modeling is not a prerequisite.\nInstead, one can employ experimental data obtained from sinusoidal testing of the system.\nThis approach is useful when the exact mathematical model of the system is unknown or hard to determine.\n\n\n\nImportance of Frequency Domain Analysis\n\nVersatility: Control engineers often work with inputs that are not sinusoidal, yet the frequency domain approach remains applicable due to its versatility.\nNoise Characteristics: Understanding the noise characteristics of a system is more straightforward in the frequency domain. This includes bandwidth and noise filtering behavior.\n\n\n\nAdvantages of Frequency Domain Formalism\n\nNoise Filtering: The frequency domain provides clearer insights into a system’s noise filtering characteristics.\nModel Independence: It can work with less accurate or experimental models.\nEase of Analysis and Design: Offers simpler methods for analysis and design compared to the root locus method.\n\n\n\nComplementary Nature of Analysis Methods\n\nRoot Locus and Frequency Domain: These methods are not mutually exclusive but complement each other, each with its unique advantages.\nContinued Evolution: The field of control engineering is continuously evolving, with no single foolproof design method. Therefore, understanding various methods, including those beyond root locus and frequency domain, is crucial for a control engineer.\n\nPop-up Question: Why is the frequency domain formalism preferred when the mathematical model of the system is unknown?\nAnswer: The frequency domain formalism is preferred because it allows for analysis and design directly from experimental data, bypassing the need for a precise mathematical model.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#introduction-to-frequency-domain-analysis",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#introduction-to-frequency-domain-analysis",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Introduction to Frequency Domain Analysis",
    "text": "Introduction to Frequency Domain Analysis\n\nBasic Steps of Frequency Domain Analysis\n\nStability Analysis\n\nStability is determined using the Routh-Hurwitz criterion or the root locus itself.\nIn frequency domain analysis, we use the Nyquist stability criterion, a central feature of this approach.\n\nPerformance Specification\n\nTime Domain: Specifications include rise time, settling time, peak overshoot, etc.\nFrequency Domain: Specifications include bandwidth, resonant peak, and resonant frequency. Some of these features will need to be interpreted indirectly when translated to the time domain. This is the main limitation of the frequency domain methods.\n\nDesign\n\nSimilar compensators (lag, lead, lag-lead) are used in both root locus and frequency domain methods. However, the design process is often simpler in the frequency domain.\n\nIn the context of time domain or s-plane domain design, a critical element is the dominance conditions. When these conditions aren’t met, the primary recourse often turns to trial and error, leaving designers with the binary choice of either accepting or rejecting the design as it stands. However, in the frequency domain, the reliance on trial and error is significantly diminished. Instead, we have access to more precise and systematic methods to tackle design challenges, offering a broader range of solutions and adjustments.\n\nPop-up Question: What is a key difference between performance specifications in the time domain and the frequency domain?\nAnswer: In the time domain, specifications are focused on transient response characteristics like rise time and overshoot, whereas in the frequency domain, they are centered around steady-state response characteristics like bandwidth and resonant frequency.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#nyquist-stability-criterion---stability-in-frequency-domain-analysis",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#nyquist-stability-criterion---stability-in-frequency-domain-analysis",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Nyquist Stability Criterion - Stability in Frequency Domain Analysis",
    "text": "Nyquist Stability Criterion - Stability in Frequency Domain Analysis\nThe Nyquist stability criterion is based on the complex variable theory and Cauchy’s Argument Principle. It provides a way to determine the stability of a system by analyzing the open-loop transfer function in the frequency domain.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#understanding-the-criterion",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#understanding-the-criterion",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Understanding the Criterion",
    "text": "Understanding the Criterion\nClosed-Loop Transfer Function:\nConsider a general single-loop system where the closed-loop transfer function is \\[ \\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)H(s)} \\].\n\n\n\n\n\n\n\nStability Determination:\n\nThe denominator of the closed loop transfer function is: $ 1 + G(s)H(s) $, and this is the equation that we need to focus on.\nThe stability is determined by analyzing the locus of $ 1 + G(s)H(s) $ in the complex plane.\nIf no point in the right-half of the s-plane, including the imaginary axis, satisfies $ 1 + G(s)H(s) = 0 $, the system is stable.\n\nIn other words:\n\nThe S-Plane: Imagine the s-plane as a complex plane where each point ‘s’ represents a complex number with a real part (\\(\\sigma\\)) and an imaginary part (\\(j\\omega\\)).\nRegions of Interest: We are particularly interested in the right-half and the left-half of this s-plane. The right-half includes the imaginary axis (\\(j\\omega\\) axis).\nStability Definition: A control system is considered stable if all the closed-loop poles (the solutions of the system’s characteristic equation) lie in the left-half of the s-plane.\n\n\nUnderstanding G(s)H(s) - The Open-Loop Transfer Function\n\nComposition of G(s)H(s): This function represents the product of all individual transfer functions in the control loop when the loop is open. It typically includes process, compensator, and sensor transfer functions. This function is known.\n\n\n\n\n\n\n\n\n\nPolynomial Representation: We often express \\(G(s)H(s)\\) as a ratio of two polynomials, \\(N(s)\\) and \\(\\Delta(s)\\).\n\n\\[G(s)H(s) = \\frac{N(s)}{\\Delta(s)}\\]\nIn most cases, \\(G(s)H(s)\\) takes this form, except in specific scenarios like dead time represented by $ e^{-s_d} $. For now, we restrict the analysis to \\(G(s)H(s)\\) as a ratio of two polynomials, but we can extend it to the more general case.\n\nPoles and Zeros of G(s)H(s)\n\nPoles and Zeros: These are fundamental in determining the behavior of the system. The zeros of \\(G(s)H(s)\\) are the roots of the numerator polynomial \\(N(s)\\), and the poles are the roots of the denominator polynomial \\(\\Delta(s)\\).\nKnown Quantities: In open-loop analysis, these poles and zeros are known and form the basis for further stability analysis.\n\n\n\n\nStability in Open-Loop and Closed-Loop Systems\n\nOpen-Loop Stability: If the poles of \\(G(s)H(s)\\) lie in the left-half of the s-plane, the system is open-loop stable. Conversely, if any pole lies in the right-half, the system is open-loop unstable.\nClosed-Loop Stability Focus: Our primary interest lies in the stability of the system under closed-loop conditions, i.e., when feedback is applied. Even an open-loop unstable system can be stabilized with appropriate feedback.\n\nNote that an open-loop unstable system does not matter - we want to study the stability properties when the loop is closed, i.e., under feedback. At the same time, the open-loop poles (and zeros) are known to me.\n\n\nAnalyzing Closed-Loop Stability\nThe closed loop transfer function is:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)H(s)} \\]\n\nThe Function $ 1 + $: To analyze closed-loop stability, we focus on this function. It represents the denominator of the closed-loop transfer function.\n\nWe can expand this function as:\n\\[ 1 + \\frac{N(s)}{\\Delta(s)} = \\frac{\\Delta(s) + N(s)}{\\Delta(s)}\\]\n\nPolynomial Form: Assuming \\(\\Delta(s)\\) is an nth-order polynomial, we can express it in a factorized form as:\n\n\\[ \\Delta(s) = (s - \\alpha_1)(s - \\alpha_2)...(s - \\alpha_n) \\]\nThe numerator (\\(\\Delta(s) + N(s)\\))’s order is \\(n\\). This is because the \\(\\text{order}[N(s)] \\le \\text{order}[\\Delta(s)]\\) to ensure physical realisability.\nFor this reason we can then re-write our function as:\n\\[ 1+G(s)H(s) = 1 + \\frac{N(s)}{\\Delta(s)} = \\frac{\\Delta(s) + N(s)}{\\Delta(s)} = \\frac{(s - \\beta_1)(s - \\beta_2)...(s - \\beta_n)}{(s - \\alpha_1)(s - \\alpha_2)...(s - \\alpha_n)}\\]\nRemember, if any value of ‘s’ in the right-half of the plane or on the imaginary axis satisfies the equation (1 + G(s)H(s) = 0), then the system is deemed unstable. This forms the basis of our conjecture regarding system stability.\nPop-up Question: Why do we focus on the left-half of the s-plane for stability?\nAnswer: The left-half of the s-plane indicates that all poles have negative real parts, which corresponds to decaying responses in the time domain, a key characteristic of a stable system.\nPop-up Question: What is the principle behind the Nyquist Stability Criterion?\nAnswer: The Nyquist Stability Criterion is based on the principle of argument in complex analysis, which relates the number of encirclements of a point by a function in the complex plane to the number of zeroes and poles of that function.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#understanding-the-s-plane-and-w-plane",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#understanding-the-s-plane-and-w-plane",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Understanding the S-Plane and W-Plane",
    "text": "Understanding the S-Plane and W-Plane\n\nThe S-Plane\n\nDescription: The s-plane is a complex plane where each point ‘s’ represents a complex number, with a real part (\\(\\sigma\\)) and an imaginary part (\\(j\\omega\\)).\nComplex Variable Representation: Each point on the s-plane is a complex variable, represented as σ + jω.\n\n\n\nThe W-Plane\n\nRelationship with S-Plane: When we apply the function \\(1 + G(s)H(s)\\) to a point on the s-plane, it maps to a point on another complex plane, called the W-plane.\nComplex Variable on W-Plane: This mapped point on the W-plane is also a complex variable, represented as \\(u + jv\\).\n\n(see picture Left, below.)\n\nMapping from S-Plane to W-Plane\n\nFunction Application: The function \\(1 + G(s)H(s)\\) transforms each point ‘s’ on the s-plane to a corresponding point on the W-plane.\nOne-to-One Mapping: For a rational function (like the one we have), for every point on the s-plane, there is a unique corresponding point on the W-plane.\n\n(see picture Right, below.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nStability Analysis Using \\(1+G(s)H(s)\\) Mapping\n\nObjective: To analyze the stability of a system, we examine how the right-half of the s-plane, including the imaginary axis, maps onto the W-plane using \\(1 + G(s)H(s)\\).\nStability Criteria: If the origin of the W-plane is not covered by this mapping, the system is stable. If the origin is covered, the system is unstable.\n\nThis is the equivalent statement of saying “equation \\(1 + G(s)H(s)\\) does not have any roots in the RHP (including the imaginary axis)”.\n\n\nContour Mapping\n\nConcept of Contours: A contour in the s-plane, which is a connected set of points (a contour is a continuous path in the s-plane, which can be a simple curve or a closed loop), will map to a corresponding contour in the W-plane due to the one-to-one nature of the mapping.\nMapping to W-Plane: When we map this contour to the W-plane using our transfer function, the resulting path in the W-plane reflects the characteristics of the system’s poles and zeros.\n\n\n\nFocus on Qualitative Mapping\n\nQualitative Analysis: Our primary interest is not in the exact one-to-one quantitative mapping but in understanding how the mapping qualitatively affects system stability, particularly around the origin of the \\(\\omega\\)-plane. In other words, we would like to know if the origin of the W-plane is covered or not.\n\nIn our analysis, the focus is primarily on the qualitative characteristics of how specific contours in the s-plane, which may encircle key points such as zeros or poles, are transformed and represented in the W-plane.\nIndeed, if we were to emphasize a precise, quantitative one-to-one mapping between these planes, the task would become exceedingly complex. Such an approach would diminish the practical utility and relevance of the Nyquist criterion in system analysis.\nPop-up Question: Why do we focus on qualitative rather than quantitative mapping in system analysis?\nAnswer: We focus on qualitative mapping because it reveals how the system behaves near critical points, like the origin of the \\(\\omega\\)-plane, which is crucial for assessing system stability.\n\nExample of Contour Mapping\n\nScenario: Consider a contour in the s-plane enclosing a zero of the function \\(1 + G(s)H(s)\\) and analyze its mapping onto the W-plane.\nAnalysis: The key is to understand how the angles contributed by different points on this contour result in the mapping on the W-plane.\n\nOur transfer function performs the task of transforming a point from the s-plane to a corresponding point in a new plane, denoted as the \\(\\omega\\)-plane.\n\nWhen we select numerous points on the s-plane that are connected to form a continuous path (known as a contour), these points are mapped to form a continuous path in the \\(\\omega\\)-plane as well.\nSpecifically, when we choose points along a contour in the s-plane, which is essentially a line that forms a loop and connects back to itself, this results in a closed loop in the \\(\\omega\\)-plane. We refer to this closed loop as a plot.\nImportantly, this plot in the \\(\\omega\\)-plane encapsulates crucial information about the system. It conveys both the magnitude and the phase angle associated with each pole and zero of the system.\n\n\n\n\nVisualization code for mapping a contour from the s-plane to the \\(\\omega\\)-plane.\nWe can verify this with Python as shown below.\nThis code shows a graphical representation of a contour in the s-plane and its corresponding path in the \\(\\omega\\)-plane.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the subplots\nfig, axs = plt.subplots(1, 2, figsize=(15, 7))\n\n# Improve plot aesthetics (axis, grids, scale)\nfor i in range(len(axs)):\n    axs[i].axhline(0, color='black', linewidth=1.5, linestyle='--') # horizontal axis\n    axs[i].axvline(0, color='black', linewidth=1.5, linestyle='--') # vertical axis\n    axs[i].axis([-4, 3, -3, 3]) # scale the axis\n    axs[i].grid(True, which='both', linestyle='--', linewidth=0.5) # add grid\n    axs[i].set_aspect('equal', 'box')\n    axs[i].set_xticks(np.arange(-4, 4, 1))\n    axs[i].set_yticks(np.arange(-3, 4, 1))\n    axs[i].set_xlabel('Real')\n    axs[i].set_ylabel('Imaginary')\n\naxs[0].set_title('S-Plane')\naxs[1].set_title('$\\omega$-Plane')\n\n# Plot poles and zeros in the s-plane with annotations\npole = (-3, 0)\nzero = (-2, 0)\naxs[0].plot(pole[0], pole[1], 'bo', markersize=12) # blue circle for pole\naxs[0].plot(zero[0], zero[1], 'rx', markersize=12) # red cross for zero\naxs[0].text(pole[0], pole[1]+0.1, '  Pole', verticalalignment='bottom', horizontalalignment='right')\naxs[0].text(zero[0], zero[1]-0.2, '  Zero', verticalalignment='top', horizontalalignment='right')\n\n# Mapping from s-plane to w-plane\nfor xi in np.linspace(0, 2*np.pi, 100):\n    s_point = np.sin(xi), 3*np.cos(xi) # pick one s-point\n    axs[0].plot(s_point[0], s_point[1], 'm.', markersize=12) # plot the s-point in the s-plane\n    \n    # Map one s_point to a W_point\n    W_point = (complex(s_point[0], s_point[1]) + 3)/(complex(s_point[0], s_point[1]) + 2)\n    axs[1].plot(np.real(W_point), np.imag(W_point), 'r.', markersize=12) # plot the W_point\n\nplt.show()",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#sample-contour-analysis-in-the-s-plane-and-its-mapping-to-the-omega-plane",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#sample-contour-analysis-in-the-s-plane-and-its-mapping-to-the-omega-plane",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Sample Contour Analysis in the S-Plane and its Mapping to the \\(\\omega\\)-Plane",
    "text": "Sample Contour Analysis in the S-Plane and its Mapping to the \\(\\omega\\)-Plane\nConsider a specific path, or contour, in the s-plane that includes a zero of the transfer function \\(1 + G(s)H(s)\\). Our goal is to understand how this contour translates into the \\(\\omega\\)-plane.\n\n\n\n\n\n\n\nGiven that all poles and zeros of \\(1 + G(s)H(s)\\) are known, we express it as:\n\\[\n  1 + G(s)H(s) = \\frac{(s-\\beta_1)(s-\\beta_2)...}{(s-\\alpha_1)(s-\\alpha_2)...}\n  \\]\n\nMapping a Point from S-Plane to \\(\\omega\\)-Plane\n\nExample with a Specific Point \\(s_1\\): To illustrate, let’s focus on a particular point \\(s_1\\) on our s-plane contour.\n\\[\n1 + G(s_1)H(s_1) = \\frac{(s_1-\\beta_1)(s_1-\\beta_2)...}{(s_1-\\alpha_1)(s_1-\\alpha_2)...}\n\\]\nHere, each term $ (s_1-_i) $ represents a ‘numerator phasor’, and each $ (s_1-_i) $ is a ‘denominator phasor’.\nCalculating the Mapped Point’s Magnitude and Phase:\n\nMagnitude: The magnitude of the mapped point on the \\(\\omega\\)-plane is derived by multiplying each numerator phasor and dividing by each denominator phasor.\nPhase: The phase angle of the mapped point is calculated by summing up the phases of the numerator phasors and subtracting the phases of the denominator phasors.\n\nResulting Mapped Point \\(w_1\\): This process results in a point in the \\(\\omega\\)-plane, denoted as \\(w_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Phasors and Contour Mapping\n\nGraphical Representation: The phasors corresponding to the point \\(s_1\\) are graphically represented below (Left), showing how they contribute to the mapping process.\nContour Movement and Mapping: As we continue to move along the contour in the s-plane, say in a clockwise direction, we create a corresponding contour in the \\(\\omega\\)-plane (Right below).\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, FloatSlider\n\n# Define the transfer function\ndef transfer_function(s):\n    return s + 2\n\n# Zero of the transfer function\nzero = -2\n\n# Define the contour in the s-plane (a circle of radius 3)\ndef s_plane_contour(theta):\n    return 3 * np.exp(1j * theta)\n\n# Map the contour to the omega-plane using the transfer function\ndef omega_plane_mapping(s):\n    return transfer_function(s)\n\n# Pre-calculate all the points on the contour for the omega-plane\ntheta_values = np.linspace(0, 2*np.pi, 300)\nomega_points = [omega_plane_mapping(s_plane_contour(theta)) for theta in theta_values]\n\n# Function to plot the contours\ndef plot_contours(theta):\n    s_point = s_plane_contour(theta)\n    omega_point = omega_plane_mapping(s_point)\n\n    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n    # Plotting in the s-plane\n    axs[0].plot(np.real(s_point), np.imag(s_point), 'ro', label='Current Point')  # current point\n    axs[0].plot(zero, 0, 'gX', markersize=10, label='Zero')  # zero of the transfer function\n    circle = plt.Circle((0, 0), 3, color='b', fill=False)\n    axs[0].add_artist(circle)\n    axs[0].set_xlim([-4, 4])\n    axs[0].set_ylim([-4, 4])\n    axs[0].axhline(0, color='black')\n    axs[0].axvline(0, color='black')\n    axs[0].grid(True)\n    axs[0].set_title('S-Plane')\n    axs[0].set_xlabel('Real')\n    axs[0].set_ylabel('Imaginary')\n    axs[0].legend()\n\n    # Plotting in the omega-plane\n    axs[1].plot([np.real(wp) for wp in omega_points], [np.imag(wp) for wp in omega_points], 'b-', alpha=0.7)  # all points\n    axs[1].plot(np.real(omega_point), np.imag(omega_point), 'ro', label='Current Point')  # current point\n    axs[1].set_xlim([-5, 5])\n    axs[1].set_ylim([-5, 5])\n    axs[1].axhline(0, color='black')\n    axs[1].axvline(0, color='black')\n    axs[1].grid(True)\n    axs[1].set_title('$\\omega$-Plane')\n    axs[1].set_xlabel('Real')\n    axs[1].set_ylabel('Imaginary')\n    axs[1].legend()\n\n    plt.show()\n\n# Create a slider for interactive plot\ninteract(plot_contours, theta=FloatSlider(min=0, max=2*np.pi, step=0.01, value=0, description='Theta:'))\n\n\n\n\n&lt;function __main__.plot_contours(theta)&gt;\n\n\nLet’s consider once again our arbitrary contour:\n\n\n\n\n\n\n\n\n\n\nConsider the behavior of individual phasors, such as the $ (s - _1) $ phasor, while moving along a specific contour in the s-plane.\n\n**Phasor $ (s - _1) $**: As we travel along the contour that includes the zero $ _1 $, the phasor $ (s - _1) $ will contribute a total angle change. When you start at a certain point on the contour and move all the way around it, the angle change contributed by $ (s - _1) $ sums up to $ -2$ radians.\n**Phasor $ (s - _2) $**: Now, if you consider a different phasor, $ (s - _2) $, where $ _2 $ is not enclosed by the contour, the scenario changes. As you follow the same contour starting from one point and returning back to it, the net angle change contributed by $ (s - _2) $ ends up being zero. This is because any positive angle change during one part of the journey is canceled out by a corresponding negative angle change in another part.\n\nThis understanding is crucial for the Nyquist stability criterion. It tells us that:\n\nIf a zero of the function $ 1 + G(s)H(s) $ is enclosed within the contour, it contributes an angle of $ 2$ radians to the total angle change as we traverse the contour.\nIf all other poles and zeros are outside the contour, they do not contribute to the net angle change.\n\nTherefore, regardless of the shape of the contour, if it encloses a zero of $ 1 + G(s)H(s) $, the resulting mapped contour in the \\(\\omega\\)-plane will encircle the origin exactly once, and in a clockwise direction, due to the total angle change of $ -2$ radians.\n\n\nCase of Enclosing a Zero\n\nEnclosing a Zero: Suppose our contour in the s-plane encircles a zero of the function \\(1 + G(s)H(s)\\). In this scenario, as we traverse the contour in a clockwise direction, the total angle change contributed by this enclosed zero is $ -2$ radians.\nResulting Encirclement: This means that the corresponding contour in the \\(\\omega\\)-plane will encircle the origin in the clockwise direction exactly once.\n\n\n\nCase of Enclosing a Pole\n\nEnclosing a Pole: Now, imagine instead that the contour encloses a pole (not a zero) of \\(1 + G(s)H(s)\\). All other zeros and poles are outside this contour.\n\n\n\n\n\n\n\n\n\nEffect on Angle Contribution: The angle contribution for a pole is the opposite of that for a zero. Therefore, the total angle change is $ +2$ radians, indicating a counter-clockwise encirclement in the \\(\\omega\\)-plane.\nNet Encirclement: This results in one complete counter-clockwise rotation around the origin in the \\(\\omega\\)-plane.\n\n\n\nCombining Poles and Zeros\n\nCombining Poles and Zeros: Consider a contour that encloses both poles and a zero. For example, a contour with two poles and one zero.\nNet Rotation Calculation: The net rotation in the W-plane is determined by the difference between counter-clockwise rotations (contributed by poles) and clockwise rotations (contributed by zeros). In our example, we have two counter-clockwise rotations (poles) and one clockwise rotation (zero), resulting in one net counter-clockwise rotation (\\(2 - 1 = 1\\)).\n\nTHE CODE BELOW IS NOT WORKING WELL!! FIX IT!!\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, IntSlider, Dropdown\n\ndef transfer_function(s, case):\n    if case == 'Case 1':\n        return s/(s**2 + 6*s + 18)\n    elif case == 'Case 2':\n        return (s**2 + 1.5*s + 0.8125)/((s + 1)*(s + 0.8))\n    elif case == 'Case 3':\n        return 1/((s + 1)*(s + 0.8))\n    elif case == 'Case 4':\n        return s + 3\n    else:\n        return s  # Default case\n\ndef plot_contour_point(angle, case):\n    # Define the contour based on the selected case\n    if case in ['Case 1', 'Case 3', 'Case 4']:\n        radius = 3\n        center = (-3, 0)\n    elif case == 'Case 2':\n        radius = 2\n        center = (0.5, 0)\n    else:        \n        radius = 2\n        center = (0, 0)\n            \n    angle = np.deg2rad(angle)\n    s = complex(center[0] + radius * np.cos(angle), center[1] + radius * np.sin(angle))\n    tnf = transfer_function(s, case)\n\n    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n    axs[0].set_title('S-plane')\n    axs[1].set_title('W-plane')\n    \n    # Plot the contour and current point in the s-plane\n    theta = np.linspace(0, 2*np.pi, 100)\n    axs[0].plot(center[0] + radius * np.cos(theta), center[1] + radius * np.sin(theta), 'b-')\n    axs[0].plot(np.real(s), np.imag(s), 'ro')\n    \n    # Plot in the omega-plane\n    omega_points = [transfer_function(complex(center[0] + radius * np.cos(t), center[1] + radius * np.sin(t)), case) for t in theta]\n    axs[1].plot([np.real(w) for w in omega_points], [np.imag(w) for w in omega_points], 'b-')\n#     axs[1].plot(np.real(tnf), np.imag(tnf), 'ro')\n\n    for ax in axs:\n        ax.axhline(0, color='black', linewidth=1)\n        ax.axvline(0, color='black', linewidth=1)\n        ax.grid(True)\n        ax.set_xlabel('Real')\n        ax.set_ylabel('Imaginary')\n\n    plt.show()\n\n# Interactive widgets\nangle_slider = FloatSlider(min=0, max=360, step=1, value=0, description='Angle:')\ncase_dropdown = Dropdown(options=['Case 1', 'Case 2', 'Case 3', 'Case 4'], value='Case 1', description='Case:')\n\ninteract(plot_contour_point, angle=angle_slider, case=case_dropdown)\n\n\n\n\n&lt;function __main__.plot_contour_point(angle, case)&gt;\n\n\n\n\nImplications for Nyquist Criterion\nThese observations form the basis of the Nyquist stability criterion. It’s important to note that while we’ve discussed the qualitative aspects of the mapping, the exact shape of the contour in the W-plane is not our primary concern.\nWith this understanding, we are now prepared to delve into stating and applying the Nyquist stability criterion in control system analysis.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#cauchys-argument-principle",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#cauchys-argument-principle",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Cauchy’s argument principle",
    "text": "Cauchy’s argument principle\nWe can tell the relative difference between the number of poles and zeros inside of a contour by counting how many time the plot circles the origin and in which direction.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#the-nyquist-stability-criterion",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#the-nyquist-stability-criterion",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "The Nyquist Stability Criterion",
    "text": "The Nyquist Stability Criterion\nWe are going to apply Cauchy’s Argument Principle to a specific contour in the s-plane, as illustrated on the left in the figure below.\nThis contour encircles the entire right half-plane (RHP), including the imaginary axis. This contour is called the Nyquist Contour.\nFor the initial analysis, we’ll assume that there are no poles located on the contour itself. We will consider the implications of having poles on the contour at a later stage.\nThrough the function \\(1 + G(s)H(s)\\), this specific contour in the s-plane is mapped to the \\(\\omega\\)-plane, shown on the right in the picture.\n\n\n\n\n\n\n\nKey Points to Note:\n\nOpen-Loop Poles: The poles of \\(1 + G(s)H(s)\\) are the same as the open-loop poles of the system, which we know from the zeros and poles of \\(G(s)H(s)\\).\nClosed-Loop Poles: The zeros of \\(1 + G(s)H(s)\\) correspond to the closed-loop poles of the system. These zeros are not known beforehand and are what we aim to determine for stability analysis.\n\nAccording to the Nyquist Criterion:\n\nIf the mapping in the W-Plane encircles the origin \\(N\\) times in a counter-clockwise direction, this number of encirclements (\\(N\\)) is mathematically expressed as the number of poles of \\(1 + G(s)H(s)\\) (denoted as \\(P\\)) minus the number of its zeros (denoted as \\(Z\\)). This relationship is captured in the Nyquist equation:\n\\[\nN = P - Z\n\\]\nThe Nyquist equation forms the basis of the Nyquist Criterion, which asserts that the total number of counter-clockwise encirclements of the origin in the W-Plane by the function \\(1 + G(s)H(s)\\) is equal to the difference between the number of its poles and zeros.\n\nTherefore, to determine the closed-loop stability of the system, it’s necessary to map the contour onto the W-plane and count the number of times (\\(N\\)) this mapping encircles the origin.\nFrom the Nyquist equation we obtain directly how many zeros of \\(1+G(s)H(s)\\) are in the right half plane.\n\nSide Comments\n\nRegarding the scenario where a zero of \\(1 + G(s)H(s)\\) (pole in closed loop) lies on the contour, it will be important to consider its impact. If a zero is on the contour, this implies that the contour will pass through the origin in the W-Plane. Such a situation typically indicates a condition of marginal stability for the system. In other words, when the contour in the s-plane, transformed by the function \\(1 + G(s)H(s)\\), passes through the origin in the W-Plane, it represents a special case where the function’s zeros (which are the closed-loop poles) coincide with the contour. This scenario requires careful analysis as it relates to the system’s stability margin.\nAnother important consideration arises when a pole of the open-loop transfer function $ G(s)H(s) $ falls on the Nyquist contour. In such instances, the mapping of that point to the W-Plane results in an infinite value. This occurrence requires special attention in the analysis of the system’s stability.\nZeros of \\(G(s)H(s)\\) do not create any problem. Unlike poles, which can map to infinity on the W-plane and complicate the analysis (as infinite values need special consideration), zeros do not result in such extreme values in the mapping process. Therefore, they do not add complexity to the graphical interpretation of the Nyquist plot.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#translating-the-nyquist-plot",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#translating-the-nyquist-plot",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Translating the Nyquist Plot",
    "text": "Translating the Nyquist Plot\nIn our study of control systems, we have focused on analyzing the Nyquist Plot of the function\n\\[\n1 + G(s)H(s)\n\\]\nand observed its behavior in terms of the number of times it encircles the origin in the W-plane.\nCreating the plot of this function can be challenging due to its complexity. To simplify our analysis, we can instead consider the Nyquist Plot of just the function $ G(s)H(s) $. This approach involves counting the encirclements around the critical point \\(-1 + 0j\\) on the complex plane.\nThis method not only simplifies the plotting process but also provides us with the essential information needed to assess the stability of the control system.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#interpretation-of-the-nyquist-stability-criterion",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#interpretation-of-the-nyquist-stability-criterion",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Interpretation of the Nyquist Stability Criterion",
    "text": "Interpretation of the Nyquist Stability Criterion\nThe criterion relates to the frequency response of a system and is expressed as:\n\\[\nN = P - Z\n\\]\nwhere: - \\(N\\) is the number of counter-clockwise encirclements of the $-1+0j $point in the W-plane. - \\(P\\) is the number of poles of \\(1 + G(s)H(s)\\) in the right half of the s-plane. - \\(Z\\) is the number of zeros of \\(1 + G(s)H(s)\\) in the same plane.",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#applying-the-criterion",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#applying-the-criterion",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Applying the Criterion",
    "text": "Applying the Criterion\nTo apply this criterion, we follow these steps:\n\nMapping the Contour: Consider a contour in the s-plane that encompasses the right half, including the imaginary axis. We assume no poles lie directly on this contour initially (we’ll address the scenario with poles on the contour later).\nTransformation to W-Plane: This contour is then mapped onto the W-plane via the function \\(G(s)H(s)\\).\nCounting Encirclements: The number of times this mapped contour encircles the point -1 in the W-plane (in a counter-clockwise direction) gives us \\(N\\). This also means that \\(N\\) is positive when the contour encircles the point -1 in the counter-clockwise direction.\nDetermining Stability:\n\nWe use the equation \\(N = P - Z\\) to determine \\(Z\\) the zeros of \\(1 + G(s)H(s)\\) in the RHP, which correspond to the closed loop poles in the RHP.\n\n\n\nOpen-Loop Stable Systems\n\nFor an open-loop stable system (where \\(P = 0\\)), the closed-loop system is stable if the Nyquist plot in the W-plane does not encircle the origin.\nWhen \\(P=0\\) (open loop system is stable)\n\\(Z=N \\Rightarrow N=0\\) or no encirclements of the point \\(-1\\) to have a stable closed loop system (for stability \\(Z=0\\)).\nThis is the case we come across most often.\n\nFor example, given an open-loop stable system we would like a Nyquist plot as:\n\n\n\n\n\n\n\n\n\nOpen-Loop Unstable Systems\n\nFor an open-loop unstable system, say with one pole in the right-half plane (\\(P = 1\\)), the system is stable under closed-loop operation if the G(s)H(s) plot encircles the point \\(-1 + j0\\) once in the counter-clockwise direction.\nIn order to guarantee that there are no zeros (roots of \\(1+G(s)H(s)\\)) in the right half plane (\\(Z=0\\)), we need to have exactly 1 counter-clockwise (CCW) encirclement of the point -1 for each open loop pole in the right half plane:\n\n\\[\nP = N\n\\]",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "introduction_to_frequency_domain_analysis_in_control_systems.html#check-your-understanding",
    "href": "introduction_to_frequency_domain_analysis_in_control_systems.html#check-your-understanding",
    "title": "Introduction to Frequency Domain Analysis in Control Systems",
    "section": "Check Your Understanding",
    "text": "Check Your Understanding\n\nQuestion: What does \\(N = P - Z\\) signify in the Nyquist criterion?\nAnswer: It represents the relationship between the number of counter-clockwise encirclements of the origin in the W-plane, the number of poles, and the number of zeros of the open-loop transfer function in the right half of the s-plane.\nQuestion: For an open-loop stable system, what is the key condition for closed-loop stability?\nAnswer: The Nyquist plot of \\(G(s)H(s)\\) in the W-plane should not encircle the point \\(-1 + j0\\).",
    "crumbs": [
      "Introduction to Frequency Domain Analysis in Control Systems"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/relay_control_it.html",
    "href": "IT_TCLab_🇮🇹/relay_control_it.html",
    "title": "Controllo relè",
    "section": "",
    "text": "Il codice seguente implementa il controllo del relè per la temperatura T1 nel Laboratorio di controllo della temperatura.\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    Q^{max} &\\text{if $T \\leq T_{setpoint}$}\\\\\n    0       & \\text{if $T \\geq T_{setpoint}$}\n    \\end{cases}\n\\end{align}\\]\nQuesto è semplice da implementare, infatti è solo una riga di codice nella cella seguente. Regolare “Tsetpoint” sul valore di setpoint desiderato, quindi eseguire la cella.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 40\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    for t in clock(tfinal, tstep):\n        T1 = a.T1                             # measure temperature\n        Q1 = Qmax if a.T1 &lt; Tsetpoint else 0  # compute manipulated variable\n        a.Q1(Q1)                              # adjust power\n        h.update(t)                           # log results\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-relè-semplice",
    "href": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-relè-semplice",
    "title": "Controllo relè",
    "section": "",
    "text": "Il codice seguente implementa il controllo del relè per la temperatura T1 nel Laboratorio di controllo della temperatura.\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    Q^{max} &\\text{if $T \\leq T_{setpoint}$}\\\\\n    0       & \\text{if $T \\geq T_{setpoint}$}\n    \\end{cases}\n\\end{align}\\]\nQuesto è semplice da implementare, infatti è solo una riga di codice nella cella seguente. Regolare “Tsetpoint” sul valore di setpoint desiderato, quindi eseguire la cella.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 40\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    for t in clock(tfinal, tstep):\n        T1 = a.T1                             # measure temperature\n        Q1 = Qmax if a.T1 &lt; Tsetpoint else 0  # compute manipulated variable\n        a.Q1(Q1)                              # adjust power\n        h.update(t)                           # log results\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-relè-con-isteresi",
    "href": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-relè-con-isteresi",
    "title": "Controllo relè",
    "section": "Controllo relè con isteresi",
    "text": "Controllo relè con isteresi\nUno dei problemi con il semplice controllo del relè è il rischio di “vibrazioni”, ovvero situazioni in cui la variabile manipolata (in questo caso la potenza del riscaldatore) si accende e si spegne rapidamente. Ciò può essere causato da sistemi che rispondono molto bene agli input di controllo o in cui le misurazioni dei sensori comportano un rumore significativo.\nIl tipico termostato domestico utilizzato per il controllo del forno incorpora una soluzione semplice ma altamente efficace al periodo di chiacchiere. L’idea è di superare intenzionalmente il setpoint. Quindi, dopo lo stato di commutazione del controllo, ci sarà almeno un breve periodo di tempo in cui non dovrebbero essere necessarie ulteriori azioni di controllo. L’algoritmo di controllo può essere scritto\n\\[\\begin{align}\nQ(t) & = \\begin{cases}\n    0       & \\text{if $T \\geq T_{Setpoint} - \\frac{d}{2}$}\\\\\n    Q^{max} &\\text{if $T \\leq T_{Setpoint} + \\frac{d}{2}$}\\\\\n    Q(t-\\delta t) & \\mbox{otherwise}\n    \\end{cases}\n\\end{align}\\]\ndove \\(d\\) è la tolleranza o isteresi. Per i sistemi di riscaldamento domestico, un valore tipico è compreso tra 0,5 e 1 grado F. Questa immagine mostra come veniva regolata l’isteresi su un tipico termostato domestico di uso comune alla fine del XX secolo.\n\nIl forno è acceso per temperature inferiori all’intervallo\ned è rivolto a temperature superiori all’intervallo. All’interno dell’intervallo, tuttavia, il forno può essere acceso o spento a seconda di ciò che è accaduto nell’ultimo punto decisionale.\nIl seguente codice implementa il controllo del relè con isteresi.\n\nfrom tclab import TCLab, clock, Historian\n\n# control parameters\nQmax = 100\nTsetpoint = 50\nd = 0.5\n\n# time horizon and time step\ntfinal = 300\ntstep = 1\n\n# perform experiment\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    Q1 = a.Q1()\n    for t in clock(tfinal, tstep):\n        T1 = a.T1\n        if T1 &lt;= Tsetpoint - d/2:\n            Q1 = Qmax\n        if T1 &gt;= Tsetpoint + d/2:\n            Q1 = 0\n        a.Q1(Q1)\n        h.update()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-on-off-multivariabile",
    "href": "IT_TCLab_🇮🇹/relay_control_it.html#controllo-on-off-multivariabile",
    "title": "Controllo relè",
    "section": "Controllo On-Off multivariabile",
    "text": "Controllo On-Off multivariabile\n\nfrom tclab import TCLab, clock, Historian\n\nTsetpoint1 = 45\nTsetpoint2 = 35\nQmax = 100\ntfinal = 480\nd = 0.5\n\nwith TCLab() as a:\n    h = Historian(a)\n    h.initplot(tfinal)\n    Q1 = a.Q1()\n    Q2 = a.Q2()\n    for t in clock(tfinal):\n        T1 = a.T1\n        if T1 &lt;= Tsetpoint1 - d/2:\n            Q1 = Qmax\n        if T1 &gt;= Tsetpoint1 + d/2:\n            Q1 = 0\n        a.Q1(Q1)\n\n        T2 = a.T2\n        if T2 &lt;= Tsetpoint2 - d/2:\n            Q2 = Qmax\n        if T2 &gt;= Tsetpoint2 + d/2:\n            Q2 = 0\n        a.Q2(Q2)\n        h.update()\n\n\n\n\n\n\n\n\nTCLab disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/relay_control_it.html#esercizi",
    "href": "IT_TCLab_🇮🇹/relay_control_it.html#esercizi",
    "title": "Controllo relè",
    "section": "Esercizi",
    "text": "Esercizi\n\nEsaminando le risposte a circuito chiuso, è ovvio che il riscaldatore è sovradimensionato ai fini del controllo a 40 gradi C. Prova altri valori per \\(Q^{\\max}\\) per vedere se puoi migliorare le prestazioni a circuito chiuso.\nQual è l’effetto del tempo di campionamento sulle prestazioni del controllo? Cosa succede se si allunga il tempo di campionamento del controller?\nIn una nuova cella, creare una modifica dello script per includere una modifica nel setpoint da 40 gradi C a 50 gradi C al segno dei 300 secondi. Esegui l’esperimento per almeno 10 minuti per vedere l’effetto completo.\nPer un controllo relè con isteresi, provare a tracciare un grafico di \\(Q\\) in funzione di \\(T\\) assumendo \\(T_{Setpoint} = 50\\) e \\(h = 3\\). Puoi disegnare una funzione unica? Perché no?",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Controllo relè"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html",
    "title": "Compito di laboratorio: Controllo PID",
    "section": "",
    "text": "Il primo passo è tentare il controllo completamente manuale dei doppi riscaldatori. Utilizzando l’interfaccia GUI di seguito, connettersi al laboratorio di controllo della temperatura e regolare i riscaldatori Q1 e Q2 per raggiungere temperature stabili di 50°C per T1 e 40°C per T2.\nSuggerimento: esiste un’interazione tra i riscaldatori, ovvero una regolazione in Q1 o Q2 influenzerà sia T1 che T2. Quindi questo è un esercizio per soddisfare due vincoli manipolando due variabili.\n\nfrom tclab.gui import NotebookUI\n\ninterface = NotebookUI()\n\n\ninterface.gui",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio: Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-1.-controllo-manuale",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-1.-controllo-manuale",
    "title": "Compito di laboratorio: Controllo PID",
    "section": "",
    "text": "Il primo passo è tentare il controllo completamente manuale dei doppi riscaldatori. Utilizzando l’interfaccia GUI di seguito, connettersi al laboratorio di controllo della temperatura e regolare i riscaldatori Q1 e Q2 per raggiungere temperature stabili di 50°C per T1 e 40°C per T2.\nSuggerimento: esiste un’interazione tra i riscaldatori, ovvero una regolazione in Q1 o Q2 influenzerà sia T1 che T2. Quindi questo è un esercizio per soddisfare due vincoli manipolando due variabili.\n\nfrom tclab.gui import NotebookUI\n\ninterface = NotebookUI()\n\n\ninterface.gui",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio: Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-2.-implementazione-di-un-controller-pid",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-2.-implementazione-di-un-controller-pid",
    "title": "Compito di laboratorio: Controllo PID",
    "section": "Parte 2. Implementazione di un controller PID",
    "text": "Parte 2. Implementazione di un controller PID\nData una variabile di processo \\(PV\\) e un setpoint \\(SP\\), il controllo proporzionale-integrale-derivativo determina il valore di una variabile manipolata MV mediante la regola\n\\[\\begin{align}\nMV & = \\bar{MV} + K_p\\left(SP - PV\\right) + K_i \\int_0^t \\left(SP-PV)\\right)dt + K_d \\frac{d\\left(SP-PV\\right)}{dt}\n\\end{align}\\]\ndove \\(K_p\\), \\(K_i\\) e \\(K_d\\) sono rispettivamente i coefficienti proporzionale, integrale e derivativo.\nIl codice seguente definisce un oggetto Python che implementa questo algoritmo.\n\nclass PID:\n    def __init__(self):\n        self.Kp = 1\n        self.Ki = 100\n        self.Kd = 0\n\n        self.e = 0\n        self.dedt = 0\n        self.eint = 0\n        self.mv = 0\n\n    def update(self, setpoint, pv):\n        e = setpoint - pv\n        self.dedt = self.e - e\n        self.eint += e\n        self.e = e\n\n        self.mv = self.Kp * self.e + self.Ki * self.eint + self.Kd * self.dedt\n        return self.mv\n\nLa cella seguente fornisce un’implementazione iniziale del controllo PID per il riscaldatore T1. Modifica questo codice per aggiungere un secondo controller, “pid2”, per il riscaldatore T2. Prova utilizzando il simulatore offline. Quando sei soddisfatto dei risultati, applica il controllo al riscaldatore vero e proprio.\n\nfrom tclab import setup, clock, Historian, Plotter\n\nTCLab = setup(connected=False, speedup = 20)\n\npid1 = PID()\npid1.Kp = 2\npid1.Ki = .1\npid1.Kd = 2\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 800)\n    for t in clock(800):\n        lab.U1 = pid1.update(50, lab.T1)\n        p.update(t)\n\nSimulated TCLab\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio: Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-3.-regolazione-del-controller-pid",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pid-control_it.html#parte-3.-regolazione-del-controller-pid",
    "title": "Compito di laboratorio: Controllo PID",
    "section": "Parte 3. Regolazione del controller PID",
    "text": "Parte 3. Regolazione del controller PID\nUtilizzando il codice sviluppato sopra, crea una nuova cella di seguito e verifica i seguenti problemi:\n\nCosa succede quando Ki = 0?\nCosa succede quando Ki = 0,1 e Kd = 3?\n\nDescrivere i vantaggi dell’azione integrale e derivativa.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio: Controllo PID"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html",
    "href": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html",
    "title": "Adattamento dei dati dei test di fase ai modelli empirici",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\ndf.plot(grid=True)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Adattamento dei dati dei test di fase ai modelli empirici"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#leggi-il-file-dati",
    "href": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#leggi-il-file-dati",
    "title": "Adattamento dei dati dei test di fase ai modelli empirici",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\ndf.plot(grid=True)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Adattamento dei dati dei test di fase ai modelli empirici"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#parametro",
    "href": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#parametro",
    "title": "Adattamento dei dati dei test di fase ai modelli empirici",
    "section": "Parametro",
    "text": "Parametro\n\nAdattamento dei dati di modifica del passo a un modello del primo ordine\nPer un sistema lineare del primo ordine inizialmente allo stato stazionario, la risposta a una variazione dell’ingresso a gradino a \\(t=0\\) è data da\n\\[y(t) = y(0) + K(1 - e^{-t/\\tau}) \\Delta U\\]\ndove \\(\\Delta U\\) è l’entità del cambiamento graduale. Conversione nella notazione utilizzata per il laboratorio di controllo della temperatura dove \\(y(t) = T_1(t)\\) e \\(\\Delta U = \\Delta Q_1\\)\n\\[T_1(t) = T_1(0) + K_1(1 - e^{-t/\\tau_1}) \\Delta Q_1\\]\nle celle seguenti forniscono le stime iniziali per il guadagno in stato stazionario \\(K_1\\) e la costante di tempo \\(\\tau_1\\).\n\n\nLettura dei dati salvati\n\ndf[['Q1','T1','T2']].plot(grid=True)\n\n\n\n\n\n\n\n\n\n\nStima del guadagno e della costante di tempo\nNel limite \\(t\\rightarrow\\infty\\) diventa il modello del primo ordine\n\\[T_1(\\infty) = T_1(0) + K_1\\Delta Q_1\\]\nche fornisce un metodo per stimare \\(K_1\\)\n\\[K_1 = \\frac{T_1(\\infty) - T_1(0)}{\\Delta Q_1}\\]\nQuesti calcoli vengono eseguiti di seguito dove utilizziamo la prima e l’ultima misurazione di \\(T_1\\) come stime di \\(T_1(0)\\) e \\(T_1(\\infty)\\), rispettivamente.\n\nT1 = df['T1']\nQ1 = df['Q1']\n\nDeltaT1 = max(T1) - min(T1)\nDeltaQ1 = Q1.mean()\n\nK1 = DeltaT1/DeltaQ1\nprint(\"K1 is approximately\", K1)\n\nK1 is approximately 0.6968700000000001\n\n\n\n# find when the increase in T1 gets larger than 63.2% of the final increase\ni = (T1 - T1.min()) &gt; 0.632*(T1.max()-T1.min())\ntau1 = T1.index[i].min()\nprint(\"tau1 is approximately\", tau1, \"seconds\")\n\ntau1 is approximately 163.0 seconds\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nexp = np.exp\nt = df.index\n\nT1_est = T1.min() + K1*(1 - exp(-t/tau1))*DeltaQ1\n\nplt.figure(figsize=(10,5))\nax = plt.subplot(2,1,1)\ndf['T1'].plot(ax = ax, grid=True)\nplt.plot(t,T1_est)\nplt.title('Step Test Data Compared to Model')\n\nplt.subplot(2,1,2)\nplt.plot(t,T1_est-T1)\nplt.grid()\nplt.title('Residual Error')\n\nText(0.5, 1.0, 'Residual Error')\n\n\n\n\n\n\n\n\n\nUn modello del primo ordine cattura determinate caratteristiche e fornisce un risultato ragionevolmente buono quando il sistema si avvicina a un nuovo stato stazionario. Il problema, tuttavia, è che per il controllo abbiamo bisogno di un buon modello durante il transitorio iniziale. È qui che il modello del primo ordine crolla e prevede una risposta qualitativamente diversa da quella che osserviamo.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Adattamento dei dati dei test di fase ai modelli empirici"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#primo-ordine-più-ritardo-o-tempo-morto",
    "href": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#primo-ordine-più-ritardo-o-tempo-morto",
    "title": "Adattamento dei dati dei test di fase ai modelli empirici",
    "section": "Primo Ordine più Ritardo (o Tempo Morto)",
    "text": "Primo Ordine più Ritardo (o Tempo Morto)\n\\[T_1(t) = T_1(0) + K (1-e^\\frac{t-\\theta}{\\tau}) Q_{step}\\]\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\n\ndf = pd.read_csv('data/step-test-data.csv')\ndf = df.set_index('Time')\n\nT1 = df['T1']\nQ1 = df['Q1']\nt = df.index\n\nDeltaT1 = max(T1) - min(T1)\nDeltaQ1 = Q1.mean()\n\nK1 = DeltaT1/DeltaQ1\ni = (T1 - T1.min()) &gt; 0.632*(T1.max()-T1.min())\ntau1 = T1.index[i].min()\n\ndef fopdt(K=K1, tau=tau1, theta=0, T10=T1.min()):\n    def Q1(t):\n        return 0 if t &lt; 0 else DeltaQ1\n    Q1vec = np.vectorize(Q1)\n    T1_fopdt = T10 + K*(1-np.exp(-(t-theta)/tau))*Q1vec(t-theta)\n    plt.figure(figsize=(10,5))\n    plt.subplot(2,1,1)\n    plt.plot(t,T1_fopdt)\n    plt.plot(t,df['T1'])\n    plt.subplot(2,1,2)\n    plt.plot(t,T1_fopdt - T1)\n    plt.show()\n    \ninteract(fopdt,K=(0,1,.001),tau=(50,200,.5),theta=(0,50,.5),T10=(15,25,.1))\n\n\n\n\n&lt;function __main__.fopdt(K=0.6968700000000001, tau=163.0, theta=0, T10=20.9)&gt;",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Adattamento dei dati dei test di fase ai modelli empirici"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#secondo-ordine",
    "href": "IT_TCLab_🇮🇹/fitting_step_test_data_to_empirical_models_it.html#secondo-ordine",
    "title": "Adattamento dei dati dei test di fase ai modelli empirici",
    "section": "Secondo ordine",
    "text": "Secondo ordine\nSEMD Equaz. 5-48\n\\[T_1(t) = T_1(0) + K\\left(1 - \\frac{\\tau_1 e^{-t/\\tau_1} - \\tau_2 e^{-t/\\tau_2}}{\\tau_1 - \\ \\tau_2}\\right)Q_1(t)\\]\n\nfrom scipy.optimize import least_squares\nimport numpy as np\nQmax = 50\n\ndef f(x):\n    K,tau1,tau2,T10 = x\n    t = df.index\n    exp = np.exp\n    Tpred = T10 + K*(1 - (tau1*exp(-t/tau1) - tau2*exp(-t/tau2))/(tau1-tau2))*Qmax\n    resid = df['T1'] - Tpred\n    return resid\n\nic = [0.86,40,130,20]\n\nr = least_squares(f,ic,bounds=(0,np.inf))\nr.x\n\narray([  0.69537389,  19.68872647, 141.40950924,  20.91093839])\n\n\nE la funzione di trasferimento risultante è:\n\\[ G_1(s) = \\frac{0,70}{(20s + 1)(141s + 1)} \\]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Adattamento dei dati dei test di fase ai modelli empirici"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html",
    "title": "Modellazione del sistema",
    "section": "",
    "text": "Conduzione: flusso di calore attraverso il contatto fisico diretto, significativo nel nostro sistema a causa delle connessioni tra il riscaldatore, la batteria e la struttura del veicolo spaziale.\nRadiazione: Trasferimento di calore attraverso onde elettromagnetiche, rilevante a causa dell’esposizione al sole e allo spazio profondo.\nConvezione: meno rilevante nel vuoto dello spazio, ma un fattore da considerare durante i test sulla terra.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#primo-diagramma-a-blocchi-quanto-è-accurato",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#primo-diagramma-a-blocchi-quanto-è-accurato",
    "title": "Modellazione del sistema",
    "section": "Primo diagramma a blocchi: quanto è accurato?",
    "text": "Primo diagramma a blocchi: quanto è accurato?\n\n\n\n\n\n\n\n\nSpiegazione dettagliata dei meccanismi di trasferimento del calore\n\nConduzione\nLa conduzione è il trasferimento di calore attraverso il contatto fisico diretto. In un veicolo spaziale, ciò si verifica quando le molecole o gli atomi in una regione ad alta temperatura vibrano intensamente e trasmettono la loro energia alle particelle vicine in un’area a temperatura più bassa.\n\nImportanza nei veicoli spaziali: nel nostro sistema di controllo termico satellitare, la conduzione è fondamentale in quanto consente il trasferimento del calore dal riscaldatore alla batteria e quindi alla struttura del veicolo spaziale. Questo meccanismo è fondamentale per mantenere le temperature entro i limiti operativi.\nEsempio: immagina di tenere un’estremità di un’asta di metallo sopra una fiamma. A poco a poco, il calore si sposta lungo l’asta, riscaldando l’estremità distante. Questo è simile al modo in cui il calore viene condotto dal riscaldatore attraverso la batteria nel nostro sistema.\n\n\n\nRadiazioni\nLa radiazione si riferisce al trasferimento di calore sotto forma di onde elettromagnetiche. Non richiede un mezzo attraverso il quale viaggiare, rendendolo una modalità primaria di trasferimento del calore nello spazio.\n\nRuolo nei veicoli spaziali: nel contesto di un veicolo spaziale, le radiazioni sono significative per due motivi. In primo luogo, tiene conto del guadagno di calore proveniente dal Sole, poiché la radiazione solare colpisce direttamente parti del satellite. In secondo luogo, è il metodo con cui la navicella spaziale cede calore al freddo dello spazio profondo.\nEsempio: Il calore che senti quando sei esposto al sole è dovuto al trasferimento di calore radiante. Il calore del Sole viaggia attraverso il vuoto dello spazio e ti riscalda tramite radiazioni.\n\n\n\nConvezione\nLa convezione è il trasferimento di calore mediante il movimento fisico di un fluido (come aria o liquido). Implica la circolazione o il movimento delle particelle all’interno del fluido, dove le particelle calde si spostano verso aree più fredde e viceversa.\n\nRilevanza nei test sui veicoli spaziali: sebbene la convezione non sia un meccanismo di trasferimento del calore nel vuoto dello spazio, diventa significativa durante i test sulla Terra dei sistemi dei veicoli spaziali. Qui, la presenza di aria attorno al veicolo spaziale consente il trasferimento di calore convettivo, che può influenzare le prestazioni e i risultati dei test dei sistemi di controllo termico.\nEsempio: Quando si scalda l’acqua in una pentola, l’acqua sul fondo, più vicina alla fonte di calore, diventa calda e sale verso l’alto, mentre l’acqua più fredda scende per sostituirla, creando un movimento circolare. Questo processo di trasferimento del calore attraverso il movimento del fluido è la convezione.\n\nComprendere questi meccanismi di trasferimento del calore è importante per gestire efficacemente l’ambiente termico di un veicolo spaziale. Garantisce che i sistemi di bordo funzionino entro le rispettive tolleranze di temperatura, migliorando così le prestazioni complessive e la longevità del satellite.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#introduzione-alla-modellazione-dinamica",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#introduzione-alla-modellazione-dinamica",
    "title": "Modellazione del sistema",
    "section": "2.1 Introduzione alla modellazione dinamica",
    "text": "2.1 Introduzione alla modellazione dinamica\n\nDefinizione: Spiegare il concetto di modellazione dinamica nei sistemi di controllo.\nImportanza: discutere in che modo la modellazione dinamica aiuta a prevedere il comportamento del sistema nel tempo.\nRappresentazione matematica: introdurre le equazioni differenziali come strumento per la modellazione dinamica.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#fondamenti-matematici",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#fondamenti-matematici",
    "title": "Modellazione del sistema",
    "section": "2.2 Fondamenti matematici",
    "text": "2.2 Fondamenti matematici\n\nEquazioni differenziali: spiegazione dettagliata delle equazioni differenziali nel contesto dei sistemi di controllo.\nEquazioni di bilancio: spiegare le equazioni di bilancio per energia, massa, ecc., nella modellazione di sistemi.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#modello-dinamico-semplificato-di-tclab",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#modello-dinamico-semplificato-di-tclab",
    "title": "Modellazione del sistema",
    "section": "2.3 Modello Dinamico Semplificato di TCLab",
    "text": "2.3 Modello Dinamico Semplificato di TCLab\n\nEquazione: Presenta il modello semplificato di TCLab: \\[\\tau_p \\frac{dT}{dt} = \\left(T_a-T\\right) + K_p \\, Q\\]\nSpiegazione: scomponi l’equazione, spiegando ogni termine in dettaglio.\nInterpretazione fisica: usa metafore, come confrontare il trasferimento di calore con l’acqua che scorre dentro e fuori da un serbatoio, per spiegare il concetto.\n\n[Inserisci qui la rappresentazione grafica]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#concetto-di-risposta-al-gradino",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#concetto-di-risposta-al-gradino",
    "title": "Modellazione del sistema",
    "section": "3.1 Concetto di risposta al gradino",
    "text": "3.1 Concetto di risposta al gradino\n\nDefinizione: spiegare cos’è la risposta al gradino e il suo significato nei sistemi di controllo.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#conduzione-dellesperimento",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#conduzione-dellesperimento",
    "title": "Modellazione del sistema",
    "section": "3.2 Conduzione dell’esperimento",
    "text": "3.2 Conduzione dell’esperimento\n\nObiettivo: dichiara lo scopo dell’esperimento.\nProcedura: guida passo passo per eseguire l’esperimento di risposta al gradino utilizzando TCLab.\nCodice Python per la raccolta dati: include uno script Python per raccogliere dati da TCLab.\n# [Inserisci qui il codice Python per l'esperimento Step Response]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#analisi-dei-dati",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#analisi-dei-dati",
    "title": "Modellazione del sistema",
    "section": "4.1 Analisi dei dati",
    "text": "4.1 Analisi dei dati\n\nTracciamento dei dati: guida sul tracciamento dei dati raccolti utilizzando matplotlib in Python.\nInterpretazione dei risultati: discutere come interpretare i risultati dell’esperimento.\n\n[Inserisci qui un grafico di esempio]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#simulazione-del-sistema",
    "href": "IT_TCLab_🇮🇹/system_model_and_identification_tclab_it.html#simulazione-del-sistema",
    "title": "Modellazione del sistema",
    "section": "4.2 Simulazione del Sistema",
    "text": "4.2 Simulazione del Sistema\n\nObiettivo: Spiegare lo scopo della simulazione del comportamento di TCLab.\nCodice Python per la simulazione: fornisce uno script per simulare la risposta di TCLab utilizzando la funzione odeint o GEKKO.\n# [Inserisci qui il codice Python per la simulazione]\n\n[Inserisci qui il grafico dei risultati della simulazione]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Modellazione del sistema"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html",
    "href": "IT_TCLab_🇮🇹/tclab_it.html",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "",
    "text": "La risorsa principale per TCLab è disponibile su apmonitor.com.\nNelle sezioni successive esploreremo le complessità della modellazione dinamica, comprendendo le risposte del sistema e l’implementazione di varie strategie di controllo.\nIl nostro approccio comporterà l’utilizzo della programmazione Python per interagire con l’hardware TCLab, condurre analisi dei dati e visualizzare in modo efficace i comportamenti del sistema.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#cosè-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#cosè-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Cos’è TCLab?",
    "text": "Cos’è TCLab?\nTCLab è una configurazione da laboratorio compatta che include un microcontrollore Arduino, riscaldatori, sensori di temperatura e un LED. È progettato per apprendere e applicare i principi dell’ingegneria di controllo in modo pratico.\n\nL’hardware del Laboratorio di controllo della temperatura è costituito da cinque componenti:\n\nMicrocontrollore Arduino (Arduino Uno, Arduino Leonardo o equivalenti): funge da cervello della configurazione.\nLa scheda plug-in del Laboratorio di controllo della temperatura (nota anche come scudo). Include:\n\nRiscaldatori: forniscono energia termica al sistema.\nSensori di temperatura: misura la temperatura del sistema.\nLED: indicatore visivo per determinate azioni o stati.\n\nAlimentatore USB da cinque watt.\nCavo di alimentazione da 5,5 mm a USB.\nCavo dati USB 2.0. (con connettore mini-USB per Arduino Uno o cavo micro-USB per Arduino Leonardo.)\n\nPrima di procedere, assicurati di completare i passaggi delineati in Configurazione hardware come descritto in TCLab README.\nGli utenti Mac OS potrebbero dover installare un driver seriale disponibile qui.\nNormalmente lo scudo TCLab sarà già montato sulla scheda Arduino e il driver del firmware sarà stato caricato su Arduino.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#comprendere-il-kit-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#comprendere-il-kit-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Comprendere il kit TCLab",
    "text": "Comprendere il kit TCLab\n\nI componenti principali di TCLab\nIl Temperature Control Lab (TCLab) è un sistema integrato composto da diversi componenti chiave, ciascuno dei quali contribuisce in modo significativo alla sua funzionalità:\n\nMicrocontrollore Arduino:\n\nScopo: Serve come unità di elaborazione centrale per TCLab.\nFunzionalità: elabora i dati di input dai sensori di temperatura e gestisce il funzionamento dei riscaldatori.\nConnettività: utilizza una connessione USB per il trasferimento dei dati e consente il controllo in tempo reale tramite script Python.\n\nRiscaldatori:\n\nDescrizione: TCLab è dotato di due riscaldatori, ciascuno in grado di generare energia termica regolabile.\nRuolo: Agire come principale fonte di calore per gli esperimenti, replicando scenari che richiedono la regolazione della temperatura. Funzionano come gli attuatori del sistema.\n\nSensori di temperatura:\n\nTipo: questi sensori sono termistori, un tipo di resistore la cui resistenza varia con le variazioni di temperatura.\nIntervallo di misurazione: in grado di misurare temperature comprese tra $ -40^$C e \\(150^\\circ\\)C.\nFunzionalità: posizionato vicino a ciascun riscaldatore per misurare con precisione la temperatura, fornendo un feedback essenziale per il controllo della temperatura.\n\nDissipatori di calore:\n\nTipo: Composto da dissipatori di calore a transistor.\nScopo: impiegato per dissipare in modo efficiente il calore lontano dai transistor.\n\nLED (diodo a emissione luminosa):\n\n\nScopo: Serve come indicatore visivo per vari stati o azioni, come segnalare l’attivazione di un riscaldatore.\n\n\n\nConfigurazioni operative di TCLab\nTCLab può essere configurato in varie modalità a seconda degli obiettivi formativi:\n\nIngresso singolo Uscita singola (SISO):\n\nUtilizza solo un riscaldatore e un sensore. Ideale per semplici esperimenti di controllo e per apprendere le basi del controllo della temperatura.\n\nIngresso singolo Uscita singola (SISO) con disturbo:\n\nUtilizza un riscaldatore/sensore come sistema di controllo primario e il secondo riscaldatore come fonte di disturbo esterno. Questa configurazione è utile per comprendere come i fattori esterni influenzano i sistemi di controllo.\n\nIngressi multipli Uscite multiple (MIMO):\n\nImplica l’utilizzo simultaneo di riscaldatori e sensori. Questa configurazione più avanzata non è trattata qui ma è utile per studi di sistemi di controllo complessi.\n\n\nOgni componente del TCLab svolge un ruolo specifico, rendendolo uno strumento versatile per insegnare e sperimentare vari aspetti dell’ingegneria di controllo. Sia per l’apprendimento fondamentale che per l’esplorazione avanzata, TCLab offre una piattaforma pratica per comprendere la dinamica e il controllo dei sistemi basati sulla temperatura.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#come-funziona-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#come-funziona-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Come funziona TCLab",
    "text": "Come funziona TCLab\n\nFlusso operativo:\n\nSegnale di ingresso: uno script Python invia un comando ad Arduino, impostando il livello di potenza desiderato per i riscaldatori.\nAzione di riscaldamento: i riscaldatori generano calore corrispondente ai comandi del livello di potenza ricevuti.\nMisurazione della temperatura: i termistori misurano le temperature risultanti vicino ai riscaldatori.\nCiclo di feedback: queste letture della temperatura vengono inviate al computer.\nRegolazioni: l’algoritmo di controllo nello script Python regola la potenza del riscaldatore in base al feedback della temperatura, cercando di raggiungere e mantenere una temperatura target.\n\n\n[Inserisci qui il diagramma di flusso o il diagramma che mostra il ciclo di feedback]",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#microcontrollore-arduino",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#microcontrollore-arduino",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "2.1 Microcontrollore Arduino",
    "text": "2.1 Microcontrollore Arduino\n\nDescrizione dettagliata: Fornisci dettagli sul modello Arduino utilizzato in TCLab, le sue capacità e i suoi limiti\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObiettivi:\n\nModellazione dinamica con equazioni di bilancio\nLa differenza tra controllo manuale e automatico\nTest di passaggio per generare dati dinamici\nAdattamento dei dati dinamici a un modello First Order Plus Dead Time (FOPDT).\nOttenimento dei parametri per il controllo PID dalle regole di ottimizzazione standard\nOttimizzazione del controller PID per migliorare le prestazioni",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#descrizione-dellhardware-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#descrizione-dellhardware-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Descrizione dell’hardware TCLab",
    "text": "Descrizione dell’hardware TCLab\nIncludere uno schema a blocchi",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#sezione-1-installazione-di-python-utilizzando-conda",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Sezione 1: Installazione di Python utilizzando Conda",
    "text": "Sezione 1: Installazione di Python utilizzando Conda",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-mac",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-mac",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Installazione di Python su Mac",
    "text": "Installazione di Python su Mac\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Mac.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri Terminale.\nDigita “conda –version” e premi Invio. Se Anaconda è stato installato correttamente, vedrai il numero di versione.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-windows",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-windows",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Installazione di Python su Windows",
    "text": "Installazione di Python su Windows\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Windows.\nEsegui il programma di installazione: apri il file scaricato e segui le istruzioni visualizzate sullo schermo.\nVerifica installazione:\n\nApri il prompt di Anaconda.\nDigita “conda –version” e premi Invio.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel prompt di Anaconda, digita “conda create -n tclab_env python=3.8” e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-linux",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#installazione-di-python-su-linux",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "1.3 Installazione di Python su Linux",
    "text": "1.3 Installazione di Python su Linux\n\nPassaggio 1: installa Anaconda\n\nScarica Anaconda: visita la Pagina di download di Anaconda e scarica il programma di installazione per Linux.\nEsegui programma di installazione: apri Terminale, vai alla directory contenente il file scaricato ed esegui lo script utilizzando bash Anaconda3-XXXX.sh.\nVerifica installazione:\n\nNel Terminale, digita “conda –version”.\n\n\n\n\nPassaggio 2: configurazione dell’ambiente (facoltativo)\n\nCrea un nuovo ambiente: nel Terminale, digita conda create -n tclab_env python=3.8 e premi Invio.\nAttiva ambiente: digita “conda activate tclab_env” e premi Invio.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#configurazione-dellambiente-conda",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#configurazione-dellambiente-conda",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Configurazione dell’ambiente Conda",
    "text": "Configurazione dell’ambiente Conda\nPer configurare l’ambiente Conda per questo corso, attenersi alla seguente procedura:\n\nScarica il file tclab_environment.yml da questo repository.\nApri il terminale o il prompt di Anaconda e vai alla directory in cui si trova il file.\n\nIl file tclab_environment.yml assomiglia a questo:\nnome: tclab_env\ncanali:\n  - valori predefiniti\ndipendenze:\n  - pitone=3.10\n  - pip\n  - insensato\n  - matplotlib\n  - scipito\n  - panda\n  - pip:\n    -tclab\n\nCrea l’ambiente dal file tclab_environment.yml:\nconda env create -f tclab_environment.yml\nAttiva il nuovo ambiente:\nconda attiva tclab\nPer verificare che l’ambiente sia stato installato correttamente, è possibile utilizzare:\nconda env list\n\n\nInstallazione del pacchetto TCLab\n\nAttivazione dell’ambiente:\n\nAssicurati che il tuo ambiente Anaconda sia attivo. Apri il tuo Terminale (o il prompt di Anaconda su Windows) e attiva il tuo ambiente:\nconda attiva tclab_env\n\nInstallazione di TCLab:\n\nLa libreria tclab è fondamentale per l’interfacciamento con l’hardware del Laboratorio di controllo della temperatura. Installalo inserendo il seguente comando:\npip installa tclab\nPremi Invio per eseguire il comando e completare l’installazione.\n\n\n\nInstallazione di librerie utili aggiuntive\nPer un’esperienza completa con TCLab e per supportare vari aspetti dell’ingegneria di controllo e dell’analisi dei dati, verranno installate anche le seguenti librerie:\n\ninsensibile:\n\nSignificato: una libreria fondamentale per i calcoli numerici in Python.\nComando di installazione:\npip installa numpy\n\nmatplotlib:\n\nSignificato: fondamentale per creare rappresentazioni visive dei dati, in particolare per l’analisi degli esperimenti TCLab.\nComando di installazione:\npip installa matplotlib\n\nscipy:\n\nSignificato: fornisce un’ampia gamma di strumenti per il calcolo scientifico, compresi metodi per risolvere equazioni differenziali ordinarie, utili nella modellizzazione dei sistemi.\nComando di installazione:\npip installa scipy\n\npanda:\n\nSignificato: offre funzionalità estese per la manipolazione e l’analisi dei dati, ideali per la gestione di set di dati complessi.\nComando di installazione:\npip installa panda\n\ngeco:\n\nSignificatività: pacchetto avanzato per l’ottimizzazione e il controllo, adatto all’implementazione di strategie di controllo predittivo del modello.\nComando di installazione:\npip installa gekko",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#schemi-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#schemi-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Schemi TCLab",
    "text": "Schemi TCLab",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#test-iniziali-con-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#test-iniziali-con-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Test iniziali con TCLab",
    "text": "Test iniziali con TCLab\n\nPassaggio 1: collega TCLab\n\nConnetti TCLab: collega il dispositivo TCLab al computer utilizzando un cavo USB.\n\n\n\nPassaggio 2: testare la connessione TCLab\n\nScrivi script di prova:\n\nApri il tuo IDE Python o Jupyter Notebook.\nScrivi il seguente codice Python ed esegui lo script. Se stampa la temperatura, TCLab è collegato correttamente.\n\n\n\nimport tclab\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")\n\nTCLab version 1.0.0\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\n\n\nRuntimeError: No Arduino device found.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_it.html#utilizzo-del-simulatore-tclab",
    "href": "IT_TCLab_🇮🇹/tclab_it.html#utilizzo-del-simulatore-tclab",
    "title": "Il Laboratorio di Controllo della Temperatura",
    "section": "Utilizzo del simulatore TCLab",
    "text": "Utilizzo del simulatore TCLab\n\nPerché utilizzare un simulatore: il simulatore TCLab è utile quando non si dispone dell’hardware fisico.\nInstalla simulatore: nel terminale o nel prompt di Anaconda, digita nuovamente pip install tclab (include il simulatore).\nScript di prova con simulatore:\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.04 seconds. T1: 20.949499999999997°C\nTime 6.03 seconds. T1: 20.949499999999997°C\nTime 8.06 seconds. T1: 20.949499999999997°C\nTime 10.07 seconds. T1: 20.949499999999997°C\nTime 12.02 seconds. T1: 20.949499999999997°C\nTime 14.03 seconds. T1: 20.949499999999997°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.04 seconds. T1: 20.949499999999997°C\nTime 20.2 seconds. T1: 20.949499999999997°C\nTime 22.01 seconds. T1: 20.949499999999997°C\nTime 24.19 seconds. T1: 20.949499999999997°C\nTime 26.24 seconds. T1: 20.949499999999997°C\nTime 28.16 seconds. T1: 20.949499999999997°C\nTime 30.03 seconds. T1: 20.949499999999997°C\nTime 32.12 seconds. T1: 20.949499999999997°C\nTime 34.2 seconds. T1: 20.6272°C\nTime 36.04 seconds. T1: 20.949499999999997°C\nTime 38.02 seconds. T1: 20.6272°C\nTime 40.21 seconds. T1: 20.949499999999997°C\nTime 42.14 seconds. T1: 20.949499999999997°C\nTime 44.01 seconds. T1: 20.6272°C\nTime 46.3 seconds. T1: 20.949499999999997°C\nTime 48.22 seconds. T1: 20.949499999999997°C\nTime 50.07 seconds. T1: 20.949499999999997°C\nTime 52.27 seconds. T1: 20.949499999999997°C\nTime 54.09 seconds. T1: 20.949499999999997°C\nTime 56.28 seconds. T1: 20.949499999999997°C\nTime 58.19 seconds. T1: 20.949499999999997°C\nTime 60.04 seconds. T1: 20.949499999999997°C\nTime 62.2 seconds. T1: 20.949499999999997°C\nTime 64.11 seconds. T1: 20.949499999999997°C\nTime 66.08 seconds. T1: 20.949499999999997°C\nTime 68.23 seconds. T1: 20.6272°C\nTime 70.13 seconds. T1: 20.949499999999997°C\nTime 72.07 seconds. T1: 20.949499999999997°C\nTime 74.05 seconds. T1: 20.949499999999997°C\nTime 76.1 seconds. T1: 20.6272°C\nTime 78.1 seconds. T1: 20.6272°C\nTime 80.22 seconds. T1: 20.949499999999997°C\nTime 82.28 seconds. T1: 20.949499999999997°C\nTime 84.22 seconds. T1: 20.949499999999997°C\nTime 86.16 seconds. T1: 20.949499999999997°C\nTime 88.23 seconds. T1: 20.949499999999997°C\nTime 90.0 seconds. T1: 20.949499999999997°C\nTime 92.27 seconds. T1: 20.949499999999997°C\nTime 94.0 seconds. T1: 20.949499999999997°C\nTime 96.16 seconds. T1: 20.949499999999997°C\nTime 98.02 seconds. T1: 20.949499999999997°C\nTime 100.1 seconds. T1: 20.949499999999997°C\nTime 102.24 seconds. T1: 20.949499999999997°C\nTime 104.0 seconds. T1: 20.6272°C\nTime 106.18 seconds. T1: 20.949499999999997°C\nTime 108.27 seconds. T1: 20.949499999999997°C\nTime 110.27 seconds. T1: 20.949499999999997°C\nTime 112.1 seconds. T1: 20.949499999999997°C\nTime 114.22 seconds. T1: 20.949499999999997°C\nTime 116.24 seconds. T1: 20.949499999999997°C\nTime 118.18 seconds. T1: 20.949499999999997°C\nTime 120.19 seconds. T1: 20.949499999999997°C\nTime 122.06 seconds. T1: 20.949499999999997°C\nTime 124.22 seconds. T1: 20.6272°C\nTime 126.19 seconds. T1: 20.949499999999997°C\nTime 128.18 seconds. T1: 20.949499999999997°C\nTime 130.25 seconds. T1: 20.949499999999997°C\nTime 132.02 seconds. T1: 20.6272°C\nTime 134.2 seconds. T1: 20.949499999999997°C\nTime 136.27 seconds. T1: 20.949499999999997°C\nTime 138.01 seconds. T1: 20.6272°C\nTime 140.2 seconds. T1: 20.949499999999997°C\nTime 142.18 seconds. T1: 20.949499999999997°C\nTime 144.2 seconds. T1: 20.949499999999997°C\nTime 146.23 seconds. T1: 20.949499999999997°C\nTime 148.24 seconds. T1: 20.949499999999997°C\nTime 150.19 seconds. T1: 20.949499999999997°C\nTime 152.28 seconds. T1: 20.949499999999997°C\nTime 154.25 seconds. T1: 20.949499999999997°C\nTime 156.23 seconds. T1: 20.6272°C\nTime 158.04 seconds. T1: 20.949499999999997°C\nTime 160.11 seconds. T1: 20.949499999999997°C\nTime 162.04 seconds. T1: 20.949499999999997°C\nTime 164.05 seconds. T1: 20.949499999999997°C\nTime 166.01 seconds. T1: 20.949499999999997°C\nTime 168.23 seconds. T1: 20.6272°C\nTime 170.08 seconds. T1: 20.949499999999997°C\nTime 172.01 seconds. T1: 20.949499999999997°C\nTime 174.14 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.22 seconds. T1: 20.949499999999997°C\nTime 180.2 seconds. T1: 20.949499999999997°C\nTime 182.2 seconds. T1: 20.949499999999997°C\nTime 184.21 seconds. T1: 20.949499999999997°C\nTime 186.08 seconds. T1: 20.949499999999997°C\nTime 188.29 seconds. T1: 20.949499999999997°C\nTime 190.24 seconds. T1: 20.949499999999997°C\nTime 192.18 seconds. T1: 20.949499999999997°C\nTime 194.09 seconds. T1: 20.949499999999997°C\nTime 196.22 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.02 seconds. T1: 20.6272°C\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Il Laboratorio di Controllo della Temperatura"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html",
    "title": "Compito di laboratorio 4: Controllo PI",
    "section": "",
    "text": "Data una variabile di processo \\(PV\\) e un setpoint \\(SP\\), il controllo proporzionale-integrale-derivativo determina il valore di una variabile manipolata MV mediante l’equazione\n\\[\\begin{align}\nMV & = \\bar{MV} + k_p\\left(SP - PV\\right) + k_i \\int_0^t \\left(SP-PV)\\right)dt\n\\end{align}\\]\ndove \\(k_p\\) e \\(k_i\\) sono rispettivamente il coefficiente proporzionale e quello integrale. Il valore \\(\\bar{MV}\\) è un valore nominale o iniziale della variabile manipolata.\nL’effettiva implementazione del controllo PI viene normalmente eseguita calcolando quanto \\(MV\\) dovrebbe cambiare in ogni fase temporale. Definire l’errore al momento \\(k\\) come\n\\[\\begin{align}\ne_k & = SP_k - PV_k\n\\end{align}\\]\nquindi i valori consecutivi di \\(MV\\) sono dati da\n\\[\\begin{align}\nMV_{k-1} & = \\bar{MV} + k_p e_{k-1} + k_i \\sum_{j=0}^{k-1} e_{j} \\\\\nMV_{k} & = \\bar{MV} + k_p e_{k} + k_i \\sum_{j=0}^{k} e_{j}\n\\end{align}\\]\nPrendendo le differenze si ottiene una formula pratica per aggiornare il valore di \\(MV\\) in risposta alle misurazioni\n\\[\\begin{align}\nMV_{k} & = MV_{k-1} + k_p(e_{k} - e_{k-1}) + k_i e_{k}\n\\end{align}\\]\nIl codice seguente definisce un oggetto Python che implementa questo algoritmo.\n\nclass PI:\n    def __init__(self, kp=1, ki=0, MV=0):\n        self.kp = kp\n        self.ki = ki\n        self.e_prev = 0\n        self.MV = MV\n\n    def update(self, SP, PV):\n        e = SP - PV\n        self.e = e\n        self.MV += self.kp * (e - self.e_prev) + self.ki * e\n        self.MV = max(0, min(100, self.MV))\n        self.e_prev = e\n        return self.MV",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio 4: Controllo PI"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#implementazione-di-un-semplice-controller-pi",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#implementazione-di-un-semplice-controller-pi",
    "title": "Compito di laboratorio 4: Controllo PI",
    "section": "",
    "text": "Data una variabile di processo \\(PV\\) e un setpoint \\(SP\\), il controllo proporzionale-integrale-derivativo determina il valore di una variabile manipolata MV mediante l’equazione\n\\[\\begin{align}\nMV & = \\bar{MV} + k_p\\left(SP - PV\\right) + k_i \\int_0^t \\left(SP-PV)\\right)dt\n\\end{align}\\]\ndove \\(k_p\\) e \\(k_i\\) sono rispettivamente il coefficiente proporzionale e quello integrale. Il valore \\(\\bar{MV}\\) è un valore nominale o iniziale della variabile manipolata.\nL’effettiva implementazione del controllo PI viene normalmente eseguita calcolando quanto \\(MV\\) dovrebbe cambiare in ogni fase temporale. Definire l’errore al momento \\(k\\) come\n\\[\\begin{align}\ne_k & = SP_k - PV_k\n\\end{align}\\]\nquindi i valori consecutivi di \\(MV\\) sono dati da\n\\[\\begin{align}\nMV_{k-1} & = \\bar{MV} + k_p e_{k-1} + k_i \\sum_{j=0}^{k-1} e_{j} \\\\\nMV_{k} & = \\bar{MV} + k_p e_{k} + k_i \\sum_{j=0}^{k} e_{j}\n\\end{align}\\]\nPrendendo le differenze si ottiene una formula pratica per aggiornare il valore di \\(MV\\) in risposta alle misurazioni\n\\[\\begin{align}\nMV_{k} & = MV_{k-1} + k_p(e_{k} - e_{k-1}) + k_i e_{k}\n\\end{align}\\]\nIl codice seguente definisce un oggetto Python che implementa questo algoritmo.\n\nclass PI:\n    def __init__(self, kp=1, ki=0, MV=0):\n        self.kp = kp\n        self.ki = ki\n        self.e_prev = 0\n        self.MV = MV\n\n    def update(self, SP, PV):\n        e = SP - PV\n        self.e = e\n        self.MV += self.kp * (e - self.e_prev) + self.ki * e\n        self.MV = max(0, min(100, self.MV))\n        self.e_prev = e\n        return self.MV",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio 4: Controllo PI"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-1.-eseguire-il-tuning-del-controllore-pi-per-il-laboratorio-di-controllo-della-temperatura",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-1.-eseguire-il-tuning-del-controllore-pi-per-il-laboratorio-di-controllo-della-temperatura",
    "title": "Compito di laboratorio 4: Controllo PI",
    "section": "Esercizio 1. Eseguire il tuning del controllore PI per il laboratorio di controllo della temperatura",
    "text": "Esercizio 1. Eseguire il tuning del controllore PI per il laboratorio di controllo della temperatura\nLa cella seguente fornisce un’implementazione iniziale del controllo PI per il riscaldatore T1. Questo è configurato per testare con la modalità di simulazione offline di tclab. Sperimenta la simulazione per trovare i valori appropriati per \\(k_p\\) e \\(k_i\\). L’obiettivo della progettazione è raggiungere il setpoint e rimanere all’interno di una zona di +/- 2 gradi il più rapidamente possibile.\n\nfrom tclab import setup, clock, Historian, Plotter\n\nTCLab = setup(connected=False, speedup = 20)\n\npi = PI(kp=2, ki=0.1)\nSP = 50\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 800)\n    for t in clock(800):\n        PV = lab.T1               # measure the the process variable\n        MV = pi.update(SP, PV)    # PI control to determine the MV\n        lab.Q1(MV)                # set the heater power\n        p.update(t)               # log data\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio 4: Controllo PI"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-2.-test-hardware-del-controller-pi",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-2.-test-hardware-del-controller-pi",
    "title": "Compito di laboratorio 4: Controllo PI",
    "section": "Esercizio 2. Test hardware del controller PI",
    "text": "Esercizio 2. Test hardware del controller PI\n\nCopia e incolla il codice sopra nella cella sottostante. Collega il codice all’hardware tclab modificando ‘connesso’ a ‘Vero’. Regola l’orizzonte dell’esperimento su 1200 secondi per avere tutto il tempo necessario per i test.\nMetti alla prova il tuo controller. Le prestazioni corrispondono alla simulazione?\nDopo che il controller ha raggiunto il setpoint, introdurre un disturbo. Un esempio di disturbo potrebbe essere aumentare il flusso d’aria attorno al dispositivo o toccare il riscaldatore con qualcosa di termicamente conduttivo (fai attenzione, non usare le dita. 50 gradi C sono abbastanza caldi da bruciare la pelle).\nAggiungi una cella di testo qui sotto e commenta i tuoi risultati. Vedete delle carenze in questa implementazione del controllo?\n\n\n# put your code here\n\nScrivi i tuoi commenti in questa cella.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio 4: Controllo PI"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-3.-controllo-pi-multivariabile",
    "href": "IT_TCLab_🇮🇹/lab-assignment-pi-control_it.html#esercizio-3.-controllo-pi-multivariabile",
    "title": "Compito di laboratorio 4: Controllo PI",
    "section": "Esercizio 3. Controllo PI multivariabile",
    "text": "Esercizio 3. Controllo PI multivariabile\nL’esercizio successivo consiste nell’estendere il sistema per controllare entrambi i riscaldatori. Non avrai abbastanza tempo in laboratorio per farlo sperimentalmente, quindi esegui questo esercizio utilizzando la modalità di simulazione di tclab.\n\nCopia e incolla il codice dell’esercizio 1 nella cella sottostante.\nAggiungi un secondo controller PI (rinomina il primo pi_1 e chiama il secondo pi_2, ad esempio). Regolare il setpoint per il primo riscaldatore a 40 gradi C e il secondo a 35 gradi C. Sintonizzare i controller per ottenere una rapida acquisizione dei setpoint.\n\n\n# put your code here",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "Compito di laboratorio 4: Controllo PI"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "",
    "text": "Per questa sessione di laboratorio raccoglierai dati da un esperimento di step test, quindi adatterai i dati a modelli derivati ​​dai bilanci energetici dei principi primi. Adattare i modelli ai dati è un’abilità ingegneristica che collega il mondo reale dei sistemi ingegneristici alla teoria appresa in classe.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-1.-verificare-il-funzionamento-del-laboratorio-di-controllo-della-temperatura.",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-1.-verificare-il-funzionamento-del-laboratorio-di-controllo-della-temperatura.",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "Esercizio 1. Verificare il funzionamento del laboratorio di controllo della temperatura.",
    "text": "Esercizio 1. Verificare il funzionamento del laboratorio di controllo della temperatura.\nEseguire la cella seguente per verificare di disporre di una connessione funzionante all’hardware del laboratorio di controllo della temperatura. Questo testerà l’installazione di TCLab.py, la connessione al dispositivo Arduino e il firmware funzionante all’interno di Arduino.\n\nfrom tclab import TCLab, clock, Historian, Plotter\n\nlab = TCLab()\nprint(\"TCLab Temperatures:\", lab.T1, lab.T2)\nlab.close()",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-2.-verifica-dello-stato-stazionario",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-2.-verifica-dello-stato-stazionario",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "Esercizio 2. Verifica dello stato stazionario",
    "text": "Esercizio 2. Verifica dello stato stazionario\nCome discusso in classe, per un buon adattamento del modello è essenziale che l’hardware TCLab sia allo stato stazionario prima di procedere con lo step test. Eseguire il codice seguente per verificare che i riscaldatori siano spenti e che le temperature siano a una temperatura ambiente costante.\n\n# experimental parameters\ntfinal = 30\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    for t in clock(tfinal):\n        p.update(t)",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-3.-prova-a-passi.",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-3.-prova-a-passi.",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "Esercizio 3. Prova a passi.",
    "text": "Esercizio 3. Prova a passi.\nIl test a gradini consiste nell’accendere un riscaldatore al 50% della potenza e registrare i dati di temperatura per almeno 800 secondi. Copia e incolla il codice dell’esercizio 2 nella cella seguente, quindi modificalo secondo necessità per eseguire lo step test.\n\n# write your code here",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-4.-verifica-e-salva-i-dati-in-un-file-.csv",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-4.-verifica-e-salva-i-dati-in-un-file-.csv",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "Esercizio 4. Verifica e salva i dati in un file .csv",
    "text": "Esercizio 4. Verifica e salva i dati in un file .csv\nEsegui la cella seguente per verificare e salvare i tuoi dati in un file “.csv”. Assicurati di poter trovare e localizzare i dati sul tuo laptop prima di lasciare il laboratorio. Avrai bisogno di accedere a questi dati per gli esercizi successivi.\n\nimport matplotlib.pyplot as plt\n\nt, T1, T2, Q1, Q2 = h.fields\n\nplt.plot(t, T1, t, T2, t, Q1, t, Q2)\nplt.legend(['T1','T2','Q1','Q2'])\nplt.xlabel('Time / seconds')\nplt.grid()\n\nh.to_csv('tclab-data.csv')",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-5.-analisi",
    "href": "IT_TCLab_🇮🇹/tclab_lab_2_model_identification_it.html#esercizio-5.-analisi",
    "title": "TCLab Lab 2: Identificazione del modello",
    "section": "Esercizio 5. Analisi",
    "text": "Esercizio 5. Analisi\n1.) Approssimando i risultati dello step test per T1 come funzione di trasferimento del primo ordine, stimare la costante di tempo e il guadagno. Scrivi la tua risposta nella cella seguente.\n\n# write your code here\n\n2.) Come abbiamo discusso in classe, un semplice modello di bilancio energetico per T1 è dato da\n\\[C_p \\frac{dT_1}{dt} = U_a(T_{amb} - T_1) + P Q_1\\]\ndove il parametro \\(P\\) è stato determinato, con mezzi indipendenti, come un aumento percentuale di 0.04 watt in \\(Q_1\\). Utilizza i risultati di questo esperimento per stimare i valori di \\(C_p\\) e \\(U_a\\). Scrivi le tue risposte nella cella seguente.",
    "crumbs": [
      "IT_TCLab_🇮🇹",
      "TCLab Lab 2: Identificazione del modello"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html",
    "href": "feedback_system_performance_based_on_frequency_response.html",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "",
    "text": "In our final phase of discussion, we delve into the design aspects of control systems within the frequency domain. Our focus is to understand how a system can be represented and characterized in this domain. The upcoming lectures will lay out the design algorithms essential for frequency domain analysis.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#representing-and-characterizing-a-system-in-frequency-domain",
    "href": "feedback_system_performance_based_on_frequency_response.html#representing-and-characterizing-a-system-in-frequency-domain",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Representing and Characterizing a System in Frequency Domain",
    "text": "Representing and Characterizing a System in Frequency Domain\nTo begin with, it’s important to understand what we mean by the “frequency domain.” Unlike the time domain, where we analyze systems based on their response over time, the frequency domain focuses on how systems respond to different frequencies. This is important in control systems, especially for analyzing how systems behave under various sinusoidal inputs.\nConsider a feedback system with an open-loop transfer function in the forward path, denoted as \\(G(s)\\), and a sensor or feedback path transfer function, \\(H(s)\\). The closed-loop transfer function \\(M(s)\\) is given by:\n\\[ M(s) = \\frac{G(s)}{1 + G(s)H(s)} \\]\n\n\n\n\n\n\n\nTo analyze these transfer functions in the frequency domain, we replace the Laplace variable $ s $ with $ j$. Thus, our closed-loop transfer function in the frequency domain becomes:\n\\[ M(j\\omega) = \\frac{G(j\\omega)}{1 + G(j\\omega)H(j\\omega)} \\]\nAs frequency varies from 0 to infinity, understanding the behavior of the closed-loop system requires evaluating the magnitude and phase angle of \\(M(j\\omega)\\).\nIn other words, I know the behavior of the closed-loop system if I am able to evaluate the magnitude and phase angle of \\(M(j\\omega)\\).\n\nFrequency Response\nWhen analyzing control systems, one key concept is the open-loop frequency response \\(G(j\\omega)H(j\\omega)\\), which appears in the closed loop transfer function. This response is particularly important as it provides foundational information about the system’s behavior without the influence of a feedback loop.\nLet’s break this down:\n\nOpen-Loop Frequency Response: This refers to how the system, consisting of the sensor and the plant, responds to different frequencies when there is no feedback applied. Essentially, it’s the system’s natural behavior in response to inputs.\nSignificance: The reason we focus on the open-loop frequency response is because it offers valuable insights into the inherent characteristics of the system. By understanding the system’s response in an open-loop state, we can make informed predictions about how it will behave once we introduce a feedback loop (i.e., in a closed-loop configuration).\n\nTo sum up, the open-loop frequency response, which includes the combined effect of the sensor and the plant (denoted as $ GH $), is a critical piece of information. It can be derived either from a theoretical model of the sensor and plant or through experimental methods to measure how the system responds to various frequencies in an open-loop state.\n\n\nFrom Open-Loop to Closed-Loop\nLet’s explore a critical aspect of control systems: determining the closed-loop behavior from the open-loop frequency response data. This task, while seemingly straightforward, actually poses a complex question that needs careful analysis.\nHere’s the process broken down:\n\nClosed-Loop Behavior Analysis: Our goal is to understand how the system behaves when feedback is applied. This is known as the closed-loop behavior.\nUsing Open-Loop Data: We start with what we know - the open-loop frequency response. This is the response of the system without feedback, as discussed earlier.\nTransitioning to Closed-Loop: To analyze the closed-loop behavior, we apply the open-loop frequency response data into the closed-loop transfer function formula. This is a mathematical approach that integrates the open-loop data into a framework that considers feedback.\nUnderstanding the Outcome: By applying the open-loop data to the closed-loop formula, we can calculate important aspects like the magnitude and phase angle of the closed-loop transfer function, denoted as $ M $. These calculations give us a clear picture of how the feedback alters the system’s response.\n\nIn summary, to grasp the closed-loop behavior, we need to effectively translate our understanding of the open-loop system (the system without feedback) into the closed-loop context (the system with feedback). This translation is done through the closed-loop transfer function formula, utilizing the open-loop frequency response data as our starting point.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#ideal-low-pass-filter-characteristics-in-control-systems",
    "href": "feedback_system_performance_based_on_frequency_response.html#ideal-low-pass-filter-characteristics-in-control-systems",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Ideal Low-Pass Filter Characteristics in Control Systems",
    "text": "Ideal Low-Pass Filter Characteristics in Control Systems\nIn control systems, the concept of a low-pass filter is essential. Let’s unpack this idea to understand its role and functionality better.\n\nWhat is a Low-Pass Filter?\n\nA low-pass filter is a type of system that allows signals with frequencies below a certain threshold (known as the cutoff frequency) to pass through it without attenuation.\nSignals with frequencies above this cutoff frequency are significantly weakened or attenuated.\nThis characteristic makes low-pass filters ideal for blocking out unwanted high-frequency noise while permitting lower-frequency signals to pass through.\n\nUnderstanding the Cutoff Frequency (\\(\\omega_c\\))\n\nThe cutoff frequency, denoted as \\(\\omega_c\\), is a critical point in a low-pass filter. It determines the threshold between the frequencies that are allowed to pass and those that are attenuated.\nUp to this frequency, the filter maintains a constant gain, which we often consider as unity (or no change to the signal strength).\nBeyond \\(\\omega_c\\), the filter sharply reduces the gain, effectively filtering out higher frequencies.\n\nIdeal Characteristics of a Low-Pass Filter\n\nIn an ideal low-pass filter, this transition from unity gain to zero gain at the cutoff frequency is abrupt and distinct.\nThis ideal behavior is highly sought after in many control systems, especially in scenarios where filtering out high-frequency noise is crucial while maintaining the integrity of lower-frequency signals.\n\nApplication in Control Systems\n\nThe low-pass filter finds its utility in various control systems where it’s essential to preserve low-frequency signals (like actual system inputs or commands) while eliminating high-frequency disturbances (like electronic noise or irrelevant rapid fluctuations)\n\n\n\n\n\n\n\n\n\nUnderstanding the role of low-pass filters in control systems is important. Let’s delve into why low-pass characteristics are particularly suited for control systems.\n\nLow-Pass Filter Characteristics in Control Systems\n\nIdeal Low-Pass Filter: The ideal characteristic of a low-pass filter is a perfect fit for many control systems. This characteristic involves allowing low-frequency signals to pass unaltered while blocking or attenuating high-frequency signals.\nRelevance to Control Systems: Control systems often deal with signals in the low-frequency range, which are the primary signals of interest, such as control commands or system inputs.\nNoise Filtering: High-frequency components in the signal usually represent noise or unwanted disturbances. A low-pass filter’s ability to filter out these high-frequency components is crucial for maintaining the integrity and performance of the control system.\n\nPractical Application in Control Systems\n\nReal-World Scenario: In practice, control systems often exhibit low-pass filter behavior, though they might not perfectly match the ideal characteristics of an ideal low-pass filter.\nFunctionality: These systems are designed to let through low-frequency signals — the useful part of the signal — while reducing the impact of high-frequency noise. This ensures that the control system responds primarily to actual control inputs rather than being disrupted by noise.\n\nDesigning Control Systems with Low-Pass Characteristics\n\nWhen designing a control system in the frequency domain, one of the key objectives is to imbue it with low-pass characteristics. This ensures that the system performs effectively by focusing on the low-frequency range signals while filtering out high-frequency noise.\n\n\nIn summary, low-pass filters are an integral concept in control systems, aligning with the primary goal of these systems to respond to relevant low-frequency signals while filtering out undesirable high-frequency noise.\nControl systems often exhibit low-pass filter characteristics, filtering out high-frequency noise while preserving the low-frequency signals that are of interest.\nIdeally, a low-pass filter would have a flat gain up to a certain cut-off frequency \\(\\omega_c\\), beyond which the gain sharply drops to zero. However, such an ideal characteristic is not realizable in practice.\n\nTypical Frequency Response of a Feedback Control System\nIn practice, an ideal low-pass filter is not realizable. Control systems tend to have a more gradual decline in gain beyond the cutoff frequency.\n\n\n\n\n\n\n\nFigure: A more realistic low-pass filter characteristic showing a gradual decline in gain.\n\nCharacteristic Curve of a Feedback System\n\nResonant Frequency and Peak:\n\nIn a practical feedback control system, the frequency response curve exhibits a unique feature known as the resonant frequency. This is the frequency at which the system’s response (or gain) reaches its maximum.\nAccompanying the resonant frequency is the resonant peak, which is the actual magnitude of this maximum response. This peak is indicative of the system’s most pronounced response to a particular frequency.\n\nGradual Decline Beyond Resonant Frequency:\n\nUnlike an ideal low-pass filter with a sharp cutoff, real-world control systems typically show a more gradual decline in gain beyond the resonant frequency.\nThis means that instead of a sudden drop to zero gain past a certain frequency, practical systems slowly attenuate the signal as the frequency increases beyond the resonant point.\n\n\n\n\n\nUnderstanding Bandwidth in Control Systems\n\nBandwidth Defined:\n\nBandwidth ($ _b $) refers to the range of frequencies over which a control system maintains a consistent gain, close to its maximum value.\nThis range is crucial because it determines the frequencies at which the system operates most effectively.\n\nSetting the Cutoff Frequency:\n\nDetermining the exact point for the cutoff frequency can be challenging (see Figure above). However, in control systems, we often define the bandwidth as the frequency range where the system’s gain remains near unity.\nThe cutoff frequency, in this case, is where the gain drops to $ $ of the unity value. This point marks the transition from the system’s effective operational range to where it begins attenuating the signal.\nWe select the unity value and not the peak, because a unity value at all frequencies would be the ideal value. It would correspond to perfect tracking to any input.\n\nSignificance of Bandwidth:\n\nWithin the bandwidth, the system performs optimally, processing signals with minimal attenuation. This is the frequency range where the system’s gain is almost flat, signifying stable and effective signal handling.\nBeyond the bandwidth, the system’s gain starts to decrease, indicating the start of signal attenuation. This characteristic is crucial for filtering out unwanted high-frequency signals while maintaining fidelity for signals within the bandwidth.\n\nPractical Application:\n\nIn real-world scenarios, control systems are designed to have a specific bandwidth that aligns with the frequency range of the signals they are intended to manage or control.\nBy understanding and setting the appropriate bandwidth, engineers can ensure that the system responds accurately to the relevant frequencies while filtering out undesirable noise or disturbances.\n\n\nThe bandwidth ($ _b $) in control systems is a critical parameter that defines the range of frequencies over which the system can effectively process signals with near-unity gain. Beyond this range, the system’s efficiency in handling signals decreases, making bandwidth a vital factor in system design and performance analysis.\n\nBandwidth and System Performance\nThere is not clear cut-off frequency and for this reason,\n\nDefining Bandwidth (\\(\\omega_b\\)):\n\nBandwidth is a critical concept in control systems. It is defined based on the frequency range over which the system maintains a near-unity gain, effectively processing the signals.\nTechnically, the bandwidth (\\(\\omega_b\\)) is the frequency at which the system’s gain drops to \\(\\frac{1}{\\sqrt{2}}\\) of the maximum (or unity) gain. This point is crucial because it marks the beginning of the system’s attenuation phase for higher frequencies.\n\nPractical Implications:\n\nThe bandwidth helps in understanding how wide a range of frequencies the system can handle effectively. Within this range, the system performs optimally, maintaining a steady gain.\nBeyond the bandwidth, the system’s ability to process signals diminishes, which is vital for designing control systems that need to filter out unwanted high-frequency signals.\n\n\nIn summary, the frequency response of a typical feedback control system is characterized by its resonant frequency and peak, followed by a gradual reduction in gain beyond this point. The bandwidth of the system, a key performance indicator, defines the range of frequencies over which the system maintains effective control and signal processing capabilities.\n\n\n\nQuantifying System Performance\n\n**Large Bandwidth ($ _b $)**: Desirable for good tracking performance and low rise time. It means that the system gain is as large as possible for a range of frequencies, improving tracking performance and speed of response.\nResonant Peak ($ M_r $): Should not be too high to ensure the flat gain requirement is met.\nLimitations: Factors like noise characteristics and saturation risk limit the achievable bandwidth. High bandwidth means that noise might be entering the loop. Knowing the sensor characteristics means knowing the maximum bandwidth that we can support, even if that might mean trading off tracking accuracy. Large bandwidth also means large gains and hence possibly saturation. With reference to the equation below, \\(M(j\\omega)=1\\) (large bandwidth in a large range of frequency) only when \\(G(j\\omega) \\rightarrow \\infty\\):\n\n\\[ M(j\\omega) = \\frac{G(j\\omega)}{1 + G(j\\omega)H(j\\omega)} = 1 \\Rightarrow G(j\\omega) \\rightarrow \\infty\\]\n\n\nQuantifying Control System Behavior\n\nFrequency Response Characteristics:\n\nTo fully grasp a control system’s behavior, we examine its frequency response. This involves understanding how the system reacts across a range of frequencies.\n\nClosed-Loop vs. Open-Loop Frequency Response:\n\nIt’s important to note that the frequency response we refer to here is the closed-loop response, though initially, we have access to open-loop frequency data. This means that to construct a closed-loop frequency response graph, we need to process the open-loop data accordingly.\n\n\n\nCharacterizing Parameters of Frequency Response\n\nResonant Frequency (\\(\\omega_r\\)):\n\nThis is the frequency at which the system’s response reaches its maximum. It’s a critical point in understanding system behavior.\n\nResonant Peak (M_r):\n\n$ M_r $ is the magnitude of the system’s response at the resonant frequency. It should ideally not be too high to ensure a stable system response.\n\nBandwidth (\\(\\omega_b\\)):\n\nThe bandwidth is defined as the frequency range where the system’s response (or gain) is near its maximum. Beyond this range, the system starts attenuating signals.\n\nRise Time and Bandwidth:\n\nBoth \\(\\omega_r\\) and \\(\\omega_b\\) are linked to the system’s rise time. A shorter rise time requires larger values of \\(\\omega_r\\) and \\(\\omega_b\\).\n\n\n\n\nAdditional Indices for System Characterization\n\nPhase Margin and Gain Margin:\n\nThese are derived from the open-loop frequency response and are indicative of the system’s relative stability in closed-loop.\nThe phase margin (\\(\\phi\\)) is measured with respect to the negative real axis, and a positive phase margin suggests stability.\nThe gain margin, calculated as \\(\\frac{1}{a}\\), also gives an indication of system stability.\n\n\n\n\n\n\n\n\n\n\n\nComprehensive System Characterization\n\nTime Domain vs. Frequency Domain:\n\nWhile we can characterize a system in the frequency domain using indices like \\(\\omega_r\\), \\(M_r\\), \\(\\omega_b\\), gain margin, and phase margin, it’s also crucial to understand their impact in the time domain.\nThe time domain perspective gives us insights into how the system responds to inputs like step changes and how it deals with transient errors.\n\nLinking Time Domain and Frequency Domain:\n\nThe real challenge in system design is to correlate these two domains. This correlation is crucial for leveraging the simplicity of frequency domain design and the intuitive understanding from the time domain.\nAlthough theoretically, time domain behavior and frequency domain behavior are linked via Fourier transform, practically, this transformation can be complex. Therefore, we often rely on simulations and approximations to make this correlation more manageable.\n\n\n\n\n\n\n\n\n\n\n\nKey Performance Indices\nA control system’s behavior in the frequency domain can be characterized by several indices:\n\nResonant Peak (\\(M_r\\))\nResonant Frequency (\\(\\omega_r\\))\nBandwidth (\\(\\omega_b\\))\nGain Margin (GM)\nPhase Margin (PM)\nSteady State Error (\\(e_{ss}\\))\nSystem Constants (\\(K_p, K_v, K_a\\))\n\nThese specifications guide the design process and help in tuning the system to achieve the desired performance in both frequency and time domains.\nThese parameters are derived from the open-loop frequency response data but reflect the closed-loop behavior. They offer insights into the relative stability of the system.\n\n\n\nVisualizing System Behavior in Time Domain\nUnderstanding the relationship between frequency and time is key to analyzing and designing effective control systems.\n\nTime Domain Visualization:\n\nThe time domain is particularly useful for visualizing how a system behaves in response to certain inputs, like a step input.\nFor instance, in the time domain, we can easily see how well a system tracks an input and identify the transient errors (the initial difference between the desired and actual response).\nThe dynamic behavior of a system, such as its response to changes over time, is often more intuitively understood in the time domain.\n\n\n\n\nSimplifying with Frequency Domain Design\n\nAdvantages of Frequency Domain:\n\nDesigning in the frequency domain is generally simpler and more straightforward.\nHowever, to fully leverage its advantages, we need to establish a connection between the time domain and frequency domain characteristics.\n\nLinking Time and Frequency Domains:\n\nThis linking involves correlating parameters like resonant peak \\(M_r\\), resonant frequency \\(\\omega_r\\), bandwidth \\(\\omega_b\\), phase margin, and gain margin between the two domains.\nBy understanding these relationships, we can appreciate how frequency domain decisions will impact the time domain behavior.\n\n\n\nPractical Approach\n\nFourier Transform Limitations:\n\nTheoretically, the Fourier transform can be used to derive the time response from frequency response data. However, in practice, this can be complex and impractical.\n\nUsing Computational Tools:\n\nWith the advent of computers, a more practical approach is to use the transfer function derived from frequency domain data and simulate it in the time domain.\nThis method allows us to approximate how frequency domain parameters will manifest in the time domain, bypassing the complexities of Fourier transforms.\n\nApproximating Relationships:\n\nOur goal is to quickly gauge if the chosen frequency domain parameters make sense when converted into time domain behavior.\nA complete and accurate depiction of time domain behavior can be achieved through thorough simulation.\nWhat this means is that we are going to accept approximations and we will verify if the assumptions and approximations done are correct through thorough simulations. This is similar to what we did when using the dominance condition to identify two closed-loop poles that were dominant in the response of the system. This approximation is used for the initial design and then if discrepancies arise in simulations, adjustments are made accordingly.\n\n\n\n\n\nKey Approximation in Frequency-Domain Closed-Loop System Design\n\nAssuming Second-Order System Behavior:\n\nA significant simplification in the design process is to approximate the behavior of the closed-loop system as being similar to a second-order system. This means we assume the system has a dominant pair of roots that predominantly influence its response.\n\nImplications for Time Domain Visualization:\n\nWith this approximation, it becomes more straightforward to predict and visualize the system’s behavior in the time domain. For instance, understanding how the system responds to certain inputs or its overall dynamic behavior becomes more intuitive.\n\nDealing with Approximation Limitations:\n\nIt’s important to acknowledge that this is an approximation. If the actual system significantly deviates from a second-order behavior, there might be a noticeable discrepancy between our predictions and the actual performance observed in simulations.\nTo address such discrepancies, we often rely on a trial and error approach. This involves adjusting the design based on simulation outcomes to better match the expected behavior.\n\n\n\n\nThe Role of Simulation in Refining Design\n\nBridging the Gap with Simulation:\n\nSimulations are crucial in verifying and refining our design approximations. They provide a practical view of how the system will behave, allowing us to make necessary adjustments.\n\nIterative Approach in Design:\n\nSystem design in the frequency domain often requires an iterative process, moving back and forth between designing, simulating, and tweaking based on the simulation results. This iterative process helps ensure that the final design aligns well with the desired performance specifications.\n\n\nIn essence, while approximating the closed-loop system as a second-order system simplifies the design process, it’s important to validate and adjust this approximation through simulation to achieve a design that performs effectively in real-world conditions.\nBefore moving forward it is worth re-emphasising the use of the second-order approximation that we will be doing.\n\n\nClarification on the Use of Approximation\n\nScope of the Approximation:\n\nThe approximation of treating the closed-loop system as a second-order system is primarily used for quick visualization and understanding. It’s important to emphasize that this is a tool for conceptualization rather than a direct element in the actual design process.\n\nApplication in Visualization:\n\nThe main purpose of this approximation is to provide a simpler way to translate and comprehend system behavior from the frequency domain into the time domain. It’s a method to quickly gauge how the system might behave in real-time operation based on its frequency domain characteristics.\n\nNot Directly Used in Design:\n\nWhen it comes to the actual design of the system in the frequency domain, this approximation does not directly influence the design decisions or calculations. It’s not re-entered into the design process.\n\nCaution in Design Process:\n\nDesigners should exercise caution and not overly rely on this approximation for making design choices. While it’s useful for initial understanding, the actual design should be based on more precise analyses and simulations that take into account the specific characteristics of the system.\n\n\n\n\nImportance of Precision in Design\n\nDesign Accuracy:\n\nAccurate and effective design in the frequency domain requires considering all the detailed characteristics of the system, beyond the simplifications offered by the approximation.\n\nRole of Simulations:\n\nSimulations play a critical role in validating the design, offering a more accurate picture of how the system will behave in various scenarios, which might differ from the simplified approximation.\n\n\nThe approximation of a closed-loop system as a second-order system is a helpful tool for initial visualization and understanding, it should not be directly used in the design process. Accurate design requires a detailed analysis and simulations tailored to the specific system being developed.\n\nPop-Up Question: Why is it important to understand both time domain and frequency domain behaviors in control systems?\nAnswer: Understanding both domains allows for a comprehensive view of the system’s performance. The time domain offers insights into the system’s real-world response to inputs, while the frequency domain simplifies the design and analysis process, particularly in filtering and stability aspects.\nPop-Up Question: Why is it beneficial to link time domain and frequency domain analyses?\nAnswer: Linking these domains allows for leveraging the simplicity of frequency domain design while appreciating and verifying system performance in the more intuitive time domain.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#approximating-second-order-system-behavior",
    "href": "feedback_system_performance_based_on_frequency_response.html#approximating-second-order-system-behavior",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Approximating Second-Order System Behavior",
    "text": "Approximating Second-Order System Behavior\nA common approximation in control system analysis is assuming that the system behaves like a second-order system with two dominant poles. This simplification is often valid, especially when the final design exhibits two dominant poles, and non-dominant poles have a minimal effect.\nTypical System Behavior: - A standard second-order system is represented by the transfer function\n\\[\\frac{\\omega_n^2}{ s(s + 2 \\zeta \\omega_n) }\\]\nand by the following feedback loop:\n\n\n\n\n\n\n\n\nIn many designs, such systems exhibit two dominant poles, which significantly influence the system’s behavior.\n\n\nDeriving Resonant Frequency and Peak in a Second-Order System\nWe begin determining the resonant frequency (\\(\\omega_r\\)) and the resonant peak (\\(M_r\\)). Let’s break down this process step by step for clarity.\n\n\nClosed-Loop Transfer Function of a Second-Order System\nConsider the following transfer function:\n\\[\nM(s) = \\frac{\\omega_n^2}{s^2 + 2 \\zeta \\omega_n s + \\omega_n^2}\n\\]\nThis equation represents the closed-loop transfer function for a second-order system, where \\(\\omega_n\\) is the natural frequency and \\(\\zeta\\) is the damping ratio.\n\n\nExpressing the Transfer Function with Complex Frequency\nTo analyze the system’s behavior at different frequencies, we express \\(M(s)\\) using a complex frequency \\(j\\omega\\):\n\\[\nM(j\\omega) = \\frac{\\omega_n^2}{- \\omega^2 + j 2 \\zeta \\omega_n \\omega + \\omega_n^2}\n\\]\n\n\nUsing Normalized Frequency\n\nDefining Normalized Frequency:\n\nLet’s introduce a normalized frequency $ u = $. This simplifies our calculations and helps in comparing systems with different natural frequencies.\n\nModified Transfer Function:\n\nWith this normalized frequency, our transfer function becomes:\n\n\\[\nM(ju) = \\frac{1}{1 - u^2 + j 2 \\zeta u}\n\\]\n\n\n\nDetermining Resonant Frequency and Peak\n\nCalculating the Resonant Frequency (\\(\\omega_r\\)):\n\nTo find the resonant frequency, we need to determine the point where the magnitude of $ M(ju) $ reaches its maximum. This involves differentiating the magnitude with respect to $ u $ and setting the derivative to zero ($ = 0 $).\n\nMagnitude of $ M(ju) $:\n\nThe magnitude of $ M(ju) $ is given by:\n\n\\[\n\\left|M(ju)\\right| = \\frac{1}{\\sqrt{(1 - u^2)^2 + (2 \\zeta u)^2}}\n\\]\nFinding $ u_r $ and $ M_r(u_r) $:\n\nBy setting $ = 0 $, we find $ u_r $, the normalized frequency at which the resonant peak occurs.\nSubstituting this value back into the magnitude equation gives us $ M_r(u_r) $, the resonant peak.\n\nCalculating Resonant Frequency and Peak:\n\n\\[ u_r = \\sqrt{1 - 2\\zeta^2} \\] \\[ \\omega_r = \\omega_n\\sqrt{1 - 2\\zeta^2} \\] \\[ M_r = \\frac{1}{2\\zeta\\sqrt{1 - \\zeta^2}} \\]\n\nRelationship Between Damping Ratio and Resonant Peak\nThe frequency domain index, \\(\\omega_r\\) (resonant frequency), and \\(M_r\\) (resonant peak), are directly related to the time domain parameter, damping ratio (\\(\\zeta\\)). This relationship is ties the peak overshoot in the time domain, which is a function of \\(\\zeta\\), to the frequency domain characteristics.\n\\[ M_r = \\frac{1}{2\\zeta\\sqrt{1 - \\zeta^2}} \\quad \\text{for} \\quad 0 &lt; \\zeta &lt; 0.707 \\]\nThe equation illustrates a direct relationship between the resonant peak (\\(M_r\\)) in the frequency domain and the peak overshoot in the time domain (which is obtained through \\(\\zeta\\)).\nWe can make the following plot of \\(M_r\\) as \\(\\zeta\\) varies:\n\n\n\n\n\n\n\nThe equation is valid for $ 0 &lt; &lt; 0.707 $. When $ &gt; 0.707 $ the system behaves very close to a critically damped system and in practise there is no overshoot peak (overshoot will be between 2% and 5%). We are more interested in capturing important behaviours that can affect the stability of the system, whereas we can capture detailed behaviours through simulations.\nIn other words, the resonant peak equation is defined for \\(0 &lt; \\zeta &lt; 0.707\\). For \\(\\zeta &gt; 0.707\\), the system approximates a critically damped response, with no significant overshoot. This implies that for larger values of \\(\\zeta\\), the system’s behavior is akin to having no resonant peak, leading to a flatter frequency response.\n\n\nInterpreting \\(\\omega_r\\) and \\(\\omega_b\\)\nThe values of \\(\\omega_r\\) and \\(\\omega_b\\) (bandwidth) can give insights into the rise time and settling time of the system. Given a specific damping ratio (\\(\\zeta\\)), \\(\\omega_r\\) helps determine the natural frequency (\\(\\omega_n\\)), and consequently, the rise time and settling time.\n\\(\\omega_r\\) depends on \\(\\zeta\\) and \\(\\omega_n\\) and hence is representive of the rise time or settling timne.\nGiven \\(\\omega_r\\) and \\(M_r\\) we can obtain \\(\\zeta\\) and \\(\\omega_n\\) and hence the transient behaviour of the system in terms of settling time, rise time, peak overshoot, etc.\nThe only caveat is that the system must be approximated by a second-order system. If not, in this course, we will rely on simulations only.\n\n\nCalculating Bandwidth for Second-Order Systems\nTo calculate the bandwidth, we go back to our magnitude equation:\n\\[\n   \\left|M(ju)\\right| = \\frac{1}{\\sqrt{(1 - u^2)^2 + (2 \\zeta u)^2}}\n\\]\nand set \\(\\left|M(ju)\\right| = 0.707\\) to find \\[u_b=\\frac{\\omega_b}{\\omega_n}\\]\nand finally it can be calculated for a second-order system as follows:\n\\[ \\text{Bandwidth, } \\omega_b = \\omega_n \\left[ (1 - 2\\zeta^2) + \\sqrt{4\\zeta^4-4\\zeta^2 +2} \\right]^{\\frac{1}{2}} \\]\nIn time domain, \\(\\omega_b\\) is related to the system’s rise time, settling time. In frequency domain, \\(\\omega_b\\) is related to noise filtering characteristics.\n\n\n\nConsistency in System Specifications\nIn designing control systems, especially in the frequency domain, we need to ensure that the specifications we choose are consistent and compatible with each other.\nLet’s explore this concept further and understand how it applies to the selection of specifications like resonant peak (\\(M_r\\)), the resonant frequency (\\(\\omega_r\\)) and bandwidth (\\(\\omega_b\\)).\n\nInterrelated Nature of Frequency Domain Specifications:\n\nIn the frequency domain, key parameters such as resonant frequency (\\(\\omega_r\\)), resonant peak (\\(M_r\\)), and bandwidth (\\(\\omega_b\\)) are closely interrelated. They cannot be set independently of each other as their values influence one another.\nGiven this interdependence, these specifications need to be consistent with each other. For instance, a change in the resonant peak (\\(M_r\\)) might necessitate adjustments in the bandwidth (\\(\\omega_b\\)) or the resonant frequency (\\(\\omega_r\\)) to maintain system coherence.\nIn scenarios where more than two specifications are involved, typically, one of these parameters will be a result of the other two. This means that if you specify two parameters, the third should logically follow or be derived based on those choices.\n\nSelecting Compatible Specifications:\n\nWhen multiple specifications are given for a system’s behavior, they must align with each other. For example, if you set a certain resonant frequency (\\(\\omega_r\\)), it should be in harmony with other parameters like the resonant peak (\\(M_r\\)) and bandwidth (\\(\\omega_b\\)).\n\n\n\n\nChoosing Effective Specifications\n\nResonant Peak (\\(M_r\\)) and Bandwidth (\\(\\omega_b\\)):\n\nA practical approach in frequency domain design is to primarily use \\(M_r\\) and \\(\\omega_b\\) as key specifications.\n\\(M_r\\) effectively represents the damping characteristics, while \\(\\omega_b\\) relates to both noise filtering characteristics and, in terms of time domain, to the rise time or settling time of the system.\n\nImplementing in Design Algorithms:\n\nThese specifications, \\(M_r\\) and \\(\\omega_b\\), can be embedded into the design algorithm. This allows for a focused and consistent approach to system design.\nAdditional specifications, like \\(\\omega_r\\), can be checked for compatibility post the initial design process.\n\nSimplification Through Specific Methods:\n\nHaving a clear method for specifying system performance can simplify the design process. By focusing on key parameters like \\(M_r\\) and \\(\\omega_b\\), we can effectively control important aspects of the system’s behavior.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#obtaining-closed-loop-frequency-response-from-open-loop-data",
    "href": "feedback_system_performance_based_on_frequency_response.html#obtaining-closed-loop-frequency-response-from-open-loop-data",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Obtaining Closed-Loop Frequency Response from Open-Loop Data",
    "text": "Obtaining Closed-Loop Frequency Response from Open-Loop Data\n\nIt’s important to understand that the critical indices for characterizing a control system — such as resonant frequency (\\(\\omega_r\\)), resonant peak (\\(M_r\\)), bandwidth (\\(\\omega_b\\)) — are derived exclusively from the system’s closed-loop frequency response.\nA significant task in control system analysis is to determine the closed-loop frequency response based on the open-loop frequency response data. The open-loop response gives us insights into the system’s inherent behavior without feedback, but it’s the closed-loop response that shows us how the system will perform under actual operating conditions with feedback.\nIn the modern context, where computational tools are readily available, this transition becomes much more manageable. With the help of computers, we can efficiently process the open-loop data to generate the closed-loop frequency response.\n\n\nUtilizing Open-Loop Data for Closed-Loop Characterization\n\nOur goal is to find efficient methods to characterize the closed-loop frequency response of a system. The indices such as resonant peak (\\(M_r\\)), resonant frequency (\\(\\omega_r\\)), and bandwidth (\\(\\omega_b\\)) are valuable for this purpose.\nThe challenge is obtaining these parameters quickly, especially when we usually only have open-loop frequency response data.\nWe will see how to characterize the closed-loop system behavior directly using the open-loop frequency response data.\nWe saw one method already: the Nyquist stability criterion. This criterion allows us to infer the closed-loop behavior of the system using the open-loop frequency response data. We will see how the Nyquist Criterion and the Bode’s Plot help us understand key aspects like gain margin and phase margin directly from the open-loop data, bridging the gap between open and closed-loop analysis.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#understanding-gain-margin-and-phase-margin-and-application-to-second-order-systems",
    "href": "feedback_system_performance_based_on_frequency_response.html#understanding-gain-margin-and-phase-margin-and-application-to-second-order-systems",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Understanding Gain Margin and Phase Margin and Application to Second-Order Systems",
    "text": "Understanding Gain Margin and Phase Margin and Application to Second-Order Systems\n\nGain margin and phase margin are critical parameters in assessing the stability of a control system.\nGain margin indicates how much the system’s gain can be increased before it becomes unstable, calculated as \\(1/a\\) where \\(A\\) is the gain at the phase crossover frequency.\nPhase margin \\(\\phi\\) is the additional phase shift that would bring the system to the edge of instability, offering insight into how far the system is from a potential oscillatory or unstable state.\n\n\nApplication to Second-Order Systems\nFor a standard second-order system, these stability parameters become especially significant. We can relate the system’s gain margin and phase margin to its characteristic behavior, providing a clear picture of its stability in closed loop.\nFor a standard second-order system, represented by the transfer function\n\\[G(s) = \\frac{\\omega_n^2}{s(s + 2 \\zeta \\omega_n)}\\]\nits open-loop frequency response presents unique characteristics.\nLet’s explore how to analyze this system directly from its open-loop frequency response data.\n\n\nPolar Plot Characteristics\nThe polar plot of a standard second-order system does not cross the imaginary axis but is asymptotic to it. This behavior is a key characteristic of a type-1, second-order system.\n\nCalculating Phase Margin for a Second-Order System\n\nGain Crossover Frequency (\\(\\omega_{gc}\\)): This is the frequency at which the gain of the system is equal to unity. It is important for determining the phase margin of the system.\nPhase Margin Calculation: The phase margin is calculated at the gain crossover frequency. It is the angle measured positive with respect to the negative real axis at \\(\\omega_{gc}\\).\nGain Margin: The Gain Margin is infinity for a standard second-order system.\n\n\n\n\n\n\n\n\nFigure: A polar plot of the open-loop frequency response for a standard second-order system.\nWe can plot it using Python as shown below.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the parameters for the second-order system\nomega_n = 1.0  # Natural frequency\nzeta = 0.5     # Damping ratio\n\n# Define the transfer function G(s)\nnum = [omega_n**2]\nden = [1, 2 * zeta * omega_n, 0]\nG = ctl.TransferFunction(num, den)\n\n# Nyquist plot\n_, contour = ctl.nyquist(G, plot=True, return_contour=True)\n\nreal, imag = np.real(G(contour)), np.imag(G(contour))\n\n# Plot the unit circle for reference\ncircle = plt.Circle((0, 0), 1, color='blue', fill=False, linestyle='dotted')\nplt.gca().add_artist(circle)\n\n# Annotations for Gain Margin and Phase Margin\ngm, pm, wg, wp = ctl.margin(G)\n# Gain Margin\n# plt.plot([real[0], 1], [imag[0], 0], 'g--')\nplt.text(0.5, 0, f'GM: {gm:.2f}', color='green')\n# Phase Margin\nplt.plot([0, -1], [0, -np.tan(pm * np.pi / 180)], 'r--')\nplt.text(-1, -np.tan(pm * np.pi / 180), f'PM: {pm:.2f}°', color='red')\n\nplt.title(\"Nyquist Plot of a Standard Second-Order System with Phase and Gain Margins\")\nplt.xlabel(\"Real\")\nplt.ylabel(\"Imaginary\")\nplt.grid(True)\nplt.axis('equal')\nplt.xlim((-2,1))\nplt.ylim((-2,2))\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nGain Crossover Frequency and Phase Margin\n\nDeriving Gain Crossover Frequency (\\(\\omega_{gc}\\))\nFor a standard second-order system, the gain crossover frequency can be found by setting the magnitude of the open-loop frequency response to 1:\n\\[\nG(j\\omega) = \\frac{\\omega_n^2}{j\\omega(j\\omega + 2\\zeta\\omega_n)}\n\\]\nfrom which:\n\\[\n\\left| G(j\\omega) \\right| = \\frac{\\omega_n^2}{\\omega\\sqrt{(\\omega^2 + 4\\zeta^2\\omega_n^2)}}\n\\]\nSet this magnitude equal to 1 and solve for \\(\\omega\\), which gives you the gain crossover frequency \\(\\omega_{gc}\\).\n\\[\n\\omega_{gc} = \\omega_n k\n\\]\nwhere\n\\[\nk=\\sqrt{\\sqrt{4\\zeta^4+1} - 2\\zeta^2}\n\\]\nNote that we are obtaining this directly from the open-loop frequency response, without plotting the closed-loop frequency response.\n\n\nDeriving Phase Margin, PM (\\(\\phi\\))\n\\[\nPM = 180^\\circ + \\text{phase of } G(j\\omega_gc) = \\tan^{-1}\\frac{2\\zeta}{k}\n\\]\nWe need to be careful with the signs of the angles:\n\n\n\n\n\n\n\n\n\nPhase Margin as a Function of Damping Ratio (\\(\\zeta\\))\nFor a standard second-order system, the phase margin is a function of \\(\\zeta\\) only.\nAn interesting observation is that for values of \\(\\zeta\\) less than 0.5, the phase margin is approximately linear and equals \\(100 \\times \\zeta\\).\nTo plot the Phase Margin (PM) in degrees as a function of the damping ratio (\\(\\zeta\\)), we can write a simple Python script. The phase margin formula given is:\n\\[\nPM =  \\tan^{-1}\\left(\\frac{2\\zeta}{k}\\right)\n\\]\nwhere $ k = $.\nThis script will create a plot of the Phase Margin (PM) in degrees against the damping ratio (\\(\\zeta\\)). You can adjust the range of \\(\\zeta\\) values in zeta_values if you want to explore different ranges.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the range of zeta values\nzeta_values = np.linspace(0.01, 1, 500)  # Avoid starting from 0 to prevent division by zero\n\n# Calculate k and PM for each zeta\nk_values = np.sqrt(np.sqrt(4 * zeta_values**4 + 1) - 2 * zeta_values**2)\npm_values = np.arctan2(2 * zeta_values, k_values) * 180 / np.pi  # Convert from radians to degrees\n\n# Calculate the linear relationship PM = 100 * zeta\nlinear_pm_values = 100 * zeta_values\n\n# Plot PM as a function of zeta\nplt.figure()\nplt.plot(zeta_values, pm_values, label='PM vs. Zeta (Complex Formula)')\nplt.plot(zeta_values, linear_pm_values, label='PM = 100 * Zeta (Linear Approximation)', linestyle='--')\nplt.title('Phase Margin (PM) as a Function of Damping Ratio (Zeta)')\nplt.xlabel('Damping Ratio (Zeta)')\nplt.ylabel('Phase Margin (PM) in Degrees')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCorrelating Frequency Domain Indices with Time Domain Behavior\n\nPhase Margin and Gain Crossover Frequency as Indicators\n\nFrequency Domain Representation:\n\nThe phase margin and gain crossover frequency together form a set of parameters that effectively represent a system’s behavior in the frequency domain.\n\nInferring Time Domain Behavior:\n\nBy analyzing these two parameters, we can draw inferences about how the system behaves in the time domain. This includes the system’s response to input changes and its overall stability characteristics.\n\nUnderstanding Gain Margin in Second-Order Systems:\n\nIt’s important to note that for a second-order system, the gain margin is typically infinity. However, when dealing with higher-order systems, the gain margin becomes a finite value and plays a significant role in the design process.\nA larger gain margin implies greater relative stability of the system, indicating a higher tolerance for gain increases before becoming unstable.\n\n\n\n\nIntegrating Phase Margin and Gain Crossover Frequency in Design\n\nBuilding Design Specifications:\n\nWe can incorporate the phase margin (PM) and the gain crossover frequency into our design specifications.\nThese specifications will help guide the design process, ensuring that the system meets both frequency domain requirements and desired time domain performance.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#control-system-design-specifications",
    "href": "feedback_system_performance_based_on_frequency_response.html#control-system-design-specifications",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Control System Design Specifications",
    "text": "Control System Design Specifications\nWhen designing control systems, selecting the right specifications is important for achieving the desired system performance. These specifications not only influence the design but also help in fine-tuning the system to function effectively in both the frequency and time domains.\n\nKey Specifications in Control System Design\n\nEssential Parameters:\n\nA typical control system design might include several critical specifications:\n\nResonant Peak (\\(M_r\\))\nBandwidth (\\(\\omega_b\\))\nPhase Margin (PM)\nGain Crossover Frequency (\\(\\omega_{gc}\\))\nSteady-State Error Constants (\\(K_p\\), \\(K_v\\), \\(K_a\\))\n\n\nGuiding the Design Process:\n\nThese parameters are not just arbitrary values; they are there to guide the design process and ensuring that the system meets its performance objectives.\n\n\n\n\nDesign Approaches Based on Specifications\n\nStarting with Resonant Peak and Bandwidth:\n\nOne approach is to begin the design focusing on the Resonant Peak (\\(M_r\\)) and Bandwidth (\\(\\omega_b\\)). After the initial design, we then check how the system aligns with the other specifications.\n\nUsing Phase Margin and Bandwidth:\n\nAnother common method is to use Phase Margin and Bandwidth as the starting points for the design.\nPhase Margin is indicative of the damping ratio (\\(\\zeta\\)), and Bandwidth is important for defining the system’s noise filtering capabilities.\n\nDesigning with Open-Loop Frequency Response:\n\nIf working primarily with open-loop frequency response data, the Phase Margin and Gain Crossover Frequency (\\(\\omega_{gc}\\)) become more relevant specifications.\nIn such cases, if there is also a specification on Bandwidth (\\(\\omega_b\\)), the design starts with Phase Margin and Gain Crossover Frequency, and then checks if the Bandwidth specification is met by calculating the closed-loop frequency response.\nIf discrepancies arise, a process of trial and error is used to adjust the design until the desired outcome is achieved.\n\n\n\n\nConclusion and Practical Application\n\nFlexibility in Design: These design approaches illustrate the flexibility and adaptability required in control system design, ensuring that the final system meets all specified criteria.\nBalancing Specifications: The key is to balance these specifications, understanding that each influences the system’s performance in distinct ways.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "feedback_system_performance_based_on_frequency_response.html#check-your-understanding",
    "href": "feedback_system_performance_based_on_frequency_response.html#check-your-understanding",
    "title": "Feedback System Performance Based On Frequency Response",
    "section": "Check Your Understanding",
    "text": "Check Your Understanding\nPop-Up Question: What does a high phase margin imply about the system’s stability?\nAnswer: A high phase margin indicates that the system has a good degree of relative stability and is far from the brink of instability.\nPop-Up Question: How do specifications like \\(M_r\\) and \\(\\omega_b\\) influence the final system design?\nAnswer: Specifications like \\(M_r\\) and \\(\\omega_b\\) directly influence the damping characteristics and response speed of the system, thus impacting its overall performance.\nPop-Up Question: Why is it important to consider multiple specifications in control system design?\nAnswer: Considering multiple specifications is important because it ensures a holistic approach to design, where the system’s stability, responsiveness, noise immunity, and error handling are all optimized to work together harmoniously.",
    "crumbs": [
      "Feedback System Performance Based On Frequency Response"
    ]
  },
  {
    "objectID": "a_first_complete_application.html",
    "href": "a_first_complete_application.html",
    "title": "A Feedback Control System",
    "section": "",
    "text": "In our previous discussion, we delved into the realm of process control applications, with a specific cases involving the usage of DC and DC motors. In this notebook, we’ll revisit those core concepts and further expand our exploration with an in-depth look at another pivotal application - the heat exchanger.\n\n\nProcess control can be characterized by the regulation of certain variables. These variables include: - Temperature - Pressure - Liquid level - Composition\nThese applications are often influenced by factors with large time constants. Therefore, pneumatic devices, which inherently possess slower response characteristics, are well-suited for these applications.\n\n\n\n1. Control Valve\n- Input: Electrical signal - Output: Pressure signal or control stem position alteration - Purpose: To regulate fluid flow to the process\n2. Electropneumatic Transducer\n- A device that interfaces between the actuator (control valve) and the electronic controller (which could be either Op-Amp based or digital computer-based). - Input: Electrical signal - Output: Pressure signal that is suitable for the control valve (actuator)\nIt’s worth noting that while I mentioned the electropneumatic transducer’s construction is quite identical in principle to an electrohydraulic device, we’re focusing on a block diagrammatic description for simplicity.\n\n\n\nHistorically, controllers were positioned in a dedicated control room, separate from the process. This requires signal transmission from the process to the control room and vice versa.\n\n\n\n\n\nFigure: Diagram showing the transmission of signals between process and control room\nPrior to the 1950s, this communication was predominantly facilitated by pneumatic or air pressure signals. This method can still be witnessed in older industries with extensive tubing networks. However, as technology has evolved, newer industries have gradually adopted electronic or digital controllers, transitioning from pneumatic to electrical signals for communication.",
    "crumbs": [
      "A Feedback Control System"
    ]
  },
  {
    "objectID": "a_first_complete_application.html#introduction",
    "href": "a_first_complete_application.html#introduction",
    "title": "A Feedback Control System",
    "section": "",
    "text": "In our previous discussion, we delved into the realm of process control applications, with a specific cases involving the usage of DC and DC motors. In this notebook, we’ll revisit those core concepts and further expand our exploration with an in-depth look at another pivotal application - the heat exchanger.\n\n\nProcess control can be characterized by the regulation of certain variables. These variables include: - Temperature - Pressure - Liquid level - Composition\nThese applications are often influenced by factors with large time constants. Therefore, pneumatic devices, which inherently possess slower response characteristics, are well-suited for these applications.\n\n\n\n1. Control Valve\n- Input: Electrical signal - Output: Pressure signal or control stem position alteration - Purpose: To regulate fluid flow to the process\n2. Electropneumatic Transducer\n- A device that interfaces between the actuator (control valve) and the electronic controller (which could be either Op-Amp based or digital computer-based). - Input: Electrical signal - Output: Pressure signal that is suitable for the control valve (actuator)\nIt’s worth noting that while I mentioned the electropneumatic transducer’s construction is quite identical in principle to an electrohydraulic device, we’re focusing on a block diagrammatic description for simplicity.\n\n\n\nHistorically, controllers were positioned in a dedicated control room, separate from the process. This requires signal transmission from the process to the control room and vice versa.\n\n\n\n\n\nFigure: Diagram showing the transmission of signals between process and control room\nPrior to the 1950s, this communication was predominantly facilitated by pneumatic or air pressure signals. This method can still be witnessed in older industries with extensive tubing networks. However, as technology has evolved, newer industries have gradually adopted electronic or digital controllers, transitioning from pneumatic to electrical signals for communication.",
    "crumbs": [
      "A Feedback Control System"
    ]
  },
  {
    "objectID": "a_first_complete_application.html#evolution-of-transmission-standards-in-process-control",
    "href": "a_first_complete_application.html#evolution-of-transmission-standards-in-process-control",
    "title": "A Feedback Control System",
    "section": "Evolution of Transmission Standards in Process Control",
    "text": "Evolution of Transmission Standards in Process Control\nIn the realm of process control, particularly within industrial environments, the transmission of information between controllers, sensors, actuators, and other equipment is essential. Over the years, the standards and means of this transmission have undergone significant transformation.\n\n1950s: The prevalent industrial standard for signal transmission was between 3 to 15 psi (pressure pounds per square inch).\nPost-1950s: A myriad of transmission standards emerged, such as ±10 volts, 1 volt to 5 volts, 1 milliampere to 5 milliamperes, and so on.\nModern Era: Standardization has largely gravitated towards the 4 milliamperes to 20 milliamperes range for transmission purposes.\n\n\nPneumatic Transmission:\n1. Pneumatic Signals (pre-1950s): Prior to the 1950s, communication between the control room and the process often used pneumatic signals. These are typically represented in terms of air pressure.\n\nStandard: The industrial standard for these pneumatic signals was usually between 3 to 15 psi (pounds per square inch).\nInfrastructure: Pneumatic systems required tubing for transmitting these pressure signals between devices. This tubing is why, when you’d visit older process industries, you’d see a web of tubes connecting different equipment.\nLimitations: Pneumatic systems are generally slow to respond due to the physical nature of air or gas being compressed or decompressed. This makes them adequate for systems with large time constants but not for rapid-response applications.\n\n\n\nElectronic Transmission:\n2. Electronic Signals (1950s onwards): As technology evolved, electronic and electrical signals began to replace pneumatic transmissions.\n\nEarly Standards: Before an industry-wide standardization took place, there were several electronic signal standards like ±10 volts, 1 volt to 5 volts, and a variety of current signals like 1 milliampere to 5 milliampere.\n4-20 mA Standard: This became the dominant standard for current transmission. It’s notable because a 4 mA signal can be used to indicate a system’s “off” state, while any value above indicates an “active” state. This ensures that even if the signal drops to its minimum (4 mA), it’s still detectable and distinct from a complete signal loss or a wire break.\nAdvantages: Electronic signals can be transmitted faster, with less energy loss, and over longer distances compared to pneumatic signals. Electronic systems are also less affected by environmental changes.\n\n\n\nDigital Transmission:\n3. Digital Signals (Late 20th century onwards): With the advent of computers and digital technology, digital signaling began to emerge in industrial control.\n\nMicroprocessor-based controllers: These controllers are capable of handling complex operations, supporting a variety of communication protocols, and interacting with modern digital infrastructure.\nProtocols: Digital communication introduced a range of protocols like Modbus, PROFIBUS, and later, Ethernet-based standards such as EtherCAT and PROFINET.\nAdvantages: Digital signals are immune to noise and can carry a vast amount of data. They can be integrated with IT infrastructure, allowing for more sophisticated control, monitoring, and reporting mechanisms.\n\n\n\nImplications:\nThe evolution from pneumatic to electronic to digital transmission represents not just a shift in technology but also in the complexity and capability of process control systems. Modern systems can manage multiple variables, integrate with other IT systems, and offer unparalleled control precision.\nWhile the transition has enabled more advanced and complex systems, it also requires new skill sets for maintenance, integration, and troubleshooting. It’s essential for modern control engineers to understand not just the traditional aspects of their processes but also the digital communication and IT facets.\n🤔 Pop-up Question: Why was the 4-20 mA standard adopted over other early electronic signal standards in the process control industry?\nAnswer: The 4-20 mA standard offers distinct advantages: 1. A 4 mA signal can indicate an “off” state, making it distinguishable from a complete signal loss or wire break. 2. Current signals like these are less affected by the resistance of long cables, ensuring signal integrity over long distances. 3. They are also less susceptible to electrical noise compared to voltage signals.\n\n\nSignal Transmission Block Diagram\nImagine a typical process where a quantity (temperature, liquid level, or composition) is measured. This signal, once processed by a sensor, would be converted into an electrical signal. Most of these sensor outputs are voltage signals. But for transmission, these voltage signals are often converted into current signals, mainly because current signals are less susceptible to noise.\n\n\n\n\n\n\nVoltage to current conversion will be needed at the sensor point,\nCurrent to voltage conversion will be needed at the controller.\n\nSignal Conditioning Circuit (or Transmitter)\nSignal conditioning is a fundamental aspect of electronics and instrumentation. It refers to the process of modifying a signal in such a way that it meets the requirements of the next stage or device in a system. This process can involve amplification, filtering, converting, range matching, isolation, and any other functions that optimize the signal for further processing.\n\nThis unit consists of signal conditioning and line driving components.\nIts role is to convert the sensor’s electrical signal into a format compatible with the controller, while also accommodating the distance between the process and the controller.\n\n\nNote on Terminology\nIn process control language, the interface between the process and the controller is often termed as a “transmitter.” This word is used interchangeably with “sensor” throughout our discussion, but remember that in a broader context, the transmitter can include the sensor component as well.\n\n\n\nComponents and Types of Signal Conditioning:\n\nAmplifiers: These are the most common signal conditioners. They boost the amplitude of a signal. For example, sensors that produce a very low output voltage (like thermocouples) often need amplification before their signals can be read by most analog-to-digital converters (ADCs).\n\nOperational Amplifiers (Op-Amps): Widely used in signal conditioning circuits due to their versatility. They can be configured for a range of functions such as inverting, non-inverting, differential, integrator, and differentiator circuits.\n\nFilters: Filters are used to remove unwanted frequencies from a signal.\n\nLow-pass filters: They allow signals with a frequency lower than a certain cutoff frequency to pass through and attenuate frequencies higher than the cutoff frequency.\nHigh-pass filters: They do the opposite, attenuating frequencies below the cutoff frequency and allowing those above it to pass.\nBand-pass filters: They only allow signals within a certain frequency range to pass.\n\nAnalog-to-Digital Converters (ADCs): They convert analog signals into a digital format that can be processed by digital equipment like computers.\nVoltage-to-Current and Current-to-Voltage Converters: These converters are useful for transmitting signals over long distances. For instance, the 4-20mA current loop standard in industrial settings.\nLinearizers: Some sensors have non-linear outputs, meaning the relationship between the physical quantity being measured and the sensor’s output isn’t a straight line. Linearizers are used to correct these outputs.\nIsolators: They are crucial in applications where it’s essential to break the electrical path between two circuits, yet still transfer the signal. They can protect sensitive equipment from voltage spikes and reduce ground loops.\nMultiplexers (MUX): When several signals need to be sent through a single ADC, a multiplexer can be used. It selects one signal at a time to pass to the ADC.\n\n\n\nImportance of Signal Conditioning:\n\nAccuracy: Conditioning improves the accuracy of the final data by ensuring the signal is optimally prepared for processing.\nProtection: By isolating signals, sensitive equipment can be shielded from potential damage due to electrical issues like surges or ground loops.\nCompatibility: It ensures that signals from various sensors and sources can be made compatible with a wide range of processing and display equipment.\nEnhanced Performance: Filters can help reduce noise, amplifiers can boost weak signals, and ADCs can facilitate digital processing.\nReliability: Proper conditioning can make a system more robust and reliable by minimizing the impact of electrical noise, interference, or other issues that might otherwise distort or degrade the signal.\n\n\n\nApplications:\nSignal conditioning circuits are ubiquitous in electronic systems. Some common applications include:\n\nIndustrial Automation: Ensuring sensors’ signals are correctly processed for control systems.\nMedical Electronics: Enhancing signals from biomedical sensors.\nCommunication Systems: Preparing signals for transmission or reception.\nConsumer Electronics: For example, in audio processing in radios or music players.\n\nIn summary, signal conditioning is about preparing a signal to be just right for its next stage of processing, ensuring the end data is accurate, reliable, and meaningful.",
    "crumbs": [
      "A Feedback Control System"
    ]
  },
  {
    "objectID": "a_first_complete_application.html#a-complete-application---temperature-control-system",
    "href": "a_first_complete_application.html#a-complete-application---temperature-control-system",
    "title": "A Feedback Control System",
    "section": "A Complete Application - Temperature Control System",
    "text": "A Complete Application - Temperature Control System\nWith the foundational knowledge set, let’s explore a real-world application involving a heat exchanger.\nAlthough we will only be discussing the temperature variable in this context, in a real industrial process, multiple variables might need to be controlled simultaneously.\n\nSingle Variable Control: The example of the temperature control loop illustrates a single-variable control system. In this scenario, the system focuses on controlling the temperature alone, assuming that flow rates are maintained by another control loop and disturbances are negligible.\nMulti-Variable Control: In an actual process control environment, multiple variables (like temperature, flow, composition, pH value, etc.) might need simultaneous attention. The complexity arises because a change in one variable might affect others. For instance, the flow rate might influence temperature, or a change in composition might impact pH.\n\nIn the rest of the discussion, the assumption is that there might be more than one control loop but that each variable can be controlled independently.\n\nA Closer Look at the Heat Exchanger\nAs an application, let’s consider a Temperature Control Loop that uses a heat exchanger.\nThe heat exchanger, as the name suggests, is a device that allows for the exchange of heat between two or more fluids without allowing them to mix. Maintaining an optimal temperature is crucial for ensuring both the efficiency and safety of processes in industries ranging from petrochemicals to food processing.\nThe objective of this segment is to get an in-depth understanding of the temperature control loop of a heat exchanger, from the physical setup to the mathematical modeling. We’ll kick off by understanding the hardware components involved, followed by deriving a mathematical representation of the system. Furthermore, through experimental methods, we will understand how to ascertain critical parameters that govern the system’s behavior.\nHeat Exchanger Schematic:\nThe heat exchanger is depicted as a set of hollow tubes. The process fluid (whose temperature we aim to control) circulates through these tubes, entering at a specific point and exiting at another.\n\n\n\n\n\nAt a high level, a heat exchanger consists of hollow tubes through which a process fluid passes. This fluid enters at a certain temperature (inlet temperature) and exits at another (outlet temperature). Our primary goal is to control the temperature of this fluid as it exits the tubes.\nHowever, remember that we’re focusing solely on the temperature control loop. In a real-world setting, multiple variables might need control, and there would be various control loops in place. Each loop could control variables like temperature, flow rate, composition, pH, etc. For simplicity and clarity, we’re isolating one control loop – the temperature control loop – assuming minimal interference from other control loops.\n\nHeat Exchanger Detailed Walkthrough\nThe heat exchanger we’re examining comprises hollow tubes. The process fluid, whose temperature we aim to control, circulates through these tubes.\n\n\n\n\n\n\nThe fluid enters with an inlet temperature (denoted as \\(\\theta_i\\), a perturbation from the desired steady-state value) and exits at another temperature (denoted as \\(\\theta\\)).\nThe core objective is to ensure that the fluid exits at a specific commanded temperature, irrespective of any disturbances.\nFrom the steam the heat is stripped off and we have condensate coming out. Steam, when used as a heating medium, releases heat by condensing (changing its phase from vapor to liquid). As steam gives up its latent heat of vaporization, it turns back into water, which is termed “condensate.” The process of steam condensation releases a significant amount of heat, which is used for heating purposes in various applications.\n\nLet’s denote: - $ $: Perturbation from the desired temperature value in \\(^oC\\). - $ i $: Perturbation in the inflowing temperature relative to the steady-state value - $ q_m $: Perturbation in the flow rate relative to the steady-state value. The perturbation in the flow rate can affect the temperature. - $ q{ms} $: is the perturbation in the steam flow. This is our manipulated variable which we will control using a controller that acts on the valve to reduce \\(\\theta\\) to zero.\nWe are not considering how to control of the flow rate, but we need to consider it because the perturbation in the flow rate will be a disturbance for our system.\nNote that we are discussing perturbations with respect to the steady state. This means that the objective of the control will be to reduce $ $ to zero.\n🤔 Pop-up Question: In which era did the industrial standard for signal transmission shift towards 4 milliamperes to 20 milliamperes?\n\n1950s\n\n1960s\n\nModern Era\n\nBefore 1950s\n\nAnswer: c) Modern Era\n\n\n\n\n\n\nThe actuator is a control valve which is pneumatically operated. Since the output of the controller (e.g, a digital computer or analog electrical device) we need an interface between the output of the controller and the actuator. This is why we need the electropneumatic transducer.\n\n\n\n\nSideBar - Electropneumatic transducers\nAn electropneumatic transducer, often referred to as an “I/P converter” (Current-to-Pressure) or “E/P converter” (Electrical-to-Pneumatic), is a device that converts an electrical signal, usually a current or voltage, into a corresponding pneumatic output, typically in the form of air pressure.\n\n\n\n\n\nMore specifically:\n\nInput Signal: The most common input signal for I/P converters is the standard 4-20 mA current loop, though some models accept voltage signals like 0-5V or 0-10V.\nOutput Signal: The output is typically a pneumatic signal ranging from 3-15 psi (pounds per square inch), though other ranges like 3-27 psi or 6-30 psi are also possible, depending on the device and application.\nWorking Principle: Internally, the electropneumatic transducer uses a solenoid, a flapper/nozzle mechanism, or other electronic components to detect the incoming electrical signal. This signal is then used to control a pneumatic valve mechanism that modulates the output air pressure.\nApplications: Electropneumatic transducers are widely used in industrial control systems. They allow electronic control systems to interface with pneumatic actuators, valves, and other devices. For example, a PLC (Programmable Logic Controller) might use an I/P converter to control a pneumatic valve in a process plant. By sending different current values to the I/P converter, the PLC can open, close, or partially open the valve, depending on the required process condition.\nAdvantages:\n\nSafety: Pneumatic systems are inherently safer in certain explosive or flammable environments. By using an I/P converter, electronic control systems can safely interface with pneumatic devices in such areas.\nIntegration: They allow for easy integration of electronic and pneumatic systems, enabling more versatile and comprehensive control strategies.\n\nConsiderations: It’s essential to ensure that I/P converters are correctly calibrated, free from external vibration, and have a clean supply of air. Contaminated air or moisture can impact their performance or cause them to malfunction.\n\nIn short, electropneumatic transducers play a crucial role in bridging the gap between electronic control systems and pneumatic actuation, enabling precise control in a variety of industrial applications.\n— END OF SIDEBAR\n\n\nDeriving a Mathematical Model - Building a Block Diagrammatic Description Using Experimental Methods\nWe are poised to formulate the comprehensive mathematical model for our Temperature Control System.\nJust as we previously leaned on physical principles for equation derivation, experimental methods can also be employed for model identification. By conducting experiments, we can discern the transfer function models of distinct components, thereby enabling the creation of the mathematical model for the whole system.\n\nIdentifying the Process Parameters:\nLet’s start from the Plant, the Process itself.\nLet’s assume that the process can be approximated by a first-order system:\n\\[\nG_p(s) = \\frac{K_p}{\\tau_p s +1}\n\\]\n\nLet’s assume that the parameters $ K_p $ and $ _p $ of our model can be determined experimentally.\nSuppose the steam flow rate $ q_{ms} $ is $ A $ kilograms per second. This will be considered as our input:\n\n\\[ q_{ms} = A\\;\\; kg/sec \\]\nOutput Curve Representation:\nWhen this specific input is given, the experimentally obtained output can be plotted as $ $ versus $ $. The resultant curve might resemble that of a typical first-order process.\n\n\n\n\n\nFrom the steady state of this curve, we can denote $ _{ss} $ as the experimentally obtained steady state value. We can establish:\n\\[ K_p = \\frac{\\theta_{ss}}{A} \\]\nSecond, considering the transfer function, our goal is to determine the time constant. By analyzing the transient of this process reaction curve (or response curve), we can model it as:\n\\[ \\frac{\\theta(s)}{Q_{ms}(s)} = \\frac{K_p}{\\tau_p s + 1} \\]\nFor a unit step input or for an input of magnitude $ A $:\n\\[ \\theta(s) = \\frac{K_p \\cdot A}{s(\\tau_p s + 1)} \\]\nTaking the inverse Laplace transform, we get:\n\\[ \\theta(t) = K_p \\cdot A (1 - e^{-\\frac{t}{\\tau_p}}) \\]\nFrom which, it follows (given than $ K_p A = _{ss}$):\n\\[ \\theta(t) = \\theta_{ss} (1 - e^{-\\frac{t}{\\tau_p}}) \\]\nConsidering the slope at $ t = 0 $, we get:\n\\[ \\frac{d\\theta}{dt} \\Big|_{t=0} = \\frac{\\theta_{ss}}{\\tau_p} \\Big|_{t=0}\\]\nThis slope helps us understand the process reaction curve further.\n\n\n\n\n\nThis graphical representation facilitates the experimental determination of $ _p $. Consequently, we can represent our process transfer function $ G_p(s) $ as:\n\\[ G_p(s) = \\frac{K_p}{\\tau_p s + 1} \\]\nand with a simple experiment we can identify \\(K_p\\) and \\(\\tau_p\\).\nAn Industrial Example:\nConsider a heat exchanger experiment. The identified parameters were $ K_p = 50 $ and $ _p = 30 $, giving us the model:\n\\[ G_p(s) = \\frac{50}{30s + 1} \\]\nRemember, this model is valid when the temperature $ $ is the output and the steam flow rate is the input. It’s essential to recognize that other inputs, like disturbances in the process, can influence the process. For our heat exchanger, the disturbances are \\(q_m\\) (disturbance in the process flow rate), and \\(\\theta_i\\) (disturbance in the temperature of the process fluid inflow).\nThe other transfer functions can also be experimentally determined. For instance:\n\\[ \\frac{\\theta(s)}{Q_m(s)}: \\frac{1}{30s + 1} \\]\nThis means, that the gain is \\(1^oC\\) per \\(Kg/sec\\) of the input. The time constant is \\(30\\) sec. This in fact is the process time constant so it is what we identified before.\n\\[ \\frac{\\theta(s)}{\\theta_i(s)}: \\frac{3}{30s + 1} \\]\nThis represents when the input is a variation in temperature. The gain is, in this case \\(3^oC\\) of output per each degree centrigrade in the input. The time constant is \\(30\\) sec. This in fact is the process time constant so it is what we identified before.\n\n\n\n\n\nThe Electropneumatic Transducer and Control Valve:\nNext, we explore the Electropneumatic Transducer combined with the Control Valve. The transducer takes current as input and produces pressure as output. With a range of 4 to 20 milliamperes for current and 3 to 15 psi for pressure, the transducer gain is $ $ psi per milliampere (assuming that the device is linear in the range under consideration):\n\\[\nK_T = \\frac{15-3}{20-4} = \\frac{12}{16}\\;\\; \\text{psi/mA}\n\\]\nConsidering the control valve, a pressure of 3 to 15 psi leads to a flow output. For our system, the maximum flow is 1.6 kilograms per second (we have determined this, for example through experiments), leading to a control valve gain of $ $ kilograms per second per psi.\n\\[\nK_V = \\frac{1.6-0}{15-3} = \\frac{1.6}{12}\\;\\; \\text{kg/sec per psi}\n\\]\nWhen both units are taken together, we get the combined gain $ K_v $ as 0.1 kilograms per second per milliampere.\n\\[K_v = \\frac{12}{16}\\cdot\\frac{1.6}{12} = 0.1\\;\\; \\text{kg/sec per mA}\\]\nIf the time constant of the Electropneumatic Transducer and Control Valve can be neglected than this can be my entire model.\nDepending on the dynamics of the Electropneumatic Transducer and Control Valve and their relationship with the Process, we can represent their transfer function as:\n\\[ G_v(s) = \\frac{0.1}{3s + 1} \\]\nNote that in this case, experiments with the Electropneumatic Transducer and Control Valve have given a time constant of 3 sec.\nIf you think 3 sec is negligible relative to 30 sec than you can consider the simpler gain only model.\n\n\n\nThe Sensor Model\nWhen thinking about the sensor, we should consider its input and output. In our system: - Input: Temperature (\\(^oC\\)) - Output: Milliamperes (mA)\nSo, for the temperature control system we’re designing, we need to define the temperature range. For a typical application, this range is between 50°C to 150°C. Accordingly, the sensor’s output will range from 4 to 20 mA.\n🤔 Pop-up Question: What do you think will happen if the temperature goes below 50°C or above 150°C?\nAnswer: The sensor may not provide accurate readings, or it may operate outside its specified range, potentially causing inaccuracies or even damage.\nWith the above information, we can determine the sensor’s gain by observing its linearity over the defined range. Given:\n\\[ \\text{Output range} = 20 \\text{mA} - 4 \\text{mA} = 16 \\text{mA} \\]\n\\[ \\text{Input range} = 150°C - 50°C = 100°C \\]\nThe sensor gain (K) is given by:\n\\[ K = \\frac{\\text{Output range}}{\\text{Input range}} = \\frac{16}{100} = 0.16 \\]\nThus, the unit for the sensor gain is milliamperes per degree centigrade (mA/°C).\nHowever, merely considering the sensor’s gain might not give us the entire picture. Often, in real-world applications, the dynamics of the sensor can’t be ignored. Especially in scenarios where the sensor has an appreciable time constant. For instance, in our case, the sensor has a time constant of 10 seconds. Given the process time constant of 30 seconds, neglecting the sensor’s dynamics would be a poor approximation.\nIt’s essential to remember that considering only a zero-order model (only gain) won’t suffice in systems with significant time constants.\nConducting a similar experiment for our sensor, let’s represent its transfer function, H(s), as:\n\\[ H(s) = \\frac{0.16}{10s + 1} \\]\nThis represents a first-order factor for our sensor.\n\n\nComplete System Model\nWith the above information, we can construct a comprehensive block diagram for our temperature control system.\n(Insert Diagram here)\nIn the diagram, Gp(s) is the process transfer function, given by:\n\\[ Gp(s) = \\frac{50}{30s + 1} \\]\nThe disturbance transfer functions, which consider factors like changes in the inlet temperature (theta i) and changes in the flow rate of the inflowing fluid (q m), are:\n\\[ \\frac{1}{30s + 1} \\]\n\\[ \\frac{3}{30s + 1} \\]\nNow, let’s think about the control valve. Its transfer function, as determined earlier, is:\n\\[ \\frac{0.1}{3s + 1} \\]\nIn this system, our objective is to make the output temperature (theta) follow a particular command. The challenge lies in converting the command signal, given in temperature, to a corresponding current in milliamperes for error detection.\nIt’s crucial to understand that for effective error detection, the command signal and the sensor’s output must be in the same unit (mA).\nGiven that the sensor’s steady-state gain is 0.16 mA/°C, it makes sense to choose a scale factor of 0.16 for our system. This ensures that at steady state, the commanded signal’s value (in mA) matches the sensor’s output, facilitating effective error detection.\n\n\n\n\n\n\n\nWrapping Up\nThe values we’ve discussed pertain to a typical industrial process. However, with the methodology we’ve outlined, it’s possible to apply this to any situation. By identifying various transfer functions experimentally, we can construct a comprehensive model of the system.\nTo further refine our system, we can introduce a controller, \\(D(s)\\), in the loop. The design of this controller is crucial to ensure the output \\(\\theta\\) (temperature of the outflowing process fluid) follows the command (\\(\\theta_r\\)), despite any disturbances acting on the process, \\(\\theta_i\\) (change in inlet temperature) and \\(q_m\\) (change in the flow rate of the inflowing fluid).\n\n\n\n\n\n🤔 Pop-up Question: Why is it crucial to ensure that the sensor’s output and the command signal are in the same unit for error detection?\nAnswer: If they’re in different units, the comparison would be meaningless. It’s like comparing apples to oranges. Having them in the same unit ensures that any difference (error) between them accurately represents the deviation of the system from its desired behavior.\n\n\nSidebar - Scaling Factor in Feedback Systems\nIn a feedback control system, especially when working with sensors and actuators, there might be discrepancies between the units or magnitudes of the reference signal and the feedback signal. To make the two signals comparable, we sometimes need to introduce a scaling factor.\n\n\nWhy 0.16 as the Scaling Factor?\nGiven the context:\n\nSensor’s Behavior: The sensor in our system translates temperature into a current signal, producing an output in milliamperes (mA). The sensor’s steady-state gain, which indicates how much the output changes for a given change in input, is 0.16 mA/°C. In simpler terms, for every degree Celsius increase in temperature, the sensor’s output increases by 0.16 mA.\nObjective of Feedback Control: In our feedback control system, the goal is to make the process output (temperature) follow a reference or command signal. The error detector then compares the sensor’s output (a mA value) with this reference signal.\nUnit Consistency: The comparison in the error detector requires the two signals to be in the same unit. Since the sensor’s output is in mA, the reference signal (which is a desired temperature) needs to be converted into its equivalent in mA.\nMatching the Sensor’s Behavior: To ensure the reference signal in mA correctly represents the desired temperature, it’s logical to use the sensor’s steady-state gain as the scaling factor. When we desire a particular temperature as our reference, multiplying it by 0.16 (sensor’s gain) gives us the exact current value that the sensor would output at that temperature.\n\n\n\nAn Illustrative Example\nSuppose you set a reference temperature (\\(\\theta_r\\)) of 100°C. To convert this into a reference current for comparison:\n\\[ \\text{Reference current} = \\theta_r \\times \\text{Scaling Factor} \\]\n\\[ \\text{Reference current} = 100°C \\times 0.16 \\text{mA/°C} = 16 \\text{mA} \\]\nSo, when the process achieves 100°C, the sensor would ideally output 16 mA. The error detector would then see zero error between the reference current (16 mA) and the sensor’s output (16 mA), indicating the system is operating at the desired condition.\nIn conclusion, using the sensor’s steady-state gain as the scaling factor ensures that the error detector compares apples to apples. This is vital for the proper functioning of the feedback system, ensuring that the control actions are based on meaningful comparisons.\n— END OF SIDEBAR\nIn the next notebooks, we’ll explore the intricacies of controller design and understand how to tailor it to our specific needs. This will ensure that our temperature control system operates optimally under various conditions.",
    "crumbs": [
      "A Feedback Control System"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Principles of Automatic Control",
    "section": "",
    "text": "Welcome to the course on Principles of Automatic Control. In this series of interactive Jupyter notebooks, we’ll discuss the fundamental principles, concepts, and terminologies used in the field of control engineering.",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "intro.html#introduction-to-control-systems",
    "href": "intro.html#introduction-to-control-systems",
    "title": "Principles of Automatic Control",
    "section": "Introduction to Control Systems",
    "text": "Introduction to Control Systems\nControl engineering or control systems engineering deals with designing systems to behave in a desired manner. Today, control systems are integral to our daily lives, and they have a vast range of applications.\n\nControl System Terminology\nIn our initial discussions, we’ll focus on the terminologies used in control systems. It’s crucial to get acquainted with these terms to have a clear understanding of the subsequent topics.\nLet’s begin!\n\n\nThe Role of Control Systems in Modern Technology\nControl systems play a key role in the development of modern civilization and technology. Examples abound in daily life:\n\nDomestic Appliances: Home heating systems, refrigerators, air conditioners, automobiles.\nIndustrial Applications: Inventory control, automatic assembly lines, machine tool control.\nAdvanced Technology: Space technology, weapon systems, robotics, power plants.\n\nThese systems ensure efficient, reliable, and safe operations in various sectors.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeedback control theory, which we will be focusing on in this course, is also utilized in inventory control and socio-economic systems.\nWhile our primary focus will be on engineering systems, where the system to be controlled obeys specific physical laws.\nIt’s essential to note that control system can be also applied to socio-economic and biological systems (cybernetics), but we will not discuss them in this course.\n\n\nHistorical Context and Evolution\nThe application of control techniques began primarily in process control during the early 20th century (1900-1940). The Second World War accelerated the development of control systems with the advent of automatic airplane pilots, gun positioning systems, radar, and antenna control systems.\nThis period marked the birth of servomechanisms, derived from “servo” (meaning slave or servant) and “mechanism”, indicating a system responding to commands. This convergence of disciplines led to the unified feedback control theory we study today.\n\n\nBasic Control System Terminologies\nBefore we move forward, let’s define some of the basic terminologies used in control systems:\n\n1. The Process or Plant or Controlled System\n\nDefinition: The system that is being controlled. It can be any system, machine, or process that needs automated control.\nExamples in Industries: Chemical, petroleum, steam power, etc., where control of temperature, pressure, liquid level, humidity, and composition is required. These applications are often referred to as “process control applications.”\n\n\n\n2. Response or Controlled Variable\n\nDefinition: The output or the variable of the process we aim to control.\nExample: Temperature in a heating system.\n\n\n\n3. Manipulated Variable\n\nDefinition: The variable adjusted by the controller to influence the response variable.\nExample: The valve position in a heating system to regulate heat flow.\n\n\n\n4. Controller\n\nRole: To adjust the manipulated variable to ensure the controlled variable follows the set commands.\n\n\n\n5. Disturbance\n\nCharacteristics: An unwanted, uncontrollable, often random signal that affects the process. This signal is beyond our control.\nSources: External environmental factors or internal process changes.\nExample: Ambient temperature fluctuations affecting a heating system (external); Parameter changes with time (internal)\n\n\n\n\nBlock Diagram Representation\nTo understand how a basic control system operates, it’s beneficial to use a block diagram representation.\n\n\n\n\n\n\n\n\nor we can also see the command signal as coming to a single block, which produces the response variable:\n\n\n\n\n\n\n\nFigure: Block diagram representing the basic control system structure and it main components and signals.\nNote that although the disturbance is visualised as a signal coming from outside, it might be an internal change (e.g., parameter change).\nThis latter block diagram shows the our objective is to have a response variable that follows the set commands. Let’s now see how we can achieve this objective.\n\n\nOpen-Loop Control System\n\nStructure: The controller receives the command signal and adjusts the manipulated variable accordingly, regardless of any disturbances.\nLimitation: Lack of feedback; the system does not adapt to disturbances or changes in the process.\n\nHowever, such a system can be vulnerable to disturbances. If a random disturbance affects the system, and the controller isn’t aware of this change, it may fail to make the response variable follow the command.\n\n\nClosed-Loop Control System\nTo tackle this, a more intelligent system, known as the “closed-loop control” system, is utilized. Here, the controller receives feedback from the response variable, allowing it to adjust the manipulated variable in real-time and ensuring the output closely follows the command, even when disturbances occur.\n\nThe Intelligence of Closed-Loop Systems\nThe closed-loop system continuously monitors the process it controls and makes real-time adjustments to keep things running smoothly. Here’s how it works:\n\nFeedback Mechanism: The controller in a closed-loop system is constantly informed about the current state of the process (the response variable). This continuous stream of feedback is the system’s way of keeping its finger on the pulse.\nDynamic Adjustment: Based on this feedback, the controller makes immediate adjustments to the manipulated variable – the component of the system that directly influences the output.\n\n\n\nDealing with Disturbances\nIn an ideal scenario, if we could predict every disturbance, we could pre-emptively adjust our systems to counteract them. But in reality, disturbances are often random and unpredictable. This is where the closed-loop system’s ability to measure and react comes into play:\n\nWhen a disturbance affects the process, this impact is reflected in the response variable.\nBy measuring this variable, the system indirectly gathers information about the disturbance.\nThe controller then compares the actual output (controlled variable) with the intended output (command signal) and identifies any discrepancies.\nThis comparison produces an error signal, which the controller uses to generate a corrective control signal. This signal is fed back into the process, reducing the error towards zero.\n\nFeedback control systems are key in various sectors due to their error-minimizing capabilities. They operate on a straightforward yet effective principle: use feedback to reduce the gap between what is desired (the command signal) and what is actually happening (the actual output).\n\n\nComponents of a Closed-Loop Control System\n\nSensor: This component measures the controlled variable, effectively taking the system’s temperature.\nComparator: Acting as a judge, it compares the sensor’s readings with the desired command signal.\nController: Based on the comparator’s findings, the controller alters the manipulated variable to correct any errors.\n\n\n\n\n\n\n\n\nDiagram: A block diagram representing the closed-loop control system. The structure illustrates the feedback from the response variable to the controller.\n\n\n\nStructure of Feedback Control Systems\nThe mechanism of a feedback control system is an error self-nulling process.\nThe system continually checks for discrepancies between the desired command and the actual output, employing controller actions to mitigate these errors. Such a system is commonly known as a closed-loop system due to its looped structure, facilitating the feedback process.\nThe components of this system can be understood as follows:\n\nCommand Signal: The desired output or set point.\nControlled Variable: The actual output of the system.\nError Signal: Difference between the command signal and controlled variable.\nController: It processes the error signal to produce the control signal.\nPlant: The actual system being controlled.\nSensor: Measures the output of the plant\n\n\n\nChallenges in Feedback Control System\nDespite their effectiveness, closed-loop systems present specific challenges:\n\nSensor Noise: One of the primary sources of challenges in the feedback control system is the sensor. The inclusion of the sensor, which was absent in open-loop systems, presents its own set of problems:\n\nNoise: The sensor might introduce noise, especially at high frequencies, during measurement. This noise can disrupt the proper functioning of the plant and the controller, thereby reducing the system’s efficiency.\nSolutions to Noise: Installing suitable noise filters can address this issue, ensuring that the high-frequency noise does not interfere with the operation of the loop.\n\nController Requirements: A significant aspect of the feedback system is its controller.\n\nThe controller’s primary aim is to render the system robust. A robust system implies that the controlled variable closely follows the command signal, even in the presence of external disturbances or variations in plant parameters. Achieving this requires a careful balance between system accuracy and stability, a delicate trade-off that forms the core of feedback control theory.\nThe objective is for the controlled variable to follow the command. This means that the controller in a closed-loop system should achieve:\n\nAccuracy at Steady State: Minimizing the long-term error between the controlled variable and the command signal.\nSpeed of Response: Responding quickly to changes in the command or disturbances.\n\n\nStability Concerns (Trade-off Between Accuracy and Stability):\n\nAs we strive for increased system accuracy, stability might get compromised. This trade-off is an inherent challenge of the feedback structure. Feedback control theory and its designs aim to strike a balance between these conflicting requirements.\n\n\n\n\nFeedback Control Advantages\nFeedback control systems are indispensable, primarily due to their robust nature. Despite their associated challenges, their ability to filter disturbances and adjust to parameter variations makes them superior to open-loop systems. Without feedback control structures, it would be challenging to achieve system accuracy effectively.\n\n\n\nExample\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\n\ndef open_loop_system(y, t, K, tau):\n    \"\"\"Open-loop system model.\"\"\"\n    u = 1  # step input\n    if 3 &lt;= t &lt;= 8:  # Adding a disturbance between time 3 and 5\n        u += 1.0\n    dydt = (-y + K * u) / tau\n    return dydt\n\ndef closed_loop_system(states, t, K, tau, Ki, Kd):\n    \"\"\"Closed-loop system model with PID control.\"\"\"\n    y, e_prev, e_int = states  # y is system output, e_prev is previous error, e_int is integral of error\n    setpoint = 1  # desired setpoint\n    disturbance = 0\n    \n    if 3 &lt;= t &lt;= 5:  # Adding a disturbance between time 3 and 5\n        disturbance += 1.0\n        \n    # Error\n    e = setpoint - y\n    \n    # PID Controller\n    u = K * e + Ki * e_int + Kd * (e - e_prev)\n    \n    dydt = (-y + u + disturbance) / tau  # Disturbance is added directly to the system dynamics\n    deintdt = e  # Integral of error over time\n    dedt = e - e_prev\n    \n    return [dydt, dedt, deintdt]\n\n\n# System parameters\nK = 2.5\ntau = 1.0\nKi = 1.0  # Integral gain\nKd = 0.5  # Derivative gain\n\n# Time array\nt = np.linspace(0, 10, 100)\n\n# Solve ODE for the open-loop system\ny_open = odeint(open_loop_system, 0, t, args=(K, tau))\nerror_open = 1 - y_open.squeeze()  # desired setpoint is 1, so error is 1 - output\n\n# Solve ODE for the closed-loop system\ninitial_conditions = [0, 0, 0]  # initial values for y, e_prev, and e_int\ny_closed, error_closed, _ = odeint(closed_loop_system, initial_conditions, t, args=(K, tau, Ki, Kd)).T\n\n# Plot Responses\nplt.figure(figsize=(10,6))\nplt.subplot(2, 1, 1)\nplt.plot(t, y_closed, 'r-', label='Closed-loop Response (PID)')\nplt.plot(t, y_open, 'b--', label='Open-loop Response')\nplt.ylabel('Response')\nplt.title('Control System Response with Disturbance')\nplt.legend()\nplt.grid()\n\n# Plot Errors\nplt.subplot(2, 1, 2)\nplt.plot(t, error_closed, 'r-', label='Closed-loop Error (PID)')\nplt.plot(t, error_open, 'b--', label='Open-loop Error')\nplt.xlabel('Time')\nplt.ylabel('Error')\nplt.title('Control System Errors with Disturbance')\nplt.legend()\nplt.grid()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe system we’re simulating is a basic first-order system. It’s one of the simplest dynamical systems used often as a foundational building block in control theory. The equations governing its dynamics, in general, look like:\n\\[\n\\tau \\frac{dy(t)}{dt} + y(t) = Ku(t)\n\\]\nHere: - \\(\\tau\\) is the time constant of the system. It gives an idea of how fast the system responds to changes in the input. - \\(K\\) is the system gain. It tells you how much the system output changes for a given change in the input. - \\(u(t)\\) is the system input at time \\(t\\). - \\(y(t)\\) is the system output at time \\(t\\).\nThe open-loop system directly acts on the system with the input \\(u(t)\\). There’s no feedback, so if there’s a disturbance or the system isn’t behaving as expected, the open-loop system cannot correct for it.\nThe closed-loop system, on the other hand, uses feedback. The system output \\(y(t)\\) is constantly measured and compared to the desired setpoint to determine the error. A controller then adjusts the system input \\(u(t)\\) based on this error to make the system output match the desired setpoint. This allows the closed-loop system to correct for disturbances and system behavior that deviates from the desired behavior.\nIn our specific simulation: - The open-loop system was modeled to show how it reacts directly to an input and a disturbance without any feedback mechanism. - The closed-loop system was modeled using a simple proportional controller with a derivative term. The controller tries to minimize the error, which is the difference between the desired output (setpoint + disturbance) and the actual system output. This allows the closed-loop system to correct when there’s a disturbance or other unexpected behavior.\nWith this feedback mechanism, the controller can dynamically adjust and correct any deviations, ensuring the system remains stable and performs as desired.",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "intro.html#design-approaches-for-feedback-control-systems",
    "href": "intro.html#design-approaches-for-feedback-control-systems",
    "title": "Principles of Automatic Control",
    "section": "Design Approaches for Feedback Control Systems",
    "text": "Design Approaches for Feedback Control Systems\nDesigning an effective controller is paramount. There are various approaches to this, and they can be categorized as follows:\n\nExperimental Approach (Controller Tuning):\n\nMethod: Adjusting the controller based on practical experience and real-time feedback. A controller is installed based on past experiences and then adjusted in real-time until the desired results are achieved.\nUse Case: Commonly used in process control where accurate process models are hard to obtain or very complex (e.g., highly non-linear plants).\nNature: It’s an ad-hoc approach, relying more on empirical knowledge than theoretical models.\n\nModel-Based Approach (Analytical Approach):\n\nMethod: Developing a mathematical model of the system (differential equations, transfer functions, state variable models) and designing the controller based on this model.\nUse-case: This is a methods used for complex systems where control requirements are tight, a model-based approach is more suitable. Here, the system’s dynamics are captured in a mathematical model, which is then used to design the controller analytically.\nAdvantage: Provides a more precise control, especially for complex systems.\n\nKnowledge-Based or Data-Based Approach:\n\nRecent Trends: Includes methods like expert control, fuzzy control, neural networks, and reinforcement learning. The core idea is to utilize qualitative guidelines or rules derived from expert knowledge (either an expdert user or data) to design the controller.\nApplication: Becoming increasingly popular in industrial applications.\n\n\nFor the scope of this course, we will primarily focus on the model-based control. This involves deriving a mathematical model of the physical system, which can be based on physical laws or experimentation.\n\nApproach\nFor a physical system we will obtain a methematical model. This can be derived:\n\nUsing Physical Laws: Deriving differential equations based on the physical principles governing the system, which can then be translated into a more convenient representation, e.g., transfer functions or state-space variables.\nPerforming Experimentation: Conducting experiments to determine input-output relationships and modeling these using suitable mathematical forms, for example, transfer functions. This is called system identification.",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "intro.html#historical-context",
    "href": "intro.html#historical-context",
    "title": "Principles of Automatic Control",
    "section": "Historical Context:",
    "text": "Historical Context:\nThe evolution of control design methods can be broadly categorized into two main eras:\n\nClassical Control Design (1940-1960): This period witnessed the development of frequency domain design methods. Techniques like Nyquist Stability methods, Bode plots, and Root Locus plots emerged. They are still very much in use, especially in industrial control applications (servo mechanism development).\nModern Control Design (1960s onwards): Space vehicle control requirements gave birth to state-space techniques, known as Modern Control Design. While these methods are termed “modern,” it’s crucial to understand that both classical and modern methods are still prevalent and critical in their respective applications.\n\nThe term “modern control design” might be a bit misleading. It emerged primarily from the specific requirements of tracking in space vehicles. Yet, in the realm of industrial control, the classical methods of design are still widely prevalent. In fact, about 75% of today’s industrial control problems are addressed using these classical techniques.\nWhile modern methods have their origins and advantages, particularly in specialized applications like space vehicles, it is still debatable which method offers more robustness. Robustness, after all, is the primary requirement for most systems.\nThis ongoing debate makes it imperative to forgo the terminology of classical and modern control, as both are equally relevant depending on the application.\nFor the scope of this course, our primary concentration will be on the frequency domain methods of design. This will provide you with a comprehensive understanding of the foundational methods in control design.\nHowever, we won’t neglect the state variable methods altogether. Instead, they’ll be introduced not from a design perspective but rather for system simulation. System simulation, when approached through state variable formulation, can be more intuitive and effective.",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "intro.html#illustrative-examples-of-control-systems",
    "href": "intro.html#illustrative-examples-of-control-systems",
    "title": "Principles of Automatic Control",
    "section": "Illustrative Examples of Control Systems",
    "text": "Illustrative Examples of Control Systems\nIt’s often helpful to relate theoretical concepts to real-world examples. This helps in understanding the broader applications and nuances of control systems in everyday life.\n\nExamples of Controlled Systems:\n\nBathroom Toilet Tank: A seemingly simple system, but it is, in essence, a feedback control mechanism.\nAutomobile Driving: Encompasses various control systems, from speed regulation to power steering.\nResidential Heating: Thermostats and HVAC systems rely on feedback to maintain desired temperatures.\nHydraulic Steering Mechanism: A critical component for many heavy-duty vehicles and systems.\nAntenna Servo System: Used for tracking and communications.\nSpeed Control System: Found in various machines, from industrial setups to home appliances.\n\nWe will delve further into these examples, framing them within the context of feedback control systems. By doing so, we aim to provide a deeper understanding of how these principles are applied in practical scenarios.\n\n\n\n\n\n\n\n\nSpaceX Nails Landing of Reusable Rocket on Land, From Bloomberg Technology\n\n\n\n\n\n\n\n\n\n\n\n\nSpaceX Nails Landing of Reusable Rocket on Land (close up)\n\n\n\n\n\nWhere does Control System Engineering come into place?\n\nAttitude control\nLanding control\nTrajectory tracking\nLand control (e.g., antennna tracking)\n\n\n\n\n\n\n\n\nAutonomous Ferries (Rolls-Royce)\n\n\n\n\n\n\n\n\n\n\n\n\nAtlas (Boston Dynamics)",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "intro.html#conclusions",
    "href": "intro.html#conclusions",
    "title": "Principles of Automatic Control",
    "section": "Conclusions",
    "text": "Conclusions\nFeedback control systems form the backbone of many modern engineering applications. The ability to provide a mechanism to automatically adjust system behavior based on feedback from outputs makes these systems indispensable. However, the design and implementation of these systems require a comprehensive understanding of their structure, challenges, advantages, and the various approaches available. In subsequent chapters, we’ll delve deeper into each of these aspects, providing a more detailed look at the intricacies of feedback control systems.",
    "crumbs": [
      "Principles of Automatic Control"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html",
    "href": "hardware_and_case_studies.html",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "",
    "text": "In this notebook, we’ll introduce the hardware components commonly found in control systems, particularly in the industrial sector. While we won’t delve into exhaustive detail about each component, our goal is to provide a clear understanding of their basic characteristics and how they influence a given control system’s behavior.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#case-study-speed-control-system",
    "href": "hardware_and_case_studies.html#case-study-speed-control-system",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Case Study: Speed Control System",
    "text": "Case Study: Speed Control System\nTo kickstart our exploration, let’s consider a speed control system. In this system, the primary objective is to control the speed of a load. We’ll use this example to showcase the various components involved and their interactions.\n\nSystem Overview:\nImagine a scenario where you wish to control the speed of a specific load, represented by parameters \\(J\\) (moment of inertia) and \\(B\\) (viscous friction). This load is subjected to a disturbance torque, \\(T_w\\).\nOur goal is to ensure that the load maintains a specified speed, \\(\\omega\\), even in the presence of disturbances.\n\n\n\n\n\n\n\nComponents and their Roles:\n\nActuator (Motor and Power Amplifier):\n\nThe actuator provides the necessary torque to drive the load at the desired speed, \\(\\omega\\).\nIt comprises a motor combined with a power amplifier.\nThe actuator receives a control signal, \\(u\\), from a controller.\n\nController (Amplifier):\n\nIn this basic setup, the controller is a simple amplifier. However, in more advanced configurations, it could be a complex system involving the derivative or integral of an error signal.\nThe controller’s primary role is to process the error signal and produce an appropriate control signal, \\(u\\).\nWe will see how to design controllers later\n\nReference Input Elements (Potentiometer):\n\nThis component provides the reference signal, \\(e_r\\), which corresponds to the required commanded speed, \\(\\omega_r\\) (not shown in the diagram). We would like \\(\\omega \\rightarrow \\omega_r\\)\nBy adjusting the position of the potentiometer’s wiper arm, one can change the reference signal, thereby commanding a different speed.\n\nFeedback Element (Tachogenerator):\n\nThe tachogenerator senses the actual speed, \\(\\omega_r\\), and produces a feedback signal, \\(e_t\\), that’s proportional to this speed.\nThis feedback signal is essential to compare the actual speed with the desired speed and generate an error signal.\nThe difference between \\(e_r\\) (proportional to controlled variable) and \\(e_t\\) (proportional to commanded variable) provides the actuating error signal \\(\\hat{e}\\).\nThe actuating error signal \\(\\hat{e}\\) is amplified through the controller to generate the control signal \\(u\\) and provided to the actuator that runs the load.\n\n\nKeep in mind that the primary goal of controller design is to adjust it appropriately to meet specific objectives. While other components, like the motor, remain constant and may not be easily modified, it’s more practical and efficient to alter the controller settings.\n\n\nBlock Diagram Representation:\nThe physical system can be abstracted into a block diagram to visualize the feedback structure and the fundamental elements in a more structured manner.\n\n\n\n\n\n\n\nThe feedback element, such as the tachogenerator (with constant \\(K_T\\)), provides real-time information about the system’s current state (in this case, the actual speed). This feedback allows the controller to compare the actual speed with the desired speed and make necessary adjustments to reduce any discrepancies.\nCompare the control structure with the feedback control loops that we discussed before (from \\(e_r\\) to \\(\\omega\\)). This is a non-unity feedback structure.\nThe transfer function of the sensor (the tachogenerator) is \\(K_T\\).\nThis configuration can be converted into a unity-feedback format to facilitate analysis and design, all while preserving the vital details of the system. For this conversion to be effective, the block bridging $ _r $ and $ e_r $ should possess a transfer function equivalent to $ K_T $. Or in other words, the potentiometer’s constant, \\(K_P\\), should be set equal to the tachogenerator’s constant, \\(K_T\\).\nThe actuation error signal is \\(\\hat{e} = e_r - e_t\\). This is a voltage signal. The unit is Volts, not radians per seconds. These Volts will be proportional to the error in speed if and only if \\(K_P=K_T\\). This is the job of the control engineer! You can set the constant of the potentiometer.\nThe reference input element might not be physically present in the system (like the tachogenerator) but I still have the block in the diagram because it explains the working of the system!\n\nWe can now re-write the block diagram as the equivalent unity feedback\n\n\n\n\n\n\n\nThis diagram has the same equations of the previous one. This is an equivalent block diagram representation which holds the same mathematical relationship as the original block diagram between \\(\\omega\\) and \\(\\omega_r\\).\nFor this block diagram, \\(e\\) represents the system error — the difference between the commanded and the actual speed.\nA unity feedback system turns out to be more convenient for analysis and design.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#analyzing-the-motor-block",
    "href": "hardware_and_case_studies.html#analyzing-the-motor-block",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Analyzing the Motor Block",
    "text": "Analyzing the Motor Block\nLet’s delve deeper into the dynamics of the motor and its representation in block diagrams to complete the previous block diagram.\nThe armature-controlled motor is a specific type of motor where the speed is controlled by varying the voltage across its armature. A schematic is reported in the picture below:\n\n\n\n\n\n\nFigure from Control Systems Principles and Design\n\nThe non-turning part (called the stator) has magnets which establish a field across the turning part (called the rotor).\nThe magnets may be electromagnets or, for small motors, permanent magnets. In an electromagnet motor, the stator is wound with wire and current is forced through this winding (called the field winding). For a constant field current \\(i_f\\), the magnetic flux \\(\\phi\\) is constant, and the magnetic flux may be varied by varying the field current.\nThe rotor is wound with wire and through this winding (called the armature winding) a current \\(i_a\\) is forced through the (stationary) brushes and the (rotating) commutator. The reaction of the magnetic flux \\(\\phi\\) with the armature current \\(i_a\\) produces a torque \\(T_M\\) that forces the armature to rotate. The relationship among the developed torque \\(T_M\\) (newton-m), flux (webers) and current \\(i_a\\) (amps) is:\n\n\\[\nT_M = K_T i_a\n\\]\n\nAs the armature rotates in the magnetic field, a voltage is induced into the armature winding.\nThis voltage is 180° out of phase with the applied armature voltage and is therefore called back emf.\nThe relationship among the back emf \\(e_b\\), (volts), rotor velocity \\(\\omega\\) (rad/sec) and flux \\(\\phi\\) (webers) is:\n\n\\[\ne_b = K_b\\phi\\omega\n\\]\nIn a permanent-magnet motor the flux \\(\\phi\\) is constant; the torque exerted on the motor roto can therefore be controlled by varying the armature current (through \\(T_M = K_T i_a\\)). If the direction of the armature current is reversed, the torque is reversed.\nIn a wound-field motor (electromagnet motor), the torque can be controlled by varying the armature current and/or the field current. In this case,\n\\[\nT_M = K_{Tf} i_f i_a\n\\]\nFor a wound-field motor, the back emf is:\n\\[\ne_b = K_{bf}i_f\\omega\n\\]\nIn general one of these is varied and the other is held constant. In the armature control mode, the field current is held constant, and \\(i_a\\) (armature current) is used to control the torque. In the field-control mode, the armature current is held constant, and \\(i_f\\) (field current) is used to control the torque.\n\n\n\n\n\n\n\nMotor’s Components\n\nArmature: The armature is the primary rotating component of the motor. It carries the current (often referred to as the armature current, \\(i_a\\), which interacts with the magnetic field produced by the field windings. This interaction between the current and the magnetic field results in a torque that causes the armature to rotate. The voltage across the armature (\\(e_a\\)) and the current through it (\\(i_a\\)) determine the speed and torque of the motor.\nField Windings: These are coils wrapped around the motor’s stator, which produce a magnetic field when energized. When current passes through the field windings, it produces a magnetic field. In an armature-controlled motor, the field current (\\(i_f\\)) is typically held constant, ensuring a consistent magnetic field.\n\n\nThe strength of the magnetic field generated by the field windings affects the motor’s torque and speed.\nBy varying the field current, one can control the motor’s characteristics, especially in field-controlled motors.\n\n\nBack EMF (\\(e_b\\)), (Electromotive Force): As the armature rotates, it induces a voltage that opposes the applied armature voltage. This induced voltage is called the back EMF (\\(e_b\\)).\n\n\nIt acts as a natural feedback mechanism: as the motor speed increases, the back EMF increases, which in turn reduces the net voltage across the armature and thus limits the speed.\nIt’s directly proportional to the motor’s speed.\nThe back EMF plays a crucial role in stabilizing the motor’s speed. Understanding its dynamics is essential for designing controllers that can efficiently regulate motor speed, especially in armature-controlled motors.\n\nThe motor in our control system is characterized by:\n\napplied armature voltage, \\(e_a\\)\nits armature resistance, \\(R_a\\)\nand current \\(i_a\\).\n\nWhen it runs, it produces a torque \\(T_M\\). This torque, along with a disturbance torque \\(T_W\\), acts on the motor shaft.\n\nCommutator A commutator is essential in a direct current (DC) motor because it serves the function of switching the direction of current through the motor’s windings as the armature rotates. This switching is necessary to maintain a continuous rotational motion.\n\nRotation Principle: In a DC motor, the armature (the rotating part) is placed within a magnetic field created by the stator (the stationary part). When electric current flows through the armature windings, it generates a force (as described by Lorentz’s law) that acts perpendicular to both the magnetic field and the current, causing the armature to rotate.\nContinuous Rotation: For continuous rotation, the direction of the current in the armature windings must be reversed every half turn (180 degrees). Without this reversal, the armature would stop moving when it aligns with the magnetic field because the forces on both sides of the armature would balance out.\nFunction of the Commutator: The commutator, attached to the armature’s shaft, rotates with the armature. It consists of segments connected to different parts of the armature windings. Brushes, stationary conductive contacts, supply current to the commutator. As the commutator rotates, the connections between the windings and the external electrical circuit are reversed at the precise moment necessary to maintain the rotation direction of the motor. This ensures that the torque direction remains constant, allowing for continuous rotation.\n\n\n\n\nArmature controlled motor model\nLet’s slightly revised the previous diagram to explicit the presence of the Back EMF.\n\n\n\n\n\n\nWe can also notice that in a simplified model, the armature inductance can be neglected. In many scenarios, especially at steady state, the effects of armature resistance and back EMF dominate over the transient effects of armature inductance. Also, the armature inductance (\\(L_a\\)), and resistance (\\(R_a\\)), together define an electrical time constant for the motor, given by \\(\\tau_e=\\frac{L_a}{R_a}\\). For many motors, especially smaller ones, this electrical time constant is much smaller than the mechanical time constant (defined by parameters like the motor’s inertia and friction). If the system’s response or the control strategy doesn’t operate on a timescale where this electrical time constant is significant, it can be neglected.\nIn this case, we can establish the following key relationships:\n\nThe armature current is influenced by the difference between the applied voltage and the back EMF, divided by the armature resistance:\n\n\\[\n\\begin{align}\ni_a = \\frac{e_a-e_b}{R_a}\n\\end{align}\n\\]\n\nThe field current \\(i_f\\) is constant, and \\(i_a\\) depends on the applied voltage \\(e_a\\). However, the torque produced by the motor (\\(T_M\\)) is proportional to the product of the two fluxes, and hence of the two currents. Since the \\(i_f\\) is kept constant, we can say that the torque produced by the motor is proportional to armature current:\n\n\\[\n\\begin{align}\nT_M = K_T \\times i_a\n\\end{align}\n\\]\nWhere \\(K_T\\) is the torque constant of the motor.\nThe motor is called armatured controlled because we are controlling the armature current \\(i_a\\) through the applied voltage \\(e_a\\), and this makes it possible to control the speed of the motor.\n\nThe back EMF is proportional to the speed of the motor:\n\n\\[\n\\begin{align}\ne_b = K_b \\times \\omega\n\\end{align}\n\\]\nWhere \\(K_b\\) is the back EMF constant.\n\nFactor in External Forces and Torques\n\nThe torque \\(T_m\\) is driving the load and we can write a force balance equastion, accounting for external influences like the disturbance torque \\(T_W\\), the inertial torque due to the motor’s inertia \\(J\\), and frictional torque due to viscous friction \\(B\\):\n\\[\n\\begin{align}\nT_M = J\\dot{\\omega} + B\\omega + T_W\n\\end{align}\n\\]\n\nRepresenting in a Block Diagram\nHaving understood the relationships and equations governing the motor’s dynamics, we can represent these in a block diagram.\nThe input signal is \\(e_a\\), which we can transform to \\(E_a(s)\\).\n\n\n\n\n\n\n\nThe feedback loop is inherent in the motor operation, and an important characteristic of the armature controlled motors. It provides damping.\nThe back EMF opposes the applied armature voltage, affecting the armature current and, consequently, the speed and torque of the motor. It also introduces an inherent feedback loop in armature-controlled motors, influencing the motor’s dynamic response.\n\n\n\nDerive the Transfer Function\nCombining the above relationships and equations, we derive the transfer function for the motor, relating the output speed \\(\\omega\\) to the input armature voltage \\(e_a\\). If we set the \\(T_W=0\\), we obtain:\n\\[\n\\begin{align}\n\\frac{\\omega(s)}{E_a(s)} = \\frac{\\frac{K_T/R_a}{Js+B}}{1+\\frac{K_bK_T/R_a}{Js+B}} = \\frac{K_T/R_a}{Js + B + K_bK_T/R_a}\n\\end{align}\n\\]\nThis transfer function is crucial as it gives us a mathematical model of the motor’s dynamics, which can be used for analysis and design purposes.\nWe can port this transfer function into a standard first-order form:\n\\[\n\\begin{align}\n\\frac{\\omega(s)}{E_a(s)} = \\frac{K_m}{\\tau_m s + 1}\n\\end{align}\n\\]\nwhere:\n\\[\n\\tau_m = \\frac{J}{B+K_bK_T/R_a}\n\\]\n\\[\nK_m = \\frac{K_T/R_a}{B+K_bK_T/R_a}\n\\]\n\n\nComments on the Motor Inherent Feedback\nOne of the unique features of the armature-controlled motor is the inherent feedback loop due to \\(K_b\\).\n\nThe back EMF \\(e_b\\) is a voltage that’s generated in the armature windings of a motor when it is turning. It opposes the applied voltage \\(e_a\\), and its magnitude is proportional to the speed of the motor. The constant of proportionality is often denoted as \\(K_b\\).\n\\(K_b\\) increases the value of \\(B\\) and hence increases the effective damping of the motor. When the motor speeds up, the back EMF increases. This increased back EMF opposes the applied voltage more strongly, effectively reducing the net voltage across the armature. This, in turn, reduces the armature current, which then decreases the torque produced by the motor. This behavior acts as a natural damping mechanism, slowing the motor down when it tries to run too fast.\nThis inherent feedback provides the required damping, ensuring quick damping of oscillations and faster steady-state response.\nThis is not available in all the motors (e.g., the field controlled motors).\nNote also that the time constant of the motor decreases when \\(K_b\\) increases, leading to a faster response (i.e., gets to its state value quicker).\n\n\nSidebar - how does the back EMF affect damping\nRemember the motor’s equations:\n\\[\n\\begin{align}\ni_a = \\frac{e_a-e_b}{R_a}\n\\end{align}\n\\]\n\\[\n\\begin{align}\nT_M = K_T \\times i_a\n\\end{align}\n\\]\n\\[\n\\begin{align}\ne_b = K_b \\times \\omega\n\\end{align}\n\\]\n\\[\n\\begin{align}\nT_M = J\\dot{\\omega} + B\\omega + T_W\n\\end{align}\n\\]\nSubstituing in equation (2), the expression for \\(i_a\\) from (1) and then the expression for \\(e_b\\) from (3):\n\\[\n\\begin{align}\nT_M = K_T \\times \\frac{e_a-e_b}{R_a} = K_T \\times \\frac{e_a-(K_b\\omega)}{R_a}\n\\end{align}\n\\]\nThe torque produced by the motor must balance out the torques resisting the motor’s motion, which we can now write as:\n\\[\nK_T \\times \\frac{e_a-(K_b\\omega)}{R_a} = T_M = J\\dot{\\omega} + B\\omega + T_W\n\\]\nThe back EMF does not directly entes the torque equation, it affects the armature current, which in turn affects the torque produced by the motor. The back EMF’s influence on the torque is indirect, through its influence on the armature current.\n– END OF SIDEBAR\nPop-up Question: If the constant \\(K_b\\) were to increase (meaning the motor generates more back EMF for a given speed), would the motor be more damped or less damped?\nAnswer: The motor would be more damped. An increase in \\(K_b\\) means that for any given speed, the back EMF would be larger, opposing the applied voltage more strongly, and thus increasing the damping effect in the system.\n\n\n\n\nRevisiting the Original System\nLet’s return to the primary system where we integrate the motor and derive the overall transfer function.\n\n\n\n\n\n\n\nUsing block diagram reduction methods (e.g., signal flow graphs or directly) it becomes easy to obtain the overall transfer function between any signal of interest.\nIn general:\n\\[\n\\omega(s) = M(s)\\omega_r(s) + M_W(s)T_W(s)\n\\]\nQuestion (Popup): Why do we use \\(\\omega_r\\) instead of \\(e_r\\) in our block diagram representation?\nAnswer: \\(\\omega_r\\) is used because, for the purpose of analysis and design in the block diagram, it provides an equivalent representation. It’s about mathematical equivalency rather than physical connection.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#understanding-the-block-diagram",
    "href": "hardware_and_case_studies.html#understanding-the-block-diagram",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Understanding the block diagram",
    "text": "Understanding the block diagram\n\nThe reference input \\(e_r\\) represents the desired position, which can be set on a potentiometer. Thus, \\(e_r = K_p \\theta_r\\), where \\(K_p\\) is the potentiometric constant.\nThe feedback signal at this stage is the load position \\(\\theta_L\\). This position is also converted into a voltage signal, represented as \\(e_0 = K_p \\theta_L\\).\n\nFor simplicity and to facilitate a unity-feedback block diagram representation, we assume that the potentiometric constants for the commanded and actual positions are identical. If the two constants are not equal we would not get a unity feedback block diagram.\n\nThe error detector captures the difference between the desired and actual positions. It outputs a voltage proportional to this difference, \\(e_r - e_o\\). Note that the input of the op-amp is \\(e_r - e_o\\) because the sign of the two potentiometers are reversed.\nThe second op-amp is an inverting amplifier to reverse the sign of the signal.\nThe output from the amplifier, \\(u\\), serves as the input to the power amplifier, resulting in the voltage \\(e_a\\). This voltage drives the armature-controlled motor.\nThe torque generated by the motor, after considering external disturbances, drives the load.\nObserve that a gear train is present, serving as an intermediary between the motor shaft and the load. This is often essential when there’s a necessity for torque amplification to move the load, which simultaneously results in a reduction in speed.\nThe gear train is essential to provide the necessary torque amplification, especially when dealing with a heavier load.\nFinally, the load position \\(\\theta_L\\) is sensed by the potentiometer and fed back.\n\n\nGear Train in the Motor System\n\nThe gear train plays a crucial role in amplifying torque and decreasing speed, tailored to the demands of the load.\nOur focus will be on modeling two gears. If the system involves more than two gears, a corresponding model must be formulated.\n\n\n\n\n\n\n\n\n\n\\(\\theta_M\\) signifies the motor’s position, while \\(\\theta_L\\) denotes the load’s position. Their directions are reversed due to the mechanics of the gear train.\n\\(T_W\\) is the disturbance torque, which, as illustrated, counteracts the load’s motion direction. However, it’s important to remember that this is an algebraic value.\n\n\n\nDeriving the Relationship Between Torque and Speed\nLet’s begin by deriving an equation that relates the torque and speeds of two connected gears.\n\n\n\n\n\n\n\nConsider two gears, Gear 1 and Gear 2. The radii of these gears are \\(r_1\\) and \\(r_2\\), respectively.\nAs the gears rotate, the number of revolutions of the two gears is different: the linear distance covered by their surfaces remains constant, leading to the relation:\n\\[\n\\theta_Mr_1 = \\theta_Lr_1\n\\]\nPop-up Question: Why do the linear distances traveled by the two gears have to be the same? Answer: The gears are in contact, so for every revolution of one gear, the corresponding part of the other gear also travels the same linear distance.\nAssuming the radii and number of teeth are proportional, we can write:\n\\[\n\\begin{align}\n\\frac{N_1}{N_2} = \\frac{\\theta_L}{\\theta_M}  \\;\\;\\;\\;\\text{(1)}\n\\end{align}\n\\]\nThis becomes our first fundamental equation. But there’s more to this story. If we differentiate the above equation \\(\\theta_Mr_1 = \\theta_Lr_1\\) with respect to time, we get the relationship between the angular velocities of the two gears:\n\\[\n\\begin{align}\n\\frac{N_1}{N_2} = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M}  \\;\\;\\;\\;\\text{(1a)}\n\\end{align}\n\\]\nThe ratio \\(\\frac{N_1}{N_2}\\) is often termed as the gear ratio, denoted by \\(n\\).\n\n\nExamining Torque Dynamics\nNow, let’s shift our focus to the torques involved.\n\n\n\n\n\n\n\n\nThe torque generated by the motor is represented by \\(T_M\\).\nThe torque transmitted through the gear train to the load shaft is \\(T_{21}\\). This torque \\(T_{21}\\) is responsible to drive the load inertia against the disturbance torque \\(T_W\\).\nAnother torque to consider is \\(T_{12}\\), which signifies the load due to Gear 2 (and the connected load) on the motor shaft. We can intuitively understand this because the load on the motor shaft when we have the Gear 2 and when we do not have it is different.\n\nAt the point of contact between the gears, the forces developed by the two gears should equate. Therefore:\n\\[\n\\frac{T_{12}}{r_1} = \\frac{T_{21}}{r_2}\n\\]\n\\[\n\\frac{T_{12}}{T_{21}} = \\frac{N_{1}}{N_2} = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M}\n\\]\n\nIf \\(n &lt; 1\\), the gear ration amplifies the torque (and reduces the speed).\nTypical value is \\(n=\\frac{1}{30}\\). Depending on the characteristics of the motor and of the load you design the needed gear ratio.\n\n\n\nIntegrating Gear Effects into the System\nOne of the intriguing outcomes of our discussion so far is that we can represent the combined effects of the motor and gear train as if they were a single entity. Mathematically, the entire system behaves as if there is a motor directly driving a load with an “equivalent” moment of inertia and friction. Let’s see work this out.\n\n\n\n\n\n\n\nFor the second gear, the equation at the load shaft, is:\n\\[\nT_{21} = J_L\\ddot{\\theta_L} + B_L\\dot{\\theta_L} + T_W\n\\]\nFor the first gear, the equation at the motor shaft, is:\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + T_{12}\n\\]\nwhere \\(T_{12}\\) represents the opposition of the load and second gear to the motor shaft.\nSince \\(\\frac{T_{12}}{T_{21}} = \\frac{N_{1}}{N_2}\\), the combined effects can be expressed as:\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + \\frac{N_{1}}{N_2}\\Big[J_L\\ddot{\\theta_L} + B_L\\dot{\\theta_L} + T_W\\Big]\n\\]\nSince \\(n = \\frac{N_1}{N_2} = \\frac{\\theta_L}{\\theta_M}\\) we can re-write the equation as a function of \\(\\theta_M\\):\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + \\Big(\\frac{N_{1}}{N_2}\\Big)^2J_L\\ddot{\\theta_M} + \\Big(\\frac{N_{1}}{N_2}\\Big)^2B_L\\dot{\\theta_M} + \\frac{N_{1}}{N_2}T_W\n\\]\nWe can finally group things together:\n\\[\nT_M = \\Big(J_M+n^2J_L\\Big)\\ddot{\\theta_M} + \\Big(B_M+n^2B_L\\Big)\\dot{\\theta_M}+ nT_W\n\\]\nMathematically, the position control system is equivalent to the following:\n\\[\nT_M = J_{eq}\\ddot{\\theta_M} + B_{eq}\\dot{\\theta_M}+ nT_W\n\\]\nwhere: - \\(J_{eq} = \\Big(J_M+n^2J_L\\Big)\\) - \\(B_{eq} = \\Big(B_M+n^2B_L\\Big)\\) - \\(nT_W\\), is the equivalent disturbance acting on the motor shaft (the disturbance is acting on the load in reality).\nWith new representation we have reported the control problem to the same one we had with the speed control.\n\n\nBlock Diagram\n\n\n\n\n\n\n\n\nThe motor’s dynamics (including the effects of the gear train) is represented by the previously derived equations (see for example Section Revisiting the Original System).\nFeedback loops are introduced to account for back EMF and the position control mechanism.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#some-additional-comments-on-the-dc-position-controlled-system",
    "href": "hardware_and_case_studies.html#some-additional-comments-on-the-dc-position-controlled-system",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Some additional comments on the DC Position Controlled System",
    "text": "Some additional comments on the DC Position Controlled System\nIn our previous discussions, we dived deep into the intricacies of the DC position controlled system. We can revisit this system further, exploring its significance in control systems and understanding its foundational components.\nDC motors actuate many loads, making the DC position controlled system a pivotal element in automatic control. This system has several components and we saw the equivalence when we report the load and the gear train onto the motor shaft:\n\n\n\n\n\n\n\nFigure: Left: Motor, gear train and load. Right: Equivalent representation.\nFrom our previous discussions, we deduced that the load parameters could be mirrored onto the motor shaft. This realization allows us to mathematically represent the system in a simplified manner, without involving the gear train explicitly. For clarity, consider a system where a motor drives a load through a gear train. This system can be equivalently represented as a motor driving a direct load, provided we adjust the load’s parameters appropriately to account for the gear train’s effects.\n\nEquivalent Moment of Inertia on the Motor Shaft \\[J_{eq} = \\Big(J_M+n^2J_L\\Big)\\]\nEquivalent Viscous Frictional Coefficient \\[B_{eq} = \\Big(B_M+n^2B_L\\Big)\\]\n\nHere, \\(J_M\\) and \\(B_M\\) represent the inertia due to the rotor, gears, etc., and the frictional coefficient on the motor shaft respectively. \\(n\\) is the gear ratio defined as the ratio of the number of teeth on the two gears, \\(N_1\\) and \\(N_2\\).\n\nThe Core Motor Equation:\n\n\\[\nT_M = J_{eq}\\ddot{\\theta_M} + B_{eq}\\dot{\\theta_M}+ nT_W\n\\]\nPlease note, \\(T_W\\) is the disturbance on the load shaft and \\(n\\) reflects this disturbance onto the motor shaft.\nTo model our system, we start by considering the armature controlled motor. The control variable here is the armature voltage \\(e_a\\), while the opposing back EMF is \\(e_b\\). We are neglecting the armature inductance as previously discussed.\nHere, for the motor loaded through a gear train, the load directly connected to it has parameters \\(J\\) and \\(B\\) reflected from the original load via the gear train. If the load is connected through a gear train \\(J\\) and \\(B\\) will include this directly. The disturbance in this context is \\(nT_W\\).\n\n\n\n\n\n\n\nBlock Diagram Model\nFrom the previous picture we can generate the following block diagram, starting from the input \\(e_a\\) to the output \\(\\theta_M\\).\n\n\n\n\n\n\n\nFigure: Block diagram showcasing the entire system, from the error detector comparing the armature voltage and back EMF, to the gear train and load parameters, and finally to the output\nBased on this diagram, applying the superposition principle (and hence setting \\(T_W=0\\)), the transfer function relating output speed \\(\\omega\\) to input \\(e_a\\) is:\n\\[\n\\frac{\\omega(s)}{E_a(s)} = \\frac{\\frac{K_T/R_a}{Js+B}}{\\Big(1+\\frac{K_bK_T/R_a}{Js+B}\\Big)} = \\frac{K_T/R_a}{Js+B+K_bK_T/R_a}\n\\]\nNote from the equation above how the back EMF constant \\(K_b\\) adds to the mechanical friction in the system (the \\(B\\) term), thereby providing additional damping, stabilizing the system, and making it less susceptible to oscillations (almost providing ‘electric friction’)\nOur previously derived transfer function can be interpreted in its standard form for first-order systems as:\n\\[\n\\frac{\\omega(s)}{E_a(s)} = \\frac{K_m}{\\tau_m s + 1}\n\\]\nwhere:\n\n\\(K_m\\) is the system’s gain.\n\\(\\tau_m\\) is the mechanical time constant, which can be computed as:\n\n\\[\n\\tau_m = \\frac{J}{B+\\frac{K_TK_b}{R_a}}\n\\]\nIf we’re more interested in the relationship between position \\(\\theta_M\\) and the input voltage \\(e_a\\), the transfer function becomes to:\n\\[\n\\frac{\\theta_M(s)}{E_a(s)} = \\frac{K_m}{s\\Big(\\tau_m s + 1\\Big)}\n\\]\n\n\n\nSidebar - Deeper Dive into the Correlation Between \\(K_T\\) and \\(K_b\\)\nThe interrelation between the torque constant \\(K_T\\) and the back EMF constant \\(K_b\\) is a foundational aspect of DC motor dynamics. These constants are intrinsic properties of the motor, governing its electrical and mechanical behaviors. To truly appreciate their significance and relationship, it’s essential to understand them in detail.\n\nWhat are \\(K_T\\) and \\(K_b\\)?\n\nTorque Constant \\(K_T\\): It signifies the torque produced per unit current. In simple terms, it provides a measure of how effective the motor is in converting electrical current into mechanical torque. A higher \\(K_T\\) implies that the motor can generate more torque for the same current. Its unit is Newton meter per ampere (Nm/A).\nBack EMF Constant \\(K_b\\): The back EMF constant determines the voltage produced per unit speed. When a motor rotates, it inherently generates an EMF opposing the driving voltage; this is called the back EMF. \\(K_b\\) quantifies this effect, essentially indicating how much voltage the motor generates for every radian/second it rotates. Its unit is volts per radian per second (V/(rad/s)).\n\n\n\nMathematical Derivation of Their Relationship:\nConsidering the power developed in the motor due to the back EMF:\n\\[\n\\begin{align}\nP &= e_b \\times i_a\\;\\;\\;\\; \\text{watts} \\\\\n  &= K_bw \\times i_a\\;\\;\\;\\; \\frac{\\text{volts}}{\\text{rad/s}}\\text{rad/s} \\times \\text{amp}\n\\end{align}\n\\]\nOn the mechanical side, the power is also given by:\n\\[\n\\begin{align}\nP &= T_M \\times \\omega\\;\\;\\;\\; \\text{watts} \\\\\n   &= (\\text{Newton-m})(\\text{rad-s})\n\\end{align}\n\\]\nWhich can be expanded as: \\[\n\\begin{align}\nP &= K_Ti_a \\times \\omega\\;\\;\\;\\; \\text{watts} \\\\\n   &= \\frac{\\text{Newton-m}}{\\text{amp}} \\text{amp} \\times \\text{rad/s}\n\\end{align}\n\\]\nGiven that both expressions represent the power developed in the motor, we equate them:\n\\[\nK_b \\omega \\times i_a = K_T i_a \\times \\omega\n\\]\nUpon simplifying, we find: \\[\n\\begin{align}\nK_b &= K_T \\\\\n\\frac{\\text{Newton-m}}{\\text{amp}} &= \\frac{\\text{volts}}{\\text{rad/s}}\n\\end{align}\n\\]\nThus, this derivation highlights that the torque constant $ K_T $ and the back EMF constant $ K_b $ are numerically equal when $ K_T $ is measured in Newton meter per ampere and $ K_b $ in volts per radian per second. Their numerical values are the same. This is the case when we consider them using these specific units. If we use different units they can be related by a constant and hence their numerical values might be different.\n\n\nPractical implications\n\nThis equivalence is not just a mathematical curiosity; it has real-world implications. For example, when designing motor controllers or when procuring motors for specific applications, knowing that \\(K_T\\) and \\(K_b\\) are equal (under consistent units) can simplify calculations and provide insights into motor behavior.\nFrom an experimental standpoint, measuring \\(K_b\\) is simpler and potentially more accurate than measuring \\(K_T\\). For instance, determining \\(K_b\\) requires only measuring back EMF and speed, while assessing \\(K_T\\) would entail torque measurements. Given the aforementioned relationship between \\(K_T\\) and \\(K_b\\), one can measure \\(K_b\\) experimentally and derive \\(K_T\\) from it, offering a more straightforward approach.\nThe ease of measuring \\(K_b\\) compared to \\(K_T\\) means that engineers often determine \\(K_b\\) experimentally (you measure back EMF and speed) and then infer \\(K_T\\) (requires to mearure a torque). This can lead to cost savings and more accurate motor characterizations in practical scenarios.\n\n– END OF SIDEBAR",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#field-controlled-motors",
    "href": "hardware_and_case_studies.html#field-controlled-motors",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Field Controlled Motors",
    "text": "Field Controlled Motors\nHaving understood armature controlled motors, it’s now time to introduce the concept of field controlled motors.\nIn these motors, the armature current \\(i_a\\) remains constant, while the field current \\(i_f\\) is varied to control the torque \\(T_M\\).\n\\(e_f\\) is the controlling voltage, it controls the torque.\n\n\n\n\n\n\n\n\nNow the field resistance and inductance are not negligible.\n\n\n\n\n\n\n\nThe ‘electric resistance’ effect is not present anymore. There is no back EMF against \\(e_f\\).\n\nThe resulting transfer function from \\(\\omega(s)\\) and \\(E_f(s)\\) is:\n\\[\n\\frac{\\omega(s)}{E_f(s)} = \\frac{K^{'}_m}{(\\tau_f s + 1)(\\tau^{'}_m s + 1)}\n\\]\nwhich is a second-order model.\nThe transfer function from the position \\(\\theta_M(s)\\) and \\(E_f(s)\\) we have a third order model:\n\\[\n\\frac{\\theta_M(s)}{E_f(s)} = \\frac{K^{'}_m}{s(\\tau_f s + 1)(\\tau^{'}_m s + 1)}\n\\]\nThe higher the order of the model the more complex is the design. The additional complexity comes from the fact that \\(L_f\\) cannot be neglected.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#additional-comments",
    "href": "hardware_and_case_studies.html#additional-comments",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Additional comments:",
    "text": "Additional comments:\nAdvancements have addressed some of the challenges associated with these motor drives. Some key trends include:\n\nBrushless DC Motors: One major challenge with the motors discussed so far is the brush friction, which introduces non-linearity into our mathematical models.\n\nBrushless DC motors, with electronic commutation, are now available to mitigate the non-linear effects due to brush friction. Note that in our modeling we have assumed that we can have a linear model, with viscous friction only and neglecting the effects of brush fiction (which is constant frictional source independent on the speed - this would make the model non-linear).\n\nGears and Backlash: Our discussion assumes a linear relationship between motor input and output through gears and the defined gear ratio.\n\nHowever, in reality, gear backlash introduces non-linearity. This is due to the fact that when the gears have to reverse this will not be instantaneous (e.g., object tracking requires the tracker to move back and forth and hence the motor will need to often reverse its direction). Direct-drive motors are now designed to interface directly with the load, eliminating the need for gear trains and the associated nonlinear challenges.\n\nFeedback Mechanisms: Although potentiometers provide a simple way to measure angular position, they introduce their own challenges.\n\nFor example they have a finite resolution. The resolution (minimum change in output voltage obtained by moving the wiper, expressed as a percentage of the total applied voltage) of precision wire-wound potentiometers ranges from 0.001 to 0.5 percent. This discontinuous output voltage contributes to servo inaccuracy. Potentiometers are temperature-sensitive, a characteristic that affects their accuracy. The wiper contact is another limiting factor, being subject to wear and dirt and potentially producing electrical noise.\nIn our models we have neglected these nuances and assumed a linear relationship between \\(\\theta_R\\) and \\(e_r\\) through \\(\\theta_R = K_p e_r\\). Modern systems are leaning towards more advanced sensors that offer higher precision and better linearity.",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "hardware_and_case_studies.html#defining-the-variables",
    "href": "hardware_and_case_studies.html#defining-the-variables",
    "title": "Hardware of Control Systems and Case Studies",
    "section": "Defining the Variables",
    "text": "Defining the Variables\nThe variable \\(\\theta_L\\) is our attribute of interest - the one we want to control. For illustration, let’s assume \\(\\theta_L\\) represents an antenna’s position. On the other hand, \\(\\theta_R\\) is the command signal, which in many real-world applications can come digitally or from various devices.\nFor the purpose of this notebook, we will represent the command signal symbolically, using a wiper on a potentiometer to adjust \\(\\theta_R\\). As the wiper moves, it adjusts the voltage (let’s call this voltage \\(e_r\\)), which is directly proportional to \\(\\theta_R\\).\n\nPotentiometer\nThe relationship between \\(\\theta_R\\) and \\(e_r\\) depends on the potentiometer constant \\(K_p\\), which depends on the voltage provided to the potentiometre, and on the resistor:\n\\[e_r = K_P\\theta_R\\]\nNote that we are using another potentiometer to sense the output \\(\\theta_L\\).\nPotentiometers are often used in these systems. However, they can introduce nonlinearities due to their finite resolution. For instance, a wire-wound potentiometer changes step by step, not allowing for continuous adjustments (e.g., wire-wound potentiometer). Despite this, for our mathematical model, we will assume a linear relationship for simplicity.\nFor now, we are using Potentiometers as representations of devices that make it possible to generate reference and feedback signals, but the actual device might be different from a potentiometer, with better linear characteristics.\n\n\nFrom Voltage to Position Control\nLet’s focus now on the first operational amplifier.\nThis circuit gives an output voltage proportional to the difference \\(e_r−e_0\\), where \\(e_0\\) is the feedback voltage corresponding to \\(\\theta_L\\). This operation makes the Op-Amp behave like a differential amplifier with a specific gain (\\(\\frac{-R_f}{R}\\)). Depending on the arrangement, the voltage output can represent either position or speed.\nThe Op-Amp acts as a differential amplifier, producing an output voltage based on the difference between the reference and feedback voltages.\nGiven the specific arragements with the potentiometers ( \\(e_r\\) is a negative voltage, and \\(e_0\\) is a positive voltage), we have:\n\n\n\n\n\n\nNote that to make the representation straightforward, we have restructured our block diagram by flipping the signs for these voltages.\n\nWe can then add the potentiometers to have the explicit presence of the two angles:\n\n\n\n\n\nThis can also be equivalently written as:\n\n\n\n\n\n\nWe have moved \\(K_P\\) inside the loop\nThis is now a unity feedback loop\n\n\n\nIncorporating Tachogenerator Feedback\nA crucial part of our system is the addition of a tachogenerator, introducing a secondary (or minor) feedback loop for velocity. The voltage from the tachogenerator (\\(e_t\\)) plays a pivotal role in the performance and control of the system.\nThe second Op-Amp is also activing as a differential amplifier with gain: \\(\\frac{-R^{'}_f}{R^{'}}\\). The input to this Op-Amp is \\(e^{'}-e_t\\).\n\n\n\n\n\n\nThe final Op-Amp is used as a power amplifier with gain: \\[-\\frac{R_{fp}}{R_p}\\]\nNote that given that we have two Op-Amps in cascade, their negative signs cancel out and we have the desired signal at the end of the chain.\n\nWe can now finish the block diagram:\n\n\n\n\n\n\nNote that you can detail the block digram with a more detailed representation of the motor which includes the back EMF loop.\nRemember that the gear ration is defined as:\n\n\\[n = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M} = \\frac{\\theta_L}{\\theta_M}\\]\nThe system has two loops:\n\nPrimary Loop (Position Feedback): This provides feedback based on the position \\(\\theta_L\\).\nSecondary or Minor Loop (Velocity Feedback): This loop provides feedback based on the velocity or speed. It derives its signal from a tachogenerator, symbolized by \\(e_t\\). This secondary loop serves a similar damping purpose as the inherent back EMF in the motor but has the advantage of being adjustable.\nMotor-internal loop: The inherent nature of the motor introduces another feedback loop, the back EMF, which isn’t directly under our control. In contrast, the tachogenerator’s output can be controlled, allowing us to adjust the system’s damping.\n\n\n\nBreaking the loops\n\nBreaking the velocity loop\n\nIf we break the secondary velocity feedback, what happens to the performance of the system?\nThe tachogenerator inherently provides information about the system’s velocity (we are feeding back the derivative of \\(\\theta_M\\) through the tachometer).\nThe lack of the secondary loop leads to a Loss of Damping\n\nThe system will continue to act as a position control system but through the secondary loop we are controlling the damping of the system. The tachogenerator typically provides a damping effect to the system, helping to stabilize it. This damping effect is beneficial in minimizing oscillations around the setpoint or reference value. Without this feedback, the system might experience prolonged or even sustained oscillations upon any disturbances or setpoint changes. Performance might deteriorate.\nNote that is similar to what happened when we were analysing the effect of the back EMF. The back EMF was also proportional to speed and was able to improve our damping. The only difference is that the back EMF (\\(K_b\\)) is out of our control (once the motor is selected you cannot change your \\(K_b\\)). The \\(K_T\\) instead is something you can explicitly control selecting the tachogenerator.\nReal-world consequences: If our system were controlling the position of an antenna, a loss of damping might lead to the antenna overshooting its desired position and then oscillating back and forth before settling. This could result in interrupted or degraded communication signals.\n\n\n\n\nBreaking the position loop\n\n\n\n\n\n\nWhen the primary feedback loop (position) is disrupted, but the secondary loop (velocity) remains, the system behaves as a speed-controlled system.\nNote that the actual input we have is the voltage \\(e_r\\). Previously we interpreted this signal as a position.\nThe voltage \\(e_r\\) in the forward loop, which was previously interpreted as position, is now indicative of speed, given the feedback is now from the tachogenerator representing velocity.\nThe system becomes a speed controlled system. We can also now explicit that the tachogenerator provides a speed:",
    "crumbs": [
      "Hardware of Control Systems and Case Studies"
    ]
  },
  {
    "objectID": "dynamic_systems.html",
    "href": "dynamic_systems.html",
    "title": "Modeling in Control Systems",
    "section": "",
    "text": "When we discuss control systems, the importance of modeling cannot be overstated. Models are mathematical representations of systems and play a pivotal role in the analysis and design of control systems. While many of you might be familiar with some of the models from previous studies, it’s always a good idea to review and set the terminologies and symbols we’ll be using throughout the course.\nPopup Question: Why is modeling important in control systems?\nAnswer: Modeling provides a mathematical representation of systems which aids in their analysis, design, and understanding.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#state-variable-model",
    "href": "dynamic_systems.html#state-variable-model",
    "title": "Modeling in Control Systems",
    "section": "State Variable Model",
    "text": "State Variable Model\nIn our last discussion, we introduced the concept of the state variable model. This model revolves around the idea that the energy state of a system can be defined using state variables.\nConsider a system with state variables \\(x_1, x_2, ... x_n\\).\nThe relationship between these variables and the system’s differential equations can be represented as:\n\\[\n\\begin{aligned}\n\\dot{x_1} &= a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n + b_1r\\\\\n\\dot{x_2} &= a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n + b_2r\\\\\n\\vdots\\\\\n\\dot{x_n} &= a_{n1}x_1 + a_{n2}x_2 + ... + a_{nn}x_n + b_nr\\\\\n\\end{aligned}\n\\]\nWhere \\(r\\) is the input variable and the coefficients form the matrices \\(A\\) and \\(B\\).\nAdditionally, the output equation is:\n\\[\ny = c_{1}x_1 + c_{2}x_2 + ... + c_{n}x_n + dr\n\\]\nThe output is an attribute of the system and is obtained as an algebric combination of the state variables.\nThe model is comprised of \\(n\\) state equations and one output equation for a Single Input Single Output (SISO) system.\nThis is a \\(n-th\\) order system. The order of the system is directly linked to the number of state variables.\nIn matrix notation, this system can be represented as:\n\\[\n\\dot{x} = Ax+br\n\\]\nand the output equation:\n\\[\ny=cx+dr\n\\]\nWhere: - \\(A\\) is a \\(n \\times n\\) matrix - \\(b\\) is a \\(n \\times 1\\) vector - \\(c\\) is a \\(1 \\times n\\) vector - \\(d\\) is a scalar constant.\nNote: in the state-variable representation, the input is denoted by \\(u\\) or \\(r\\).\n\nPopup Question: What does the order of a system represent? Answer: The order of a system is directly linked to the number of state variables which represent the energy state of the system.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#modeling-the-rlc-circuit",
    "href": "dynamic_systems.html#modeling-the-rlc-circuit",
    "title": "Modeling in Control Systems",
    "section": "Modeling the RLC circuit",
    "text": "Modeling the RLC circuit\nLet’s revisit the circuit we saw before.\nThere are two energy storing elements in this circuit, the capacitor and the inductor. This system will be represented by a second order model.\n\n\n\n\n\n\n\nAs before, we start from the differential equations:\nThe loop equation is given by: \\[\nR i + e + L\\frac{di}{dt} = e_i\n\\]\nwhich we can port to the Laplace domain as:\n\\[\nRI(s) + E(s) + sLI(s) = E_i(s)\\;\\;\\;\\;(1)\n\\]\nWe also have a second equation:\n\\[\ni = C\\frac{de}{dt}\n\\]\nand we can write:\n\\[\nI(s) = sCE(s) \\;\\;\\;\\;(2)\n\\]\nWe have two algebric equations that can easily be manipulated to have the transfer function.\n\\[\nG(s) = \\frac{Y(s)}{E_i(s)}\n\\]\nwhere \\(Y(s)\\) is the output that we need to define.\nFor example, \\(y(t)\\) can be taken as the voltage across the inductor:\n\\[\ny(t) = L\\frac{di}{dt}\n\\]\nwhich I need to Laplace transform:\n\\[\nY(s) = sLI(s) \\;\\;\\;\\;(3)\n\\]\nWe have three equations that we need to have the transfer function model.\nRearranging these equation we obtain:\n\\[\nG(s) = \\frac{Y(s)}{E_i(s)} = \\frac{s^2}{s^2+\\frac{R}{L}s+\\frac{1}{LC}}\n\\]\nwhich is also a second order system.\n\nGeneric Form of a Transfer Function\nWe are now ready to write the generic form of a transfer function:\n\\[\nG(s) = \\frac{b_0 s^m + b_1 s^{m-1} + \\ldots + b_{m-1} s + b_m}{a_0 s^n + a_1 s^{n-1} + \\ldots + a_{n-1} s + a_n}\n\\]\nwhere \\(m \\le n\\) (causal/realisability condition).\nNote that \\(a_0\\) could also be taken as \\(a_0=1\\) dividing all the coefficient by \\(a_0\\) (see sidebar below).\nTransfer functions can be classified based on the order of the numerator and denominator polynomials. For many physical systems, the order of the numerator polynomial is usually less than the order of the denominator, categorized as strictly proper transfer functions.\n\nIf \\(m=n\\), the transfer function is a proper transfer function.\nIf \\(m&lt;n\\), the transfer function is a strictly proper transfer function.\n\nA system is realisable if \\(m \\le n\\).\n\nall the \\(a_i\\), and \\(b_j\\) are real. This guarantees that the roots of the numerator and denominator polynomials of \\(F(s)\\) will be either real or complex-conjugate pairs.\n\nWe will also write the transfer function as :\n\\[\nG(s) = \\frac{N(s)}{D(s)} = \\frac{N(s)}{\\Delta(s)}\n\\]\nwhere:\n\\(N(s)= b_0 s^m + b_1 s^{m-1} + \\ldots + b_{m-1} s + b_m\\)\nand\n\\(\\Delta(s) = a_0 s^n + a_1 s^{n-1} + \\ldots + a_{n-1} s + a_n\\)\nThis form of the transfer function is called polynomial form.\n\nSidebar - Writing the general form of the denominator as a monic polynomial\nWhile the denominator polynomial often has its highest order term with a coefficient of 1 (rendering it a monic polynomial), there’s no loss of generality here. If there’s a coefficient other than 1, it can be normalized. This representation is chosen for convenience, as will be evident later.\n\nPopup Question: Why might one choose to represent the highest order term of the denominator polynomial with a coefficient of 1?\nAnswer: This is done for convenience, as it simplifies certain mathematical operations and representations. Furthermore, any transfer function can be rearranged to have this form without loss of generality.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#poles-and-zeros",
    "href": "dynamic_systems.html#poles-and-zeros",
    "title": "Modeling in Control Systems",
    "section": "Poles and Zeros",
    "text": "Poles and Zeros\nThe roots of the numerator polynomial are termed as zeros of the transfer function. In contrast, the roots of the denominator polynomial are termed the poles of the transfer function.\n\nThe behavior of a system, particularly its dynamical evolution, is profoundly influenced by its poles.\nThese poles, or the roots of the denominator polynomial, are so central to system dynamics that they’ve been named the characteristic roots of the system. They dictate the system’s response nature.\nThe zeros, on the other hand, primarily affect the response’s amplitude.\n\nThe polinomial \\(\\Delta(s)\\), whose roots are the poles of the transfer function \\(\\Delta(s)=0\\), plays an important role in the dynamics of the system. For this reason, \\(\\Delta(s)\\) is called characteristic polinomial of the system.\nThe polinomial \\(N(s)\\), the numberator of the transfer function, will play a role in determining the amplitude of the response.\n\nThe Laplace transform zeros are the values of s for which the transform is zero.\nThe zeros are found by setting the numerator polynomial to 0 and solving the resulting equation.\nThe Laplace transform poles are the values of s for which the transform is infinite.\nThe poles are found by setting the denominator polynomial to 0 and solving the resulting equation.\n\nPopup Question: Why are the poles so vital in determining the nature of the system’s response?\nAnswer: Poles are the roots of the denominator polynomial in the transfer function. The location and nature of these poles dictate stability, oscillatory behavior, damping, and transient response of the system. Hence, they play a paramount role in system analysis.\nExpressed in a form that elucidates the poles and zeros directly, the transfer function, $ G(s) $, becomes:\n\\[\nG(s) = \\frac{K (s+z_1)(s+z_2)\\ldots(s+z_m)}{(s+p_1)(s+p_2)\\ldots(s+p_n)}\n\\]\nwhere: - \\(z_i\\) are the zeros - \\(p_i\\) are the poles - \\(K\\) is the gain constant, equating to $ b_0 $.\nThis representation is often termed the pole-zero form.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#input-output-block-diagram-using-the-transfer-function-model",
    "href": "dynamic_systems.html#input-output-block-diagram-using-the-transfer-function-model",
    "title": "Modeling in Control Systems",
    "section": "Input-Output Block Diagram Using the Transfer Function Model",
    "text": "Input-Output Block Diagram Using the Transfer Function Model\nWhen we are given a transfer function model, it becomes important to understand its relation in terms of the system’s input and output. This relationship can be efficiently visualized using block diagrams, which offer a clear graphical representation of how the various components interact.\n\nThe Basic Block Diagram\nIn its simplest form, the block diagram using a transfer function model consists of:\n\nAn input, \\(R(s)\\), representing the Laplace-transformed input signal (this is the manipulated input).\nThe transfer function, \\(G(s)\\), that maps the input to the output.\nAn output, \\(Y(s)\\), representing the Laplace-transformed output signal.\n\n\n\n\n\n\n\n\n\n\nExpanding to Include Disturbances\nWhile the basic block diagram gives an overall picture, it does not encapsulate every possible influence on a system. In reality, systems often encounter disturbances, which can significantly affect their performance.\nTo model this accurately we need to explicitly two types of inputs that act on the system:\n\nManipulated Input, \\(R(s)\\): This is the input that we have control over. It’s usually the input we manipulate to achieve desired system behavior.\nDisturbance, \\(W(s)\\): Disturbances are inputs that aren’t under our control. These could be anything from environmental changes, external loads, or any unforeseen changes that can affect the system. Disturbances are crucial as they determine how robust our system is.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#disturbances-in-systems",
    "href": "dynamic_systems.html#disturbances-in-systems",
    "title": "Modeling in Control Systems",
    "section": "Disturbances in Systems",
    "text": "Disturbances in Systems\nDisturbances are inevitable perturbations in any system. By definition, a disturbance is something that is not under our control. The nature of the disturbance is hence not known to you, at least not completely. If it was known that you can easily derive a controller that an reduce or nullify its presence.\nDisturbances can arise from various sources and can be of various natures. For instance, in a power system, electrical loads can be disturbances; in a robotic system, payload variations can act as disturbances. In thermal systems, environmental temperatures can disturb the system’s desired state.\nThe objective of the controller will be that of filtering out the effect of the disturbances.\nDisturbances are classified into two main categories:\n\nErratic signals with unknown waveforms, often high-frequency in nature. These are usually called Noise. These disturbances require stochastic modeling. We will not deal with stochastic modeling in this course.\nSlow-vary signals, where the waveform’s general nature is somewhat predictable.\n\nExamples: - Payload variations in a robotic system - Electrical load on a power plant. Variations are predictable (e.g., higher use in the evenings). - Environmental temperature variations in a room heating system - Wind acting on an airplane - etc.\nThese disturbances can be modeled through deterministic models.\n\nTypes of Disturbances:\n\nExternal Disturbances: These arise from the system’s environment. Examples include wind acting on a building, changes in ambient temperature influencing a room’s thermostat, or unforeseen load changes in electrical systems.\nInternal Disturbances: These are changes that occur within the system but are not part of the desired operation. For instance, voltage fluctuations in an electronic circuit, wear and tear in machinery, or internal thermal changes in a process.\n\nPopup Question: In a robotic system, how might payload variations act as a disturbance?\nAnswer: A robotic system is often designed to function optimally with a specific payload. Any variation, either an increase or decrease from this optimal payload, can affect the robot’s performance, balance, energy consumption, and other dynamics, thereby acting as a disturbance.",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#categories-of-disturbance-models",
    "href": "dynamic_systems.html#categories-of-disturbance-models",
    "title": "Modeling in Control Systems",
    "section": "Categories of Disturbance Models",
    "text": "Categories of Disturbance Models\nWhile there’s an infinite array of disturbances, for the sake of analysis and design, they can be broadly modeled as:\n\nPulse and Impulse Disturbance:\n\n\nPulse: Represents a short-duration, constant disturbance.\n\n\n\n\n\n\n\n\n\nImpulse: Represents a short-duration, high-magnitude disturbance.\nUseful for situations resembling sudden shocks.\nExample: A sudden voltage spike in a circuit.\n\n\n\n\n\n\n\n\nA unit impulse function is defined as:\n\\[\n\\delta(t) = 0\\;\\;\\text{for}\\;\\;\\;t\\neq0\n\\] \\[\n\\delta(t) = \\infty\\;\\;\\text{for}\\;\\;\\;t=0\n\\]\nand such that:\n\\[\n\\int_{-\\infty}^{\\infty} \\delta(t) = 1\n\\]\nand:\n\\[\n\\int_{-\\infty}^{\\infty} f(t)\\delta(t)dt = f(0)    \n\\]\nFor example, a sudden shock to a system might be approximated by an impulse, while a short-duration disturbance might be approximated by a pulse.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 4, 600)\n\n# Define a function for the rectangular pulse\ndef rectangular_pulse(t):\n    if 0 &lt;= t &lt;= 2:\n        return 1\n    else:\n        return 0\n\n# Vectorize the function to allow numpy array inputs\nvectorized_pulse = np.vectorize(rectangular_pulse)\n\n# Get the pulse values\npulse_values = vectorized_pulse(t)\n\nplt.figure(figsize=(10, 4))\nplt.plot(t, pulse_values, 'b', linewidth=2)\nplt.title(\"Rectangular Pulse\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 4])\nplt.ylim([-0.2, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n# Create impulse signal\nimpulse = np.where((t &gt; -0.01) & (t &lt; 0.01), 1, 0)\n\nplt.figure(figsize=(10, 4))\nplt.stem(t, impulse, basefmt=\" \") #, use_line_collection=True)\nplt.title(\"Impulse Signal\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([0, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nStep Disturbance:\n\n\nConstant magnitude, mimicking a persistent change.\nRelevant for scenarios like electrical load variation during evening hours.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n# Create step signal\nstep = np.where(t &gt;= 0, 1, 0)\n\nplt.figure(figsize=(10, 4))\nplt.plot(t, step, lw=2)\nplt.title(\"Step Signal\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([-0.2, 1.2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nRamp Disturbance:\n\n\nRepresents a continuously increasing or decreasing disturbance over time.\nCaptures situations where a disturbance variable drifts.\n\n\nParabolic Disturbance:\n\n\nA faster mode compared to ramp, depicting a more rapid drift of disturbance.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the time range\nt = np.linspace(-2, 2, 400)\n\n# Create ramp signal for t &gt;= 0\nramp = np.where(t &gt;= 0, t, 0)\n\n# Create parabolic signal for t &gt;= 0\nparabola = np.where(t &gt;= 0, t**2, 0)\n\nplt.figure(figsize=(10, 4))\n\n# Plot both signals\nplt.plot(t, ramp, lw=2, label=\"Ramp Signal\")\nplt.plot(t, parabola, lw=2, label=\"Parabolic Signal\")\n\n# Add title, labels, legend, etc.\nplt.title(\"Ramp and Parabolic Signals\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.xlim([-2, 2])\nplt.ylim([-0.5, 4.5])\nplt.legend()\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThese categories provide a good spectrum of disturbances for analysis.\nIt’s important to note that these models, while deterministic, are approximations of the real-world scenario.\n\n\nMathematical Modeling using Laplace Transforms\nThe Laplace domain offers a powerful tool to analyze these disturbances.\n\nImpulse Response:\n\n\n\\(\\delta(t)\\) (where \\(\\delta\\) is the Dirac delta function)\nLaplace transform: \\(1\\)\n\n\nStep signal:\n\n\nDenoted as \\(\\mu(t)\\) (Note: We deviate from the usual notation of using \\(u\\) to avoid confusion with control signals.)\nLaplace transform: \\(\\frac{1}{s}\\)\n\n\nRamp Signal:\n\n\n\\(f(t)=t\\), for \\(t\\ge0\\) or equivalently \\(t\\mu(t)\\)\nLaplace transform: \\(\\frac{1}{s^2}\\)\n\n\nParabolic Signal:\n\n\n\\(f(t)=\\frac{t^2}{2}\\mu(t)\\) for \\(t\\ge0\\)\nLaplace transform: \\(\\frac{1}{s^3}\\)",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "dynamic_systems.html#relationship-between-transfer-function-modeling-and-state-variable-modeling",
    "href": "dynamic_systems.html#relationship-between-transfer-function-modeling-and-state-variable-modeling",
    "title": "Modeling in Control Systems",
    "section": "Relationship between Transfer Function modeling and State Variable Modeling",
    "text": "Relationship between Transfer Function modeling and State Variable Modeling\nThe transformation from State Variable Model to Transfer Function Model for a linear time-invariant (LTI) system can be easily established using linear algebra and Laplace transform principles.\n\nState Variable Model Representation\nThe State Variable Model of a system can be represented in the time domain by the following set of equations:\n\nState Equation:\n\\[ \\dot{x}(t) = Ax(t) + Bu(t) \\]\nHere, \\(\\dot{x}(t)\\) represents the derivative of the state vector \\(x(t)\\) with respect to time, \\(A\\) is the state matrix that describes the system dynamics, \\(B\\) is the input matrix that relates the input vector \\(u(t)\\) to the state vector.\nOutput Equation:\n\\[ y(t) = Cx(t) + Du(t) \\]\nIn this equation, \\(y(t)\\) is the output vector, \\(C\\) is the output matrix that maps the state vector to the output, and \\(D\\) is the direct transmission matrix which directly relates the input vector to the output vector.\n\n\n\nTransfer Function Representation\nThe Transfer Function \\(G(s)\\) of a system is defined in the Laplace domain as the ratio of the Laplace transform of the output \\(Y(s)\\) to the Laplace transform of the input \\(U(s)\\), assuming zero initial conditions:\n\\[ G(s) = \\frac{Y(s)}{U(s)} \\]\n\n\nConnection Between State Variable and Transfer Function Models\nTo derive the Transfer Function from the State Variable Model, we apply the Laplace transform to both the state and output equations, assuming zero initial conditions (\\(x(0) = 0\\)) for simplicity:\n\nApplying Laplace transform to the state equation:\n\\[ sX(s) = AX(s) + BU(s) \\]\n\\[Y(s) = CX(s)+DU(s) \\]\n\nRearranging for \\(X(s)\\):\n\\[ X(s) = (sI - A)^{-1}BU(s) \\]\nHere, \\(I\\) is the identity matrix, and \\(s\\) is the complex frequency variable in the Laplace domain.\n\nApplying Laplace transform to the output equation and substituting \\(X(s)\\) from above:\n\\[ Y(s) = C(sI - A)^{-1}BU(s) + DU(s) \\]\nRearranging to express in terms of \\(U(s)\\):\n\\[ \\frac{Y(s)}{U(s)} = C(sI - A)^{-1}B + D \\]\nTherefore, the Transfer Function \\(G(s)\\) is given by:\n\\[ G(s) = C(sI - A)^{-1}B + D \\]\n\nThis mathematical derivation showcases the intrinsic connection between the Transfer Function model and the State Variable model.\n\nComments\nNote that \\(G(s)\\) includes \\((sI - A)^{-1}\\) and \\(G(s)\\) can be re-written as:\n\\[ G(s) = \\frac{Q(s)}{|sI-A|} \\]\nwhere \\(Q(s)\\) is a polynomial in \\(s\\) and \\(|sI-A|\\) (determinant of the matrix \\(sI-A\\)) is the characteristic polynomial of \\(G(s)\\). In other words, the eigenvalues of \\(A\\) are the poles of \\(G(s)\\). We will come back to this point later when we discuss what subset of eigenvalues of \\(A\\) are the poles of \\(G(s)\\).\nFin",
    "crumbs": [
      "Modeling in Control Systems"
    ]
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "",
    "text": "Welcome to the FAQ page for the “Principles of Automatic Controls” course. Here, you’ll find key information and answers to common queries.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#general-information",
    "href": "faq.html#general-information",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "General Information",
    "text": "General Information\nQ: Where can I find the course website?\nA: The course website is here.\nQ: What teaching materials are available?\nA: Teaching materials are available on the course website in both English and Italian. They are provided as Jupyter notebooks.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#course-completion",
    "href": "faq.html#course-completion",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Course Completion",
    "text": "Course Completion\nQ: How can I pass the course?\nA: To successfully complete the course, you should attend lectures and first study from the suggested textbooks. Afterward, supplement your learning with the material available on the course website.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#examinations",
    "href": "faq.html#examinations",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Examinations",
    "text": "Examinations\nQ: What is the format of the exams?\nA: Exams are oral. They involve completing exercises in writing first, followed by a discussion of these exercises and other topics with the instructor.\nQ: What content is included in the exams?\nA: All topics discussed in class are part of the exam, except for Python programming. TCLab programming is not a requirement and will not be a part of the exam. However, the concepts underlying TCLab are included in the exam.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#software-and-tools",
    "href": "faq.html#software-and-tools",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Software and Tools",
    "text": "Software and Tools\nQ: Is learning Python or MATLAB important for studying Feedback Systems in this course?\nA: Yes, using a software package like Python or MATLAB is very beneficial for understanding Feedback Systems. While not mandatory for the exams, these tools can greatly enhance your ability to visualize and analyze control systems. They provide practical experience and a deeper insight into the theoretical concepts covered in the course.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#tclab-assignments",
    "href": "faq.html#tclab-assignments",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "TCLab Assignments",
    "text": "TCLab Assignments\nQ: Are TCLab assignments mandatory for this course?\nA: Students are expected to complete TCLab assignments. While they are not mandatory for passing the course, they are highly recommended. Completing these assignments will provide hands-on experience and a practical understanding of control systems. It is also suggested to prepare a short report on these assignments, which can be handed out before the exam. This report can serve as a valuable reference during your exam preparation.\nQ: Is there a template available for the TCLab assignment report?\nA: Yes, a report template is provided to assist with your TCLab assignments. It is available as the notebook 00_TCLab_Exercises_Report_Template under the TCLab folder on the course website. This template will guide you in organizing and presenting your findings from the TCLab exercises. The report should be concise, with a maximum length of 4 pages, focusing on highlighting key takeaways from the exercises.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "faq.html#additional-resources",
    "href": "faq.html#additional-resources",
    "title": "Frequently Asked Questions (FAQ)",
    "section": "Additional Resources",
    "text": "Additional Resources\nQ: Are there any additional resources available to help with the course?\nA: Yes, besides the primary teaching materials, we recommend engaging with online forums and study groups related to control systems. These can provide valuable insights and alternative perspectives that can enhance your understanding. Also, regularly reviewing the course materials and applying the concepts through practical exercises, such as using the TCLab kit or software simulations, can be highly beneficial.\nQ: Are there external resources available to explore the usage of AI for control systems?\nA: Yes, for those interested in exploring the use of AI in control systems, I highly recommend visiting Collimator.ai. This platform offers valuable insights and tools for understanding and applying AI in the field of control systems. It can be a great supplement to the course materials, providing practical examples and a deeper dive into how AI technologies are transforming control system methodologies.",
    "crumbs": [
      "Frequently Asked Questions (FAQ)"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html",
    "href": "steady_state_accuracy_and_design_principles.html",
    "title": "Steady State Accuracy and Design Principles",
    "section": "",
    "text": "In previous notebookes, we delved into the performance of feedback systems. This notebook focuses on two key areas: steady-state accuracy and a complete design example.\nWe aim to solidify your understanding of these concepts through a practical approach.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#steady-state-accuracy",
    "href": "steady_state_accuracy_and_design_principles.html#steady-state-accuracy",
    "title": "Steady State Accuracy and Design Principles",
    "section": "Steady-State Accuracy",
    "text": "Steady-State Accuracy\nSteady-state accuracy is a crucial aspect of control systems, indicating the system’s ability to maintain a constant output when subjected to a constant input. We visited this concept already and now we will revisit it, adding a quantitative perspective.\n\n\n\n\n\nLet’s delve deeper into the quantitative description of steady-state accuracy using the block diagram.\nWe focus on the relationship between the plant model $ G(s) $, the controller $ D(s) $, and how they interact with the command input $ R $, the output $ Y $, and the error $ E $.\nThe presence of a disturbance can be analyse in a similar way.\nAs we saw multiple times already:\n\nPlant Model $ G(s) $:\n\nThis represents the transfer function of the system we are controlling. It’s a mathematical model of the system’s dynamic behavior.\n\nController $ D(s) $:\n\n$ D(s) $ is the transfer function of the controller in the system. It defines how the controller will act on the error signal to adjust the system’s behavior.\n\nFeedback System Configuration:\n\nThe system is configured in a feedback loop where the output is compared with the input to generate an error signal $ E $.\n\nError Signal $ E(s) $:\n\nThis is a key part of the feedback loop. $ E(s) $ represents the difference between the desired output (command input $ R(s) $) and the actual output $ Y(s) $ of the system.\n\nCommand Input $ R(s) $:\n\n\nThis is the desired system output in the Laplace domain. It could be a step, ramp, or any other input form.\n\n\nSystem Output $ Y(s) $:\n\n\nThe actual output of the system, also represented in the Laplace domain.\n\n\nError Dynamics\nIn a control system, we often express the error $ E(s) $ as $ E(s) = R(s) - Y(s) $. In a feedback loop, this becomes $ E(s) = R(s) - G(s)D(s)E(s) $.\nRearranging for $ E(s) $: By rearranging the above equation, we get\n\\[ E(s) = \\frac{R(s)}{1 + D(s)G(s)} \\]\nHere, $D(s)G(s) $ represents the total loop gain of the system.\n\nWhy Split $ G(s) $ and $ D(s) $?\n\nBy considering $ G(s) $ and $ D(s) $ separately, we can study the system more flexibly, especially when considering different types of controllers (PD, PI, PID).\nThis separation allows for a modular approach to system design, where the plant and controller can be designed and analyzed independently before being combined.\n\n\n\nPractical Implications\n\nDesign Flexibility: Different controllers (PD, PI, PID) can be modeled and tested by simply changing $ D(s) $ without altering the plant model $ G(s) $.\nSystem Analysis: The impact of controller changes on system performance, including stability, transient response, and steady-state error, can be readily assessed.\nController Tuning: By manipulating $ D(s) $, the controller can be tuned to achieve desired performance specifications like minimal steady-state error, desired transient response, and stability margins.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#final-value-theorem-revisited",
    "href": "steady_state_accuracy_and_design_principles.html#final-value-theorem-revisited",
    "title": "Steady State Accuracy and Design Principles",
    "section": "Final Value Theorem Revisited",
    "text": "Final Value Theorem Revisited\nThe final value theorem is a tool we use to calculate the steady-state error of a system. Recall the theorem:\n\\[ e_{ss} = \\lim_{s \\to 0} sE(s) \\]\nWhere $ E(s) $ is the error signal in the Laplace domain.\nIn our case:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{sR(s)}{(1 + D(s)G(s))} \\]\n\nSteady-State Error for Standard Inputs\nLet’s consider three standard inputs: step, ramp, and parabola.\nWe will analyze each case:\n\nStep Input $ R(s) = $:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s(1 + D(s)G(s))}  = \\lim_{s \\to 0} \\frac{1}{1 + D(s)G(s)} = \\frac{1}{1 + \\lim_{s \\to 0} D(s)G(s)}\\]\nThis simplifies to \\[ e_{ss} = \\frac{1}{1 + K_p} \\]\nwhere $ K_p $ is called position error constant.\nInstead of specifying the steady state error of the system to a unit-step input you can equivalently reference the position error constant.\n\nIt is important to highlight that in the realm of position control systems, a step input is synonymous with a position input. This concept, though, is not limited to just position control scenarios. The principle can be extended to various types of control systems. For instance, in temperature control or liquid level control systems, the step input may represent a sudden change in the desired temperature or level. The position error constant thus becomes a versatile tool, providing a universal metric to quantify and compare the steady-state accuracy of diverse control systems across different applications.\n\nRamp Input $ R(s) = $:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s^2(1 + D(s)G(s))}  = \\lim_{s \\to 0} \\frac{1}{s(1 + D(s)G(s))} \\]\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} \\]\nThis leads to \\[ e_{ss} = \\frac{1}{K_v} \\]\nwith $ K_v = _{s } sD(s)G(s)$ being the velocity error constant.\nIn position control systems, a ramp input equates to a velocity command. When discussing the velocity error constant, it’s understood that the system is responding to a ramp input.\nParabolic Input $ R(s) = $:\n\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s^3(1 + D(s)G(s))}  = \\lim_{s \\to 0} \\frac{1}{s^2(1 + D(s)G(s))} \\]\n$ e_{ss} = _{s } $\nResults in \\[ e_{ss} = \\frac{1}{K_a} \\]\nwhere $ K_a = _{s }s^2D(s)G(s)$ is the acceleration error constant.\nIn position control systems, a ramp input equates to an acceleration command. When discussing the acceleration error constant, it’s understood that the system is responding to a parabolic input.\nThe conclusion from our discussion on steady-state accuracy is quite significant. There are two primary ways to describe the steady-state accuracy of a system:\n\nSteady-State Error with a Specified Input: This approach involves directly specifying the steady-state error for a given type of input signal.\nError Constants $ K_p, K_v, $ and $ K_a $: Alternatively, we can describe the system’s steady-state accuracy using error constants:\n\n$ K_p $ for position error constant,\n$ K_v $ for velocity error constant,\n$ K_a $ for acceleration error constant.\n\n\nThese error constants are defined specifically for standard input types: unit-step, unit-ramp, and unit-parabolic signals.\nHowever, it’s important to understand that if the input to your system differs from these standard forms, you’ll need to apply appropriate scaling to the error constants. This scaling is necessary to accurately represent the steady-state error for non-standard inputs. By doing so, you can extend the application of these error constants to a wider range of input signals, maintaining the system’s steady-state accuracy description’s relevance and accuracy. The process of scaling, once understood, becomes straightforward, allowing for flexible adaptation to various input types.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#general-expression-of-the-transfer-function",
    "href": "steady_state_accuracy_and_design_principles.html#general-expression-of-the-transfer-function",
    "title": "Steady State Accuracy and Design Principles",
    "section": "General Expression of the Transfer Function",
    "text": "General Expression of the Transfer Function\nThe transfer function of a control system, whether it be the plant model $ G(s) $ or the combined system $ D(s)G(s) $, can generally be represented as\n\\[ \\frac{\\prod_i (s - z_i)}{s^N \\prod_j (s - p_j)} \\]\nIn this representation, $ z_i $ and $ p_j $ signify the zeros and poles of the transfer function, respectively.\nThe term $ s^N $ is particularly important as it indicates the presence of poles at the origin (s = 0) on the s-plane.\nFor our analysis, we focus on cases where $ N $, implying no negative powers of $ s $ in the denominator.\nAny zeros at the origin can be represented through $ z_i = 0 $. However, in this representation all potential pole-zero cancellations at the origin are already accounted for.\n\nUnderstanding the Role of Poles at $ s = 0 $ in Steady-State Analysis\n\nKey Insights on $ s^N $ in System’s Transfer Function:\nThe term $ s^N $ in the transfer function $ D(s)G(s) $ is pivotal in shaping the steady-state behavior of a control system. It directly influences how the system responds to various inputs, determined by the value of $ N $, the number of poles at the origin.\n\nAnalyzing the Impact as $ s $ Approaches Zero:\n\nThe focus here is on the system’s behavior in a steady-state condition.\nAs $ s $ nears zero, each term in the transfer function, such as $ (s - z_i) $ and $ (s - p_j) $, maintains a defined value.\nThe behavior of $ D(s)G(s) $ largely hinges on $ N $, the number of poles at $ s = 0 $. Specifically, different values of $ N $ can lead to certain terms in the function becoming infinite when $ s = 0 $. This is crucial because it determines whether the system can achieve a steady state for given inputs. For instance, a Type-0 system (with $ N = 0 $) has a finite error for step inputs but infinite errors for ramp and parabolic inputs.\nThe significance of $ s^N $ lies in its primary influence on the system’s steady-state behavior, essentially deciding whether the system will exhibit finite or infinite steady-state errors for various input types.\n\nConsidering Negative Values of $ N $:\n\nIn scenarios where $ N $ is negative, indicating a zero at the origin, the analysis remains unproblematic. This is because any term involving $ s $ would result in a zero magnitude in such instances, leading to a defined and predictable behavior in the transfer function.\n\n\nIn essence, the term $ s^N $ is a key determinant in the transfer function, shaping the control system’s steady-state accuracy. Understanding how this term behaves, particularly as $ s $ converges to zero, is vital in gaining insights into the system’s capacity to maintain a steady state under different input conditions.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#system-classification-and-steady-state-behavior-based-on-n",
    "href": "steady_state_accuracy_and_design_principles.html#system-classification-and-steady-state-behavior-based-on-n",
    "title": "Steady State Accuracy and Design Principles",
    "section": "System Classification and Steady-State Behavior Based on \\(N\\)",
    "text": "System Classification and Steady-State Behavior Based on \\(N\\)\n\nClassification of Systems by $ N $ and Consideration of Input Types:\nControl systems are classified based on the value of $ N $, which signifies the number of poles at the origin. This is equivalently the number of integrators in the system’s forward path. In this classification:\n\nA Type-0 system, where $ N = 0 $, has no integrators at the origin.\nA Type-1 system has one integrator, indicating a single pole at the origin, and this pattern continues for higher system types.\n\nIt’s crucial to understand, however, that the influence of $ N $ on the system’s response isn’t absolute but varies with the type of input. If the system’s numerator has terms that counteract the $ s^N $ effect in the denominator, then the system might not exhibit infinite behavior for certain inputs.\nThe value of $ N $ is generally a strong indicator of the system’s potential for steady-state accuracy. Yet, the actual steady-state behavior also hinges on the nature of the input. In some cases, specific input types may lead to cancellations in the transfer function, altering the expected steady-state error irrespective of $ N $. Hence, the system’s steady-state response is determined not just by $ N $ alone, but also by the interaction of $ N $ with the particular input function $ R(s) $. This nuanced understanding is vital for accurately predicting and designing system responses.\n\n\nController’s Influence and Handling Different Inputs\nThe controller $ D(s) $ has the capability to modify the count of integrators in the forward path of a system, thereby significantly shaping its steady-state behavior.\nFor instance, using a PI controller is a strategic way to integrate an additional integrator into the forward path. This deliberate addition is crucial for fine-tuning the system’s performance to align with specific operational requirements.\nThe nature of the input signal, whether it’s a step, ramp, or parabolic type, also plays a critical role in influencing the system’s reaction. In the case of a Type-1 system (one integrator), one can expect a finite steady-state error when dealing with a step input. However, the response but could have infinite error for a ramp or parabolic input, unless there’s a cancellation in the transfer function that alters this behavior.\n\n\nType Number of the System\nThe following table illustrates the relationship between the value of $ N $ and the corresponding type of control system:\n\n\n\n\n\n\n\n\nValue of $ N $\nType of System\nDescription\n\n\n\n\n0\nType-0 System\nThe system has no integrators in the forward path, meaning no poles at the origin.\n\n\n1\nType-1 System\nThe system includes one integrator in the forward path, equivalent to a single pole at the origin.\n\n\n2\nType-2 System\nThe system contains two integrators in the forward path, indicating two poles at the origin.\n\n\n3\nType-3 System\nThe system has three integrators in the forward path, corresponding to three poles at the origin.\n\n\n…\n…\nAs $ N $ increases, the number of integrators in the forward path increases accordingly.\n\n\n\nThis table categorizes control systems based on the number of integrators (poles at the origin), which is a key factor in determining their steady-state response to different types of input signals.\nThe system characterized by the transfer function\n\\[ \\frac{s}{s^2} = \\frac{1}{s} \\]\nis identified as a Type-1 system.\nThis system effectively acts as an integrator, but it’s also important to recognize that this behavior results from an imperfect pole-zero cancellation.\nWhile its operational effects closely mimic those of an ideal integrator, the presence of practical imperfections means that it does not achieve the exact behavior of a perfect integrator. This distinction highlights the system’s real-world limitations compared to the theoretical ideal that we are representing mathematically.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#exploring-system-types-and-their-behaviours-based-on-n",
    "href": "steady_state_accuracy_and_design_principles.html#exploring-system-types-and-their-behaviours-based-on-n",
    "title": "Steady State Accuracy and Design Principles",
    "section": "Exploring System Types and Their Behaviours Based on $ N $",
    "text": "Exploring System Types and Their Behaviours Based on $ N $\nThe transfer function of a control system, whether it be the plant model $ G(s) $ or the combined system $ D(s)G(s) $, can typically be represented as:\n\\[\nD(s)G(s) = \\frac{K \\prod_{i}(s - z_i)}{(s^N \\prod_{j}(s - p_j))}\n\\]\nHere’s a table that outlines different system types based on the value of $ N$, along with examples and key characteristics:\n\n\n\n\n\n\n\n\n\nValue of $ N$\nSystem Type\nCharacteristics\nExample\n\n\n\n\n0\nType-0 System\nNo integrators in the forward path. Typically, finite steady-state error for step inputs but infinite error for ramp or parabolic inputs.\nTemperature control systems modeled as $ $, Liquid level control systems.\n\n\n1\nType-1 System\nOne integrator in the forward path. Zero steady-state error for step inputs, finite for ramp inputs, but infinite for parabolic inputs.\nMotor control systems in speed control applications, modeled as $ $.\n\n\n2\nType-2 System\nTwo integrators in the forward path. Zero steady-state error for both step and ramp inputs, finite for parabolic inputs.\nAttitude control of a satellite, modeled as $ $.\n\n\n≥3\nType-3 System\nThree or more integrators in the forward path. Highly specialized applications requiring advanced static accuracy.\nAdvanced radar or antenna control systems tracking fast-moving targets.\n\n\n\nThis table provides a clear overview of how the number of integrators in the forward path, indicated by $ N$, categorizes the system and influences its response to various inputs.\n\nAnalyzing Steady-State Error in Type-0 Systems\nIn a Type-0 system, the position error constant $ K_p $ is given by:\n\\[ K_p = \\frac{K \\prod_{i}(s - z_i)}{\\prod_{j}(s - p_j)}\\Big|_{s=0} \\]\nFor this system type, the steady-state error ( e_{ss} ) in response to a step input is calculated as:\n\\[ e_{ss} = \\frac{1}{1 + K_p} \\]\nThis value is finite, indicating that Type-0 systems can effectively handle step inputs with a finite error at steady state.\nHowever, when it comes to ramp and parabolic inputs, the scenario changes dramatically:\n\nFor Ramp Inputs: \\[ e_{ss}^{ramp} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} = \\frac{1}{K_v} = \\infty \\] The system exhibits an infinite steady-state error, demonstrating its inability to maintain accuracy with ramp inputs.\nFor Parabolic Inputs: \\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} = \\frac{1}{K_a} = \\infty \\] Similar to ramp inputs, the error is infinite for parabolic inputs as well.\n\n\nImplications for Type-0 Systems\nThis analysis reveals that Type-0 systems are limited in their ability to achieve high steady-state accuracy, especially for ramp and parabolic inputs. While they can provide reasonable performance for step inputs, their utility is constrained when faced with more complex input types.\nTo enhance the steady-state behavior and meet higher accuracy demands, it is necessary to intentionally introduce integrators into the controller’s design. Adding integrators effectively increases the type of the system, thereby improving its ability to handle a broader range of input types with better steady-state accuracy.\n\n\n\nAnalyzing Steady-State Error in Type-1 Systems\n\n\nUnderstanding Steady-State Error in Type-1 Systems\nIn Type-1 systems, characterized by one integrator in the forward path, the \\(D(s)G(s)\\) transfer function is:\n\\[\nD(s)G(s) = \\frac{K \\prod_{i}(s - z_i)}{s\\prod_{j}(s - p_j)}\n\\]\nthe position error constant $ K_p $ becomes infinite:\n\\[ K_p = \\infty \\]\nDue to this characteristic, the steady-state error $ e_{ss} $ for a step input is:\n\\[ e_{ss} = \\frac{1}{1 + K_p} = 0 \\]\nThis results in zero steady-state error for step inputs, signifying perfect tracking of such inputs.\n\nResponses to Ramp and Parabolic Inputs:\n\nFor Ramp Inputs: The velocity error constant $ K_v $ is finite, and the steady-state error for a ramp input is calculated as:\n\\[ e_{ss}^{ramp} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} = \\frac{1}{K_v} \\]\nand\n\\[\nK_v =  \\lim_{s \\to 0} s \\frac{K \\prod_{i}(s - z_i)}{s\\prod_{j}(s - p_j)}  = \\frac{K \\prod_{i}(s - z_i)}{\\prod_{j}(s - p_j)} \\Big|_{s=0}\n\\]\nIn this case, $ e_{ss}^{ramp} $ is finite, indicating that Type-1 systems can handle ramp inputs with a finite steady-state error.\nFor Parabolic Inputs: The acceleration error constant $ K_a $ is zero for Type-1 systems, leading to:\n\\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} = \\frac{1}{K_a} = \\infty \\]\nHence, the steady-state error for parabolic inputs is infinite, showing that Type-1 systems cannot accurately track such inputs at steady state.\n\n\n\nPractical Implications for Type-1 Systems\nType-1 systems excel in tracking step inputs perfectly with zero steady-state error and offer reasonable performance for ramp inputs with finite error. However, they fall short in tracking parabolic inputs, as indicated by the infinite steady-state error.\nThis analysis underscores that Type-1 systems are suitable for applications where step or ramp inputs are predominant, but they may not be adequate for scenarios requiring accurate tracking of more complex input types like parabolic signals. In such cases, further modifications or a different system type might be necessary for optimal performance.\n\n\n\nAnalysis of Steady-State Error in Type-2 Systems\nType-2 systems are characterized by having two integrators in the forward path. This feature significantly influences their response to different types of inputs.\n\nSteady-State Error for Different Inputs:\n\nStep Input:\n\nFor a step input, the steady-state error $ e_{ss} $ is given by: \\[ e_{ss} = \\frac{1}{1 + K_p} \\] Since $ K_p = \\(, the steady-state error for a step input is:\\)$ e_{ss} = = 0 $$ This indicates zero steady-state error for step inputs, showcasing perfect tracking capability.\n\nRamp Input:\n\nFor a ramp input, the velocity error constant $ K_v $ is also infinite for a Type-2 system. The steady-state error for a ramp input is calculated as: \\[ e_{ss}^{ramp} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} \\] Given that $ K_v = \\(, the steady-state error for a ramp input becomes:\\)$ e_{ss}^{ramp} = = = 0 $$ Hence, Type-2 systems also exhibit zero steady-state error for ramp inputs.\n\nParabolic Input:\n\nFor parabolic inputs, we look at the acceleration error constant $ K_a $. In a Type-2 system, $ K_a $ is finite. The steady-state error for a parabolic input is given by: \\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} \\] This yields a finite value for $ e_{ss}^{parabola} $, implying that Type-2 systems have a finite steady-state error for parabolic inputs.\n\n\n\n\nSummary and Implications for Type-2 Systems\nType-2 systems are highly capable in terms of steady-state performance. They demonstrate zero steady-state error for both step and ramp inputs, indicating excellent tracking abilities for these input types. For parabolic inputs, Type-2 systems maintain a finite steady-state error, making them suitable for applications where precise tracking of such inputs is required.\nIn summary, Type-2 systems offer an advanced level of control, particularly in scenarios where the inputs can vary from simple steps to more complex parabolic forms. Their dual integrators in the forward path equip them with the ability to handle a wider range of input types effectively compared to Type-0 and Type-1 systems. However, two integrators in the forward path will make the system closer to instability. There is a design trade-off to make.\n\n\n\nCommentary on Type-3 Systems\nType-3 systems are characterized by having three integrators in the forward path. While less common than Type-0, Type-1, or Type-2 systems, they are significant in certain advanced control applications.\nThe need for a Type-3 system arises when the application demands zero steady-state error even for acceleration-type inputs. This is critical in scenarios where the input undergoes rapid changes, as in military radar systems tracking fast-moving aircraft.\n\nWhen Might a Type-3 System Be Necessary?\n\nHigh-Performance Requirements: Type-3 systems are typically required in scenarios demanding extremely precise control and high levels of steady-state accuracy for a variety of input types, including step, ramp, and parabolic inputs.\nFast-Moving Target Tracking: They are particularly useful in applications like advanced radar or antenna control systems, where tracking fast-moving targets with high precision is crucial. In these applications, the inputs can be quite complex and may involve rapid and unpredictable changes.\nSophisticated Industrial Applications: Certain high-end automation systems or robotic controls might also employ Type-3 systems to achieve superior dynamic response characteristics and minimize errors in a broad range of operating conditions.\n\n\n\nPotential Issues with Type-3 Systems\n\nComplexity in Design and Tuning: The presence of multiple integrators increases the complexity of the control system design. Tuning a Type-3 system to achieve desired performance without compromising stability can be challenging.\nStability Concerns: One of the significant issues with Type-3 systems is the increased risk of instability. The higher the number of integrators, the more challenging it becomes to maintain system stability, especially under varying operating conditions.\nPractical Limitations: Implementing a Type-3 system may face practical constraints. These include the physical limitations of the system components, environmental factors, and the inherent noise and non-linearities present in real-world systems.\n\nWhile Type-3 systems offer advanced control capabilities and can handle a wide range of input types with high accuracy, their design, implementation, and maintenance require a sophisticated understanding of control theory and practical considerations. They are typically reserved for specialized applications where their advanced characteristics are essential and justify the additional complexity and potential risks.\n\n\nSummary\nThe system’s response to various inputs (step, ramp, parabolic) depends on its type.\n\nA Type-0 system will have a finite steady-state error for a step input, but an infinite error for a ramp or parabolic input.\nA Type-1 system has zero steady-state error for a step input but finite for a ramp and infinite for a parabolic input.\n\n\n\n\nIllustrate the responses of Type-0, Type-1, and Type-2 systems\nTo illustrate the responses of Type-0, Type-1, and Type-2 systems to different inputs, we can use Python with libraries such as matplotlib for plotting and scipy for control system analysis.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\n\n# Define the time range for simulation\nt = np.linspace(0, 10, 2000)\n\n# Open-loop transfer functions\n# Type-0 system: K/(s + 0.8)\nK_0 = 10\ntype_0_ol = ctrl.TransferFunction([K_0], [1, 0.8])\n\n# Type-1 system: K/(s(s + 1))\nK_1 = 1\ntype_1_ol = ctrl.TransferFunction([K_1], [1, 1, 0])\n\n# Type-2 system: Double Integrator with damping (1/s^2)\n# Adding a small damping factor to stabilize the response\nK_2 = 10\ndamping_factor = 1\ntype_2_ol = ctrl.TransferFunction([K_2, 1], [1, damping_factor, 0, 0]) # note that we are adding a zero.\n\n\n# Closed-loop transfer functions\ntype_0_sys = ctrl.feedback(type_0_ol)\ntype_1_sys = ctrl.feedback(type_1_ol)\ntype_2_sys = ctrl.feedback(type_2_ol)\n\n\n\n# Function to plot system responses, input signal, and tracking error\ndef plot_responses_and_errors(systems, t, input_signal, input_type):\n    plt.figure(figsize=(12, 6))\n\n    # Plotting system responses and errors\n    for i, sys in enumerate(systems):\n        t_out, y_out = ctrl.forced_response(sys, T=t, U=input_signal)\n        error = input_signal - y_out\n\n        # Plotting response\n        plt.subplot(2, 1, 1)\n        plt.plot(t_out, y_out, label=f'{[\"Type-0\", \"Type-1\", \"Type-2\"][i]} System Response')\n        plt.title(f'Response of Systems to {input_type} Input')\n        plt.ylabel('Response/Signal Value')\n        plt.grid(True)\n\n        # Plotting error\n        plt.subplot(2, 1, 2)\n        plt.plot(t_out, error, label=f'{[\"Type-0\", \"Type-1\", \"Type-2\"][i]} Error')\n        plt.title(f'Tracking Error of Systems for {input_type} Input')\n        plt.xlabel('Time (seconds)')\n        plt.ylabel('Error')\n        plt.grid(True)\n\n    # Adding the input signal plot to the response subplot\n    plt.subplot(2, 1, 1)\n    plt.plot(t, input_signal, label='Input Signal', color='black', linestyle='--')\n    plt.legend()\n\n    # Adding the input signal plot to the error subplot (as zero line)\n    plt.subplot(2, 1, 2)\n    plt.plot(t, np.zeros_like(t), label='Zero Error', color='grey', linestyle='--')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Input signals: unit step, unit ramp, and unit parabola\nstep_input = np.ones_like(t)\nramp_input = t\nparabola_input = 0.5 * t**2\n\n# Systems list and plotting responses with errors\nsystems = [type_0_sys, type_1_sys, type_2_sys]\nplot_responses_and_errors(systems, t, step_input, 'Step')\nplot_responses_and_errors(systems, t, ramp_input, 'Ramp')\nplot_responses_and_errors(systems, t, parabola_input, 'Parabola')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurther comments\n\nGenerally, control system requirements assume a goal of achieving zero steady-state error for unit step inputs and maintaining finite errors for ramp inputs, unless other specifications are provided.\nWhen selecting controllers, the system’s inherent characteristics guide the choice:\n\nIf the system naturally includes an integrator, employing a Proportional-Derivative (PD) controller is often appropriate. This choice maintains the system’s existing type, enhancing control without altering its fundamental behavior.\nConversely, for systems lacking an in-built integrator, a Proportional-Integral (PI) controller is typically more effective. A PI controller introduces an additional integrator, effectively increasing the system’s type number, and thereby improving its ability to handle a wider range of input types, especially in terms of steady-state accuracy.",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "steady_state_accuracy_and_design_principles.html#design-example-a-pid-control-scheme",
    "href": "steady_state_accuracy_and_design_principles.html#design-example-a-pid-control-scheme",
    "title": "Steady State Accuracy and Design Principles",
    "section": "Design Example: A PID Control Scheme",
    "text": "Design Example: A PID Control Scheme\nLet’s apply our understanding to design a PID controller for a given plant. We’ll walk through the design process step-by-step.\n\n\n\n\n\n\nPosition Control System Design with a Proportional Controller\nIn a position control problem, our aim is to design a suitable controller $ D(s) $ that ensures desired system performance. Given that the plant already incorporates an integrator, we can start our design process with a straightforward proportional controller represented as $ D(s) = K_A $.\n\nAnalyzing the Combined System\nFor a proportional controller $ D(s) = K_A $, the transfer function of the combined system (controller and plant) is:\n\\[ D(s)G(s) = \\frac{4500 K_A}{s(s+361.2)} \\]\n\n\nCharacteristic Equation\nThe characteristic equation of this closed-loop system is:\n\\[ s^2 + 361.2 s + 4500 K_A = 0 \\]\nFrom this characteristic equation, we can derive important system parameters as functions of $ K_A $:\n\nNatural frequency ($ _n $): $ _n = $\nDamping ratio ($ $): $ = $\nSystem poles: $ s_{1,2} = -180.6 j $\nSteady-state error for unit ramp input: $ e_{ss} = $\n\nFor a unit-step input, the steady-state error is zero due to the presence of the integrator in the plant.\n\n\nSelecting $ K_A $ for Critical Damping\nTo achieve critical damping ($ = 1 $), let’s choose:\n\\[ K_A = 7.247 \\]\nThis specific value of $ K_A $ results in a critically damped response, which is ideal for position control as it ensures fast response without oscillation.\nChoosing a gain such that $ = 1 $ might lead to a high settling time. Note also that the rise time is infinity (the system only gets to 1 when \\(t\\) goes to infinity).\nTo calculate the settling time, remember that the approximation that we derived was valid when \\(0&lt;\\zeta&lt;0.7\\).\n\n\n\nSelecting \\(K_A\\) to reduce the damping ration \\(\\zeta\\).\nTo achieve critical damping ($ = 0.707 $), let’s choose:\n\\[ K_A = 14.5 \\]\nWhich leads to a maximum overshoot:\n\\[\nM_p = 4.3\\%\n\\]\nThe rise time in this case is lower than before, and in fact might be the lowest (I did not do the formal calculations).\n\\(M_p = 4.3\\%\\) is the price we are paying for a lower rise time, and might be acceptable.\nRemember that \\[\n   M_p = y(t_p) - 1 = e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n   \\]\nThe steady-state error is:\n\\[\ne_{ss} = \\frac{0.0803}{K_A}\n\\]\nwhich means that if we want to reduce it we need to reduce the value of \\(\\zeta\\) and the peak overshoot increases.\nAssume now that your requirement is:\n\\[M_p\\le25\\%\\]\nThis corresponds to a minium damping ratio of:\n\\[\n\\zeta= 0.4\n\\]\nwhich is obtained for\n\\[\nK_A = 45.3\n\\]\nThis reduces the steady-state error but we are also moving the system towards instability.\nThere is nothing else we can do with a proportional controller without violating our requirements.\n\n\nPython Simulation of the Critically Damped System\nWe will now simulate this critically damped system in Python to visualize its response to a step input:\nThis script simulates and plots the step response of the position control system with a proportional controller set for critical damping. The chosen value of $ K_A $ ensures that the system is critically damped, thereby achieving a quick and stable response to changes in input without overshooting.\nUse the code below to try:\n\n\\(K_A = 7.247\\)\n\\(K_A = 14.5\\)\n\nverify what is the associated rise time, steady state error and maximum overshoot.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for a given K_A\ndef plot_step_response(K_A):\n    # Transfer function of the system\n    G_s = ctrl.TransferFunction([4500 * K_A], [1, 361.2, 4500 * K_A])\n\n    # Time range for simulation\n    t = np.linspace(0, 0.4, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(G_s, T=t)\n    \n    # steady state error\n    e_ss = 0.0803/K_A\n    \n    # Peak overshoot\n    omega_n = np.sqrt(4500*K_A)\n    zeta = 2.692/np.sqrt(K_A)\n    omega_d = omega_n * np.sqrt(1 - zeta**2)\n    #M_p = np.exp(-zeta*omega_n*np.pi/omega_d)\n    M_p = np.exp(-np.pi*zeta/(np.sqrt(1-zeta**2)))\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with Proportional Gain K_A = {K_A:.2f}, e_ss = {e_ss:.4f}, M_p % = {M_p*100:.1f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Create a slider for K_A\nK_A_slider = widgets.FloatSlider(\n    value=7.247,\n    min=0.1,\n    max=47.0,\n    step=0.1,\n    description='K_A Slider:',\n    continuous_update=False\n)\n\n# Create a text box for K_A\nK_A_text = widgets.FloatText(\n    value=7.247,\n    description='K_A Text:',\n)\n\n# Function to synchronize slider and text box values\ndef on_value_change(change):\n    K_A_slider.value = change.new\n    K_A_text.value = change.new\n\nK_A_slider.observe(on_value_change, names='value')\nK_A_text.observe(on_value_change, names='value')\n\n# Use `interactive` to bind the plot function to both the slider and the text box\ndisplay(widgets.interactive(plot_step_response, K_A=K_A_slider))\ndisplay(K_A_text)\n\n\n\n\n\n\n\n\n\nImproving Performance - Enhanced Control System Design with PD and PI Controllers\n\nPD Control:\n\nOverview: The addition of a derivative term in PD control significantly influences the system’s damping characteristics. While it doesn’t directly reduce the steady-state error, the derivative action plays a crucial role in enhancing system stability and response.\nImpact on Design: By incorporating a derivative term, PD control allows for an increase in the proportional gain $ K_A $ without breaching maximum overshoot constraints. Specifically, the enhanced damping provided by the derivative term enables the system to tolerate a higher $ K_A $, making it possible to maintain overshoot within the desired limit of 25%.\nController Formula: $ D(s) = K_C + K_Ds $, where $ K_C $ is the proportional gain and $ K_D $ is the derivative gain.\n\nPI Control:\n\nOverview: PI control introduces an integrator to the control scheme, directly targeting the reduction of steady-state error, particularly effective in eliminating offset errors in various control applications.\nBalancing Transient and Steady-State Performance: While a PI controller is adept at minimizing steady-state error, careful tuning is required to ensure that transient performance criteria, such as settling time and overshoot, are also met.\nFor the PI (Proportional-Integral) control case, the controller $ D(s) $ is typically formulated as a combination of a proportional term and an integral term. The general form of a PI controller in the Laplace domain is:\n\n\n\\[ D(s) = K_P + \\frac{K_I}{s} \\]\nWhere: - $ K_P $ is the proportional gain. - $ K_I $ is the integral gain.\nThe proportional term $ K_P $ provides a control action proportional to the error signal, offering immediate response to changes in the system. The integral term $ $ accumulates the error over time, aiming to eliminate the steady-state error. The combination of these two actions allows the PI controller to both react promptly to system changes and methodically reduce any persistent error.\nIn a practical control system, tuning the values of $ K_P $ and $ K_I $ is crucial to achieving the desired balance between rapid response and steady-state accuracy, ensuring that the system meets its performance specifications effectively.\n\n\nAdvanced Controller Design: Root Locus and Frequency Response Methods\nIn our upcoming discussions, we will delve into more formalized methods for controller design, namely the Root Locus method and the Frequency Response method. These techniques provide powerful tools for analyzing and designing control systems, allowing us to:\n\nPrecisely shape the system’s response by adjusting controller parameters.\nVisually assess the stability and performance trade-offs.\nFine-tune controllers to achieve a desirable balance between transient response and steady-state accuracy.\n\nThrough these methods, we can develop a deeper understanding of control system dynamics and design controllers that are optimally suited to the specific requirements of our applications.\n\nPD control\nTo modify the code to use a controller described by $ D(s) = K_C + K_Ds $, which is a proportional-derivative (PD) controller, we need to update the transfer function of the combined system (controller and plant) accordingly.\nAssuming the plant transfer function remains the same as in the previous example, the combined transfer function of the system with the PD controller will be:\n\\[ D(s)G(s) = \\frac{(K_C + K_Ds) \\cdot 4500K_A}{s(s+361.2)} \\]\nLet’s update the Python script to incorporate this PD controller. We’ll add sliders for both $ K_C $ (proportional gain) and $ K_D $ (derivative gain) to interactively observe the system’s response.\nThe script below allows you to dynamically adjust the proportional gain $ K_C $ and the derivative gain $ K_D $ of the PD controller using sliders. The step response of the system will update based on these values, helping you visualize how the PD controller affects the system’s behavior. Remember, this interactive feature works in a Jupyter notebook environment.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for given K_C and K_D\ndef plot_step_response(K_C, K_D):\n    # PD controller transfer function\n    D_s = ctrl.TransferFunction([K_D, K_C], [1])\n\n    # Plant transfer function\n    G_s = ctrl.TransferFunction([4500], [1, 361.2, 0])\n\n    # Combined system transfer function\n    system = ctrl.series(D_s, G_s)\n    closed_loop_system = ctrl.feedback(system)\n\n    # Time range for simulation\n    t = np.linspace(0, 2, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(closed_loop_system, T=t)\n\n    # Peak overshoot (M_p) and steady-state error (e_ss) calculations\n    e_ss = 0.0803 / K_C  # Assuming K_C is dominant for steady-state error\n    peak = np.max(y)\n    M_p = ((peak - 1) / 1) * 100  # Peak overshoot in percentage\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with K_C = {K_C:.2f}, K_D = {K_D:.2f}, e_ss = {e_ss:.4f}, M_p % = {M_p:.1f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Sliders for K_C and K_D\nK_C_slider = widgets.FloatSlider(value=1.0, min=0.1, max=10, step=0.1, description='K_C:')\n# K_D_slider = widgets.FloatSlider(value=1.0, min=0.1, max=10, step=0.1, description='K_D:')\nK_D_slider = widgets.FloatSlider(value=.1, min=0, max=2, step=0.1, description='K_D:')\n\n# Interactive plot\nwidgets.interactive(plot_step_response, K_C=K_C_slider, K_D=K_D_slider)\n\n\n\n\n\n\nPI Control\nTo modify the code for a PI control, we need to change the transfer function of the controller to represent a PI controller and adjust the calculations accordingly. The PI controller has the form $ D(s) = K_P + $, where $ K_P $ is the proportional gain and $ K_I $ is the integral gain.\nFor simplicity, let’s assume $ K_P $ and $ K_I $ are equal and represented by the same variable $ K_A $ in the script. The transfer function of the PI controller will then be $ D(s) = K_A + $. We also need to update the combined system transfer function and adjust the calculations for the steady-state error and peak overshoot.\nThe steady-state error for a step input is zero due to the integrator in the PI controller. Calculating the peak overshoot for a PI controller analytically can be complex and is often done using numerical methods or graphically from the response plot. The script now uses interactive sliders to allow to adjust $ K_A $ and observe the system’s response.\nHere’s the modified script:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for a given K_A\ndef plot_step_response(K_A):\n    # PI controller transfer function: D(s) = K_A + K_A/s\n    D_s = ctrl.TransferFunction([K_A, K_A], [1, 0])\n\n    # Plant transfer function: G(s) = 4500/(s(s+361.2))\n    G_s = ctrl.TransferFunction([4500], [1, 361.2, 0])\n\n    # Combined system transfer function\n    system = ctrl.series(D_s, G_s)\n    closed_loop_system = ctrl.feedback(system)\n\n    # Time range for simulation\n    t = np.linspace(0, 2, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(closed_loop_system, T=t)\n    \n    # Steady-state error is zero for a step input due to the integrator in PI controller\n    e_ss = 0.0\n    \n    # Peak overshoot calculation is not straightforward for a PI controller\n    # and typically requires numerical methods or graphically from the plot\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with PI Gain K_A = {K_A:.2f}, e_ss = {e_ss:.4f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Create a slider for K_A\nK_A_slider = widgets.FloatSlider(\n    value=1.0,\n    min=0.1,\n    max=10.0,\n    step=0.1,\n    description='K_A Slider:',\n    continuous_update=False\n)\n\n# Create a text box for K_A\nK_A_text = widgets.FloatText(\n    value=1.0,\n    description='K_A Text:',\n)\n\n# Function to synchronize slider and text box values\ndef on_value_change(change):\n    K_A_slider.value = change.new\n    K_A_text.value = change.new\n\nK_A_slider.observe(on_value_change, names='value')\nK_A_text.observe(on_value_change, names='value')\n\n# Use `interactive` to bind the plot function to both the slider and the text box\ndisplay(widgets.interactive(plot_step_response, K_A=K_A_slider))\ndisplay(K_A_text)",
    "crumbs": [
      "Steady State Accuracy and Design Principles"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html",
    "href": "TCLab/understanding_tclab.html",
    "title": "Understanding TCLab",
    "section": "",
    "text": "a=456",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#the-core-components-of-tclab",
    "href": "TCLab/understanding_tclab.html#the-core-components-of-tclab",
    "title": "Understanding TCLab",
    "section": "The Core Components of TCLab",
    "text": "The Core Components of TCLab\n  \nThe Temperature Control Lab (TCLab) is an integrated system composed of several key components, each contributing significantly to its functionality:\n\nArduino Microcontroller:\n\nPurpose: Serves as the central processing unit for the TCLab.\nFunctionality: Processes input data from temperature sensors and manages the operation of heaters.\nConnectivity: Utilizes a USB connection for data transfer and allows for real-time control through Python scripts.\n\nHeaters:\n\nDescription: TCLab features two heaters, each capable of generating adjustable thermal energy.\nRole: Act as the main heat sources for experiments, replicating scenarios requiring temperature regulation. They function as the system’s actuators.\n\nTemperature Sensors:\n\nType: These sensors are thermistors, a kind of resistor whose resistance varies with temperature changes.\nMeasurement Range: Capable of measuring temperatures ranging from \\(-40^\\circ\\)C to \\(150^\\circ\\)C.\nFunctionality: Positioned near each heater to accurately measure temperature, providing essential feedback for temperature control.\n\nHeat Sinks:\n\nType: Comprised of transistor heat sinks.\nPurpose: Employed to efficiently dissipate heat away from the transistors.\n\nLED (Light Emitting Diode):\n\n\nPurpose: Serves as a visual indicator for various states or actions, such as signaling the activation of a heater.\n\n\nOperational Configurations of TCLab\nTCLab can be configured in various modes depending on the educational objectives:\n\nSingle Input Single Output (SISO):\n\nUtilizes only one heater and one sensor. Ideal for simple control experiments and learning the basics of temperature control.\n\nSingle Input Single Output (SISO) with Disturbance:\n\nEmploys one heater/sensor as the primary control system and the second heater as a source of external disturbance. This setup is useful for understanding how external factors influence control systems.\n\nMultiple Inputs Multiple Outputs (MIMO):\n\nInvolves using both heaters and sensors simultaneously. This more advanced configuration isn’t covered here but is valuable for complex control system studies.\n\n\nEach component of the TCLab plays a specific role, making it a versatile tool for teaching and experimenting with various aspects of control engineering. Whether for fundamental learning or advanced exploration, TCLab offers a practical platform for understanding the dynamics and control of temperature-based systems.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#how-tclab-works",
    "href": "TCLab/understanding_tclab.html#how-tclab-works",
    "title": "Understanding TCLab",
    "section": "How TCLab Works",
    "text": "How TCLab Works\n\nOperation Flow:\n\nInput Signal: A Python script sends a command to the Arduino, setting the desired power level for the heaters.\nHeating Action: The heaters generate heat corresponding to the received power level commands.\nTemperature Measurement: The thermistors measure the resulting temperatures near the heaters.\nFeedback Loop: These temperature readings are sent back to the computer.\nAdjustments: The control algorithm in the Python script adjusts the heater power based on the temperature feedback, striving to reach and maintain a target temperature.\n\n\n[Insert Flowchart or Diagram Showing the Feedback Loop Here]",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#tclab-schematics",
    "href": "TCLab/understanding_tclab.html#tclab-schematics",
    "title": "Understanding TCLab",
    "section": "TCLab Schematics",
    "text": "TCLab Schematics",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#section-1-installing-python-using-conda",
    "href": "TCLab/understanding_tclab.html#section-1-installing-python-using-conda",
    "title": "Understanding TCLab",
    "section": "Section 1: Installing Python Using Conda",
    "text": "Section 1: Installing Python Using Conda",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#installing-python-on-mac",
    "href": "TCLab/understanding_tclab.html#installing-python-on-mac",
    "title": "Understanding TCLab",
    "section": "Installing Python on Mac",
    "text": "Installing Python on Mac\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Mac.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Terminal.\nType conda --version and press Enter. If Anaconda is successfully installed, you’ll see the version number.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#installing-python-on-windows",
    "href": "TCLab/understanding_tclab.html#installing-python-on-windows",
    "title": "Understanding TCLab",
    "section": "Installing Python on Windows",
    "text": "Installing Python on Windows\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Windows.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Anaconda Prompt.\nType conda --version and press Enter.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Anaconda Prompt, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#installing-python-on-linux",
    "href": "TCLab/understanding_tclab.html#installing-python-on-linux",
    "title": "Understanding TCLab",
    "section": "Installing Python on Linux",
    "text": "Installing Python on Linux\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Linux.\nRun Installer: Open Terminal, navigate to the directory containing the downloaded file, and run the script using bash Anaconda3-XXXX.sh.\nVerify Installation:\n\nIn Terminal, type conda --version.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#setting-up-the-conda-environment",
    "href": "TCLab/understanding_tclab.html#setting-up-the-conda-environment",
    "title": "Understanding TCLab",
    "section": "Setting Up the Conda Environment",
    "text": "Setting Up the Conda Environment\nTo set up the Conda environment for this course, follow these steps:\n\nDownload the tclab_environment.yml file from this repository.\nOpen your terminal or Anaconda Prompt and navigate to the directory where the file is located.\n\nThe file tclab_environment.yml looks like this:\nname: tclab_env\nchannels:\n  - defaults\ndependencies:\n  - python=3.10\n  - pip\n  - numpy\n  - matplotlib\n  - scipy\n  - pandas\n  - pip:\n    - tclab\n\nCreate the environment from the tclab_environment.yml file:\nconda env create -f tclab_environment.yml\nActivate the new environment:\nconda activate tclab\nTo verify that the environment was installed correctly, you can use:\nconda env list\n\n\nInstalling the TCLab Package\n\nActivating the Environment:\n\nEnsure your Anaconda environment is active. Open your Terminal (or Anaconda Prompt on Windows) and activate your environment:\nconda activate tclab_env\n\nInstalling TCLab:\n\nThe tclab library interfaces with the Temperature Control Lab hardware. Install it by entering the following command from a window (MacOS) or command window (PC):\npip install tclab\nPress Enter to execute the command and complete the installation.\n\nAlternatively, the installation can be performed from within a Jupyter/Python notebook with the command\n!pip install tclab\nThere are occasional updates to the library. These can be installed by appending a --upgrade to the above commands and demonstrated in the next cell.\n\n\n!python -m pip install tclab --upgrade\n\nRequirement already satisfied: tclab in /Users/andreamunafo/opt/anaconda3/envs/tclab/lib/python3.10/site-packages (1.0.0)\nRequirement already satisfied: pyserial in /Users/andreamunafo/opt/anaconda3/envs/tclab/lib/python3.10/site-packages (from tclab) (3.5)\n\n\n\nInstalling Additional Useful Libraries\nFor a comprehensive experience with TCLab and to support various aspects of control engineering and data analysis, the following libraries will also be installed:\n\nnumpy:\n\nSignificance: A fundamental library for numerical computations in Python.\nInstallation Command:\npip install numpy\n\nmatplotlib:\n\nSignificance: Crucial for creating visual representations of data, especially for the analysis of TCLab experiments.\nInstallation Command:\npip install matplotlib\n\nscipy:\n\nSignificance: Provides a broad range of tools for scientific computing, including methods for solving ordinary differential equations, useful in system modeling.\nInstallation Command:\npip install scipy\n\npandas:\n\nSignificance: Offers extensive features for data manipulation and analysis, ideal for handling complex datasets.\nInstallation Command:\npip install pandas\n\ngekko:\n\nSignificance: Advanced package for optimization and control, suitable for implementing model predictive control strategies.\nInstallation Command:\npip install gekko",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#initial-tests-with-tclab",
    "href": "TCLab/understanding_tclab.html#initial-tests-with-tclab",
    "title": "Understanding TCLab",
    "section": "Initial Tests with TCLab",
    "text": "Initial Tests with TCLab\n\nStep 1: Connect TCLab\n\nConnect TCLab: Plug in the TCLab device to your computer using a USB cable.\n\n\n\nStep 2: Test TCLab Connection\n\nWrite Test Script:\n\nOpen your Python IDE or Jupyter Notebook.\nWrite the following Python code and run the script. If it prints the temperature, TCLab is connected properly.\n\n\n\nimport tclab\n\n\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")\n\nTCLab version 1.0.0\nArduino Leonardo connected on port /dev/cu.usbmodem142101 at 115200 baud.\nTCLab Firmware 3.0.0 Arduino Leonardo/Micro.\nConnected! Heater 1 is at 24.024°C\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#using-tclab-simulator",
    "href": "TCLab/understanding_tclab.html#using-tclab-simulator",
    "title": "Understanding TCLab",
    "section": "Using TCLab Simulator",
    "text": "Using TCLab Simulator\n\nWhy Use a Simulator: The TCLab simulator is useful when you don’t have the physical hardware available.\nInstall Simulator: In Terminal or Anaconda Prompt, type pip install tclab again (it includes the simulator).\nTest Script with Simulator:\n\n\nfrom tclab import TCLabModel as TCLab, setup, clock\n\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.24 seconds. T1: 20.949499999999997°C\nTime 6.23 seconds. T1: 20.949499999999997°C\nTime 8.22 seconds. T1: 20.949499999999997°C\nTime 10.18 seconds. T1: 20.949499999999997°C\nTime 12.18 seconds. T1: 20.949499999999997°C\nTime 14.2 seconds. T1: 20.6272°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.01 seconds. T1: 20.949499999999997°C\nTime 20.23 seconds. T1: 20.949499999999997°C\nTime 22.17 seconds. T1: 20.6272°C\nTime 24.12 seconds. T1: 20.949499999999997°C\nTime 26.02 seconds. T1: 20.949499999999997°C\nTime 28.02 seconds. T1: 20.949499999999997°C\nTime 30.02 seconds. T1: 20.949499999999997°C\nTime 32.15 seconds. T1: 20.949499999999997°C\nTime 34.09 seconds. T1: 20.949499999999997°C\nTime 36.03 seconds. T1: 20.949499999999997°C\nTime 38.21 seconds. T1: 20.949499999999997°C\nTime 40.25 seconds. T1: 20.949499999999997°C\nTime 42.25 seconds. T1: 20.949499999999997°C\nTime 44.13 seconds. T1: 20.949499999999997°C\nTime 46.28 seconds. T1: 20.949499999999997°C\nTime 48.17 seconds. T1: 20.949499999999997°C\nTime 50.15 seconds. T1: 20.949499999999997°C\nTime 52.04 seconds. T1: 20.6272°C\nTime 54.27 seconds. T1: 20.949499999999997°C\nTime 56.04 seconds. T1: 20.949499999999997°C\nTime 58.04 seconds. T1: 20.949499999999997°C\nTime 60.06 seconds. T1: 20.949499999999997°C\nTime 62.19 seconds. T1: 20.949499999999997°C\nTime 64.04 seconds. T1: 20.949499999999997°C\nTime 66.14 seconds. T1: 20.949499999999997°C\nTime 68.21 seconds. T1: 20.949499999999997°C\nTime 70.25 seconds. T1: 20.949499999999997°C\nTime 72.14 seconds. T1: 20.949499999999997°C\nTime 74.26 seconds. T1: 20.949499999999997°C\nTime 76.16 seconds. T1: 20.949499999999997°C\nTime 78.03 seconds. T1: 20.949499999999997°C\nTime 80.2 seconds. T1: 20.949499999999997°C\nTime 82.09 seconds. T1: 20.949499999999997°C\nTime 84.11 seconds. T1: 20.6272°C\nTime 86.29 seconds. T1: 20.949499999999997°C\nTime 88.01 seconds. T1: 20.949499999999997°C\nTime 90.26 seconds. T1: 20.949499999999997°C\nTime 92.0 seconds. T1: 20.949499999999997°C\nTime 94.2 seconds. T1: 20.949499999999997°C\nTime 96.14 seconds. T1: 20.949499999999997°C\nTime 98.08 seconds. T1: 20.949499999999997°C\nTime 100.02 seconds. T1: 20.949499999999997°C\nTime 102.26 seconds. T1: 20.949499999999997°C\nTime 104.28 seconds. T1: 20.949499999999997°C\nTime 106.08 seconds. T1: 20.949499999999997°C\nTime 108.16 seconds. T1: 20.949499999999997°C\nTime 110.25 seconds. T1: 20.949499999999997°C\nTime 112.2 seconds. T1: 20.949499999999997°C\nTime 114.0 seconds. T1: 20.949499999999997°C\nTime 116.06 seconds. T1: 20.949499999999997°C\nTime 118.02 seconds. T1: 20.6272°C\nTime 120.0 seconds. T1: 20.949499999999997°C\nTime 122.01 seconds. T1: 20.6272°C\nTime 124.09 seconds. T1: 20.6272°C\nTime 126.16 seconds. T1: 20.6272°C\nTime 128.1 seconds. T1: 20.949499999999997°C\nTime 130.01 seconds. T1: 20.949499999999997°C\nTime 132.01 seconds. T1: 20.949499999999997°C\nTime 134.25 seconds. T1: 20.949499999999997°C\nTime 136.23 seconds. T1: 20.949499999999997°C\nTime 138.23 seconds. T1: 20.949499999999997°C\nTime 140.19 seconds. T1: 20.949499999999997°C\nTime 142.06 seconds. T1: 20.949499999999997°C\nTime 144.21 seconds. T1: 20.6272°C\nTime 146.02 seconds. T1: 20.949499999999997°C\nTime 148.08 seconds. T1: 20.949499999999997°C\nTime 150.09 seconds. T1: 20.949499999999997°C\nTime 152.02 seconds. T1: 20.949499999999997°C\nTime 154.02 seconds. T1: 20.949499999999997°C\nTime 156.21 seconds. T1: 20.949499999999997°C\nTime 158.23 seconds. T1: 20.949499999999997°C\nTime 160.02 seconds. T1: 20.949499999999997°C\nTime 162.24 seconds. T1: 20.949499999999997°C\nTime 164.12 seconds. T1: 20.949499999999997°C\nTime 166.29 seconds. T1: 20.949499999999997°C\nTime 168.06 seconds. T1: 20.949499999999997°C\nTime 170.19 seconds. T1: 20.949499999999997°C\nTime 172.19 seconds. T1: 20.949499999999997°C\nTime 174.27 seconds. T1: 20.949499999999997°C\nTime 176.27 seconds. T1: 20.949499999999997°C\nTime 178.07 seconds. T1: 20.949499999999997°C\nTime 180.13 seconds. T1: 20.949499999999997°C\nTime 182.19 seconds. T1: 20.6272°C\nTime 184.03 seconds. T1: 20.949499999999997°C\nTime 186.23 seconds. T1: 20.949499999999997°C\nTime 188.04 seconds. T1: 20.949499999999997°C\nTime 190.16 seconds. T1: 20.6272°C\nTime 192.25 seconds. T1: 20.949499999999997°C\nTime 194.06 seconds. T1: 20.949499999999997°C\nTime 196.0 seconds. T1: 20.949499999999997°C\nTime 198.24 seconds. T1: 20.949499999999997°C\nTime 200.01 seconds. T1: 20.949499999999997°C\nTCLab Model disconnected successfully.\n\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.03 seconds. T1: 20.949499999999997°C\nTime 4.0 seconds. T1: 20.949499999999997°C\nTime 6.02 seconds. T1: 20.949499999999997°C\nTime 8.05 seconds. T1: 20.949499999999997°C\nTime 10.06 seconds. T1: 20.949499999999997°C\nTime 12.0 seconds. T1: 20.949499999999997°C\nTime 14.1 seconds. T1: 20.949499999999997°C\nTime 16.1 seconds. T1: 20.949499999999997°C\nTime 18.08 seconds. T1: 20.949499999999997°C\nTime 20.21 seconds. T1: 20.949499999999997°C\nTime 22.15 seconds. T1: 20.949499999999997°C\nTime 24.12 seconds. T1: 20.6272°C\nTime 26.01 seconds. T1: 20.949499999999997°C\nTime 28.21 seconds. T1: 20.6272°C\nTime 30.14 seconds. T1: 20.949499999999997°C\nTime 32.01 seconds. T1: 20.949499999999997°C\nTime 34.01 seconds. T1: 20.949499999999997°C\nTime 36.01 seconds. T1: 20.949499999999997°C\nTime 38.18 seconds. T1: 20.949499999999997°C\nTime 40.0 seconds. T1: 20.949499999999997°C\nTime 42.16 seconds. T1: 20.949499999999997°C\nTime 44.02 seconds. T1: 20.949499999999997°C\nTime 46.12 seconds. T1: 20.949499999999997°C\nTime 48.02 seconds. T1: 20.949499999999997°C\nTime 50.29 seconds. T1: 20.949499999999997°C\nTime 52.19 seconds. T1: 20.949499999999997°C\nTime 54.23 seconds. T1: 20.949499999999997°C\nTime 56.14 seconds. T1: 20.949499999999997°C\nTime 58.29 seconds. T1: 20.949499999999997°C\nTime 60.15 seconds. T1: 20.6272°C\nTime 62.18 seconds. T1: 20.949499999999997°C\nTime 64.25 seconds. T1: 20.949499999999997°C\nTime 66.04 seconds. T1: 20.6272°C\nTime 68.2 seconds. T1: 20.6272°C\nTime 70.18 seconds. T1: 20.949499999999997°C\nTime 72.14 seconds. T1: 20.949499999999997°C\nTime 74.22 seconds. T1: 20.949499999999997°C\nTime 76.04 seconds. T1: 20.949499999999997°C\nTime 78.09 seconds. T1: 20.949499999999997°C\nTime 80.05 seconds. T1: 20.949499999999997°C\nTime 82.11 seconds. T1: 20.949499999999997°C\nTime 84.24 seconds. T1: 20.949499999999997°C\nTime 86.23 seconds. T1: 20.949499999999997°C\nTime 88.16 seconds. T1: 20.949499999999997°C\nTime 90.08 seconds. T1: 20.949499999999997°C\nTime 92.08 seconds. T1: 20.6272°C\nTime 94.29 seconds. T1: 20.949499999999997°C\nTime 96.12 seconds. T1: 20.949499999999997°C\nTime 98.22 seconds. T1: 20.949499999999997°C\nTime 100.12 seconds. T1: 20.949499999999997°C\nTime 102.2 seconds. T1: 20.949499999999997°C\nTime 104.02 seconds. T1: 20.6272°C\nTime 106.15 seconds. T1: 20.949499999999997°C\nTime 108.24 seconds. T1: 20.949499999999997°C\nTime 110.09 seconds. T1: 20.949499999999997°C\nTime 112.01 seconds. T1: 20.949499999999997°C\nTime 114.04 seconds. T1: 20.949499999999997°C\nTime 116.13 seconds. T1: 20.6272°C\nTime 118.25 seconds. T1: 20.949499999999997°C\nTime 120.23 seconds. T1: 20.949499999999997°C\nTime 122.15 seconds. T1: 20.949499999999997°C\nTime 124.17 seconds. T1: 20.949499999999997°C\nTime 126.23 seconds. T1: 20.949499999999997°C\nTime 128.22 seconds. T1: 20.949499999999997°C\nTime 130.09 seconds. T1: 20.6272°C\nTime 132.21 seconds. T1: 20.949499999999997°C\nTime 134.28 seconds. T1: 20.949499999999997°C\nTime 136.17 seconds. T1: 20.949499999999997°C\nTime 138.2 seconds. T1: 20.949499999999997°C\nTime 140.02 seconds. T1: 20.949499999999997°C\nTime 142.2 seconds. T1: 20.949499999999997°C\nTime 144.19 seconds. T1: 20.949499999999997°C\nTime 146.19 seconds. T1: 20.949499999999997°C\nTime 148.02 seconds. T1: 20.949499999999997°C\nTime 150.27 seconds. T1: 20.949499999999997°C\nTime 152.22 seconds. T1: 20.949499999999997°C\nTime 154.16 seconds. T1: 20.949499999999997°C\nTime 156.19 seconds. T1: 20.949499999999997°C\nTime 158.22 seconds. T1: 20.949499999999997°C\nTime 160.27 seconds. T1: 20.949499999999997°C\nTime 162.03 seconds. T1: 20.949499999999997°C\nTime 164.02 seconds. T1: 20.949499999999997°C\nTime 166.09 seconds. T1: 20.949499999999997°C\nTime 168.24 seconds. T1: 20.949499999999997°C\nTime 170.13 seconds. T1: 20.6272°C\nTime 172.06 seconds. T1: 20.949499999999997°C\nTime 174.28 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.19 seconds. T1: 20.6272°C\nTime 180.28 seconds. T1: 20.949499999999997°C\nTime 182.22 seconds. T1: 20.949499999999997°C\nTime 184.0 seconds. T1: 20.949499999999997°C\nTime 186.15 seconds. T1: 20.949499999999997°C\nTime 188.01 seconds. T1: 20.949499999999997°C\nTime 190.23 seconds. T1: 20.949499999999997°C\nTime 192.0 seconds. T1: 20.949499999999997°C\nTime 194.24 seconds. T1: 20.949499999999997°C\nTime 196.06 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.07 seconds. T1: 20.949499999999997°C\nTCLab Model disconnected successfully.\n\n\n\nImporting\nOnce installed, the tclab package can be imported into Python and an instance created with the Python statements\nfrom tclab import TCLab\nlab = TCLab()\nTCLab() attempts to find a device connected to a serial port and return a connection. An error is generated if no device is found. The connection should be closed when no longer in use.\nThe following cell demonstrates this process, and uses the tclab LED() function to flash the LED on the Temperature Control Lab for a period of 10 seconds at a 100% brightness level.\n\nfrom tclab import TCLab\n\nlab = TCLab()\nlab.LED(100)\nlab.close()\n\nTCLab version 1.0.0\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\n\n\nRuntimeError: No Arduino device found.\n\n\n\n\nUsing TCLab with Python’s with statement\nThe Python with statement provides a convenient means of setting up and closing a connection to the Temperature Control Laboratory. In particular, the with statement establishes a context where a tclab instance is created, assigned to a variable, and automatically closed upon completion. The with statement is the preferred way to connect the Temperature Control Laboratory for most uses.\n\nfrom tclab import TCLab\n\nwith TCLab() as lab:\n    lab.LED(100)",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#reading-temperatures",
    "href": "TCLab/understanding_tclab.html#reading-temperatures",
    "title": "Understanding TCLab",
    "section": "Reading Temperatures",
    "text": "Reading Temperatures\nOnce a tclab instance is created and connected to a device, the temperature sensors on the temperature control lab can be acccessed with the attributes .T1 and .T2. For example, given an instance lab, the temperatures are accessed as\nT1 = lab.T1\nT2 = lab.T2\nlab.T1 and lab.T2 are read-only properties. Any attempt to set them to a value will return a Python error.\n\nfrom tclab import TCLab\n\nwith TCLab() as a:\n    print(\"Temperature 1: {0:0.2f} C\".format(a.T1))\n    print(\"Temperature 2: {0:0.2f} C\".format(a.T2))",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#setting-heaters",
    "href": "TCLab/understanding_tclab.html#setting-heaters",
    "title": "Understanding TCLab",
    "section": "Setting Heaters",
    "text": "Setting Heaters\nFor legacy reasons, there are two ways to set the power levels of the heaters.\nThe first way is to the functions.Q1() and .Q2() of a TCLab instance. For example, both heaters can be set to 100% power with the functions\nlab = TCLab()\nlab.Q1(100)\nlab.Q2(100)\nThe device firmware limits the heaters to a range of 0 to 100%. The current value of attributes may be accessed via\nQ1 = lab.Q1()\nQ2 = lab.Q2()\nImportant notes: 1. The led on the temperature control laboratory will turns from dim to bright when either heater is on. 2. Closing the TCLab instance turns the heaters off. 3. The power level of the two heaters may be different. Current versions of the firmware limit maximum power of first heater to 4 watts, and maxium power of the second heater to 2 watts. 4. In addition to the constraints imposed by the firmware, the power supply may not be capable of providing all of the power needed to operate both heaters at 100% 5. The values retrieved from these functions may be different than the values set due to the power limits enforced by the device firmware.\n\nfrom tclab import TCLab\nimport time\n\nwith TCLab() as a:\n    print(\"\\nStarting Temperature 1: {0:0.2f} C\".format(a.T1),flush=True)\n    print(\"Starting Temperature 2: {0:0.2f} C\".format(a.T2),flush=True)\n\n    a.Q1(100)\n    a.Q2(100)\n    print(\"\\nSet Heater 1:\", a.Q1(), \"%\",flush=True)\n    print(\"Set Heater 2:\", a.Q2(), \"%\",flush=True)\n    \n    t_heat = 30\n    print(\"\\nHeat for\", t_heat, \"seconds\")\n    time.sleep(t_heat)\n\n    print(\"\\nTurn Heaters Off\")\n    a.Q1(0)\n    a.Q2(0)\n    print(\"\\nSet Heater 1:\", a.Q1(), \"%\",flush=True)\n    print(\"Set Heater 2:\", a.Q2(), \"%\",flush=True)\n    \n    print(\"\\nFinal Temperature 1: {0:0.2f} C\".format(a.T1))\n    print(\"Final Temperature 2: {0:0.2f} C\".format(a.T2))\n\nAlternatively, the heaters can be set using the .U1 and .U2 attributes of a TCLab instance.\n\nlab = TCLab()\n\nprint('Setting power levels on heaters 1 and 2')\nlab.U1 = 50\nlab.U2 = 25\n\nprint('Current power level on Heater 1 is: ', lab.U1, '%')\nprint('Current power level on Heater 1 is: ', lab.U2, '%')\n\nlab.close()",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#synchronizing-with-real-time-using-clock",
    "href": "TCLab/understanding_tclab.html#synchronizing-with-real-time-using-clock",
    "title": "Understanding TCLab",
    "section": "Synchronizing with Real Time using clock",
    "text": "Synchronizing with Real Time using clock\nThe tclab module includes clock for synchronizing calculations with real time. clock(tperiod, tstep) generates a sequence of iterations over a period of tperiod seconds evenly by tstep seconds. If tstep is omitted then the default period is set to 1 second.\n\nfrom tclab import clock\n\ntperiod = 6\ntstep = 2\nfor t in clock(tperiod,tstep):\n    print(t, \"sec.\")\n\nThere are some considerations to keep in mind when using clock. Most important, by its nature Python is not a real-time environment. clock makes a best effort to stay in sync with evenly spaced ticks of the real time clock. If, for some reason, the loop falls behind the real time clock, then the generator will skip over the event to get back in sync with the real time clock. Thus the total number of iterations may be less than expected. This behavior is demonstrated in the following cell.\n\nfrom tclab import TCLab, clock\n\nimport time\n\ntfinal = 12\ntstep = 2\nfor t in clock(tfinal, tstep):\n    print(t, \"sec.\")\n    \n    # insert a long time out between 3 and 5 seconds into the event loop\n    if (t &gt; 3) and (t &lt; 5):\n        time.sleep(2.2)\n\n\nUsing clock with TCLab\n\nfrom tclab import TCLab, clock\n\ntperiod = 20\n\n# connect to the temperature control lab\nwith TCLab() as a:\n    # turn heaters on\n    a.Q1(100)\n    a.Q2(100)\n    print(\"\\nSet Heater 1 to {0:f} %\".format(a.Q1()))\n    print(\"Set Heater 2 to {0:f} %\".format(a.Q2()))\n\n    # report temperatures for the next tperiod seconds\n    sfmt = \"   {0:5.1f} sec:   T1 = {1:0.1f} C    T2 = {2:0.1f} C\"\n    for t in clock(tperiod):\n        print(sfmt.format(t, a.T1, a.T2), flush=True)",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#the-tclab-historian",
    "href": "TCLab/understanding_tclab.html#the-tclab-historian",
    "title": "Understanding TCLab",
    "section": "The TCLab Historian",
    "text": "The TCLab Historian\nThe Historian class provides means for data logging. Given an instance lab of a TCLab object, lab.sources is a list of all data sources and methods to access the data.\nlab = TCLab()\nh = Historian(lab.sources)\nThe historian initializes a data log. The data log is updated by issuing a command\nh.update(t)\nwhere t marks the current time. The following cell logs 10 seconds of data with a chaning power level to heater 1, then saves the data to a file.\n\ntemperature = []\ntime = []\n\nfor t in range(10):\n    temperature.append(lab.T1)\n    time.append(t)\n\n\ntime, temperature\n\n([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n [20.949499999999997,\n  20.949499999999997,\n  20.949499999999997,\n  20.949499999999997,\n  20.949499999999997,\n  20.949499999999997,\n  20.949499999999997,\n  20.6272,\n  20.949499999999997,\n  20.949499999999997])\n\n\n\nfrom tclab import TCLabModel, clock, Historian\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    for t in clock(10):\n        lab.Q1(100 if t &lt;= 5 else 0)\n        h.update(t)\n        \nh.to_csv('data.csv')\n\nTCLab version 1.0.0\nSimulated TCLab\nTCLab Model disconnected successfully.\n\n\nOnce saved, data can be read and plotted using the Pandas Data Analysis Library as demonstrated in this cell.\n\nimport pandas as pd\ndata = pd.read_csv('data.csv')\ndata.index = data['Time']\nprint(data)\ndata[['Q1','Q2']].plot(grid=True)\n\n        Time       T1       T2   Q1  Q2\nTime                                   \n0.00    0.00  20.9495  20.9495  100   0\n1.11    1.11  20.9495  20.9495  100   0\n2.08    2.08  20.9495  20.9495  100   0\n3.08    3.08  20.9495  20.9495  100   0\n4.06    4.06  20.9495  20.9495  100   0\n5.19    5.19  21.2718  20.9495    0   0\n6.17    6.17  21.2718  20.9495    0   0\n7.18    7.18  21.2718  20.9495    0   0\n8.18    8.18  21.2718  20.9495    0   0\n9.08    9.08  21.5941  20.9495    0   0\n10.21  10.21  21.5941  20.9495    0   0",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#the-tclab-plotter",
    "href": "TCLab/understanding_tclab.html#the-tclab-plotter",
    "title": "Understanding TCLab",
    "section": "The TCLab Plotter",
    "text": "The TCLab Plotter\nThe Plotter class adds a real time plotting of experimental data. A plotter is created from an instance of an historian as follows\nh = Historian(lab.sources)\np = Plotter(h)\nUpdating the plotter also updates the associated historian.\np.update(t)\nThe following example shows how this works.\n\nfrom tclab import TCLab, clock, Historian, Plotter\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 10)\n    for t in clock(10):\n        lab.Q1(100 if t &lt;= 5 else 0)\n        p.update(t)\n        \nh.to_csv('data.csv')",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#using-tclab-offline",
    "href": "TCLab/understanding_tclab.html#using-tclab-offline",
    "title": "Understanding TCLab",
    "section": "Using TCLab Offline",
    "text": "Using TCLab Offline\n\nfrom tclab import clock, setup, Historian, Plotter\n\nTCLab = setup(connected=False, speedup=20)\n\nSP = 40\nwith TCLab() as a:\n    h = Historian(a.sources)\n    p = Plotter(h)\n    for t in clock(120,2):\n        PV = a.T1\n        MV = 100 if SP &gt; PV else 0\n        a.U1 = MV\n        p.update()\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/understanding_tclab.html#running-diagnostics",
    "href": "TCLab/understanding_tclab.html#running-diagnostics",
    "title": "Understanding TCLab",
    "section": "Running Diagnostics",
    "text": "Running Diagnostics\n\nimport tclab\n\nprint(\"Version = \", tclab.__version__)\ntclab.diagnose()\n\nVersion =  1.0.0\n\nChecking connection\n-------------------\nLooking for Arduino on any port...\n--- Serial Ports ---\n/dev/cu.BLTH n/a n/a\n/dev/cu.BlueBeatsStudio n/a n/a\n/dev/cu.Bluetooth-Incoming-Port n/a n/a\nNo known Arduino was found in the ports listed above.",
    "crumbs": [
      "TCLab",
      "Understanding TCLab"
    ]
  },
  {
    "objectID": "TCLab/system_model_and_identification_tclab.html",
    "href": "TCLab/system_model_and_identification_tclab.html",
    "title": "System Modeling",
    "section": "",
    "text": "Conduction: Heat flow through direct physical contact, significant in our system due to connections between the heater, battery, and spacecraft structure.\nRadiation: Transfer of heat through electromagnetic waves, relevant due to exposure to the sun and deep space.\nConvection: Less relevant in the vacuum of space, but a factor to consider during earth-based testing.",
    "crumbs": [
      "TCLab",
      "System Modeling"
    ]
  },
  {
    "objectID": "TCLab/system_model_and_identification_tclab.html#first-block-diagram---how-accurate-it-is",
    "href": "TCLab/system_model_and_identification_tclab.html#first-block-diagram---how-accurate-it-is",
    "title": "System Modeling",
    "section": "First block diagram - how accurate it is?",
    "text": "First block diagram - how accurate it is?\n\n\n\n\n\n\n\n\n\nDetailed Explanation of Heat Transfer Mechanisms\n\nConduction\nConduction is the transfer of heat through direct physical contact. In a spacecraft, this occurs when molecules or atoms in a high-temperature region vibrate intensely and pass on their energy to neighboring particles in a lower temperature area.\n\nImportance in Spacecraft: In our satellite thermal control system, conduction is crucial as it enables the transfer of heat from the heater to the battery and then to the spacecraft’s structure. This mechanism is integral in maintaining the temperatures within operational limits.\nExample: Imagine holding one end of a metal rod over a flame. Gradually, heat travels along the rod, making the distant end warm. This is similar to how heat conducts from the heater through the battery in our system.\n\n\n\nRadiation\nRadiation refers to the transfer of heat in the form of electromagnetic waves. It doesn’t require a medium to travel through, making it a primary mode of heat transfer in space.\n\nRole in Spacecraft: In the context of a spacecraft, radiation is significant for two reasons. Firstly, it accounts for the heat gain from the Sun, as solar radiation directly impacts parts of the satellite. Secondly, it is the method by which the spacecraft loses heat to the coldness of deep space.\nExample: The warmth you feel when standing in sunlight is due to radiant heat transfer. The Sun’s heat travels through the vacuum of space and warms you via radiation.\n\n\n\nConvection\nConvection is the transfer of heat by the physical movement of a fluid (such as air or liquid). It involves the circulation or movement of particles within the fluid, where hot particles move to cooler areas and vice versa.\n\nRelevance in Spacecraft Testing: While convection is not a heat transfer mechanism in the vacuum of space, it becomes significant during Earth-based testing of spacecraft systems. Here, the presence of air around the spacecraft allows for convective heat transfer, which can affect the performance and testing outcomes of thermal control systems.\nExample: When you heat water in a pot, the water at the bottom, nearest to the heat source, becomes hot and rises, while cooler water moves down to replace it, creating a circular motion. This process of heat transfer through the movement of fluid is convection.\n\nUnderstanding these heat transfer mechanisms is important for effectively managing the thermal environment of a spacecraft. It ensures that the onboard systems operate within their temperature tolerances, thereby enhancing the satellite’s overall performance and longevity.",
    "crumbs": [
      "TCLab",
      "System Modeling"
    ]
  },
  {
    "objectID": "TCLab/system_model_and_identification_tclab.html#first-order-dead-time-fopdt-modeling",
    "href": "TCLab/system_model_and_identification_tclab.html#first-order-dead-time-fopdt-modeling",
    "title": "System Modeling",
    "section": "First-Order Dead Time (FOPDT) Modeling",
    "text": "First-Order Dead Time (FOPDT) Modeling\nAlso called First-Order plus time delay (FOPTD)\n\n\\(y(t)\\): output\n\\(u(t)\\): input\n\nModel:\n\\[\n\\tau_p \\frac{dy(t)}{dt} = -y(t) + K_pu(t-\\theta_p)\n\\]\nThree parameters: - \\(\\tau_p\\): time-constant - \\(K_p\\): gain \\(\\frac{\\Delta y}{\\Delta u}\\) - \\(\\theta_p\\): dead time (how long it takes the output to start responding to an input)\nThe process gain is the change in the output y induced by a unit change in the input u. The process gain is calculated by evaluating the change in \\(y(t)\\) divided by the change in \\(u(t)\\) at steady state initial and final conditions:\n\\[\nK_p = \\frac{\\Delta y}{\\Delta u} = \\frac{y_ss_2 - y_ss_1}{u_ss_2 - u_ss_1}\n\\]\nThese three parameters adjust the shape of the response between the input and the output.\n\n\n\n\n\n\n\n\nThe Laplace transform of the previous differential equation is:\n\\[\n\\tau_p sY(s) = - Y(s) + K_p e^{-\\theta_p s}U(s)\n\\]\nhence the transfer function is:\n\\[\nG(s) = \\frac{Y(s)}{U(s)} = \\frac{K_p e^{-\\theta_p s}}{\\tau_p s + 1}\n\\]\nThe solution to the previous differential equation:\n\\[\ny(t) = \\Big(1-e^{-\\frac{t-\\theta_p}{\\tau_p}}\\Big)K_p\\Delta u \\mu(t-\\theta_p)\n\\]\nwhere \\(\\mu(t-\\theta_p)\\) is the step function with a delay.\nSetting \\(t=\\tau_p\\) and \\(\\theta_p=0\\) we can calculate:\n\\[\n\\frac{y(\\tau_p)}{Kp\\Delta u} = \\Big(1-e^{-\\frac{\\tau_p}{\\tau_p}}\\Big) = (1-e^{-1}) = 0.632\n\\]\ngiven that \\(K_p = \\Delta y / \\Delta u\\) we can write:\n\\[\n\\frac{y(\\tau_p)}{\\Delta y} = \\Big(1-e^{-\\frac{\\tau_p}{\\tau_p}}\\Big) = (1-e^{-1}) = 0.632\n\\]\nwhich means:\n\\[\ny(\\tau_p) = 0.632\\Delta y\n\\]\nWe can plot this in python:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interactive\n\n\ndef step_function(t, theta_p):\n    return np.heaviside(t - theta_p, 1)\n\ndef y(t, Kp, theta_p, tau_p, Delta_u=1):\n    return (1 - np.exp(-(t - theta_p) / tau_p)) * Kp * Delta_u * step_function(t, theta_p)\n\ndef plot_response(Kp=1, theta_p=0, tau_p=1):\n    t = np.linspace(0, 10, 1000)  # Adjust time range as needed\n    Delta_u = 1  # Change as per your setup\n    y_vals = y(t, Kp, theta_p, tau_p, Delta_u)\n    \n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y_vals, label=f'$K_p$={Kp}, $\\\\theta_p$={theta_p}, $\\\\tau_p$={tau_p}')\n    plt.title('System Response')\n    plt.xlabel('Time')\n    plt.ylabel('$y(t)$')\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n\ndef plot_response_with_input(Kp=1, theta_p=0, tau_p=1):\n    t = np.linspace(0, 10, 1000)  # Adjust time range as needed\n    Delta_u = 1  # Change as per your setup\n    y_vals = y(t, Kp, theta_p, tau_p, Delta_u)\n    input_signal = step_function(t, theta_p) * Delta_u  # Assuming Delta_u is the step height\n    \n    plt.figure(figsize=(10, 6))\n    \n    # Plotting the system response\n    plt.plot(t, y_vals, label=f'System Response: $K_p$={Kp}, $\\\\theta_p$={theta_p}, $\\\\tau_p$={tau_p}')\n    # Plotting the input signal\n    plt.plot(t, input_signal, '--', label='Input Signal ($\\\\Delta u$)')\n    \n    plt.title('System Response and Input Signal')\n    plt.xlabel('Time')\n    plt.ylabel('Value')\n    plt.grid(True)\n    plt.legend()\n    plt.show()    \n    \n    \ninteractive_plot = interactive(plot_response, Kp=(0.1, 10, 0.1), theta_p=(0, 5, 0.1), tau_p=(0.1, 10, 0.1))\noutput = interactive_plot.children[-1]\noutput.layout.height = '550px'\ninteractive_plot\n\n\n\n\n\n\nGraphical Method: FOPDT to Step Test\nSee also here\nStep test data are convenient for identifying an FOPDT model through a graphical fitting method. Follow the following steps when fitting the parameters \\(K_p\\), \\(\\tau_p\\), \\(\\theta_p\\) to a step response:\n\nFind \\(\\Delta y\\) from step response.\nFind \\(\\Delta u\\) from step response.\nCalculate \\(K_p = \\frac{\\Delta y}{\\Delta u}=\\frac{3.0}{1.0}\\)\nFind \\(\\theta_p\\) apparent dead time, from step response: draw the tangent in the output curve, and compare when the tangent crosses the x-axis to when the input started. In our case it seems approximately \\(2.5s\\)\nFind \\(0.632\\Delta y\\) from step response. In our case: 1.9\nFind \\(t_{0.632}\\) for \\(y(t_{0.632}) = 0.632\\Delta y\\) from step response.\nCalculate \\(\\tau_p = t_{0.632} - \\theta_p = 6.8 - 4.5 = 2.3 s\\). This assumes that the step starts at \\(t = 0\\). If the step happens later, subtract the step time as well.\n\n\nimport numpy as np\nfrom scipy.integrate import odeint\nfrom scipy.interpolate import interp1d\n\nimport matplotlib.pyplot as plt\n\n\ndef process_model(y, t, system_order, input_value, gain, time_constant):\n    \"\"\"\n    Simulate a higher-order process.\n\n    Parameters:\n    y            : Current output values of the system.\n    t            : Current time.\n    system_order : Order of the system.\n    input_value  : Current input value to the system.\n    gain         : Process gain.\n    time_constant: Process time constant.\n\n    Returns:\n    dydt : Derivative of the system output.\n    \"\"\"\n    dydt = np.zeros(system_order)\n    dydt[0] = (-y[0] + gain * input_value) / (time_constant / system_order)\n    for i in range(1, system_order):\n        dydt[i] = (-y[i] + y[i-1]) / (time_constant / system_order)\n    return dydt\n\ndef fopdt_model(y, t, input_func, model_gain, model_time_constant, model_delay):\n    \"\"\"\n    First-Order Plus Dead-Time (FOPDT) approximation of a process.\n\n    Parameters:\n    y                  : Current output value of the model.\n    t                  : Current time.\n    input_func         : Function to interpolate input values over time.\n    model_gain         : Model gain.\n    model_time_constant: Model time constant.\n    model_delay        : Model delay time.\n\n    Returns:\n    dydt : Derivative of the model output.\n    \"\"\"\n    # Handle input value with respect to delay\n    try:\n        if t - model_delay &lt;= 0:\n            input_value = input_func(0.0)\n        else:\n            input_value = input_func(t - model_delay)\n    except:\n        input_value = 0\n\n    dydt = (-y + model_gain * input_value) / model_time_constant\n    return dydt\n\n# Simulation setup\nns = 40  # Number of steps\nt = np.linspace(0, 16, ns+1)  # Define time points\ndelta_t = t[1] - t[0]  # Time step size\nu = np.zeros(ns+1)  # Initialize input vector\nu[5:] = 1.0  # Set input to 1.0 starting from t=5\n\n# Create a function to interpolate input values over time\nuf = interp1d(t, u)\n\ndef simulate_process_data():\n    \"\"\"\n    Simulate data from a higher-order process for comparison with the FOPDT model.\n    \n    Returns:\n    yp : Simulated process output over time.\n    \"\"\"\n    # Process parameters\n    n = 10  # Order of the system\n    Kp = 3.0  # Gain\n    taup = 5.0  # Time constant\n    \n    yp = np.zeros(ns+1)  # Initialize storage for process outputs\n    for i in range(1, ns+1):\n        if i == 1:\n            yp0 = np.zeros(n)  # Initial condition\n        ts = [delta_t * (i-1), delta_t * i]  # Time span for this step\n        y = odeint(process_model, yp0, ts, args=(n, u[i], Kp, taup))\n        yp0 = y[-1]  # Update initial condition for the next step\n        yp[i] = y[1][n-1]  # Store the last output\n    return yp\n\nyp = simulate_process_data()\n\ndef simulate_fopdt_model(Km, taum, thetam):\n    \"\"\"\n    Simulate the FOPDT model based on given parameters.\n\n    Parameters:\n    Km     : Model gain.\n    taum   : Model time constant.\n    thetam : Model delay time.\n\n    Returns:\n    ym : Simulated model output over time.\n    \"\"\"\n    ym = np.zeros(ns+1)  # Initialize model output storage\n    ym[0] = 0  # Initial condition\n    for i in range(1, ns+1):\n        ts = [delta_t * (i-1), delta_t * i]  # Time span for this step\n        y1 = odeint(fopdt_model, ym[i-1], ts, args=(uf, Km, taum, thetam))\n        ym[i] = y1[-1][0]  # Corrected to ensure a scalar is assigned to ym[i]\n    return ym\n\n\n# Update model parameters for simulation\nKm = 2.5  # Model gain\ntaum = 3.0  # Model time constant\nthetam = 5.0  # Model delay\n\n# Simulate FOPDT model with the updated parameters\nym = simulate_fopdt_model(Km, taum, thetam)\n\n\n# Start plotting the results\nplt.figure(figsize=(10, 8))  # Create a new figure with a specified size\n\n# Plot the first subplot showing output comparison\nplt.subplot(2, 1, 1)  # Create a subplot in a 2x1 grid, position 1\nplt.plot(t, ym, 'r--', linewidth=3, label='FOPDT Model Fit')  # Plot the FOPDT model output\nplt.plot(t, yp, 'kx-', linewidth=2, label='Process Data')  # Plot the simulated process data\nplt.ylabel('Output')  # Label the y-axis\nplt.legend(loc='best')  # Show a legend in the best location\nplt.title('Model Fit vs. Process Data')  # Title for the subplot\n\n# Plot the second subplot showing input data\nplt.subplot(2, 1, 2)  # Create a subplot in a 2x1 grid, position 2\nplt.plot(t, u, 'bx-', linewidth=2, label='Measured Input')  # Plot the measured input data\nplt.plot(t, uf(t), 'r--', linewidth=3, label='Interpolated Input')  # Plot the interpolated input data\nplt.legend(loc='best')  # Show a legend in the best location\nplt.ylabel('Input Data')  # Label the y-axis\nplt.xlabel('Time')  # Label the x-axis with 'Time'\n\n# Display the plot\nplt.show()",
    "crumbs": [
      "TCLab",
      "System Modeling"
    ]
  },
  {
    "objectID": "TCLab/tclab.html",
    "href": "TCLab/tclab.html",
    "title": "The Temperature Control Lab",
    "section": "",
    "text": "The primary resource for TCLab can be found at apmonitor.com.\nDeveloped by John Hedengren at the Brigham Young University (USA).\nIn subsequent sections, we’ll explore the complexities of dynamic modeling, understanding system responses, and the implementation of various control strategies.\nOur approach will involve utilizing Python programming to engage with the TCLab hardware, conduct data analysis, and effectively visualize the behaviors of the system.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#what-is-tclab",
    "href": "TCLab/tclab.html#what-is-tclab",
    "title": "The Temperature Control Lab",
    "section": "What is TCLab?",
    "text": "What is TCLab?\nTCLab is a compact laboratory setup that includes an Arduino microcontroller, heaters, temperature sensors, and an LED. It is designed for learning and applying control engineering principles in a hands-on manner.\n\nThe Temperature Control Laboratory hardware consists of five components:\n\nArduino Microcontroller (Arduino Uno, Arduino Leonardo, or equivalents): Acts as the brain of the setup.\nThe Temperature Control Laboratory plug-in board (also known as a shield). Includes:\n\nHeaters: Provide thermal energy to the system.\nTemperature Sensors: Measure the system’s temperature.\nLED: Visual indicator for certain actions or states.\n\nFive watt USB power supply.\n5.5mm to USB power supply cable.\nUSB 2.0 data cable. (w/mini-USB connector for Arduino Uno, or micro-USB cable for Arduino Leonardo.)\n\nBefore going further, be sure to complete the steps outlined under Hardware setup as described in TCLab README.\nMac OS users may need to install a serial driver available here.\nNormally the TCLab shield will already be mounted on the Arduino board, and the firmware driver will have been loaded on to the Arduino.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#understanding-the-tclab-kit",
    "href": "TCLab/tclab.html#understanding-the-tclab-kit",
    "title": "The Temperature Control Lab",
    "section": "Understanding the TCLab Kit",
    "text": "Understanding the TCLab Kit\n\nThe Core Components of TCLab\nThe Temperature Control Lab (TCLab) is an integrated system composed of several key components, each contributing significantly to its functionality:\n\nArduino Microcontroller:\n\nPurpose: Serves as the central processing unit for the TCLab.\nFunctionality: Processes input data from temperature sensors and manages the operation of heaters.\nConnectivity: Utilizes a USB connection for data transfer and allows for real-time control through Python scripts.\n\nHeaters:\n\nDescription: TCLab features two heaters, each capable of generating adjustable thermal energy.\nRole: Act as the main heat sources for experiments, replicating scenarios requiring temperature regulation. They function as the system’s actuators.\n\nTemperature Sensors:\n\nType: These sensors are thermistors, a kind of resistor whose resistance varies with temperature changes.\nMeasurement Range: Capable of measuring temperatures ranging from \\(-40^\\circ\\)C to \\(150^\\circ\\)C.\nFunctionality: Positioned near each heater to accurately measure temperature, providing essential feedback for temperature control.\n\nHeat Sinks:\n\nType: Comprised of transistor heat sinks.\nPurpose: Employed to efficiently dissipate heat away from the transistors.\n\nLED (Light Emitting Diode):\n\n\nPurpose: Serves as a visual indicator for various states or actions, such as signaling the activation of a heater.\n\n\n\nOperational Configurations of TCLab\nTCLab can be configured in various modes depending on the educational objectives:\n\nSingle Input Single Output (SISO):\n\nUtilizes only one heater and one sensor. Ideal for simple control experiments and learning the basics of temperature control.\n\nSingle Input Single Output (SISO) with Disturbance:\n\nEmploys one heater/sensor as the primary control system and the second heater as a source of external disturbance. This setup is useful for understanding how external factors influence control systems.\n\nMultiple Inputs Multiple Outputs (MIMO):\n\nInvolves using both heaters and sensors simultaneously. This more advanced configuration isn’t covered here but is valuable for complex control system studies.\n\n\nEach component of the TCLab plays a specific role, making it a versatile tool for teaching and experimenting with various aspects of control engineering. Whether for fundamental learning or advanced exploration, TCLab offers a practical platform for understanding the dynamics and control of temperature-based systems.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#how-tclab-works",
    "href": "TCLab/tclab.html#how-tclab-works",
    "title": "The Temperature Control Lab",
    "section": "How TCLab Works",
    "text": "How TCLab Works\n\nOperation Flow:\n\nInput Signal: A Python script sends a command to the Arduino, setting the desired power level for the heaters.\nHeating Action: The heaters generate heat corresponding to the received power level commands.\nTemperature Measurement: The thermistors measure the resulting temperatures near the heaters.\nFeedback Loop: These temperature readings are sent back to the computer.\nAdjustments: The control algorithm in the Python script adjusts the heater power based on the temperature feedback, striving to reach and maintain a target temperature.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#arduino-microcontroller",
    "href": "TCLab/tclab.html#arduino-microcontroller",
    "title": "The Temperature Control Lab",
    "section": "2.1 Arduino Microcontroller",
    "text": "2.1 Arduino Microcontroller\n\nDetailed Description: Provide specifics about the Arduino model used in TCLab, its capabilities, and its limitations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjectives:\n\nDynamic modeling with balance equations\nThe difference between manual and automatic control\nStep tests to generate dynamic data\nFitting dynamic data to a First Order Plus Dead Time (FOPDT) model\nObtaining parameters for PID control from standard tuning rules\nTuning the PID controller to improve performance",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#section-1-installing-python-using-conda",
    "href": "TCLab/tclab.html#section-1-installing-python-using-conda",
    "title": "The Temperature Control Lab",
    "section": "Section 1: Installing Python Using Conda",
    "text": "Section 1: Installing Python Using Conda",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#installing-python-on-mac",
    "href": "TCLab/tclab.html#installing-python-on-mac",
    "title": "The Temperature Control Lab",
    "section": "Installing Python on Mac",
    "text": "Installing Python on Mac\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Mac.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Terminal.\nType conda --version and press Enter. If Anaconda is successfully installed, you’ll see the version number.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#installing-python-on-windows",
    "href": "TCLab/tclab.html#installing-python-on-windows",
    "title": "The Temperature Control Lab",
    "section": "Installing Python on Windows",
    "text": "Installing Python on Windows\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Windows.\nRun Installer: Open the downloaded file and follow the on-screen instructions.\nVerify Installation:\n\nOpen Anaconda Prompt.\nType conda --version and press Enter.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Anaconda Prompt, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#installing-python-on-linux",
    "href": "TCLab/tclab.html#installing-python-on-linux",
    "title": "The Temperature Control Lab",
    "section": "1.3 Installing Python on Linux",
    "text": "1.3 Installing Python on Linux\n\nStep 1: Install Anaconda\n\nDownload Anaconda: Visit the Anaconda Download Page and download the installer for Linux.\nRun Installer: Open Terminal, navigate to the directory containing the downloaded file, and run the script using bash Anaconda3-XXXX.sh.\nVerify Installation:\n\nIn Terminal, type conda --version.\n\n\n\n\nStep 2: Set Up Environment (Optional)\n\nCreate a New Environment: In Terminal, type conda create -n tclab_env python=3.8 and press Enter.\nActivate Environment: Type conda activate tclab_env and press Enter.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#setting-up-the-conda-environment",
    "href": "TCLab/tclab.html#setting-up-the-conda-environment",
    "title": "The Temperature Control Lab",
    "section": "Setting Up the Conda Environment",
    "text": "Setting Up the Conda Environment\nTo set up the Conda environment for this course, follow these steps:\n\nDownload the tclab_environment.yml file from this repository.\nOpen your terminal or Anaconda Prompt and navigate to the directory where the file is located.\n\nThe file tclab_environment.yml looks like this:\nname: tclab_env\nchannels:\n  - defaults\ndependencies:\n  - python=3.10\n  - pip\n  - numpy\n  - matplotlib\n  - scipy\n  - pandas\n  - pip:\n    - tclab\n\nCreate the environment from the tclab_environment.yml file:\nconda env create -f tclab_environment.yml\nActivate the new environment:\nconda activate tclab\nTo verify that the environment was installed correctly, you can use:\nconda env list\n\n\nInstalling the TCLab Package\n\nActivating the Environment:\n\nEnsure your Anaconda environment is active. Open your Terminal (or Anaconda Prompt on Windows) and activate your environment:\nconda activate tclab_env\n\nInstalling TCLab:\n\nThe tclab library is pivotal for interfacing with the Temperature Control Lab hardware. Install it by entering the following command:\npip install tclab\nPress Enter to execute the command and complete the installation.\n\n\n\nInstalling Additional Useful Libraries\nFor a comprehensive experience with TCLab and to support various aspects of control engineering and data analysis, the following libraries will also be installed:\n\nnumpy:\n\nSignificance: A fundamental library for numerical computations in Python.\nInstallation Command:\npip install numpy\n\nmatplotlib:\n\nSignificance: Crucial for creating visual representations of data, especially for the analysis of TCLab experiments.\nInstallation Command:\npip install matplotlib\n\nscipy:\n\nSignificance: Provides a broad range of tools for scientific computing, including methods for solving ordinary differential equations, useful in system modeling.\nInstallation Command:\npip install scipy\n\npandas:\n\nSignificance: Offers extensive features for data manipulation and analysis, ideal for handling complex datasets.\nInstallation Command:\npip install pandas\n\ngekko:\n\nSignificance: Advanced package for optimization and control, suitable for implementing model predictive control strategies.\nInstallation Command:\npip install gekko",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#tclab-schematics",
    "href": "TCLab/tclab.html#tclab-schematics",
    "title": "The Temperature Control Lab",
    "section": "TCLab Schematics",
    "text": "TCLab Schematics",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#initial-tests-with-tclab",
    "href": "TCLab/tclab.html#initial-tests-with-tclab",
    "title": "The Temperature Control Lab",
    "section": "Initial Tests with TCLab",
    "text": "Initial Tests with TCLab\n\nStep 1: Connect TCLab\n\nConnect TCLab: Plug in the TCLab device to your computer using a USB cable.\n\n\n\nStep 2: Test TCLab Connection\n\nWrite Test Script:\n\nOpen your Python IDE or Jupyter Notebook.\nWrite the following Python code and run the script. If it prints the temperature, TCLab is connected properly.\n\n\n\nimport tclab\nwith tclab.TCLab() as lab:\n    print(f\"Connected! Heater 1 is at {lab.T1}°C\")\n\nTCLab version 1.0.0\nArduino Leonardo connected on port /dev/cu.usbmodem142101 at 115200 baud.\nTCLab Firmware 3.0.0 Arduino Leonardo/Micro.\nConnected! Heater 1 is at 23.477°C\nTCLab disconnected successfully.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab.html#using-tclab-simulator",
    "href": "TCLab/tclab.html#using-tclab-simulator",
    "title": "The Temperature Control Lab",
    "section": "Using TCLab Simulator",
    "text": "Using TCLab Simulator\n\nWhy Use a Simulator: The TCLab simulator is useful when you don’t have the physical hardware available.\nInstall Simulator: In Terminal or Anaconda Prompt, type pip install tclab again (it includes the simulator).\nTest Script with Simulator:\n\n\nfrom tclab import setup, clock\nTCLab = setup(connected=False, speedup=5)\n\nwith TCLab() as lab:\n    for t in clock(200, 2):\n        print(f\"Time {t} seconds. T1: {lab.T1}°C\")\n\nTCLab version 1.0.0\nSimulated TCLab\nTime 0 seconds. T1: 20.949499999999997°C\nTime 2.01 seconds. T1: 20.949499999999997°C\nTime 4.04 seconds. T1: 20.949499999999997°C\nTime 6.03 seconds. T1: 20.949499999999997°C\nTime 8.06 seconds. T1: 20.949499999999997°C\nTime 10.07 seconds. T1: 20.949499999999997°C\nTime 12.02 seconds. T1: 20.949499999999997°C\nTime 14.03 seconds. T1: 20.949499999999997°C\nTime 16.15 seconds. T1: 20.949499999999997°C\nTime 18.04 seconds. T1: 20.949499999999997°C\nTime 20.2 seconds. T1: 20.949499999999997°C\nTime 22.01 seconds. T1: 20.949499999999997°C\nTime 24.19 seconds. T1: 20.949499999999997°C\nTime 26.24 seconds. T1: 20.949499999999997°C\nTime 28.16 seconds. T1: 20.949499999999997°C\nTime 30.03 seconds. T1: 20.949499999999997°C\nTime 32.12 seconds. T1: 20.949499999999997°C\nTime 34.2 seconds. T1: 20.6272°C\nTime 36.04 seconds. T1: 20.949499999999997°C\nTime 38.02 seconds. T1: 20.6272°C\nTime 40.21 seconds. T1: 20.949499999999997°C\nTime 42.14 seconds. T1: 20.949499999999997°C\nTime 44.01 seconds. T1: 20.6272°C\nTime 46.3 seconds. T1: 20.949499999999997°C\nTime 48.22 seconds. T1: 20.949499999999997°C\nTime 50.07 seconds. T1: 20.949499999999997°C\nTime 52.27 seconds. T1: 20.949499999999997°C\nTime 54.09 seconds. T1: 20.949499999999997°C\nTime 56.28 seconds. T1: 20.949499999999997°C\nTime 58.19 seconds. T1: 20.949499999999997°C\nTime 60.04 seconds. T1: 20.949499999999997°C\nTime 62.2 seconds. T1: 20.949499999999997°C\nTime 64.11 seconds. T1: 20.949499999999997°C\nTime 66.08 seconds. T1: 20.949499999999997°C\nTime 68.23 seconds. T1: 20.6272°C\nTime 70.13 seconds. T1: 20.949499999999997°C\nTime 72.07 seconds. T1: 20.949499999999997°C\nTime 74.05 seconds. T1: 20.949499999999997°C\nTime 76.1 seconds. T1: 20.6272°C\nTime 78.1 seconds. T1: 20.6272°C\nTime 80.22 seconds. T1: 20.949499999999997°C\nTime 82.28 seconds. T1: 20.949499999999997°C\nTime 84.22 seconds. T1: 20.949499999999997°C\nTime 86.16 seconds. T1: 20.949499999999997°C\nTime 88.23 seconds. T1: 20.949499999999997°C\nTime 90.0 seconds. T1: 20.949499999999997°C\nTime 92.27 seconds. T1: 20.949499999999997°C\nTime 94.0 seconds. T1: 20.949499999999997°C\nTime 96.16 seconds. T1: 20.949499999999997°C\nTime 98.02 seconds. T1: 20.949499999999997°C\nTime 100.1 seconds. T1: 20.949499999999997°C\nTime 102.24 seconds. T1: 20.949499999999997°C\nTime 104.0 seconds. T1: 20.6272°C\nTime 106.18 seconds. T1: 20.949499999999997°C\nTime 108.27 seconds. T1: 20.949499999999997°C\nTime 110.27 seconds. T1: 20.949499999999997°C\nTime 112.1 seconds. T1: 20.949499999999997°C\nTime 114.22 seconds. T1: 20.949499999999997°C\nTime 116.24 seconds. T1: 20.949499999999997°C\nTime 118.18 seconds. T1: 20.949499999999997°C\nTime 120.19 seconds. T1: 20.949499999999997°C\nTime 122.06 seconds. T1: 20.949499999999997°C\nTime 124.22 seconds. T1: 20.6272°C\nTime 126.19 seconds. T1: 20.949499999999997°C\nTime 128.18 seconds. T1: 20.949499999999997°C\nTime 130.25 seconds. T1: 20.949499999999997°C\nTime 132.02 seconds. T1: 20.6272°C\nTime 134.2 seconds. T1: 20.949499999999997°C\nTime 136.27 seconds. T1: 20.949499999999997°C\nTime 138.01 seconds. T1: 20.6272°C\nTime 140.2 seconds. T1: 20.949499999999997°C\nTime 142.18 seconds. T1: 20.949499999999997°C\nTime 144.2 seconds. T1: 20.949499999999997°C\nTime 146.23 seconds. T1: 20.949499999999997°C\nTime 148.24 seconds. T1: 20.949499999999997°C\nTime 150.19 seconds. T1: 20.949499999999997°C\nTime 152.28 seconds. T1: 20.949499999999997°C\nTime 154.25 seconds. T1: 20.949499999999997°C\nTime 156.23 seconds. T1: 20.6272°C\nTime 158.04 seconds. T1: 20.949499999999997°C\nTime 160.11 seconds. T1: 20.949499999999997°C\nTime 162.04 seconds. T1: 20.949499999999997°C\nTime 164.05 seconds. T1: 20.949499999999997°C\nTime 166.01 seconds. T1: 20.949499999999997°C\nTime 168.23 seconds. T1: 20.6272°C\nTime 170.08 seconds. T1: 20.949499999999997°C\nTime 172.01 seconds. T1: 20.949499999999997°C\nTime 174.14 seconds. T1: 20.949499999999997°C\nTime 176.01 seconds. T1: 20.949499999999997°C\nTime 178.22 seconds. T1: 20.949499999999997°C\nTime 180.2 seconds. T1: 20.949499999999997°C\nTime 182.2 seconds. T1: 20.949499999999997°C\nTime 184.21 seconds. T1: 20.949499999999997°C\nTime 186.08 seconds. T1: 20.949499999999997°C\nTime 188.29 seconds. T1: 20.949499999999997°C\nTime 190.24 seconds. T1: 20.949499999999997°C\nTime 192.18 seconds. T1: 20.949499999999997°C\nTime 194.09 seconds. T1: 20.949499999999997°C\nTime 196.22 seconds. T1: 20.949499999999997°C\nTime 198.26 seconds. T1: 20.949499999999997°C\nTime 200.02 seconds. T1: 20.6272°C\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "The Temperature Control Lab"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html",
    "href": "TCLab/tclab_lab_2_model_identification.html",
    "title": "TCLab Lab 2: Model Identification",
    "section": "",
    "text": "For this laboratory session you will collect data from a step test experiment, then fit the data to models derived from first-principles energy balances. Fitting models to data is an engineering skill that links between the real world of engineering systems to the theory you’ve been learning in the classroom.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html#exercise-1.-verify-operation-of-the-temperature-control-lab.",
    "href": "TCLab/tclab_lab_2_model_identification.html#exercise-1.-verify-operation-of-the-temperature-control-lab.",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 1. Verify operation of the temperature control lab.",
    "text": "Exercise 1. Verify operation of the temperature control lab.\nExecute the following cell to verify that you have a working connection to the temperature control lab hardware. This will test for installation of TCLab.py, connection to the Arduino device, and working firmware within the Arduino.\n\nfrom tclab import TCLab, clock, Historian, Plotter\n\nlab = TCLab()\nprint(\"TCLab Temperatures:\", lab.T1, lab.T2)\nlab.close()",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html#exercise-2.-check-for-steady-state",
    "href": "TCLab/tclab_lab_2_model_identification.html#exercise-2.-check-for-steady-state",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 2. Check for steady state",
    "text": "Exercise 2. Check for steady state\nAs discussed in class, for good model fitting it is essential for the TCLab hardware to be at steady state before proceeding with the step test. Run the following code to verify that the heaters are off and that the temperatures are at a steady ambient temperature.\n\n# experimental parameters\ntfinal = 30\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    for t in clock(tfinal):\n        p.update(t)",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html#exercise-3.-step-test.",
    "href": "TCLab/tclab_lab_2_model_identification.html#exercise-3.-step-test.",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 3. Step test.",
    "text": "Exercise 3. Step test.\nThe step test consists of turning on one heater at 50% power and recording temperature data for at least 800 seconds. Copy and paste the code from Exercise 2 into the following cell, then modify as needed to accomplish the step test.\n\n# write your code here",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html#exercise-4.-verify-and-save-data-to-a-.csv-file",
    "href": "TCLab/tclab_lab_2_model_identification.html#exercise-4.-verify-and-save-data-to-a-.csv-file",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 4. Verify and save data to a .csv file",
    "text": "Exercise 4. Verify and save data to a .csv file\nRun the following cell to verify and save your data to a ‘.csv’ file. Be sure you can find and locate the data on your laptop before leaving the lab. You will need access to this data for subsequent exercises.\n\nimport matplotlib.pyplot as plt\n\nt, T1, T2, Q1, Q2 = h.fields\n\nplt.plot(t, T1, t, T2, t, Q1, t, Q2)\nplt.legend(['T1','T2','Q1','Q2'])\nplt.xlabel('Time / seconds')\nplt.grid()\n\nh.to_csv('tclab-data.csv')",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification.html#exercise-5.-analysis",
    "href": "TCLab/tclab_lab_2_model_identification.html#exercise-5.-analysis",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 5. Analysis",
    "text": "Exercise 5. Analysis\n1.) Approximating the the step test results for T1 as a first order transfer function, estimate the time constant and gain. Write your answer in the following cell.\n\n# write your code here\n\n2.) As we discussed in class, a simple energy balance model for T1 is given by\n\\[C_p \\frac{dT_1}{dt} = U_a(T_{amb} - T_1) + P Q_1\\]\nwhere the parameter \\(P\\) has, through independent means, been determined as 0.04 watts per percent increase in \\(Q_1\\). Use the results of this experiment to estimate values for \\(C_p\\) and \\(U_a\\). Write your answers in the following cell.\n\n# write your answer here",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "",
    "text": "The purpose of this first laboratory session is to verify that you can interface and interact with the TCLab hardware, and familiarize you with the TCLab library. The first exercise will be to code a rudimentary relay (also called ‘on-off’ or thermostat) controller for one of the two heaters.\nBefore you begin, you should be familiar with the following reading meterials:",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-1.-download-and-install-tclab.py",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-1.-download-and-install-tclab.py",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 1. Download and install TCLab.py",
    "text": "Exercise 1. Download and install TCLab.py\nExecute the following cell to download and install the TCLab.py python library.\n\n!pip install tclab --upgrade",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-2.-verify-that-your-hardware-and-software-are-working-correctly.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-2.-verify-that-your-hardware-and-software-are-working-correctly.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 2. Verify that your hardware and software are working correctly.",
    "text": "Exercise 2. Verify that your hardware and software are working correctly.\nThe following cell should cause the LED on the TCLab shield to light up to 100% maximum brightness.\n\nfrom tclab import TCLab\n\nwith TCLab() as lab:\n    lab.LED(0)",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-3.-turn-on-the-heaters-for-120-seconds-and-log-temperature-response.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-3.-turn-on-the-heaters-for-120-seconds-and-log-temperature-response.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 3. Turn on the heaters for 120 seconds and log temperature response.",
    "text": "Exercise 3. Turn on the heaters for 120 seconds and log temperature response.\nFor this exercise, write a code cell that turns on heater 1 at 100% power, then log the temperature response once per second for 120 seconds. The output of the cell should report the time, power level, and temperature for each measurement. You may wish to consult 01_Understanding_TCLab notebook for relevant code examples. You will need the clock function from tclab for this exercise.\n\n# put your code here.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-4.-code-an-on-off-controller.",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-4.-code-an-on-off-controller.",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 4. Code an on-off controller.",
    "text": "Exercise 4. Code an on-off controller.\nCode an on-off controller for a setpoint of 40 degrees C using heater 1 as the manipulated variable, and temperature 1 as the measured variable. Operate the controller for at least 5 minutes (600 seconds), reporting time/power/temperature measurements every 2 seconds.\n\n# put your code here.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-5.-analysis",
    "href": "TCLab/tclab_lab_1_coding_a_relay_controller.html#exercise-5.-analysis",
    "title": "TCLab Lab 1: Coding a relay controller",
    "section": "Exercise 5. Analysis",
    "text": "Exercise 5. Analysis\nExamine the results of the previous exercise and answer the following questions.\n\nApproximately how much time elapses between power on and power off events?\nWhat is the approximate duty cycle (i.e, fraction of time the heater is in the ‘on’ state) once the initial start-up period has passed.\nWhat is the size of the oscillation around the setpoint? Why does this occur?",
    "crumbs": [
      "TCLab",
      "TCLab Lab 1: Coding a relay controller"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html",
    "title": "TCLab Lab 2: Model Identification",
    "section": "",
    "text": "For this laboratory session you will collect data from a step test experiment, then fit the data to models derived from first-principles energy balances. Fitting models to data is an engineering skill that links between the real world of engineering systems to the theory you’ve been learning in the classroom.",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-1.-verify-operation-of-the-temperature-control-lab.",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-1.-verify-operation-of-the-temperature-control-lab.",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 1. Verify operation of the temperature control lab.",
    "text": "Exercise 1. Verify operation of the temperature control lab.\nExecute the following cell to verify that you have a working connection to the temperature control lab hardware. This will test for installation of TCLab.py, connection to the Arduino device, and working firmware within the Arduino.\n\nfrom tclab import TCLab, clock, Historian, Plotter\n\nlab = TCLab()\nprint(\"TCLab Temperatures:\", lab.T1, lab.T2)\nlab.close()",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-2.-check-for-steady-state",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-2.-check-for-steady-state",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 2. Check for steady state",
    "text": "Exercise 2. Check for steady state\nAs discussed in class, for good model fitting it is essential for the TCLab hardware to be at steady state before proceeding with the step test. Run the following code to verify that the heaters are off and that the temperatures are at a steady ambient temperature.\n\n# experimental parameters\ntfinal = 30\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    for t in clock(tfinal):\n        p.update(t)",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-3.-step-test.",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-3.-step-test.",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 3. Step test.",
    "text": "Exercise 3. Step test.\nThe step test consists of turning on one heater at 50% power and recording temperature data for at least 800 seconds. Copy and paste the code from Exercise 2 into the following cell, then modify as needed to accomplish the step test.\n\n# experimental parameters\ntfinal = 800\nQ1 = 50\n\n# perform experiment\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, tfinal)\n    lab.Q1(Q1)\n    for t in clock(tfinal):\n        p.update(t)",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-4.-verify-and-save-data-to-a-.csv-file",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-4.-verify-and-save-data-to-a-.csv-file",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 4. Verify and save data to a .csv file",
    "text": "Exercise 4. Verify and save data to a .csv file\nRun the following cell to verify and save your data to a ‘.csv’ file. Be sure you can find and locate the data on your laptop before leaving the lab. You will need access to this data for subsequent exercises.\n\nimport matplotlib.pyplot as plt\n\nt, T1, T2, Q1, Q2 = h.fields\n\nplt.plot(t, T1, t, T2, t, Q1, t, Q2)\nplt.legend(['T1','T2','Q1','Q2'])\nplt.xlabel('Time / seconds')\nplt.grid()\n\nh.to_csv('tclab-data.csv')",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-5.-analysis",
    "href": "TCLab/tclab_lab_2_model_identification_solutions.html#exercise-5.-analysis",
    "title": "TCLab Lab 2: Model Identification",
    "section": "Exercise 5. Analysis",
    "text": "Exercise 5. Analysis\n1.) Approximating the the step test results for T1 as a first order transfer function, estimate the time constant and gain. Write your answer in the following cell.\nA first order system transfer function is described by the differential equation\n\\[ \\tau \\frac{dy}{dt} + y = K u \\]\nwhere \\(y\\) is the deviation in process output and \\(u\\) is the deviation in process input relative to a nominal condition. In this instance, the deviation variables are \\(u = Q_1\\) and \\(y = T_1 - T_{amb}\\). The process gain \\(K\\) can be estimated from the steady state condition at the end of the step test.\n\\[K = \\frac{y_{ss}}{u_{ss}} = \\frac{54.75 - 23.81}{50} = 0.62\\]\nThe time constant \\(\\tau\\) can be estimated as the time required to achieve 63.2% of the final response. That value of \\(T_1\\) can be computed as\n\\[23.81 + 0.632*(54.75-23.81) = 43.4\\]\nThis is about \\(\\tau = 186\\) seconds from the inspection of the data. These calculations are verified in the following code cell.\n\nK = (T1[-1] - T1[0])/Q1[0]\nprint(\"Gain K = \", K, \"degrees C per percent increase in Q1\")\n\nT = T1[0] + 0.632*(T1[-1] - T1[0])\nprint(\"63.2% of the final temperature rise corresponds to\", T, \"degrees C\")\n\ntau = t[min([k for k in range(0, len(T1)) if T &lt; T1[k] ])]\nprint(\"tau =\", tau, \"seconds\")\n\n2.) As we discussed in class, a simple energy balance model for T1 is given by\n\\[C_p \\frac{dT_1}{dt} = U_a(T_{amb} - T_1) + P Q_1\\]\nwhere the parameter \\(P\\) has, through independent means, been determined as 0.04 watts per percent increase in \\(Q_1\\). Use the results of this experiment to estimate values for \\(C_p\\) and \\(U_a\\). Write your answers in the following cell.\n\\[K = \\frac{P}{U_a} \\implies U_a = \\frac{P}{K} = \\frac{0.04}{0.62} = 0.065 \\text{ watts/deg C}\\]\n\\[\\tau = \\frac{C_p}{U_a} \\implies C_p = \\tau U_a = \\frac{\\tau P}{K} = \\frac{186 \\times 0.04}{0.62} = 12 \\text{ J/deg C}\\]\n\nP = 0.04\n\nUa = P/K\nprint(\"Heat transfer coefficient Ua =\", Ua, \"watts/degree C\")\n\nCp = tau*P/K\nprint(\"Heat capacity =\", Cp, \"J/deg C\")",
    "crumbs": [
      "TCLab",
      "TCLab Lab 2: Model Identification"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html",
    "href": "TCLab/tclab_lab_2_fitting.html",
    "title": "Model Identification: Fitting models to data",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.integrate import odeint\nfrom scipy.optimize import minimize\n\n\n\nThe following cell reads previously stored experimental step response data.\n\ndf = pd.read_csv(\"tclab-data.csv\")\nt = np.array(df[\"Time\"])\nT1 = np.array(df[\"T1\"])\nT2 = np.array(df[\"T2\"])\nQ1 = np.array(df[\"Q1\"])\nQ2 = np.array(df[\"Q2\"])\n\n\n\n\nThe following simple data plotting function is used in this notebooke to compare experimental data to model predictions.\n\ndef plot_data(t, T, T_pred, Q):\n    \n    fig = plt.figure(figsize=(8,5))\n    grid = plt.GridSpec(4, 1)\n    ax = [fig.add_subplot(grid[:2]), fig.add_subplot(grid[2]), fig.add_subplot(grid[3])]\n\n    ax[0].plot(t, T, t, T_pred)\n    ax[0].set_ylabel(\"deg C\")\n    ax[0].legend([\"T\", \"T_pred\"])\n    \n    ax[1].plot(t, T_pred - T)\n    ax[1].set_ylabel(\"deg C\")\n    ax[1].legend([\"T_pred - \"])\n    \n    ax[2].plot(t, Q)\n    ax[2].set_ylabel(\"%\")\n    ax[2].legend([\"Q\"])\n    \n    for a in ax: a.grid(True)\n    ax[-1].set_xlabel(\"time / seconds\")\n    plt.tight_layout()\n    \nplot_data(t, T1, T1, Q1)\nplot_data(t, T2, T2, Q2)",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#initializations",
    "href": "TCLab/tclab_lab_2_fitting.html#initializations",
    "title": "Model Identification: Fitting models to data",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.integrate import odeint\nfrom scipy.optimize import minimize\n\n\n\nThe following cell reads previously stored experimental step response data.\n\ndf = pd.read_csv(\"tclab-data.csv\")\nt = np.array(df[\"Time\"])\nT1 = np.array(df[\"T1\"])\nT2 = np.array(df[\"T2\"])\nQ1 = np.array(df[\"Q1\"])\nQ2 = np.array(df[\"Q2\"])\n\n\n\n\nThe following simple data plotting function is used in this notebooke to compare experimental data to model predictions.\n\ndef plot_data(t, T, T_pred, Q):\n    \n    fig = plt.figure(figsize=(8,5))\n    grid = plt.GridSpec(4, 1)\n    ax = [fig.add_subplot(grid[:2]), fig.add_subplot(grid[2]), fig.add_subplot(grid[3])]\n\n    ax[0].plot(t, T, t, T_pred)\n    ax[0].set_ylabel(\"deg C\")\n    ax[0].legend([\"T\", \"T_pred\"])\n    \n    ax[1].plot(t, T_pred - T)\n    ax[1].set_ylabel(\"deg C\")\n    ax[1].legend([\"T_pred - \"])\n    \n    ax[2].plot(t, Q)\n    ax[2].set_ylabel(\"%\")\n    ax[2].legend([\"Q\"])\n    \n    for a in ax: a.grid(True)\n    ax[-1].set_xlabel(\"time / seconds\")\n    plt.tight_layout()\n    \nplot_data(t, T1, T1, Q1)\nplot_data(t, T2, T2, Q2)",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#empirical-models",
    "href": "TCLab/tclab_lab_2_fitting.html#empirical-models",
    "title": "Model Identification: Fitting models to data",
    "section": "Empirical Models",
    "text": "Empirical Models\nEmpirical modeling is a process in which we attempt to discover models that accurately describe the input-output behavior of a process without regard to the underlying mechanisms.\n\nFirst-order linear model\nA first-order transfer function is modeled by the differential equation\n\\[ \\tau \\frac{dy}{dt} + y = K u\\]\nwhere \\(y\\) is the ‘deviation’ of the process variable from a nominal steady state, and \\(u\\) is the deviation in manipulated variable from a nominal steady state. For the temperature control lab we will assign the deviation variables as follows:\n\\[\\begin{align*}\ny & = T_1 - T_{ambient} \\\\\nu & = Q_1\n\\end{align*}\\]\nParameter \\(K\\) is the process gain which can be estimated as the ratio of the a steady-state change in \\(y\\) due to a steady-state change in \\(u\\). Parameter \\(\\tau\\) is the first-order ‘time constant’ which can be estimated as the time to achieve 63.2% of the steady-state change in output to due a steady-state change in \\(u\\).\n\ndef model_first_order(param, plot=False):\n    # access parameter values\n    K, tau = param\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(y, ti):\n        dydt  = (K*u(ti) - y)/tau\n        return dydt\n    y = odeint(deriv, 0, t)[:,0]\n\n    # comparing to experimental data\n    T_ambient = T1[0]\n    T1_pred = y + T_ambient\n    if plot:\n        print(\"K =\", K, \"tau =\", tau)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n    \nparam_first_order = [0.62, 180.0]\nmodel_first_order(param_first_order, plot=True)\n\nK = 0.62 tau = 180.0\n\n\n24.649520390255464\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_first_order, param_first_order, method='nelder-mead')\nparam_first_order = results.x\nmodel_first_order(param_first_order, plot=True)\n\nK = 0.6370841237049034 tau = 199.8617397701267\n\n\n20.651093155278453\n\n\n\n\n\n\n\n\n\n\n\nFirst-order linear model with time delay\nThe code cell below\n\ndef model_first_order_time_delay(param, plot=False):\n    # access parameter values\n    K, tau, tdelay = param\n    \n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1, left=0)\n    def deriv(y, ti):\n        dydt  = (K*u(ti-tdelay) - y)/tau\n        return dydt\n    y = odeint(deriv, 0, t)[:,0]\n\n    # comparing to experimental data\n    T_ambient = T1[0]\n    T1_pred = y + T_ambient\n    if plot:\n        print(\"K =\", K, \"tau =\", tau, \"tdelay =\", tdelay)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_first_order_time_delay = [0.62, 160.0, 15]\nmodel_first_order_time_delay(param_first_order_time_delay, plot=True)\n\nK = 0.62 tau = 160.0 tdelay = 15\n\n\n16.12137889182889\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_first_order_time_delay, param_first_order_time_delay, method='nelder-mead')\nparam_first_order_time_delay = results.x\nmodel_first_order_time_delay(param_first_order_time_delay, plot=True)\n\nK = 0.6228198545524255 tau = 167.7567962566444 tdelay = 20.18136187851927\n\n\n6.290512704413097",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#first-principles-modeling",
    "href": "TCLab/tclab_lab_2_fitting.html#first-principles-modeling",
    "title": "Model Identification: Fitting models to data",
    "section": "First-principles modeling",
    "text": "First-principles modeling\n\nFirst-order energy balance for one heater\nAssuming the heater/sensor assembly can be described as mass at uniform temperature that exchanges heat with the surrounding results in a first-order linear model.\n\\[C_p\\frac{dT_{1}}{dt} = U_a (T_{amb} - T_{1}) + P Q_1\\]\nThe model can be rearranged into the form of a first order system with time constant \\(\\tau\\) and gain \\(K\\)\n\\[\\underbrace{\\frac{C_p}{U_a}}_{\\tau}\\underbrace{\\frac{d(T_1 - T_{amb})}{dt}}_{\\frac{dy}{dt}} + \\underbrace{T_1 - T_{amb}}_y = \\underbrace{\\frac{P}{U_a}}_K \\underbrace{Q_1}_u\\]\nUsing the previous results gives estimates for \\(K\\) and \\(\\tau\\).\n\\[\\begin{align*}\nK = \\frac{P}{U_a} & \\implies U_a = \\frac{P}{K} = \\frac{0.04}{0.62} = 0.065 \\text{ watts/deg C} \\\\\n\\tau = \\frac{C_p}{U_a} & \\implies C_p = \\tau U_a = \\frac{\\tau P}{K} = \\frac{186 \\times 0.04}{0.62} = 12 \\text{ J/deg C}\n\\end{align*}\\]\n\nP = 0.04\n\nK, tau = param_first_order\n\nUa = P/K\nprint(\"Heat transfer coefficient Ua =\", Ua, \"watts/degree C\")\n\nCp = tau*P/K\nprint(\"Heat capacity =\", Cp, \"J/deg C\")\n\nHeat transfer coefficient Ua = 0.06278605683560866 watts/degree C\nHeat capacity = 12.548530552470801 J/deg C\n\n\n\ndef model_heater(param, plot=False):\n    # access parameter values\n    T_ambient, Cp, Ua = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(TH1, ti):\n        dT1  = (Ua*(T_ambient - TH1) + P1*u(ti))/Cp\n        return dT1\n    T1_pred = odeint(deriv, T_ambient, t)[:,0]\n\n    # comparing to experimental data\n    if plot:\n        print(\"Cp =\", Cp, \"Ua =\", Ua)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_heater = [T1[0], Cp, Ua]\nmodel_heater(param_heater, plot=True)\n\nCp = 12.548530552470801 Ua = 0.06278605683560866\n\n\n20.651088966149587\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_heater, param_heater, method='nelder-mead')\nparam_heater = results.x\nmodel_heater(param_heater, plot=True)\n\nCp = 10.313205580961114 Ua = 0.05862920031801483\n\n\n10.630933447435487\n\n\n\n\n\n\n\n\n\n\n\nTwo State Model\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1})\n\\end{align*}\\]\n\ndef model_heater_sensor(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        return [dT_H1, dT_S1]\n    T1_pred = odeint(deriv, [T_ambient, T_ambient], t)[:,1]\n\n    # comparing to experimental data\n    \n    if plot:\n        print(param)\n        plot_data(t, T1, T1_pred, Q1)\n    \n    return np.linalg.norm(T1_pred - T1)\n\nparam_heater_sensor = [T1[0], Cp, Cp/5, Ua, Ua]\nmodel_heater_sensor(param_heater_sensor, plot=True)\n\n[23.81, 12.548530552470801, 2.50970611049416, 0.06278605683560866, 0.06278605683560866]\n\n\n89.2722844989071\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_heater_sensor, param_heater_sensor, method='nelder-mead')\nparam_heater_sensor = results.x\nmodel_heater_sensor(param_heater_sensor, plot=True)\n\n[23.71861419  6.88125133  2.74272516  0.06428723  0.07897125]\n\n\n4.554156209522013",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#two-heater-four-state-model",
    "href": "TCLab/tclab_lab_2_fitting.html#two-heater-four-state-model",
    "title": "Model Identification: Fitting models to data",
    "section": "Two heater, four state model",
    "text": "Two heater, four state model\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_b(T_{H,2} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_a(T_{amb} - T_{H,2}) + U_b(T_{H,1} - T_{H,2}) + U_c(T_{S,2} - T_{H,2}) + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c(T_{H,2} - T_{S,2})\n\\end{align*}\\]\n\ndef model_complete(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1, T_H2, T_S2 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Ub*(T_H2 - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        dT_H2 = (Ua*(T_ambient - T_H2) + Ub*(T_H1 - T_H2) + Uc*(T_S2 - T_H2))/Cp_H\n        dT_S2 = Uc*(T_H2 - T_S2)/Cp_S\n        return [dT_H1, dT_S1, dT_H2, dT_S2]\n    T_pred = odeint(deriv, [T_ambient, T_ambient, T_ambient, T_ambient], t)\n    T1_pred = T_pred[:,1]\n    T2_pred = T_pred[:,3]\n\n    # comparing to experimental data\n    if plot:\n        print(param)\n        plot_data(t, T1, T1_pred, Q1)\n        plot_data(t, T2, T2_pred, Q1)\n    \n    return (np.linalg.norm(T1_pred - T1) + np.linalg.norm(T2_pred - T2))/2\n\nparam_complete = [T1[0], Cp, Cp/5, Ua, Ua, Ua]\nmodel_complete(param_complete, plot=True)\n\n[23.81, 12.548530552470801, 2.50970611049416, 0.06278605683560866, 0.06278605683560866, 0.06278605683560866]\n\n\n143.87441921309681\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresults = minimize(model_complete, param_complete, method='nelder-mead')\nparam_complete = results.x\nmodel_complete(param_complete, plot=True)\n\n[23.60707391  6.92707544  1.61783224  0.04676309  0.02633501  0.04303801]\n\n\n4.441799745669341",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#consequences",
    "href": "TCLab/tclab_lab_2_fitting.html#consequences",
    "title": "Model Identification: Fitting models to data",
    "section": "Consequences",
    "text": "Consequences\n\ndef model_complete(param, plot=False):\n    # access parameter values\n    T_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param\n    \n    P1 = 0.04\n\n    # simulation in deviation variables\n    u = lambda ti: np.interp(ti, t, Q1)\n    def deriv(T, ti):\n        T_H1, T_S1, T_H2, T_S2 = T\n        dT_H1 = (Ua*(T_ambient - T_H1) + Ub*(T_H2 - T_H1) + Uc*(T_S1 - T_H1) + P1*u(ti))/Cp_H\n        dT_S1 = Uc*(T_H1 - T_S1)/Cp_S\n        dT_H2 = (Ua*(T_ambient - T_H2) + Ub*(T_H1 - T_H2) + Uc*(T_S2 - T_H2))/Cp_H\n        dT_S2 = Uc*(T_H2 - T_S2)/Cp_S\n        return [dT_H1, dT_S1, dT_H2, dT_S2]\n    T_pred = odeint(deriv, [T_ambient, T_ambient, T_ambient, T_ambient], t)\n    T1_pred = T_pred[:,1]\n    T2_pred = T_pred[:,3]\n\n    # comparing to experimental data\n    if plot:\n        print(param)\n        plot_data(t, T_pred[:,1], T_pred[:,0], Q1)\n        plot_data(t, T_pred[:,3], T_pred[:,2], Q1)\n    \n    return (np.linalg.norm(T1_pred - T1) + np.linalg.norm(T2_pred - T2))/2\n\nmodel_complete(param_complete, plot=True)\n\n[23.60707391  6.92707544  1.61783224  0.04676309  0.02633501  0.04303801]\n\n\n4.441799745669341",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#state-space-model",
    "href": "TCLab/tclab_lab_2_fitting.html#state-space-model",
    "title": "Model Identification: Fitting models to data",
    "section": "State-Space Model",
    "text": "State-Space Model\nRecalling the model equations\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = U_a(T_{amb} - T_{H,1}) + U_b(T_{H,2} - T_{H,1}) + U_c(T_{S,1} - T_{H,1}) + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c(T_{H,1} - T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_a(T_{amb} - T_{H,2}) + U_b(T_{H,1} - T_{H,2}) + U_c(T_{S,2} - T_{H,2}) + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c(T_{H,2} - T_{S,2})\n\\end{align*}\\]\nNormalizing the derivatives\n\\[\\begin{align*}\nC_p^H \\frac{dT_{H,1}}{dt} & = -(U_a + U_b + U_c)T_{H,1} + U_c T_{S,1} + U_b T_{H,2} + U_a T_{amb} + P_1Q_1 \\\\\nC_p^S \\frac{dT_{S,1}}{dt} & = U_c T_{H,1} - U_c T_{S,1}) \\\\\nC_p^H \\frac{dT_{H,2}}{dt} & = U_b T_{H,1} - (U_a + U_b + U_c) T_{H,2} + U_c T_{S,2} + U_aT_{amb} + P_2Q_2 \\\\\nC_p^S \\frac{dT_{S,2}}{dt} & = U_c T_{H,2} - U_c T_{S,2}\n\\end{align*}\\]\nGathering terms on the right hand side\n\\[\\begin{align*}\n\\frac{dT_{H,1}}{dt} & = -\\frac{(U_a + U_b + U_c)}{C_p^H} T_{H,1} + \\frac{U_c}{C_p^H} T_{S,1} + \\frac{U_b}{C_p^H} T_{H,2} + \\frac{U_a}{C_p^H} T_{amb} + \\frac{P_1}{C_p^H} Q_1 \\\\\n\\frac{dT_{S,1}}{dt} & = \\frac{U_c}{C_p^S} T_{H,1} - \\frac{U_c}{C_p^S} T_{S,1} \\\\\n\\frac{dT_{H,2}}{dt} & = \\frac{U_b}{C_p^H} T_{H,1} - \\frac{(U_a + U_b + U_c)}{C_p^H} T_{H,2} + \\frac{U_c}{C_p^H} T_{S,2} + \\frac{U_a}{C_p^H} T_{amb} + \\frac{P_2}{C_p^H} Q_2 \\\\\n\\frac{dT_{S,2}}{dt} & = \\frac{U_c}{C_p^S} T_{H,2} - \\frac{U_c}{C_p^S} T_{S,2}\n\\end{align*}\\]\nState space model\n\\[ \\underbrace{\\begin{bmatrix} \\frac{dT_{H,1}}{dt} \\\\ \\frac{dT_{S,1}}{dt} \\\\ \\frac{T_{H,2}}{dt} \\\\ \\frac{T_{S,2}}{dt} \\end{bmatrix}}_{\\frac{dx}{dt}} = \\underbrace{\\begin{bmatrix} -\\frac{(U_a + U_b + U_c)}{C_p^H} & \\frac{U_c}{C_p^H} & \\frac{U_b}{C_p^H} & 0 \\\\ \\frac{U_c}{C_p^S} & - \\frac{U_c}{C_p^S} & 0 & 0 \\\\  \\frac{U_b}{C_p^H} & 0 & - \\frac{(U_a + U_b + U_c)}{C_p^H} & \\frac{U_c}{C_p^H} \\\\  0 & 0 & \\frac{U_c}{C_p^S} & - \\frac{U_c}{C_p^S} \\end{bmatrix}}_A\n\\underbrace{\\begin{bmatrix} T_{H,1} \\\\ T_{S,1} \\\\ T_{H,2} \\\\ T_{S,2} \\end{bmatrix}}_x + \\underbrace{\\begin{bmatrix} \\frac{P_1}{C_p^H} & 0 \\\\ 0 & 0 \\\\ 0 & \\frac{P_2}{C_p^H} \\\\ 0 & 0 \\end{bmatrix}}_B \\underbrace{\\begin{bmatrix} Q_1 \\\\ Q_2 \\end{bmatrix}}_u + \\underbrace{\\begin{bmatrix} \\frac{U_a}{C_p^H} \\\\ 0 \\\\ \\frac{U_a}{C_p^H} \\\\ 0 \\end{bmatrix}}_E \\underbrace{T_{amb}}_d\\]\n\\[\\underbrace{\\begin{bmatrix} T_1 \\\\ T_2 \\end{bmatrix}}_y = \\underbrace{\\begin{bmatrix} 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}}_C \\underbrace{\\begin{bmatrix} T_{H,1} \\\\ T_{S,1} \\\\ T_{H,2} \\\\ T_{S,2} \\end{bmatrix}}_x + \\underbrace{\\begin{bmatrix} 0 & 0 \\\\ 0 & 0\\end{bmatrix}}_D \\underbrace{\\begin{bmatrix} Q_1 \\\\ Q_2 \\end{bmatrix}}_u\\]\nMatrix/vector formulation\n\\[\\begin{align*}\n\\frac{dx}{dt} & = A x + B u + E d \\\\\ny & = C x + D u\n\\end{align*}\\]\n\nP1 = 0.04\nP2 = 0.02\n\nT_ambient, Cp_H, Cp_S, Ua, Ub, Uc = param_complete\n\nA = np.array([[-(Ua + Ub + Uc)/Cp_H, Uc/Cp_H, Ub/Cp_H, 0],\n     [Uc/Cp_S, -Uc/Cp_S, 0, 0],\n     [Ub/Cp_H, 0, -(Ua + Ub + Uc)/Cp_H, Uc/Cp_H],\n     [0, 0, Uc/Cp_S, -Uc/Cp_S]])\n\nB = np.array([[P1/Cp_H, 0], [0, 0], [0, P2/Cp_H], [0, 0]])\n\nC = np.array([[0, 1, 0, 0], [0, 0, 0, 1]])\n\nD = np.array([[0, 0], [0, 0]])\n\nE = np.array([[Ua/Cp_H], [0], [Ua/Cp_H], [0]])\n\nTime constants\n\neval, evec = np.linalg.eig(A)\n-1/eval\n\narray([191.1942343 ,  96.34592497,  27.18108829,  29.12414895])\n\n\n\nevec\n\narray([[ 0.44286448, -0.36815989, -0.25289296, -0.19739009],\n       [ 0.551245  , -0.60370381,  0.66033715,  0.67899717],\n       [ 0.44286448,  0.36815989,  0.25289296, -0.19739009],\n       [ 0.551245  ,  0.60370381, -0.66033715,  0.67899717]])",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/tclab_lab_2_fitting.html#putting-to-work",
    "href": "TCLab/tclab_lab_2_fitting.html#putting-to-work",
    "title": "Model Identification: Fitting models to data",
    "section": "Putting to work",
    "text": "Putting to work\n\nfrom control import *\nfrom control.matlab import *\n\n\nss = StateSpace(A, B, C, D)\n\n\nss\n\nA = [[-0.01676553  0.00621301  0.00380175  0.        ]\n [ 0.02660227 -0.02660227  0.          0.        ]\n [ 0.00380175  0.         -0.01676553  0.00621301]\n [ 0.          0.          0.02660227 -0.02660227]]\n\nB = [[0.00577444 0.        ]\n [0.         0.        ]\n [0.         0.00288722]\n [0.         0.        ]]\n\nC = [[0. 1. 0. 0.]\n [0. 0. 0. 1.]]\n\nD = [[0. 0.]\n [0. 0.]]\n\n\n\ny,t = step(ss, input=0)\nplt.plot(t,y)\n\n\n\n\n\n\n\n\n\npole(ss)\n\narray([-0.00523028, -0.01037927, -0.03679029, -0.03433577])\n\n\n\ntf(ss,)\n\n\\[\\begin{bmatrix}\\frac{0.0001536 s^2}{s^4 + 0.03957 s^3 + 0.0001796 s^2}&\\frac{7.681 \\times 10^{-5} s^2}{s^4 + 0.03957 s^3 + 0.0001796 s^2}\\\\\\frac{5.84 \\times 10^{-7} s + 1.554 \\times 10^{-8}}{s^4 + 0.08674 s^3 + 0.002428 s^2 + 2.358 \\times 10^{-5} s + 6.858 \\times 10^{-8}}&\\frac{7.681 \\times 10^{-5} s^2 + 3.331 \\times 10^{-6} s + 2.156 \\times 10^{-8}}{s^4 + 0.08674 s^3 + 0.002428 s^2 + 2.358 \\times 10^{-5} s + 6.858 \\times 10^{-8}}\\\\ \\end{bmatrix}\\]",
    "crumbs": [
      "TCLab",
      "Model Identification: Fitting models to data"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pi-control.html",
    "href": "TCLab/lab-assignment-pi-control.html",
    "title": "Lab Assignment 4: PI Control",
    "section": "",
    "text": "Given a process variable \\(PV\\) and setpoint \\(SP\\), proportional-integral-derivative control determines the value of a manipulated variable MV by the equation\n\\[\\begin{align}\nMV & = \\bar{MV} + k_p\\left(SP - PV\\right) + k_i \\int_0^t \\left(SP-PV)\\right)dt\n\\end{align}\\]\nwhere \\(k_p\\) and \\(k_i\\) are the proportional and integral coefficients, respectively. The value \\(\\bar{MV}\\) is a nominal or initial value of the manipulated variable.\nThe actual implementation of PI control is normally done by computing how much the \\(MV\\) should change at each time step. Defining the error at time \\(k\\) as\n\\[\\begin{align}\ne_k & = SP_k - PV_k\n\\end{align}\\]\nthen consecutive values of \\(MV\\) are given by\n\\[\\begin{align}\nMV_{k-1} & = \\bar{MV} + k_p e_{k-1} + k_i \\sum_{j=0}^{k-1} e_{j} \\\\\nMV_{k} & = \\bar{MV} + k_p e_{k} + k_i \\sum_{j=0}^{k} e_{j}\n\\end{align}\\]\nTaking differences gives a practical formula for updating the value of \\(MV\\) in response to measurements\n\\[\\begin{align}\nMV_{k} & = MV_{k-1} + k_p(e_{k} - e_{k-1}) + k_i e_{k}\n\\end{align}\\]\nThe following code defines a Python object that implements this algorithm.\n\nclass PI:\n    def __init__(self, kp=1, ki=0, MV=0):\n        self.kp = kp\n        self.ki = ki\n        self.e_prev = 0\n        self.MV = MV\n\n    def update(self, SP, PV):\n        e = SP - PV\n        self.e = e\n        self.MV += self.kp * (e - self.e_prev) + self.ki * e\n        self.MV = max(0, min(100, self.MV))\n        self.e_prev = e\n        return self.MV",
    "crumbs": [
      "TCLab",
      "Lab Assignment 4: PI Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pi-control.html#implementation-of-a-simple-pi-controller",
    "href": "TCLab/lab-assignment-pi-control.html#implementation-of-a-simple-pi-controller",
    "title": "Lab Assignment 4: PI Control",
    "section": "",
    "text": "Given a process variable \\(PV\\) and setpoint \\(SP\\), proportional-integral-derivative control determines the value of a manipulated variable MV by the equation\n\\[\\begin{align}\nMV & = \\bar{MV} + k_p\\left(SP - PV\\right) + k_i \\int_0^t \\left(SP-PV)\\right)dt\n\\end{align}\\]\nwhere \\(k_p\\) and \\(k_i\\) are the proportional and integral coefficients, respectively. The value \\(\\bar{MV}\\) is a nominal or initial value of the manipulated variable.\nThe actual implementation of PI control is normally done by computing how much the \\(MV\\) should change at each time step. Defining the error at time \\(k\\) as\n\\[\\begin{align}\ne_k & = SP_k - PV_k\n\\end{align}\\]\nthen consecutive values of \\(MV\\) are given by\n\\[\\begin{align}\nMV_{k-1} & = \\bar{MV} + k_p e_{k-1} + k_i \\sum_{j=0}^{k-1} e_{j} \\\\\nMV_{k} & = \\bar{MV} + k_p e_{k} + k_i \\sum_{j=0}^{k} e_{j}\n\\end{align}\\]\nTaking differences gives a practical formula for updating the value of \\(MV\\) in response to measurements\n\\[\\begin{align}\nMV_{k} & = MV_{k-1} + k_p(e_{k} - e_{k-1}) + k_i e_{k}\n\\end{align}\\]\nThe following code defines a Python object that implements this algorithm.\n\nclass PI:\n    def __init__(self, kp=1, ki=0, MV=0):\n        self.kp = kp\n        self.ki = ki\n        self.e_prev = 0\n        self.MV = MV\n\n    def update(self, SP, PV):\n        e = SP - PV\n        self.e = e\n        self.MV += self.kp * (e - self.e_prev) + self.ki * e\n        self.MV = max(0, min(100, self.MV))\n        self.e_prev = e\n        return self.MV",
    "crumbs": [
      "TCLab",
      "Lab Assignment 4: PI Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pi-control.html#exercise-1.-tune-the-pi-control-for-the-temperature-control-lab",
    "href": "TCLab/lab-assignment-pi-control.html#exercise-1.-tune-the-pi-control-for-the-temperature-control-lab",
    "title": "Lab Assignment 4: PI Control",
    "section": "Exercise 1. Tune the PI control for the Temperature Control Lab",
    "text": "Exercise 1. Tune the PI control for the Temperature Control Lab\nThe following cell provides an initial implementation of PI control for heater T1. This is setup for testing with the off-line simulation mode of tclab. Experiment with the simulation to find appropriate values for \\(k_p\\) and \\(k_i\\). Your design goal is to achieve the setpoint and stay within a zone of +/- 2 degrees as quickly as possible.\n\nfrom tclab import setup, clock, Historian, Plotter\n\nTCLab = setup(connected=False, speedup = 20)\n\npi = PI(kp=2, ki=0.1)\nSP = 50\n\nwith TCLab() as lab:\n    h = Historian(lab.sources)\n    p = Plotter(h, 800)\n    for t in clock(800):\n        PV = lab.T1               # measure the the process variable\n        MV = pi.update(SP, PV)    # PI control to determine the MV\n        lab.Q1(MV)                # set the heater power\n        p.update(t)               # log data\n\n\n\n\n\n\n\n\nTCLab Model disconnected successfully.",
    "crumbs": [
      "TCLab",
      "Lab Assignment 4: PI Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pi-control.html#exercise-2.-hardware-testing-the-pi-controller",
    "href": "TCLab/lab-assignment-pi-control.html#exercise-2.-hardware-testing-the-pi-controller",
    "title": "Lab Assignment 4: PI Control",
    "section": "Exercise 2. Hardware testing the PI controller",
    "text": "Exercise 2. Hardware testing the PI controller\n\nCopy and paste the above code into the cell below. Connect the code to the tclab hardware by changing ‘connected’ to ‘True’. Adjust the experiment horizon to 1200 seconds to provide plenty of time for testing.\nTest your controller. Does the performance match the simulation?\nAfter the controller has achieved the setpoint, introduce a disturbance. An example of a disturbance would be to increase air flow around the device, or to touch the heater with something thermally conductive (be careful, don’t use your finger. 50 deg C is hot enough to burn your skin.)\nAdd a text cell below, and comment on your results. Do you see any shortcomings in this control implementation?\n\n\n# put your code here\n\nWrite your comments in this cell.",
    "crumbs": [
      "TCLab",
      "Lab Assignment 4: PI Control"
    ]
  },
  {
    "objectID": "TCLab/lab-assignment-pi-control.html#exercise-3.-multivariable-pi-control",
    "href": "TCLab/lab-assignment-pi-control.html#exercise-3.-multivariable-pi-control",
    "title": "Lab Assignment 4: PI Control",
    "section": "Exercise 3. Multivariable PI control",
    "text": "Exercise 3. Multivariable PI control\nThe next exercise is to extend the system to control both heaters. You won’t have enough time in the lab to do this experimentally, so do this exercise using the simulation mode of tclab.\n\nCopy and past the code from Exercise 1 into the cell below.\nAdd a second PI controller (rename the first pi_1, and call the second pi_2, for example). Adjust the setpoint for the first heater to 40 deg C, and the second to 35 deg C. Tune the controllers to achieve rapid acquisition of the setpoints.\n\n\n# put your code here",
    "crumbs": [
      "TCLab",
      "Lab Assignment 4: PI Control"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "",
    "text": "Prenderemo come esempio i sistemi del secondo ordine. Tuttavia, prima di immergersi nel ciclo di progettazione, è fondamentale capire che, sebbene i sistemi del mondo reale potrebbero non essere sempre di secondo ordine, padroneggiare la progettazione di tali sistemi è fondamentale. Questa conoscenza può essere estesa a sistemi più complessi. Iniziamo con un sistema standard del secondo ordine in una configurazione a feedback unitario.",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html#analisi",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html#analisi",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "Analisi",
    "text": "Analisi\nDetermina il comportamento del sistema senza alcun controller:\n\n\n\n\n\n\\[\nG(s) = \\frac{\\omega_n^2}{s(s + 2\\zeta\\omega_n)}\n\\]\ne la funzione di trasferimento ad anello chiuso \\(Y(s)/R(s)\\) è data da:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\n\\]\nDove: - $ _n $ è la frequenza naturale non smorzata. - $ $ è il rapporto di smorzamento.\n\nComprendere il rapporto di smorzamento (\\(\\zeta\\))\n\nSistema non smorzato (\\(\\zeta = 0\\)): comportamento puramente oscillatorio.\nSotto-Smorzato (\\(0 &lt; \\zeta &lt; 1\\)): Oscillatory but decaying response.\nCritically Damped (\\(\\zeta = 1\\)): Fastest return to equilibrium without overshooting.\nOver-Damped (\\(\\zeta &gt; 1\\)): Ritorno lento all’equilibrio senza oscillazioni.\n\n\n\nEquazione caratteristica e radici\nL’equazione caratteristica è:\n\\[\n\\Delta (s) = s^2 + 2\\zeta\\omega_n s + \\omega_n^2\n\\]\nLe radici di questa equazione (poli a circuito chiuso o radici caratteristiche) sono fondamentali per l’analisi del comportamento del sistema.\nLe radici caratteristiche di un sistema standard del secondo ordine possono essere derivate dalla sua equazione caratteristica. Per il sistema rappresentato dalla funzione di trasferimento $ G(s) = $, l’equazione caratteristica si ottiene dal denominatore del trasferimento ad anello chiuso funzione:\n\\[\n\\Delta s = s^2 + 2\\zeta\\omega_n s + \\omega_n^2 = 0\n\\]\nPer trovare le radici di questa equazione caratteristica, risolviamo $ s $. Queste radici, note anche come poli del sistema, determinano il comportamento del sistema.\nRisolvendo l’equazione quadratica $ s^2 + 2_n s + _n^2 = 0 $ utilizzando la formula quadratica, otteniamo:\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{(2\\zeta\\omega_n)^2 - 4\\omega_n^2}}{2}\n\\]\nSemplificando ulteriormente:\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{4\\zeta^2\\omega_n^2 - 4\\omega_n^2}}{2}\n\\]\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm \\sqrt{4\\omega_n^2(\\zeta^2 - 1)}}{2}\n\\]\n\\[\ns = \\frac{-2\\zeta\\omega_n \\pm 2\\omega_n\\sqrt{\\zeta^2 - 1}}{2}\n\\]\n\\[\ns = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1}\n\\]\nQuindi, le radici (o poli) caratteristiche sono:\n\\[\ns = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1}\n\\]\nA seconda del valore di $ $ (il rapporto di smorzamento), queste radici possono essere reali o complesse:\n\nPer $ &lt; 1 $ (under-damped): The roots are complex conjugates.\n\\[ s = -\\zeta\\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nFor $ = 1 $ (critically damped): The roots are real and identical.\n\\[ s = -\\omega_n \\]\nFor $ &gt; 1 $ (sovrasmorzato): le radici sono numeri reali distinti.\n\nQueste radici sono cruciali per comprendere la risposta transitoria, la stabilità e il comportamento generale del sistema.\n\nVisualizzazione caratteristica delle radici\n\nPer $ = 0 $ (sottosmorzato):\n\\[ s = \\pm j\\omega_n \\]\nPer $ = 1 $ (criticamente smorzato): le radici sono reali e identiche.\n\\[ s = -\\omega_n \\]\n\nPossiamo tracciare come si muovono le radici nel piano s.\nUsiamo Python per questo eseguendo la cella sottostante\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set the undamped natural frequency\nomega_n = 1  # You can adjust this as needed\n\n# Create a range of zeta values from 0 to 2\nzeta_values = np.linspace(0, 2, 400)\n\n# Prepare a plot\nplt.figure(figsize=(10, 8))\n\nfor zeta in zeta_values:\n    # Calculate the roots for each zeta\n    if zeta &lt; 1:\n        # Under-damped (Complex conjugate roots)\n        roots = [-zeta * omega_n + 1j * omega_n * np.sqrt(1 - zeta**2),\n                 -zeta * omega_n - 1j * omega_n * np.sqrt(1 - zeta**2)]\n        color = 'blue'\n    elif zeta == 1:\n        # Critically damped (Repeated real roots)\n        roots = [-zeta * omega_n, -zeta * omega_n]\n        color = 'green'\n    else:\n        # Over-damped (Distinct real roots)\n        roots = [-zeta * omega_n + omega_n * np.sqrt(zeta**2 - 1),\n                 -zeta * omega_n - omega_n * np.sqrt(zeta**2 - 1)]\n        color = 'red'\n    \n    # Plot the roots\n    plt.plot([root.real for root in roots], [root.imag for root in roots], 'o', color=color)\n\n# Annotating key points\nplt.annotate('Undamped\\n(Complex Roots)', xy=(0, omega_n), xytext=(0.5, omega_n+0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.annotate('Critically Damped\\n(Repeated Real Roots)', xy=(-omega_n, 0), xytext=(-2, 0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\nplt.annotate('Over-Damped\\n(Distinct Real Roots)', xy=(-2*omega_n, 0), xytext=(-2.5, -0.5),\n             arrowprops=dict(facecolor='black', shrink=0.05))\n\n# Setting plot features\nplt.title('Root Locus as Damping Ratio (zeta) Varies')\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.axhline(y=0, color='k')  # x-axis\nplt.axvline(x=0, color='k')  # y-axis\nplt.grid(True)\nplt.xlim(-2.5, 0.5)\nplt.ylim(-1.5, 1.5)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nLa quantità \\(\\zeta\\omega_n\\) ha un ruolo molto importante: è la parte reale della coppia complessa coniugata.\n\n\n\n\n\n\n\n\nDeterminazione dell’angolo di smorzamento (\\(\\theta\\))\nData la geometria del diagramma del luogo delle radici sopra possiamo determinare l’angolo \\(\\theta\\) (suggerimento: il raggio del cerchio è \\(\\omega_n\\)):\n\\[\n\\omega_n\\cos\\theta = \\zeta\\omega_n\n\\]\n\\[\n\\cos(\\theta) = \\zeta \\\\\n\\theta = \\cos^{-1}(\\zeta)\n\\]\n\nL’angolo \\(\\theta\\) è chiamato angolo di smorzamento perché è una funzione solo di \\(\\zeta\\) (e non dipende da \\(\\omega_n\\).\nLa linea della costante \\(\\theta\\) (e quindi della costante \\(\\zeta\\)) è chiamata linea di smorzamento. Dato uno specifico \\(\\zeta\\) le radici si troveranno lungo la linea di smorzamento associata.\n\nDati i poli specifici \\(\\theta\\), \\(\\omega_n\\) del circuito chiuso, le radici dell’equazione caratteristica sono:\n\n\n\n\n\noppure: \\[ s = -\\zeta\\omega_n \\pm j\\omega_n\\sqrt{1 - \\zeta^2} \\]\nCiò significa che dati \\(\\theta\\), \\(\\omega_n\\) specifici possiamo tradurre questi valori in poli ad anello chiuso.\nIl criterio di progettazione sarà quindi quello di forzare i poli del circuito chiuso nella posizione desiderata, dove si ottengono le prestazioni desiderate (ovvero, soddisfare le specifiche di risposta transitoria).\n\n\n\nBARRA LATERALE - Relazione tra \\(\\zeta\\), \\(\\omega_n\\) e poli ad anello chiuso\n\nRelazione tra \\(\\zeta\\), \\(\\omega_n\\) e poli ad anello chiuso:\n\nIn un sistema standard del secondo ordine, i parametri \\(\\zeta\\) (rapporto di smorzamento) e \\(\\omega_n\\) (frequenza naturale non smorzata) sono determinanti chiave del comportamento del sistema.\nI valori di \\(\\zeta\\) e \\(\\omega_n\\) definiscono direttamente la posizione dei poli del circuito chiuso nel piano complesso. Ad esempio, un cambiamento in \\(\\zeta\\) e \\(\\omega_n\\) sposterà questi poli, influenzando la risposta transitoria del sistema.\n\nEquivalenza di specificare \\(\\zeta\\), \\(\\omega_n\\) e poli ad anello chiuso:\n\nQuando si specifica \\(\\zeta\\) e \\(\\omega_n\\) per un sistema del secondo ordine, equivale a specificare le posizioni desiderate dei poli a circuito chiuso. Questo perché esiste una relazione diretta e calcolabile tra questi parametri e i poli.\nI poli a circuito chiuso, a loro volta, determinano le principali caratteristiche prestazionali del sistema, come superamento, tempo di assestamento e frequenza di oscillazione.\n\nImportanza nella progettazione del luogo delle radici:\n\nQuesta comprensione costituisce la base della progettazione del luogo delle radici, un metodo utilizzato per determinare la stabilità di un sistema di controllo e progettare controllori.\nNella progettazione del luogo delle radici, in genere si inizia con una risposta transitoria desiderata (definita da \\(\\zeta\\) e \\(\\omega_n\\)) e quindi si regola il controller per spostare i poli del sistema in queste posizioni predefinite nel piano complesso.\n\nTraduzione di \\(\\zeta\\) e \\(\\omega_n\\) in posizioni dei poli a circuito chiuso:\n\nSpecificando \\(\\zeta\\) e \\(\\omega_n\\), essenzialmente imposti un obiettivo per dove vuoi che siano i poli a circuito chiuso. L’attività di progettazione diventa quindi una questione di modifica del sistema (spesso tramite un controller) in modo che i suoi poli effettivi si allineino con queste posizioni target.\nIl raggiungimento di questo allineamento garantisce che la risposta transitoria del sistema soddisfi i criteri di prestazione specificati.\n\n\nNel contesto di un sistema standard del secondo ordine, specificare \\(\\zeta\\) e \\(\\omega_n\\) è un modo per definire le caratteristiche prestazionali desiderate. Il metodo del luogo delle radici utilizza quindi queste specifiche per progettare un sistema di controllo che posiziona i poli del circuito chiuso in posizioni che garantiscono il rispetto di queste caratteristiche prestazionali. Si tratta di un approccio fondamentale nella progettazione dei sistemi di controllo, poiché consente agli ingegneri dei controlli di personalizzare i sistemi per soddisfare specifici requisiti di risposta ai transitori.",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html#caratteristiche-della-risposta-transitoria",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html#caratteristiche-della-risposta-transitoria",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "Caratteristiche della risposta transitoria",
    "text": "Caratteristiche della risposta transitoria\nAnalizziamo ora la risposta di un sistema sotto-smorzato ad un input a passo unitario:\n\\[\nR(s) = \\frac{1}{s}\n\\]\nIn questo caso, l’output è:\n\\[\nY(s) = \\frac{\\omega_n^2}{s(s^2 + 2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\nLa funzione di risposta, ottenuta come trasformata inversa di Laplace, è:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\nDove: - $ _d = _n $ è la frequenza smorzata. - \\(\\theta = \\cos^{-1}(\\zeta)\\) è l’angolo di smorzamento.\nIn questo caso i poli sono complessi coniugati.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the parameters\nzeta = 0.3       # Damping ratio\nomega_n = 1.0    # Natural frequency (rad/s)\nt = np.linspace(0, 10, 1000)  # Time vector\n\n# Calculate the angular frequency and phase angle\nomega_d = omega_n * np.sqrt(1 - zeta**2)\ntheta = np.arctan2(omega_n * np.sqrt(1 - zeta**2), zeta)\n\n# Compute the system response\ny = 1 - (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)) * np.sin(omega_d * t + theta)\n\n# Compute the upper and lower envelope curves\nupper_envelope = 1 + (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2))\nlower_envelope = 1 - (np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2))\n\n# Plot the response and envelope curves\nplt.figure(figsize=(8, 6))\nplt.plot(t, y, label='System Response')\nplt.plot(t, upper_envelope, 'r--', label='Upper Envelope')\nplt.plot(t, lower_envelope, 'g--', label='Lower Envelope')\nplt.xlabel('Time (s)')\nplt.ylabel('y(t)')\nplt.title('Second-Order System Response with Envelopes')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nCurve d’inviluppo e costante di tempo\nLa risposta è delimitata dalle curve di inviluppo:\n\nBusta superiore: $ 1 + $\nBusta inferiore: $ 1 - $\n\nQueste curve giocano un ruolo significativo: più velocemente decadono, più veloce è il decadimento della risposta.\nLa costante di tempo dell’inviluppo è (suggerimento: è una funzione esponenziale): \\[ \\tau = \\frac{1}{\\zeta\\omega_n} \\]\nLa risposta è:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\nma è più conveniente tracciare la risposta rispetto al tempo normalizzato \\(\\omega_n t\\). Ora abbiamo solo \\(\\zeta\\) come parametro:\n\n\n\n\n\nNotare che:\n\nper \\(\\zeta=1\\) il sistema è criticamente smorzato, praticamente senza oscillazioni.\nper \\(\\zeta&gt;1\\) il sistema è eccessivamente smorzato e diventa lento. Questo in genere non è desiderabile in un sistema di controllo.\n\n\n\nComprendere i compromessi di progettazione\n\nUn $ $ più basso (più oscillatorio) porta a un tempo di salita più breve ma a un superamento più elevato.\nUn \\(\\zeta\\) più alto (meno oscillatorio) riduce l’overshoot ma aumenta il tempo di salita.\n\n\n\nIndicatori chiave di prestazione transitoria\n\nTempo di salita (\\(t_r\\)): tempo impiegato dalla risposta per raggiungere il valore finale.\nTempo di picco (\\(t_p\\)): Tempo fino al primo picco della risposta.\nSuperamento massimo (\\(M_p\\)): Deviazione massima dal valore finale.\n\n\nCalcolo di \\(t_r\\), \\(t_p\\) e \\(M_p\\)\nPartiamo da\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\]\n\n\nTempo di salita (\\(t_r\\)):\n\\[ t_r :\\;\\; y(t_r) = 1 \\;\\; \\Rightarrow \\frac{e^{-\\zeta\\omega_nt_r}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t_r + \\theta) = 0 \\;\\; \\Rightarrow \\sin(\\omega_d t_r + \\theta) = 0 \\;\\; \\Rightarrow \\omega_d t_r + \\theta = \\pi\\]\n\\[ t_r = \\frac{\\pi - \\theta}{\\omega_d} = \\frac{\\pi - \\cos^{-1}(\\zeta)}{\\omega_n\\sqrt{1-\\zeta^2}} \\]\n\n\nOra di punta (\\(t_p\\)):\nPer determinare il tempo per raggiungere il picco (\\(t_p\\)) per un sistema standard del secondo ordine, dobbiamo analizzare la risposta del sistema e scoprire quando raggiunge il suo primo massimo. Ciò si verifica in un punto estremo della funzione di risposta, dove la derivata prima della risposta rispetto al tempo (\\(t\\)) è uguale a zero.\nAnalizziamo i passaggi per trovare \\(t_p\\):\n\nLa funzione di risposta:\nPer un sistema di secondo ordine sottosmorzato (\\(0 &lt; \\zeta &lt; 1\\)), the step response is given by: \\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta)\n\\] where \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) and \\(\\theta = \\cos^{-1}(\\zeta)\\).\nFinding the Extremum:\nThe extremum occurs where the derivative of \\(y(t)\\) with respect to \\(t\\) is zero. Let’s find this derivative:\n\\[\n\\frac{dy}{dt} = \\zeta\\omega_n \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta) - \\omega_d \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\cos(\\omega_d t + \\theta).\n\\]\nSetting \\(\\frac{dy}{dt} = 0\\) gives us the condition for the peak.\nSimplifying the Equation:\nThe equation \\(\\frac{dy}{dt} = 0\\) simplifies to: \\[\n\\zeta\\sin(\\omega_d t + \\theta) = \\sqrt{1-\\zeta^2}\\cos(\\omega_d t + \\theta).\n\\]\nUsing the identity \\(\\sin(a + b) = \\sin(a)\\cos(b) + \\cos(a)\\sin(b)\\), we get: \\[\n\\zeta[\\sin(\\omega_d t)\\cos(\\theta) + \\cos(\\omega_d t)\\sin(\\theta)] = \\sqrt{1-\\zeta^2}\\cos(\\omega_d t).\n\\]\nSince \\(\\theta = \\cos^{-1}(\\zeta)\\), \\(\\sin(\\theta) = \\sqrt{1-\\zeta^2}\\) and \\(\\cos(\\theta) = \\zeta\\). Substituting these into the equation, we simplify it to: \\[\n\\zeta^2\\sin(\\omega_d t) + \\sqrt{1-\\zeta^2}\\cos(\\omega_d t)\\sin(\\omega_d t) = \\zeta\\cos(\\omega_d t).\n\\]\nFinding \\(t_p\\):\nThe equation simplifies to \\(\\sin(\\omega_d t) = 0\\), indicating that the peak occurs at a multiple of \\(\\pi/\\omega_d\\). The first peak (\\(t_p\\)) occurs at: \\[\nt_p = \\frac{\\pi}{\\omega_d} = \\frac{\\pi}{\\omega_n\\sqrt{1-\\zeta^2}}.\n\\]\n\nThis \\(t_p\\) is the time to peak for the under-damped second-order system’s step response. It’s important to note that this derivation assumes an under-damped system (\\(0 &lt; \\zeta &lt; 1\\)). For critically damped (\\(\\zeta = 1\\)) or over-damped (\\(\\zeta &gt; 1\\)), l’approccio per trovare \\(t_p\\) sarebbe diverso, poiché in questi casi la risposta del sistema non mostra superamento.\nSi noti che il tempo per il primo superamento negativo sarebbe \\(\\omega_d t = 2\\pi\\), il tempo per il secondo superamento \\(\\omega_d t = 3\\pi\\) e così via.\n\n\nSuperamento massimo (\\(M_p\\)):\nPer ricavare il valore massimo di superamento (\\(M_p\\)) per un sistema di secondo ordine sottosmorzato, dobbiamo valutare la risposta del sistema al momento del picco (\\(t_p\\)), che abbiamo determinato in precedenza. Il superamento massimo è la quantità di cui la risposta del sistema supera il suo valore finale (che è 1 per un ingresso a gradino unitario) al primo picco.\n\nRichiama la funzione di risposta:\nLa risposta per un sistema sottosmorzato (\\(0 &lt; \\zeta &lt; 1\\)) a un ingresso a gradino unitario è:\n\\[\ny(t) = 1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\theta),\n\\]\ndove \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) e \\(\\theta = \\cos^{-1}(\\zeta)\\).\nValuta la risposta a \\(t_p\\):\nAbbiamo precedentemente scoperto che \\(t_p = \\frac{\\pi}{\\omega_d}\\). Sostituendo questo nella funzione di risposta si ottiene:\n\\[\ny(t_p) = 1 - \\frac{e^{-\\zeta\\omega_n(\\pi/\\omega_d)}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d (\\pi/\\omega_d ) + \\theta).\n\\]\nSemplifica l’espressione:\nIl termine seno si semplifica come \\(\\sin(\\pi + \\theta) = -\\sin(\\theta)\\). Poiché \\(\\theta = \\cos^{-1}(\\zeta)\\), abbiamo \\(\\sin(\\theta) = \\sqrt{1-\\zeta^2}\\). Perciò:\n\\[\ny(t_p) = 1 + e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n\\]\nCalcola il superamento massimo (\\(M_p\\)):\nL’overshoot massimo è il valore di picco meno il valore di stato stazionario (che è 1 per una risposta al gradino unitaria), quindi:\n\\[\nM_p = y(t_p) - 1 = e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n\\]\nSostituisci \\(\\omega_d\\):\nRicordiamo che \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\). Sostituendo questo in \\(M_p\\):\n\\[\nM_p = e^{-\\frac{\\zeta\\omega_n\\pi}{\\omega_n\\sqrt{1-\\zeta^2}}} = e^{-\\frac{\\pi\\zeta}{\\sqrt{1- \\zeta^2}}}.\n\\]\n\nQuesta espressione finale fornisce il massimo superamento \\(M_p\\) per un sistema del secondo ordine sottosmorzato. Quantifica quanto il primo picco della risposta del sistema supera il valore di stato stazionario in risposta a un ingresso a gradino unitario. Il superamento dipende esclusivamente dal rapporto di smorzamento \\(\\zeta\\) e quando \\(\\zeta\\) si avvicina a 1 (transizione allo smorzamento critico), \\(M_p\\) diminuisce, riflettendo un minore superamento nella risposta del sistema.\nDomanda pop-up: Cosa succede al momento di picco (\\(t_p\\)) quando il rapporto di smorzamento ($ $) aumenta?\nRisposta: All’aumentare di $ $, $ _d = _n $ diminuisce, portando ad un aumento del tempo di picco (\\(t_p\\)).",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html#specifiche-delle-prestazioni-transitorie",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html#specifiche-delle-prestazioni-transitorie",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "Specifiche delle prestazioni transitorie",
    "text": "Specifiche delle prestazioni transitorie\nContinuiamo la nostra esplorazione dell’ingegneria di controllo, concentrandoci sulle specifiche delle prestazioni transitorie. Ricorda, stiamo utilizzando una risposta al gradino, tipicamente una risposta al gradino unitario, come strumento principale per esaminare la risposta transitoria dei sistemi di secondo ordine. E, cosa interessante, queste specifiche si applicano anche ai sistemi di ordine superiore.\n\nTempo di salita, superamento del picco, tempo al picco e tempo di assestamento\nInnanzitutto, ricapitoliamo le specifiche chiave di cui stiamo discutendo: - Rise Time (t_r): il tempo necessario affinché la risposta del sistema salga dal 10% al 90% del suo valore finale. - Peak Overshoot (M_p): il valore di picco massimo della curva di risposta come percentuale rispetto al valore finale. - Time to Peak (t_p): Il tempo impiegato per raggiungere il primo superamento del picco. - Tempo di assestamento (t_s): il tempo impiegato dalla risposta per raggiungere e rimanere entro una determinata percentuale (comunemente 2% o 5%) del suo valore finale.\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n\ndef find_max_consecutive_index(arr):\n    max_consecutive_index = None\n    consecutive_start = None\n\n    for i in range(len(arr) - 1):\n        if arr[i] + 1 != arr[i + 1]:\n            if consecutive_start is not None:\n                max_consecutive_index = consecutive_start\n            consecutive_start = None\n        elif consecutive_start is None:\n            consecutive_start = i + 1\n\n    # Check if the entire array is consecutive\n    if consecutive_start is not None:\n        max_consecutive_index = consecutive_start\n\n    return max_consecutive_index if max_consecutive_index is not None else len(arr) - 1\n\n\n# Define a function to calculate and plot the system response with performance parameters\ndef plot_response(zeta, omega_n, sim_time):\n    # System parameters: zeta (damping ratio), omega_n (natural frequency)\n    num = [omega_n**2]  # Numerator (assuming unit gain)\n    den = [1, 2 * zeta * omega_n, omega_n**2]  # Denominator\n\n    # Create a transfer function model\n    system = control.tf(num, den)\n\n    # Time parameters\n    t = np.linspace(0, sim_time, int(sim_time*100))  # Time vector\n\n    # Step response\n    t, y = control.step_response(system, t)\n    steady_state_value = y[-1]\n\n    # Rise Time\n    rise_time_indices = np.where(y &gt;= steady_state_value)[0]\n    rise_time = t[rise_time_indices[0]] if rise_time_indices.size else None\n\n    # Peak Overshoot and Peak Time\n    peak_overshoot = np.max(y) - steady_state_value\n    peak_time = t[np.argmax(y)]\n\n    # Settling Time (within 2% of steady-state value). This is found numerically.\n    settling_time_indices = np.where(abs(y - steady_state_value) &lt;= 0.02 * steady_state_value)[0]\n    ts_index = find_max_consecutive_index(settling_time_indices)\n    settling_time = t[settling_time_indices[ts_index]] if settling_time_indices.size else None\n\n    # Plot\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y, label='System Response')\n    plt.axhline(steady_state_value, color='r', linestyle='--', label='Steady State')\n    # tolerange band (0.02 percent)\n    plt.axhline(steady_state_value * 1.02, color='g', linestyle=':', label='Settling Time Bound')\n    plt.axhline(steady_state_value * 0.98, color='g', linestyle=':')\n\n    if rise_time:\n        plt.axvline(rise_time, color='y', linestyle='-', label=f'Rise Time: {rise_time:.2f}s')\n    plt.axvline(peak_time, color='b', linestyle='-', label=f'Peak Time: {peak_time:.2f}s')\n    plt.scatter(peak_time, np.max(y), color='black', label=f'Peak Overshoot: {peak_overshoot:.2f}')\n    \n    if settling_time:\n        plt.scatter(settling_time, y[settling_time_indices[ts_index]], color='purple')\n        plt.axvline(settling_time, color='purple', linestyle='-', label=f'Settling Time: {settling_time:.2f}s')\n    \n    plt.title('Transient Response with Performance Parameters')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Output')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Interactive sliders\nfrom ipywidgets import interact, FloatSlider\ninteract(plot_response, \n         zeta=FloatSlider(value=0.3, min=0.01, max=1.0, step=0.01), \n         omega_n=FloatSlider(value=2, min=1, max=10, step=0.1), \n         sim_time=FloatSlider(value=10, min=1, max=50, step=1))\n\n\n\n\n&lt;function __main__.plot_response(zeta, omega_n, sim_time)&gt;\n\n\n\n\nFunzione di trasferimento del sistema del secondo ordine\nPer un sistema standard del secondo ordine, la funzione di trasferimento è:\n\\[ Y(s) = \\frac{\\omega_n^2}{s(s^2 + 2 \\zeta \\omega_n s + \\omega_n^2)} \\]\ndove $ _n $ è la frequenza naturale e $ $ è il rapporto di smorzamento.\nQuesta è la trasformazione di risposta per la quale \\(R(s) = \\frac{1}{s}.\\)\n\n\nTrasformata di Laplace inversa\nApplicando la trasformata di Laplace inversa, otteniamo la risposta nel dominio del tempo:\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\ncon \\(\\theta = \\cos^{-1}(\\zeta)\\) e \\(\\omega_d = \\omega_n \\sqrt{1 - \\zeta^2}\\), che rappresenta la frequenza naturale smorzata.\n\n\nTempo di salita (\\(t_r\\))\nIl tempo di salita può essere espresso come:\n\\[ t_r = \\frac{\\pi - \\cos^{-1}(\\zeta)}{\\omega_n \\sqrt{1 - \\zeta^2}} \\]\nSi noti che il tempo di salita dipende sia da $ $ che da $ _n $, ma l’effetto di $ $ è relativamente piccolo.\n\nCome abbiamo discusso, vorremmo che il tempo di lievitazione fosse il più breve possibile. Ciò significherebbe che il sistema risponde rapidamente.\n\nPer visualizzare come varia il tempo di salita con $ $ e $ _n $ e per dimostrare che il tempo di salita rimane relativamente costante al variare di $ $, possiamo scrivere uno script Python utilizzando librerie come matplotlib per la stampa e numpy per calcoli numerici.\nIn questo script: - Definiamo un intervallo di valori $ $ compreso tra 0,01 e 0,99. - Selezioniamo alcuni valori di $ _n $ per illustrare l’effetto sul tempo di salita. - Usiamo la formula derivata per il tempo di salita e la tracciamo rispetto a $ $ per ogni $ _n $. - Il grafico mostrerà più curve, ciascuna rappresentante un diverso $ _n $, e come varia il tempo di salita con $ $ per questi valori.\nL’esecuzione di questo codice genererà un grafico che illustra la relazione tra tempo di salita, rapporto di smorzamento $ $ e frequenza naturale $ _n $. Il grafico dimostrerà che mentre il tempo di salita varia con diversi valori $ _n $, l’effetto di $ $ sul tempo di salita è relativamente piccolo, specialmente all’interno di un intervallo tipico di $ $.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define a range of zeta and omega_n values\nzeta_values = np.linspace(0.01, 0.99, 100)  # Zeta values from 0.01 to 0.99\nomega_n_values = np.array([1, 2, 5, 10])    # Different omega_n values\n\n# Function to calculate rise time\ndef rise_time(zeta, omega_n):\n    return (np.pi - np.arccos(zeta)) / (omega_n * np.sqrt(1 - zeta**2))\n\ndef normalised_rise_time(zeta):\n    return (np.pi - np.arccos(zeta)) / (np.sqrt(1 - zeta**2))\n    \n# Plotting\nplt.figure(figsize=(10, 6))\nfor omega_n in omega_n_values:\n    rt = rise_time(zeta_values, omega_n)    \n    plt.plot(zeta_values, rt, label=f'ωₙ = {omega_n}')\n\nwnrt = normalised_rise_time(zeta_values)\nplt.plot(zeta_values, wnrt, label=f'ωₙtₙ')\n\n\n# Add vertical lines at zeta = 0.4 and zeta = 0.7\nplt.axvline(x=0.4, color='gray', linestyle='--', linewidth=1.5, label='ζ = 0.4')\nplt.axvline(x=0.7, color='gray', linestyle='--', linewidth=1.5, label='ζ = 0.7')\n\n\nplt.title('Rise Time vs Damping Ratio (ζ) for Different ωₙ')\n\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Rise Time')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nMassima Sovraelongazione (\\(M_p\\))\nLa massima sovraelongazione è data da:\n\\[\\Large M_p = e^{-\\frac{\\pi \\zeta}{\\sqrt{1 - \\zeta^2}}} \\]\nIn questo caso $ M_p $ dipende esclusivamente dal rapporto di smorzamento $ $.\nVorremmo che il tempo di salita \\(t_r\\) fosse il più breve possibile, ma anche che la massima sovraelongazione rimanesse piccola. Un elevata sovraelongazione significa che il sistema è prossimo all’instabilità e anche piccole variazioni dei parametri potrebbero rendere il sistema instabile.\nIn genere, $ M_p $ è accettabile quando è compreso tra $ 5% $ e \\(40\\%\\). È accettabile anche un valore inferiore a \\(5\\%\\), ma in genere ciò significa che il tempo di salita sarà molto elevato.\nCiò significa che in genere: \\(0,4 &lt; \\zeta &lt; 0,7\\). Con riferimento alla figura precedente, in questo intervallo \\(\\omega_n t_r\\) (il tempo di salita normalizzato) è praticamente costante e non influenzato troppo dalla variazione del rapporto di smorzamento.\nSe questo è vero allora possiamo dire che il tempo di salita è l’inverso della frequenza naturale non smorzata:\n\\[ \\omega_n t_r = cost \\Rightarrow t_r = \\frac{1}{\\omega_n} cost\\]\n\n\nTempo di salita e larghezza di banda\nPer ottimizzare le prestazioni di un sistema di controllo, in particolare la sua velocità di risposta, spesso miriamo a diminuire il tempo di salita. Il tempo di salita, che indica quanto velocemente un sistema risponde ai cambiamenti, è inversamente correlato alla frequenza naturale del sistema, $ _n $. Pertanto, per ridurre il tempo di salita, una strategia comune è progettare il sistema in modo tale che $ _n $ sia il più grande possibile.\nTuttavia, questo approccio comporta un avvertimento significativo. Aumentando $ _n $ aumenta anche la larghezza di banda del sistema. La larghezza di banda, in termini semplici, è la gamma di frequenze su cui il sistema può operare efficacemente. Una larghezza di banda maggiore significa che il sistema diventa più sensibile a una gamma più ampia di frequenze, comprese quelle nella gamma più alta.\nLa sfida con una larghezza di banda ampia è che consente ai segnali ad alta frequenza, che spesso sono rumore, di penetrare nel sistema. Questi segnali ad alta frequenza possono influire negativamente sulle prestazioni del sistema. Al contrario, i segnali utili nella maggior parte dei sistemi di controllo hanno tipicamente una frequenza più bassa. Pertanto, sebbene un’ampia larghezza di banda possa migliorare la velocità di risposta, può compromettere la capacità del sistema di filtrare il rumore indesiderato.\nPertanto, quando si progetta un tempo di salita ottimale, è necessario considerare il compromesso tra velocità di risposta e immunità al rumore. L’obiettivo non è raggiungere il tempo di salita teorico più piccolo, ma trovare un equilibrio pratico che garantisca l’affidabilità e la stabilità del sistema. Questo equilibrio è in gran parte influenzato dalle limitazioni della larghezza di banda.\nLa relazione tra la velocità di risposta (misurata dal tempo di salita) e la larghezza di banda del sistema è quasi diretta: una risposta più rapida (tempo di salita inferiore) corrisponde a una larghezza di banda più ampia. Tuttavia, una larghezza di banda infinita non è pratica perché porterebbe a un’eccessiva interferenza di rumore. Di conseguenza, un tempo di salita pari a zero, che richiederebbe una larghezza di banda infinita, è irraggiungibile.\nL’equilibrio appropriato tra tempo di salita e larghezza di banda dipende fortemente dai componenti e dalle caratteristiche specifiche del sistema. Ad esempio, se il sistema impiega sensori che non generano rumore ad alta frequenza, potrebbe essere fattibile progettare una larghezza di banda maggiore (e quindi un tempo di salita inferiore) senza compromettere in modo significativo le prestazioni del sistema. Ogni sistema richiede un approccio su misura, considerando il suo hardware e il suo ambiente operativo unici.\n\n\nConsiderazioni sulla stabilità\n\n\n\n\n\nNel contesto dei sistemi di controllo, in particolare quelli modellati come sistemi del secondo ordine, le caratteristiche di stabilità e risposta sono significativamente influenzate da due parametri: lo smorzamento ($ \\() e la frequenza naturale (\\) _n $). Lo smorzamento $ $ gioca un ruolo fondamentale nel governare il comportamento oscillatorio del sistema e la sua capacità di raggiungere l’equilibrio. Un $ $ più alto si traduce in meno oscillazioni e in un sistema più smorzato, che si stabilizza più rapidamente ma può avere una risposta più lenta. Al contrario, un $ $ inferiore porta a un sistema più sottosmorzato, caratterizzato da oscillazioni più pronunciate, e può rischiare instabilità se diventa troppo basso.\nLa frequenza naturale $ _n $, che rappresenta la velocità di oscillazione intrinseca del sistema in assenza di smorzamento, influenza la velocità di risposta del sistema. Un $ _n $ più elevato consente in genere tempi di risposta più rapidi ma, abbinato a un basso rapporto di smorzamento, può indurre oscillazioni rapide, portando il sistema verso l’instabilità.\nFondamentalmente, la massima sovraelongazione ($ M_p $) è intimamente legata a questi parametri. $ M_p $, definito come il picco massimo della curva di risposta in percentuale rispetto al valore finale, è direttamente influenzato da $ $. Nello specifico, $ M_p = e^{-} $ illustra che un rapporto di smorzamento più elevato riduce la massima sovraelongazione, allontanando il sistema dall’instabilità. Questa relazione evidenzia il delicato equilibrio richiesto nella progettazione del sistema di controllo: garantire la reattività e ridurre al minimo il superamento mantenendo la stabilità. Pertanto, la selezione di $ $ e $ _n $ deve essere effettuata con una profonda comprensione del loro impatto sia sulla risposta transitoria (tempo di salita, superamento) che sulla stabilità complessiva del sistema.\nAd esempio, un superamento di \\(100\\%\\) significa che i poli si trovano sull’asse \\(j\\omega\\) e quindi il sistema è marginalmente stabile.\nQualitativamente, per i sistemi del secondo ordine: - \\(\\zeta\\) è indicativo di stabilità. - \\(\\omega_n\\) è indicativo della velocità di risposta.\n\nIn altre parole, la stabilità di un sistema di controllo dipende da due parametri chiave: il rapporto di smorzamento $ $ e la frequenza naturale $ _n $.\n\nsmorzamento $ $: lo smorzamento $ $ determina principalmente la capacità del sistema di mitigare le oscillazioni e ritornare all’equilibrio.\n\nUn \\(\\zeta\\) più alto indica generalmente un sistema più smorzato, che tende a stabilizzarsi più rapidamente ma può rispondere più lentamente ai cambiamenti.\nAl contrario, un $ $ inferiore porta a un sistema meno smorzato che può mostrare un comportamento più oscillatorio, avvicinandosi potenzialmente all’instabilità se è troppo basso.\n\n**frequenza naturale $ _n $**: La frequenza naturale $ _n $, invece, è indicativa della tendenza intrinseca del sistema ad oscillare ad una velocità particolare in assenza di smorzamento.\n\nUn $ _n $ più alto può contribuire a un tempo di risposta più rapido, ma se combinato con un rapporto di smorzamento basso, può rendere il sistema soggetto a oscillazioni rapide e potenzialmente instabili.\n\n\nL’interazione tra $ $ e $ _n $ è quindi importante: mentre un $ _n $ più alto può migliorare la reattività del sistema, deve essere bilanciato con un $ $ appropriato per garantire che il sistema rimanga stabile e non oscilli eccessivamente . Questo equilibrio è fondamentale nella progettazione dei sistemi di controllo, poiché garantisce che i sistemi siano reattivi e stabili.\n\nPer calcolare la massima sovrelongazione (\\(M_p\\)) per $ = 0,4 $ e $ = 0,7 $ in Python, possiamo usare la libreria numpy per i calcoli numerici.\nLa cella sottostante definisce una funzione “peak_overshoot” che prende un rapporto di smorzamento $ $ e calcola il superamento del picco utilizzando la formula data. La funzione viene quindi utilizzata per calcolare il superamento del picco per $ = 0,4 $ e $ = 0,7 $. I risultati vengono stampati sia in formato decimale che percentuale.\nEcco il codice Python per farlo:\n\nimport numpy as np\n\n# Function to calculate peak overshoot\ndef peak_overshoot(zeta):\n    return np.exp(-np.pi * zeta / np.sqrt(1 - zeta**2))\n\n# Calculate peak overshoot for zeta = 0.4 and zeta = 0.7\nmp_04 = peak_overshoot(0.4)\nmp_07 = peak_overshoot(0.7)\n\nprint(f\"Peak Overshoot for ζ = 0.4: {mp_04:.4f} or {mp_04 * 100:.2f}%\")\nprint(f\"Peak Overshoot for ζ = 0.7: {mp_07:.4f} or {mp_07 * 100:.2f}%\")\n\nPeak Overshoot for ζ = 0.4: 0.2538 or 25.38%\nPeak Overshoot for ζ = 0.7: 0.0460 or 4.60%\n\n\n\n\nTempo di massima sovraelongazione (\\(t_p\\))\nIl tempo di massima sovraelongazione (o tempo di picco) \\(t_p\\) è simile al termine di salita in termini di comportamento qualitativo.\nÈ importante comprendere anche la relazione tra il tempo di massima sovraelongazione (\\(t_p\\))) e la frequenza naturale (\\(\\omega_n\\))). Il tempo di massima sovraelongazione è definito come il tempo necessario affinché la risposta del sistema raggiunga il suo primo picco massimo. Dalle premesse teoriche fornite, il tempo di picco è dato dalla formula:\n\\[ t_p = \\frac{\\pi}{\\omega_n \\sqrt{1 - \\zeta^2}} \\]\nQuesta equazione illustra che il tempo di picco è inversamente proporzionale alla frequenza naturale (\\(\\omega_n\\)) del sistema, pur essendo influenzato anche dal rapporto di smorzamento (\\(\\zeta\\)). Nello specifico, all’aumentare di \\(\\omega_n\\), il tempo di picco \\(t_p\\) diminuisce, il che implica che il sistema raggiunge la risposta di picco più rapidamente. Questa relazione evidenzia che un sistema con una frequenza naturale più elevata risponderà più velocemente, raggiungendo il suo picco in un lasso di tempo più breve.\nLa presenza di \\(\\sqrt{1 - \\zeta^2}\\)) al denominatore indica anche l’influenza del rapporto di smorzamento \\(\\zeta\\)) sul tempo di massima sovraelongazione. Tuttavia, il fattore dominante nel determinare \\(t_p\\) è \\(\\omega_n\\), poiché l’impatto del rapporto di smorzamento è moderato dalla radice quadrata e dalla sottrazione dall’unità.\nIn termini pratici, progettare un sistema di controllo con una frequenza naturale più elevata \\(\\omega_n\\) può essere utile per ottenere risposte più rapide. Tuttavia, questo deve essere attentamente bilanciato con considerazioni sulla stabilità del sistema e sul superamento, poiché influenzato sia da \\(\\omega_n\\) che da \\(\\zeta\\). Il tempo di picco funge quindi da indicatore essenziale nella progettazione e nell’analisi dei sistemi di controllo, in particolare quando sono desiderabili risposte rapide, ma non a scapito della stabilità e delle prestazioni del sistema.\n\n\nTempo di assestamento (\\(t_s\\))\nIl calcolo di un’espressione analitica per il tempo di assestamento nei sistemi di controllo, in particolare per sistemi di ordine superiore o complessi, presenta diverse sfide.\nIl tempo di assestamento è definito come la durata dopo la quale la risposta del sistema rimane all’interno di una banda di tolleranza specificata attorno al valore di stato stazionario e non esce successivamente da questa banda.\nPer i sistemi del secondo ordine, questo può spesso essere approssimato con formule standard, specialmente quando i sistemi sono poco smorzati. Tuttavia, per i sistemi che mostrano un comportamento più complesso, come quelli con dinamiche di ordine superiore, non linearità o parametri variabili, derivare un’espressione analitica esatta diventa notevolmente più complicato.\nUna delle principali difficoltà risiede nelle caratteristiche di risposta del sistema, che possono variare in modo significativo in base a fattori come il rapporto di smorzamento ($ \\(), la frequenza naturale (\\) _n $) e la presenza di elementi non lineari o disturbi esterni. La risposta potrebbe mostrare oscillazioni, superamenti o tassi di decadimento variabili, che non sono semplici da incapsulare in un’unica formula. Inoltre, i criteri per “stabilirsi” all’interno di una fascia di tolleranza non sono sempre chiari negli scenari pratici, in cui rumore e fattori esterni possono far fluttuare la risposta attorno al valore desiderato.\nDi conseguenza, i metodi numerici e le simulazioni diventano strumenti essenziali per determinare con precisione il tempo di assestamento. Consentono la modellazione dettagliata del comportamento del sistema in varie condizioni, catturando sfumature che i metodi analitici potrebbero non cogliere. Il seguente codice Python esemplifica questo approccio numerico, illustrando come il tempo di assestamento varia con il rapporto di smorzamento ($ $) in un sistema del secondo ordine. Questa analisi numerica fornisce uno strumento più flessibile e pratico per comprendere e prevedere il comportamento del sistema in scenari reali.\n\n\nTempo di assestamento rispetto al rapporto di smorzamento\nNei sistemi di controllo, la relazione tra il tempo di assestamento e il rapporto di smorzamento (\\(\\zeta\\)) può essere efficacemente illustrata attraverso un grafico.\nQuesto grafico è particolarmente interessante in quanto rivela la natura non lineare di come varia il tempo di assestamento con diversi valori di \\(\\zeta\\).\nNello specifico si evidenzia una caratteristica notevole per cui il tempo di assestamento subisce un forte aumento a determinati valori di \\(\\zeta\\).\nQuesto aumento non è lineare o graduale ma avviene in punti specifici, riflettendo la complessa dinamica di come lo smorzamento influisce sul tempo necessario affinché un sistema si stabilizzi entro i parametri operativi desiderati. Tale rappresentazione grafica è fondamentale per comprendere e progettare i sistemi di controllo, in particolare nella messa a punto dei rapporti di smorzamento per ottenere prestazioni ottimali.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)  # Extended time range for more clarity\n\n# System parameters\nzeta_values = [1, 0.9, 0.7, 0.55, 0.43]\nomega_n = 1  # Natural frequency\n\n# Function for second-order system unit-step response\ndef unit_step_response(t, zeta, omega_n):\n    if zeta &lt; 1:  # Underdamped\n        omega_d = omega_n * np.sqrt(1 - zeta**2)\n        return 1 - np.exp(-zeta * omega_n * t) * (np.cos(omega_d * t) + (zeta/np.sqrt(1-zeta**2)) * np.sin(omega_d * t))\n    elif zeta == 1:  # Critically damped\n        return 1 - np.exp(-omega_n * t) * (1 + omega_n * t)\n\n# Compute settling time\ndef compute_settling_time(t, response, tolerance=0.05):\n    upper_bound = 1 + tolerance\n    lower_bound = 1 - tolerance\n    for i in range(len(response)):\n        if all(response[j] &lt; upper_bound and response[j] &gt; lower_bound for j in range(i, len(response))):\n            return t[i]\n    return np.nan\n\n# Storing settling times\nsettling_times = []\n\n# Plotting responses for different zeta values\nplt.figure(figsize=(10, 6))\nfor zeta in zeta_values:\n    y = unit_step_response(t, zeta, omega_n)\n    settling_time = compute_settling_time(t, y)\n    settling_times.append(settling_time)\n    plt.plot(t, y, label=f'ζ = {zeta}')\n    # Annotate settling time\n    if not np.isnan(settling_time):\n        plt.axvline(x=settling_time, color='gray', linestyle='--', alpha=0.7)\n        settling_point = y[np.argmin(np.abs(t - settling_time))]\n        plt.plot(settling_time, settling_point, 'ro')  # Mark the settling point\n        plt.text(settling_time, settling_point, f' ({settling_time:.2f}s)', verticalalignment='bottom')\n        #plt.text(settling_time, settling_point, f' ({settling_time:.2f}, {settling_point:.2f})', verticalalignment='bottom')\n\n\n# Unit value and tolerance band\nplt.plot(t, np.ones_like(t), 'k--', label='Unit Value')\nplt.fill_between(t, 0.95, 1.05, color='yellow', alpha=0.3, label='5% Tolerance Band')\n\nplt.title('Unit-Step Response of a Second-Order System')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n    \n# Plotting Settling Time vs Zeta\nplt.figure(figsize=(10, 6))\nplt.plot(zeta_values, settling_times, 'o:', label='Settling Time', markersize=12)\nplt.title('Normalised Settling Time (ωₙtₙ) vs Damping Ratio (ζ)')\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Normalised Settling Time (ωₙtₙ)')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIl grafico mostra la risposta tipica di un sistema di secondo ordine che si assesta al suo valore finale all’interno di una fascia di tolleranza di \\(5\\%\\) (quindi tra valori 0,95-1,05). Il grafico mostra anche la risposta del sistema per un sistema criticamente smorzato (\\(\\zeta=1\\)).\nPossiamo definire una curva migliore variando \\(\\zeta\\):\n\n# Time array\nt = np.linspace(0, 100, 1000)  # Extended time range for more clarity and lower damping ratios\n\nzeta_values = np.linspace(0.2, 1, 500) \nsettling_times =[]\nfor zeta in zeta_values:\n    y = unit_step_response(t, zeta, omega_n)\n    settling_time = compute_settling_time(t, y)\n    settling_times.append(settling_time)\n    \n# Plotting Settling Time vs Zeta\nplt.figure(figsize=(10, 6))\nplt.plot(zeta_values, settling_times, 'o--', label='Settling Time', markersize=5)\nplt.title('Normalised Settling Time (ωₙtₙ) vs Damping Ratio (ζ)')\nplt.xlabel('Damping Ratio (ζ)')\nplt.ylabel('Normalised Settling Time (ωₙtₙ)')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nApprossimazione del tempo di assestamento\nApprossimare il tempo di assestamento di un sistema di controllo utilizzando l’inviluppo della sua risposta è un approccio pratico, soprattutto nel caso di sistemi sottosmorzati in cui la risposta presenta un comportamento oscillatorio. L’inviluppo fornisce una chiara rappresentazione visiva dell’entità massima della risposta del sistema nel tempo, che è particolarmente utile per identificare quando l’output del sistema si stabilizza all’interno di una fascia di tolleranza specificata.\nCiò consentirà di avere un’approssimazione della parte in cui \\(0 &lt; \\zeta &lt; 0.7\\) nella figura di sopra. Rocrpda che i valori tipici di smorzamento saranno in questo range. Il comportamento per \\(\\zeta&gt;0.7\\) è diverso.\nLa forma standard della risposta di un sistema del secondo ordine sottosmorzato può essere espressa come:\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\ndove $ $ è il rapporto di smorzamento, $ _n $ è la frequenza naturale e $ _d = _n $ è la frequenza naturale smorzata.\nL’inviluppo di questa risposta oscillatoria è dato dal termine esponenziale di decadimento:\n\\[\n1 \\pm \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}}\n\\]\nQuesto inviluppo cattura la natura oscillatoria della risposta del sistema e il suo decadimento esponenziale.\nPer approssimare il tempo di assestamento, è possibile impostare l’inviluppo uguale al livello di tolleranza e risolvere per il tempo $ t $. Ad esempio, per un livello di tolleranza del 5%, l’equazione diventa:\n\\[ 1 + \\frac{e^{-\\zeta \\omega_n t_s}}{\\sqrt{1 - \\zeta^2}} = 0,05 \\]\nRisolvendo per \\(t\\) si ottiene:\n\\[\n\\zeta\\omega_n t_s = -\\ln(0,05\\sqrt{1-\\zeta^2})\n\\]\nE\n\\[\n\\omega_n t_s = -\\frac{1}{\\zeta}\\ln(0.05\\sqrt{1-\\zeta^2})\n\\]\ne infine:\n\\[\nt_s = -\\frac{1}{\\omega_n\\zeta}\\ln(0,05\\sqrt{1-\\zeta^2})\n\\]\nSi noti che \\(\\ln(0.05\\sqrt{1-\\zeta^2}) \\in [-3, -3.3]\\), per \\(0 &lt; \\zeta &lt; 0.7\\) (che è ciò che stiamo analizzando).\nPossiamo ottenere un’ulteriore approssimazione come:\n\\[\nt_s = \\frac{3}{\\omega_n\\zeta}\n\\]\nScriviamo il codice Python che traccia questo inviluppo per un intervallo di valori \\(\\zeta\\) e indica il tempo di assestamento associato all’interno di una banda di tolleranza del 5%. Il tempo di assestamento può essere stimato trovando il punto in cui la busta entra per la prima volta nella fascia di tolleranza e non ne esce successivamente.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)  # Time range for plotting\n\n# System parameters\nzeta_values = [0.9, 0.7, 0.55, 0.43]  # zeta values - to highlight the difference use [0.2, 0.5, 0.7] \nomega_n = 1  # Natural frequency\ncolors = ['red', 'blue', 'green', 'purple']  # Colors for each zeta value\n\n# Plotting\nplt.figure(figsize=(10, 6))\nfor zeta, color in zip(zeta_values, colors):\n    envelope_upper = 1 + np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)\n    envelope_lower = 1 - np.exp(-zeta * omega_n * t) / np.sqrt(1 - zeta**2)\n    \n    # Plot envelope\n    plt.plot(t, envelope_upper, color=color, linestyle='--', alpha=0.5)\n    plt.plot(t, envelope_lower, color=color, linestyle='--', alpha=0.5, label=f'ζ = {zeta}')\n\n    # Settling time estimation\n    settling_time = -np.log(0.05 * np.sqrt(1 - zeta**2)) / (zeta * omega_n)\n    plt.axvline(x=settling_time, color=color, linestyle='-', alpha=0.7)\n    plt.text(settling_time, 1.1, f'{settling_time:.2f}', rotation=90, verticalalignment='bottom', color=color)\n\nplt.title('Envelope and Settling Time for Underdamped Systems')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTempo di assestamento entro una banda di tolleranza del 2%.\nNelle specifiche del sistema di controllo viene comunemente utilizzata una banda di tolleranza del 2%. Attraverso dettagliate simulazioni al computer, è stato osservato che il rapporto di smorzamento critico per raggiungere una fascia di tolleranza del 2% è \\(\\zeta = 0,76\\). Il comportamento del tempo di assestamento normalizzato (\\(\\omega_n t_s\\)) rispetto a \\(\\zeta\\) in questo scenario mostra uno schema notevole:\n\nQuando \\(\\zeta\\) varia da 1 a 0,76, il tempo di assestamento normalizzato diminuisce.\nAl diminuire di \\(\\zeta\\) da 0,76 a 0, il tempo di assestamento normalizzato aumenta.\n\nLa sfida nell’ottenere un’espressione analitica per il tempo di assestamento all’interno di una banda di tolleranza del 2%, come prima, risiede nella sua complessa natura non lineare. Tuttavia è possibile fare un’approssimazione come segue:\n\\[ \\zeta \\omega_n t_s = -\\ln\\left(0.02 \\sqrt{1-\\zeta^2}\\right) \\]\nQui, il termine logaritmico \\(\\ln(0.02 \\sqrt{1-\\zeta^2})\\) varia tra -3,9 e -4,34 per valori \\(\\zeta\\) compresi nell’intervallo da 0 a 0,76, raggiungendo il suo minimo a \\(\\zeta =0,76\\). Riscrivendo questa espressione otteniamo:\n\\[ t_s = -\\frac{1}{\\zeta \\omega_n} \\ln\\left(0.02 \\sqrt{1-\\zeta^2}\\right) \\]\nIn questo contesto è importante notare che \\(\\zeta \\omega_n\\) è il reciproco della costante di tempo della curva di inviluppo. Pertanto, per una banda di tolleranza del 2%, il tempo di assestamento può essere approssimato utilizzando la costante di tempo dell’inviluppo del sistema:\n\\[ t_s = \\frac{4}{\\zeta \\omega_n} \\] (cioè quattro volte la costante di tempo)\nQuesta approssimazione utilizza efficacemente la costante di tempo della curva di inviluppo, semplificando il calcolo del tempo di assestamento all’interno della banda di tolleranza specificata.\nQuesta è l’espressione per il tempo di assestamento che utilizzeremo la maggior parte del tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html#comprensione-dellerrore-allo-stato-stazionario",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html#comprensione-dellerrore-allo-stato-stazionario",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "Comprensione dell’errore allo stato stazionario",
    "text": "Comprensione dell’errore allo stato stazionario\nL’errore allo stato stazionario è una metrica chiave nei sistemi di controllo che quantifica la differenza tra l’uscita desiderata (il setpoint) e l’uscita effettiva del sistema quando il tempo si avvicina all’infinito. In termini più semplici, misura quanto l’output del sistema può avvicinarsi al valore desiderato dopo che i transitori si sono estinti.\n\nErrore di stato stazionario per ingressi diversi\nLa natura dell’errore allo stato stazionario varia in modo significativo in base al tipo di segnale di ingresso a cui il sistema sta rispondendo.\nIn genere vengono considerati tre tipi standard di ingressi: gradino, rampa e parabolico. Quando si progetta un controller per lo stato stazionario, in genere è importante comprendere il comportamento del sistema per tutti questi input.\nL’errore a stato stazionario per ciascun tipo di input evidenzia la capacità del sistema di tracciare diversi tipi di segnali:\n\n1. Ingresso passo\nPer un input graduale (un cambiamento improvviso nell’output desiderato), un sistema del secondo ordine ben progettato avrà spesso un errore a stato stazionario pari a zero. Questo perché il sistema può regolare la propria uscita per corrispondere al nuovo setpoint dopo un certo tempo.\nCiò è chiaro osservando la risposta in passi unitari per \\(t \\rightarrow \\infty\\):\n\\[ y(t) = 1 - \\frac{e^{-\\zeta \\omega_n t}}{\\sqrt{1 - \\zeta^2}} \\sin(\\omega_d t + \\theta) \\]\n\n\n2. Ingresso rampa:\nUn ingresso di rampa (un setpoint in continuo aumento o diminuzione) introduce una nuova sfida. L’errore a regime per un ingresso di rampa è generalmente diverso da zero per un sistema standard del secondo ordine. Indica l’incapacità del sistema di tenere il passo con il setpoint in continua evoluzione. L’errore a regime in risposta a un ingresso di rampa può essere calcolato utilizzando il teorema del valore finale della teoria della trasformata di Laplace.\n\\[R(s) = \\frac{1}{s^2}\\]\nE\n\\[Y(s) = \\frac{\\omega_n^2}{s^2(s^2+2\\zeta\\omega_ns+\\omega_n^2)}\\]\nil cui inverso è:\n\\[\ny(t) = t - \\frac{2\\zeta}{\\omega_n} + \\frac{e^{-\\zeta\\omega_nt}}{\\omega_n\\sqrt{1-\\zeta^2}}\\sin(\\ omega_dt+2\\theta)\n\\]\ndove \\(\\theta = \\cos^{-1}\\zeta\\) e \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\)\nPer creare uno schizzo Python della risposta a un input rampa, utilizzeremo le formule di risposta fornite.\nIl codice seguente traccia sia la risposta del sistema a un ingresso di rampa che l’ingresso di rampa stesso. La funzione ramp_response calcola la risposta del sistema utilizzando la formula fornita. Il grafico illustrerà come si comporta l’output del sistema nel tempo in risposta a un input che aumenta linearmente. I parametri \\(\\zeta\\) e \\(\\omega_n\\) possono essere regolati per vedere come le diverse caratteristiche del sistema influenzano la risposta.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 500)\n\n# System parameters\nzeta = 0.3  # Example damping ratio\nomega_n = 2  # Example natural frequency\n\n# Calculate omega_s and theta\nomega_s = omega_n * np.sqrt(1 - zeta**2)\ntheta = np.arccos(zeta) # np.arctan(np.sqrt(1 - zeta**2) / zeta)\n\n# Response to ramp input\ndef ramp_response(t, zeta, omega_n, omega_s, theta):\n    return t - (2 * zeta / omega_n) + (np.exp(-zeta * omega_n * t) / (omega_n * np.sqrt(1 - zeta**2))) * np.sin(omega_s * t + 2 * theta)\n\n# Ramp input\nramp_input = t\n\n# Calculating response\nresponse = ramp_response(t, zeta, omega_n, omega_s, theta)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(t, response, label='System Response to Ramp Input')\nplt.plot(t, ramp_input, label='Ramp Input', linestyle='--')\nplt.title('Response to a Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nCommenti\nSi noti che da una prospettiva transitoria non ci sono nuovi comportamenti. Ci sono delle oscillazioni che abbiamo catturato già analizzando la risposta unitaria. Questo è il motivo per cui non è necessario analizzare il transitorio a più ingressi.\nSe tuttavia guardiamo allo stato stazionario, ora abbiamo un errore di stato stazionario.\nDato: \\[\ny(t) = t - \\frac{2\\zeta}{\\omega_n} + \\frac{e^{-\\zeta\\omega_nt}}{\\omega_n\\sqrt{1-\\zeta^2}}\\sin(\\ omega_dt+2\\theta)\n\\]\nquando \\(t \\rightarrow \\infty\\):\n\\[\ny_{ss} = t - \\frac{2\\zeta}{\\omega_n}\n\\]\nL’uscita segue l’ingresso della rampa ma con un errore di stato stazionario \\(\\frac{2\\zeta}{\\omega_n}\\).\nL’errore di stato stazionario può essere formalmente calcolato come:\n\\[\ne_{ss} = r - y_{ss} = t - \\big(t - \\frac{2\\zeta}{\\omega_n}\\big) = \\frac{2\\zeta}{\\omega_n}\n\\]\n\n\n\n\nCalcolo analitico\nAnaliticamente, l’errore a regime può essere determinato utilizzando il teorema del valore finale delle trasformate di Laplace.\nIn questo caso non siamo interessati al comportamento transitorio che analizziamo solo attraverso la risposta all’input di passo unitario.\nIl teorema afferma che il valore di stato stazionario di una funzione può essere trovato prendendo il limite quando \\(s\\) (la variabile di Laplace) si avvicina allo zero di \\(s\\) volte la trasformata di Laplace della funzione.\nAd esempio, l’errore a regime per un ingresso di rampa può essere calcolato applicando il teorema del valore finale al segnale di errore \\(E(s)\\), che è la differenza tra il segnale di ingresso \\(R(s)\\) e il segnale di uscita \\(Sì\\). Ciò comporta la valutazione del limite:\n\\[ e_{ss} = \\lim_{s \\to 0} sE(s) \\]\ndove \\(E(s) = R(s) - Y(s)\\).\nPer il nostro sistema:\n\n\n\n\n\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1+G(s)}\n\\]\nDa cui:\n\\[\nE(s) = \\frac{R(s)}{1+G(s)}\n\\]\nApplicando il teorema del valore finale:\n\\[ e_{ss} = \\lim_{s \\to 0} s \\frac{R(s)}{1+G(s)} \\]\nRicorda le condizioni di applicabilità del teorema del valore finale: \\(sE(s)\\) non ha poli sull’asse immaginario o nel RHP.\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1 + \\frac{\\omega_n^2}{s(s+2\\zeta\\omega_n)}} = \\frac{s( s+2\\zeta\\omega_n)}{s^2 +2\\zeta\\omega_ns + \\omega_n^2}\n\\]\ndato che \\(R(s)=\\frac{1}{s^2}\\) otteniamo:\n\\[\nE(s) = \\frac{(s+2\\zeta\\omega_n)}{s(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\n\\[\nsE(s) = \\frac{(s+2\\zeta\\omega_n)}{(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n\\]\nQuesta funzione di trasferimento non ha poli sull’asse immaginario o nel semipiano destro e possiamo applicare il Teorema del valore finale. È importante verificare!\ne infine:\n\\[ e_{ss} = \\lim_{s \\to 0} s E(s) = \\frac{2\\zeta}{\\omega_n}\\]\n\n3. Ingresso parabolico:\nL’ingresso parabolico rappresenta uno scenario ancora più impegnativo, che in genere risulta in un errore infinito in stato stazionario per un sistema standard del secondo ordine. Ciò riflette l’incapacità del sistema di tracciare un segnale che cambia a una velocità accelerata.\nApplicando lo stesso ragionamento: \\[\n   R(s) = \\frac{1}{s^3}\n   \\]\nE\n\\[\n   sE(s) = \\frac{(s+2\\zeta\\omega_n)}{s(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n   \\]\nNon possiamo applicare il Teorema del valore finale perché abbiamo un polo sull’asse immaginario.\nPer comprendere l’errore di stato stazionario possiamo analizzare:\n\\[\n   E(s) = \\frac{(s+2\\zeta\\omega_n)}{s^2(s^2 +2\\zeta\\omega_n s + \\omega_n^2)}\n   \\]\ninvertire questa espressione per ottenere \\(e(t)\\) per \\(t\\rightarrow \\infty\\). Questa funzione ha due poli all’origine, il che significa che possiamo interpretarla come un sistema instabile, cioè l’errore cresce senza limiti.\nIl sistema standard del secondo ordine nel circuito di retroazione non è in grado di seguire un input parabolico. Ciò significa che potrebbe essere necessario limitare questo sistema ai casi in cui gli ingressi sono solo gradini e rampe. In alternativa abbiamo bisogno di un controller adatto.\nPer riassumere possiamo rieseguire lo stesso codice che avevamo nel notebook 18_Performance_of_Feedback_Systems. La crescita illimitata dell’errore di stato stazionario per l’input parabolico è chiaramente visibile.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control\n\n# Define system parameters (modify as needed for your example)\nKp = 1.0    # Proportional gain\nomega_n = 1.0  # Natural frequency\nzeta = 0.5  # Damping ratio\nnum = [Kp * omega_n**2]\nden = [1, 2 * zeta * omega_n, omega_n**2]\n\n# Create transfer function\nG = control.tf(num, den)\n\n# Time vector\nt = np.linspace(0, 20, 1000)\n\n# Unit Step Input\nt_step, y_step = control.step_response(G, t)\ne_step = 1 - y_step  # Steady-state error for step input\n\n# Unit Ramp Input\nt_ramp, y_ramp = control.forced_response(G, t, t)\ne_ramp = t - y_ramp  # Steady-state error for ramp input\n\n# Unit Parabola Input\nt_parabola, y_parabola = control.forced_response(G, t, t**2 / 2)\ne_parabola = t**2 / 2 - y_parabola  # Steady-state error for parabola input\n\n# Plotting\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.plot(t_step, y_step, label='Response')\nplt.plot(t_step, np.ones_like(t_step), 'r--', label='Step Input')\nplt.plot(t_step, e_step, 'g:', label='Error')\nplt.title('Response to Unit Step Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(t_ramp, y_ramp, label='Response')\nplt.plot(t_ramp, t_ramp, 'r--', label='Ramp Input')\nplt.plot(t_ramp, e_ramp, 'g:', label='Error')\nplt.title('Response to Unit Ramp Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(t_parabola, y_parabola, label='Response')\nplt.plot(t_parabola, t_parabola**2 / 2, 'r--', label='Parabola Input')\nplt.plot(t_parabola, e_parabola, 'g:', label='Error')\nplt.title('Response to Unit Parabola Input')\nplt.xlabel('Time')\nplt.ylabel('Output')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nImplicazioni pratiche\nIn termini pratici, comprendere e calcolare l’errore di stato stazionario è fondamentale per la progettazione e la messa a punto del sistema. Aiuta a stabilire aspettative prestazionali realistiche e a scegliere il giusto tipo di controller o compensatore per ridurre al minimo l’errore per un dato tipo di input. Ad esempio, nei sistemi in cui è importante seguire un ingresso di rampa, i progettisti potrebbero optare per diverse impostazioni del controller o aggiungere un’azione integrale per ridurre l’errore a regime.\nIn sintesi, l’errore in stato stazionario è un aspetto vitale delle prestazioni del sistema di controllo, poiché offre informazioni sulla capacità di un sistema di mantenere il proprio output al livello desiderato o vicino ad esso in risposta a vari tipi di input. Analizzare e ridurre al minimo questo errore è una parte fondamentale della progettazione e dell’ottimizzazione del sistema di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/design_of_feedback_control_it.html#esercizio-e-domande",
    "href": "IT_🇮🇹/design_of_feedback_control_it.html#esercizio-e-domande",
    "title": "Ciclo di progettazione per un sistema standard del secondo ordine",
    "section": "Esercizio e domande",
    "text": "Esercizio e domande\nOra rafforziamo questi concetti con alcuni esercizi: 1. Calcola la massima sovraelongazione: Dato un rapporto di smorzamento di 0,5, calcola il superamento del picco $ M_p $. 2. Errore di stato stazionario per un ingresso di rampa: Per un sistema con $ = 0,3 $ e $ _n = 4 $, trovare l’errore di stato stazionario per un ingresso di rampa. 3. Effetto della larghezza di banda sulla stabilità: Discutere in che modo l’aumento della larghezza di banda influisce sulla stabilità del sistema e sulla sua capacità di respingere il rumore.",
    "crumbs": [
      "IT_🇮🇹",
      "Ciclo di progettazione per un sistema standard del secondo ordine"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "",
    "text": "In questo quaderno presenteremo i componenti hardware comunemente presenti nei sistemi di controllo, in particolare nel settore industriale. Anche se non entreremo nei dettagli esaustivi di ciascun componente, il nostro obiettivo è fornire una chiara comprensione delle loro caratteristiche di base e di come influenzano il comportamento di un determinato sistema di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#caso-di-studio-sistema-di-controllo-della-velocità",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#caso-di-studio-sistema-di-controllo-della-velocità",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Caso di studio: sistema di controllo della velocità",
    "text": "Caso di studio: sistema di controllo della velocità\nPer avviare la nostra esplorazione, consideriamo un sistema di controllo della velocità. In questo sistema, l’obiettivo principale è controllare la velocità di un carico. Utilizzeremo questo esempio per mostrare i vari componenti coinvolti e le loro interazioni.\n\nPanoramica del sistema:\nImmagina uno scenario in cui desideri controllare la velocità di un carico specifico, rappresentato dai parametri \\(J\\) (momento di inerzia) e \\(B\\) (attrito viscoso). Questo carico è soggetto ad una coppia di disturbo, \\(T_w\\). Il nostro obiettivo è garantire che il carico mantenga una velocità specificata, \\(\\omega\\), anche in presenza di disturbi.\n\n\n\n\n\n\n\nComponenti e loro ruoli:\n\nAttuatore (motore e amplificatore di potenza):\n\nL’attuatore fornisce la coppia necessaria per trascinare il carico alla velocità desiderata, \\(\\omega\\).\nComprende un motore abbinato ad un amplificatore di potenza.\nL’attuatore riceve un segnale di controllo, \\(u\\), da un controller.\n\nController (amplificatore):\n\nIn questa configurazione di base, il controller è un semplice amplificatore. Tuttavia, in configurazioni più avanzate, potrebbe trattarsi di un sistema complesso che coinvolge la derivata o l’integrale di un segnale di errore.\nIl ruolo principale del controller è elaborare il segnale di errore e produrre un segnale di controllo appropriato, \\(u\\).\nVedremo più avanti come progettare i controller\n\nElementi di ingresso di riferimento (potenziometro):\n\nQuesto componente fornisce il segnale di riferimento, \\(e_r\\), che corrisponde alla velocità comandata richiesta, \\(\\omega_r\\) (non mostrata nello schema). Vorremmo \\(\\omega \\rightarrow \\omega_r\\)\nRegolando la posizione del braccio del potenziometro, è possibile modificare il segnale di riferimento, comandando quindi una velocità diversa.\n\nElemento di feedback (tacogeneratore):\n\nLa dinamo tachimetrica rileva la velocità effettiva, \\(\\omega_r\\), e produce un segnale di feedback, \\(e_t\\), proporzionale a questa velocità.\nQuesto segnale di feedback è essenziale per confrontare la velocità effettiva con la velocità desiderata e generare un segnale di errore.\nLa differenza tra \\(e_r\\) (proporzionale alla variabile controllata) e \\(e_t\\) (proporzionale alla variabile comandata) fornisce il segnale di errore di attuazione \\(\\hat{e}\\).\nIl segnale di errore di attuazione \\(\\hat{e}\\) viene amplificato attraverso il controller per generare il segnale di controllo \\(u\\) e fornito all’attuatore che gestisce il carico.\n\n\nTieni presente che l’obiettivo principale della progettazione del controller è regolarlo in modo appropriato per soddisfare obiettivi specifici. Mentre altri componenti, come il motore, rimangono costanti e non possono essere modificati facilmente, è più pratico ed efficiente modificare le impostazioni del controller.\n\n\nRappresentazione del diagramma a blocchi:\nIl sistema fisico può essere astratto in uno schema a blocchi per visualizzare la struttura del feedback e gli elementi fondamentali in modo più strutturato.\n\n\n\n\n\n\n\nL’elemento di feedback, come la dinamo tachimetrica (con costante \\(K_T\\)), fornisce informazioni in tempo reale sullo stato attuale del sistema (in questo caso, la velocità effettiva). Questo feedback consente al controller di confrontare la velocità effettiva con la velocità desiderata e di apportare le modifiche necessarie per ridurre eventuali discrepanze.\nConfrontare la struttura di controllo con i cicli di controllo in feedback di cui abbiamo parlato prima (da \\(e_r\\) a \\(\\omega\\)). Questa è una struttura di feedback non unitaria.\nLa funzione di trasferimento del sensore (la dinamo tachimetrica) è \\(K_T\\).\nQuesta configurazione può essere convertita in un formato di feedback unitario per facilitare l’analisi e la progettazione, il tutto preservando i dettagli vitali del sistema. Affinché questa conversione sia efficace, il blocco che collega $ _r $ e $ e_r $ dovrebbe possedere una funzione di trasferimento equivalente a $ K_T $. In altre parole, la costante del potenziometro, \\(K_P\\), dovrebbe essere impostata uguale alla costante della dinamo tachimetrica, \\(K_T\\).\nIl segnale di errore di attuazione è \\(\\hat{e} = e_r - e_t\\). Questo è un segnale di tensione. L’unità è Volt, non radianti al secondo. Questi Volt saranno proporzionali all’errore di velocità se e solo se \\(K_P=K_T\\). Questo è il lavoro dell’ingegnere di controllo! È possibile impostare la costante del potenziometro.\nL’elemento di ingresso di riferimento potrebbe non essere fisicamente presente nel sistema (come la dinamo tachimetrica) ma ho comunque il blocco nello schema perché e’ necessario per spiegare il funzionamento del sistema!\n\nOra possiamo riscrivere il diagramma a blocchi come feedback unitario equivalente\n\n\n\n\n\n\n\nQuesto diagramma ha le stesse equazioni del precedente. Questa è una rappresentazione del diagramma a blocchi equivalente che mantiene la stessa relazione matematica del diagramma a blocchi originale tra \\(\\omega\\) e \\(\\omega_r\\).\nPer questo diagramma a blocchi, \\(e\\) rappresenta l’errore di sistema: la differenza tra la velocità comandata e quella effettiva.\nUn sistema di feedback unitario risulta essere più conveniente per l’analisi e la progettazione.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#analisi-del-blocco-motore",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#analisi-del-blocco-motore",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Analisi del Blocco Motore",
    "text": "Analisi del Blocco Motore\nApprofondiamo la dinamica del motore e la sua rappresentazione negli schemi a blocchi.\nIl motore controllato dall’armatura è un tipo specifico di motore in cui la velocità viene controllata variando la tensione ai capi dell’armatura. Uno schema è riportato nell’immagine qui sotto:\n\n\n\n\n\n\nFigura da electric4u.com\n\n\n\n\n\n\n\nComponenti del motore\n\nIndotto: L’armatura è il componente rotante principale del motore. Trasporta la corrente (spesso definita corrente di armatura, \\(i_a\\), che interagisce con il campo magnetico prodotto dagli avvolgimenti di campo. Questa interazione tra la corrente e il campo magnetico si traduce in una coppia che fa ruotare l’armatura. La tensione attraverso l’armatura (\\(e_a\\)) e la corrente che la attraversa (\\(i_a\\)) determinano la velocità e la coppia del motore.\nAvvolgimenti di campo: si tratta di bobine avvolte attorno allo statore del motore, che producono un campo magnetico quando energizzate. Quando la corrente passa attraverso gli avvolgimenti di campo, produce un campo magnetico. In un motore controllato da armatura, la corrente di campo (\\(i_f\\)) viene generalmente mantenuta costante, garantendo un campo magnetico costante.\n\n\nL’intensità del campo magnetico generato dagli avvolgimenti di campo influisce sulla coppia e sulla velocità del motore.\nVariando la corrente di campo è possibile controllare le caratteristiche del motore, soprattutto nei motori controllati dal campo.\n\n\nBack EMF (\\(e_b\\)), (Forza elettromotrice): quando l’armatura ruota, induce una tensione che si oppone alla tensione di armatura applicata. Questa tensione indotta è chiamata back EMF (\\(e_b\\)).\n\n\nAgisce come un meccanismo di feedback naturale: all’aumentare della velocità del motore, aumenta la forza controelettromotrice, che a sua volta riduce la tensione netta attraverso l’armatura e quindi limita la velocità.\nÈ direttamente proporzionale alla velocità del motore.\nLa forza elettromotrice posteriore svolge un ruolo cruciale nella stabilizzazione della velocità del motore. Comprenderne la dinamica è essenziale per progettare controllori in grado di regolare in modo efficiente la velocità del motore, soprattutto nei motori controllati da armatura.\n\nIl motore del nostro sistema di controllo è caratterizzato da:\n\ntensione di armatura applicata, \\(e_a\\)\nla sua resistenza di armatura, \\(R_a\\)\ne l’attuale \\(i_a\\).\n\nQuando funziona, produce una coppia \\(T_M\\). Questa coppia agisce sull’albero motore insieme ad una coppia di disturbo \\(T_W\\).\n\n\nModello di motore controllato da armatura\nRivediamo leggermente il diagramma precedente per esplicitare la presenza del Back EMF.\n\n\n\n\n\n\nPossiamo anche notare che in un modello semplificato l’induttanza dell’armatura può essere trascurata. In molti scenari, soprattutto in condizioni stazionarie, gli effetti della resistenza dell’armatura e dei campi elettromagnetici posteriori prevalgono sugli effetti transitori dell’induttanza dell’armatura. Inoltre, l’induttanza dell’armatura (\\(L_a\\)) e la resistenza (\\(R_a\\)), insieme definiscono una costante di tempo elettrica per il motore, data da \\(\\tau_e=\\frac{L_a}{R_a}\\). Per molti motori, soprattutto quelli più piccoli, questa costante di tempo elettrica è molto inferiore alla costante di tempo meccanica (definita da parametri come l’inerzia e l’attrito del motore). Se la risposta del sistema o la strategia di controllo non opera su una scala temporale in cui questa costante di tempo elettrica è significativa, può essere trascurata.\nIn questo caso possiamo stabilire le seguenti relazioni chiave:\n\nLa corrente di armatura è influenzata dalla differenza tra la tensione applicata e la forza controelettromotrice, divisa per la resistenza di armatura:\n\n\\[\n\\begin{align}\ni_a = \\frac{e_a-e_b}{R_a}\n\\end{align}\n\\]\n\nLa corrente di campo \\(i_f\\) è costante e \\(i_a\\) dipende dalla tensione applicata \\(e_a\\). Tuttavia la coppia prodotta dal motore (\\(T_M\\)) è proporzionale al prodotto dei due flussi, e quindi delle due correnti. Poiché \\(i_f\\) è mantenuto costante, possiamo dire che la coppia prodotta dal motore è proporzionale alla corrente di armatura:\n\n\\[\n\\begin{align}\nT_M = K_T \\times i_a\n\\end{align}\n\\]\nDove \\(K_T\\) è la costante di coppia del motore.\nIl motore è detto controllato dall’armatura perché stiamo controllando la corrente di armatura \\(i_a\\) attraverso la tensione applicata \\(e_a\\), e questo rende possibile controllare la velocità del motore.\n\nLa forza controelettromotrice è proporzionale alla velocità del motore:\n\n\\[\n\\begin{align}\ne_b = K_b \\times \\omega\n\\end{align}\n\\]\nDove \\(K_b\\) è la costante EMF posteriore.\n\nFattore di forze e coppie esterne\n\nLa coppia \\(T_m\\) guida il carico e possiamo scrivere un’equazione di equilibrio delle forze, tenendo conto delle influenze esterne come la coppia di disturbo \\(T_W\\), la coppia inerziale dovuta all’inerzia del motore \\(J\\) e la coppia di attrito dovuta all’attrito viscoso $ B$:\n\\[\n\\begin{align}\nT_M = J\\dot{\\omega} + B\\omega + T_W\n\\end{align}\n\\]\n\nRappresentazione in un diagramma a blocchi\nAvendo compreso le relazioni e le equazioni che governano la dinamica del motore, possiamo rappresentarle in uno schema a blocchi.\nIl segnale in ingresso è \\(e_a\\), che possiamo trasformare in \\(E_a(s)\\).\n\n\n\n\n\n\nIl circuito di retroazione è inerente al funzionamento del motore ed è una caratteristica importante dei motori controllati dall’armatura. Fornisce smorzamento.\nLa forza controelettromotrice si oppone alla tensione di armatura applicata, influenzando la corrente di armatura e, di conseguenza, la velocità e la coppia del motore. Introduce inoltre un anello di feedback intrinseco nei motori controllati da armatura, che influenza la risposta dinamica del motore.\n\n\nDerivare la funzione di trasferimento\nCombinando le relazioni e le equazioni di cui sopra, si ricava la funzione di trasferimento per il motore, mettendo in relazione la velocità di uscita \\(\\omega\\) con la tensione di armatura di ingresso \\(e_a\\). Se impostiamo \\(T_W=0\\), otteniamo:\n\\[\n\\begin{align}\n\\frac{\\omega(s)}{E_a(s)} = \\frac{\\frac{K_T/R_a}{Js+B}}{\\frac{1+K_bK_T/R_a}{Js+B}} = \\ frac{K_T/R_a}{Js + B + K_bK_T/R_a}\n\\end{align}\n\\]\nQuesta funzione di trasferimento è fondamentale in quanto ci fornisce un modello matematico della dinamica del motore, che può essere utilizzato per scopi di analisi e progettazione.\nPossiamo trasferire questa funzione di trasferimento in una forma standard del primo ordine:\n\\[\n\\begin{align}\n\\frac{\\omega(s)}{E_a(s)} = \\frac{K_m}{\\tau_m s + 1}\n\\end{align}\n\\]\nDove:\n\\[\n\\tau_m = \\frac{J}{B+K_bK_T/R_a}\n\\]\n\\[\nK_m = \\frac{K_T/R_a}{B+K_bK_T/R_a}\n\\]\n\n\nCommenti sul feedback intrinseco del motore\nUna delle caratteristiche uniche del motore controllato dall’indotto è il circuito di retroazione intrinseco dovuto a \\(K_b\\).\n\nLa forza controelettromotrice \\(e_b\\) è una tensione generata negli avvolgimenti dell’indotto di un motore quando gira. Si oppone alla tensione applicata \\(e_a\\) e la sua grandezza è proporzionale alla velocità del motore. La costante di proporzionalità è spesso indicata come \\(K_b\\).\n\\(K_b\\) aumenta il valore di \\(B\\) e quindi aumenta lo smorzamento effettivo del motore. Quando il motore accelera, la forza elettromotrice posteriore aumenta. Questa maggiore forza elettromotrice si oppone più fortemente alla tensione applicata, riducendo efficacemente la tensione netta attraverso l’armatura. Ciò, a sua volta, riduce la corrente di armatura, che a sua volta diminuisce la coppia prodotta dal motore. Questo comportamento agisce come un meccanismo di smorzamento naturale, rallentando il motore quando tenta di funzionare troppo velocemente.\n\nQuesto feedback intrinseco fornisce lo smorzamento richiesto, garantendo un rapido smorzamento delle oscillazioni e una risposta più rapida allo stato stazionario.\nQuesto non è disponibile in tutti i motori (ad esempio, i motori controllati dal campo).\nSi noti inoltre che la costante di tempo del motore diminuisce quando \\(K_b\\) aumenta, portando a una risposta più rapida (ovvero, raggiunge il suo valore di stato più rapidamente).\n\nBarra laterale: in che modo la forza elettromotrice posteriore influisce sullo smorzamento\nRicorda le equazioni del motore:\n\\[\n\\begin{align}\ni_a = \\frac{e_a-e_b}{R_a}\n\\end{align}\n\\]\n\\[\n\\begin{align}\nT_M = K_T \\times i_a\n\\end{align}\n\\]\n\\[\n\\begin{align}\ne_b = K_b \\times \\omega\n\\end{align}\n\\]\n\\[\n\\begin{align}\nT_M = J\\dot{\\omega} + B\\omega + T_W\n\\end{align}\n\\]\nSostituendo nell’equazione (2), l’espressione per \\(i_a\\) da (1) e poi l’espressione per \\(e_b\\) da (3):\n\\[\n\\begin{align}\nT_M = K_T \\times \\frac{e_a-e_b}{R_a} = K_T \\times \\frac{e_a-(K_b\\omega)}{R_a}\n\\end{align}\n\\]\nLa coppia prodotta dal motore deve bilanciare le coppie resistenti al movimento del motore, che ora possiamo scrivere come:\n\\[\nK_T \\times \\frac{e_a-(K_b\\omega)}{R_a} = T_M = J\\dot{\\omega} + B\\omega + T_W\n\\]\nLa forza elettromotrice posteriore non entra direttamente nell’equazione della coppia, ma influenza la corrente di armatura, che a sua volta influisce sulla coppia prodotta dal motore. L’influenza della forza controelettromotrice sulla coppia è indiretta, attraverso la sua influenza sulla corrente di armatura.\n– FINE DELLA BARRA LATERALE\nDomanda pop-up: Se la costante \\(K_b\\) dovesse aumentare (il che significa che il motore genera più forza elettromotrice posteriore per una determinata velocità), il motore sarebbe più o meno smorzato?\nRisposta: Il motore sarebbe più smorzato. Un aumento di \\(K_b\\) significa che per ogni data velocità, la forza elettromotrice posteriore sarebbe maggiore, opponendosi più fortemente alla tensione applicata e aumentando così l’effetto di smorzamento nel sistema.\n\n\n\n\nRivisitare il sistema originale\nTorniamo al sistema primario dove integriamo il motore e deriviamo la funzione di trasferimento complessiva.\n\n\n\n\n\n\n\nUtilizzando metodi di riduzione del diagramma a blocchi (ad esempio, grafici del flusso del segnale o direttamente) diventa facile ottenere la funzione di trasferimento complessiva tra qualsiasi segnale di interesse.\nGeneralmente:\n\\[\n\\omega(s) = M(s)\\omega_r(s) + M_W(s)T_W(s)\n\\]\nDomanda (Popup): Perché usiamo \\(\\omega_r\\) invece di \\(e_r\\) nella nostra rappresentazione del diagramma a blocchi? Risposta: \\(\\omega_r\\) viene utilizzato perché, ai fini dell’analisi e della progettazione nello schema a blocchi, fornisce una rappresentazione equivalente. Si tratta di equivalenza matematica piuttosto che di connessione fisica.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#comprendere-lo-schema-a-blocchi",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#comprendere-lo-schema-a-blocchi",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Comprendere lo schema a blocchi",
    "text": "Comprendere lo schema a blocchi\n\nL’ingresso di riferimento \\(e_r\\) rappresenta la posizione desiderata, impostabile su un potenziometro. Pertanto, \\(e_r = K_p \\times \\theta_r\\), dove \\(K_p\\) è la costante potenziometrica.\nIl segnale di feedback in questa fase è la posizione del carico \\(\\theta_L\\). Questa posizione viene anche convertita in un segnale di tensione, rappresentato come \\(e_0 = K_p*\\theta_L\\).\n\nPer semplicità e per facilitare una rappresentazione del diagramma a blocchi con retroazione unitaria, assumiamo che le costanti potenziometriche per le posizioni comandate e effettive siano identiche. Se le due costanti non fossero uguali non otterremmo un diagramma a blocchi con feedback unitario.\n\nIl rilevatore di errori rileva la differenza tra la posizione desiderata e quella effettiva. Fornisce una tensione proporzionale a questa differenza, \\(e_r - e_o\\). Nota che l’ingresso dell’amplificatore operazionale è \\(e_r - e_o\\) perché il segno dei due potenziometri è invertito.\nIl secondo amplificatore operazionale è un amplificatore invertente per invertire il segno del segnale.\nL’uscita dell’amplificatore, \\(u\\), funge da ingresso per l’amplificatore di potenza, risultando nella tensione \\(e_a\\). Questa tensione aziona il motore controllato dall’indotto.\nLa coppia generata dal motore, tenendo conto dei disturbi esterni, trascina il carico.\nOsservare che sia presente un rotismo che faccia da intermediario tra l’albero motore ed il carico. Ciò è spesso essenziale quando è necessario amplificare la coppia per spostare il carico, il che si traduce contemporaneamente in una riduzione della velocità.\nIl treno di ingranaggi è essenziale per fornire la necessaria amplificazione di coppia, soprattutto quando si ha a che fare con un carico più pesante.\nInfine, la posizione del carico \\(\\theta_L\\) viene rilevata dal potenziometro e restituita.\n\n\nIl treno di ingranaggi nel sistema motore\n\nIl treno di ingranaggi svolge un ruolo cruciale nell’amplificare la coppia e diminuire la velocità, adattato alle esigenze del carico.\nIl nostro focus sarà sulla modellazione di due ingranaggi. Se il sistema prevede più di due marce è necessario formulare un modello corrispondente.\n\n\n\n\n\n\n\n\n\n\\(\\theta_M\\) indica la posizione del motore, mentre \\(\\theta_L\\) indica la posizione del carico. Le loro direzioni sono invertite a causa della meccanica del treno di ingranaggi.\n\\(T_W\\) è la coppia di disturbo che, come illustrato, contrasta la direzione del movimento del carico. Tuttavia, è importante ricordare che si tratta di un valore algebrico.\n\n\n\nDerivare la relazione tra coppia e velocità\nCominciamo derivando un’equazione che mette in relazione la coppia e le velocità di due ingranaggi collegati.\n\n\n\n\n\n\n\nConsideriamo due ingranaggi, Gear 1 e Gear 2. I raggi di questi ingranaggi sono rispettivamente \\(r_1\\) e \\(r_2\\). Man mano che gli ingranaggi ruotano, il numero di giri dei due ingranaggi è diverso: la distanza lineare percorsa dalle loro superfici rimane costante, portando alla relazione:\n\\[\n\\theta_Mr_1 = \\theta_Lr_1\n\\]\nDomanda pop-up: Perché le distanze lineari percorse dai due ingranaggi devono essere le stesse?\nRisposta: Gli ingranaggi sono in contatto, quindi per ogni giro di un ingranaggio, anche la parte corrispondente dell’altro ingranaggio percorre la stessa distanza lineare.\nSupponendo che i raggi e il numero di denti siano proporzionali, possiamo scrivere:\n\\[\n\\begin{align}\n\\frac{N_1}{N_2} = \\frac{\\theta_L}{\\theta_M}\n\\end{align}\n\\]\nQuesta diventa la nostra prima equazione fondamentale. Ma c’è di più in questa storia. Se differenziamo l’equazione precedente rispetto al tempo, otteniamo la relazione tra le velocità angolari dei due ingranaggi:\n\\[\n\\begin{align}\n\\frac{N_1}{N_2} = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M}\n\\end{align}\n\\]\nIl rapporto \\(\\frac{N_1}{N_2}\\) è spesso definito rapporto di trasmissione, indicato con \\(n\\).\n\n\nEsame della dinamica della coppia\nOra spostiamo la nostra attenzione sulle coppie coinvolte.\n\n\n\n\n\n\n\n\nLa coppia generata dal motore è rappresentata da \\(T_M\\).\nLa coppia trasmessa attraverso il treno di ingranaggi all’albero di carico è \\(T_{21}\\). Questa coppia è fondamentale in quanto si oppone alla coppia di disturbo \\(T_W\\).\nUn’altra coppia da considerare è \\(T_{12}\\), che indica il carico dovuto al Gear 2 (e al carico collegato) sull’albero del motore. Possiamo capirlo intuitivamente perché il carico sull’albero motore quando abbiamo il Gear 2 e quando non lo abbiamo è diverso.\n\nNel punto di contatto tra gli ingranaggi, le forze sviluppate dai due ingranaggi dovrebbero equivalersi. Perciò:\n\\[\n\\frac{T_{12}}{r_1} = \\frac{T_{21}}{r_2}\n\\]\n\\[\n\\frac{T_{12}}{T_{21}} = \\frac{N_{1}}{N_2} = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M}\n\\]\nSe \\(n &lt; 1\\), il rapporto di trasmissione amplifica la coppia (e riduce la velocità). Il valore tipico è n=1/30.\n\n\nIntegrazione degli effetti dell’equipaggiamento nel sistema\nUno dei risultati interessanti della nostra discussione finora è che possiamo rappresentare gli effetti combinati del motore e del treno di ingranaggi come se fossero un’unica entità. Matematicamente, l’intero sistema si comporta come se ci fosse un motore che aziona direttamente un carico con un momento di inerzia e attrito “equivalente”. Vediamo come risolverlo.\n\n\n\n\n\n\n\nPer la seconda marcia, l’equazione all’albero di carico è:\n\\[\nT_{21} = J_L\\ddot{\\theta_L} + B_L\\dot{\\theta_L} + T_W\n\\]\nPer la prima marcia, l’equazione all’albero motore è:\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + T_{12}\n\\]\ndove \\(T_{12}\\) rappresenta l’opposizione del carico e della seconda marcia all’albero motore.\nPoiché \\(\\frac{T_{12}}{T_{21}} = \\frac{N_{1}}{N_2}\\), gli effetti combinati possono essere espressi come:\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + \\frac{N_{1}}{N_2}\\Big[J_L\\ddot{\\theta_L} + B_L\\dot{\\theta_L} + T_W\\ Big]\n\\]\nPoiché \\(n = \\frac{N_1}{N_2} = \\frac{\\theta_L}{\\theta_M}\\) possiamo riscrivere l’equazione in funzione di \\(\\theta_M\\):\n\\[\nT_M = J_M\\ddot{\\theta_M} + B_M\\dot{\\theta_M} + \\Big(\\frac{N_{1}}{N_2}\\Big)^2J_L\\ddot{\\theta_M} + \\Big(\\frac{ N_{1}}{N_2}\\Big)^2B_L\\dot{\\theta_M} + \\frac{N_{1}}{N_2}T_W\n\\]\nPossiamo finalmente raggruppare le cose insieme:\n\\[\nT_M = \\Big(J_M+n^2J_L\\Big)\\ddot{\\theta_M} + \\Big(B_M+n^2B_L\\Big)\\dot{\\theta_M}+ nT_W\n\\]\nMatematicamente il sistema di controllo della posizione è equivalente al seguente:\nDove: - \\(J_{eq} = \\Big(J_M+n^2J_L\\Big)\\) - \\(B_{eq} = \\Big(B_M+n^2B_L\\Big)\\) - \\(nT_W\\), è il disturbo equivalente che agisce sull’albero motore (in realtà il disturbo agisce sul carico).\nCon la nuova rappresentazione abbiamo riportato il problema del controllo allo stesso che avevamo con il controllo della velocità.\n\n\nDiagramma a blocchi\n\n\n\n\n\n\n\n\nLa dinamica del motore (compresi gli effetti del treno di ingranaggi) è rappresentata dall’equazione precedentemente derivata.\nVengono introdotti circuiti di feedback per tenere conto della forza elettromotrice posteriore e del meccanismo di controllo della posizione.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#alcuni-commenti-aggiuntivi-sul-sistema-di-controllo-della-posizione-cc",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#alcuni-commenti-aggiuntivi-sul-sistema-di-controllo-della-posizione-cc",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Alcuni commenti aggiuntivi sul sistema di controllo della posizione CC",
    "text": "Alcuni commenti aggiuntivi sul sistema di controllo della posizione CC\nNelle nostre discussioni precedenti, abbiamo approfondito le complessità del sistema di controllo della posizione CC. Oggi rivisiteremo ulteriormente questo sistema, esplorandone il significato nei sistemi di controllo e comprendendone i componenti fondamentali.\nI motori CC azionano molti carichi, rendendo il sistema di controllo della posizione CC un elemento fondamentale nel controllo automatico. Questo sistema ha diversi componenti e abbiamo visto l’equivalenza quando riportiamo il carico e il treno di ingranaggi sull’albero motore:\n\n\n\n\n\n\n\n_Figura: a sinistra: motore, treno di ingranaggi e carico. A destra: rappresentazione equivalente.\nDalle nostre discussioni precedenti, abbiamo dedotto che i parametri di carico potrebbero essere rispecchiati sull’albero motore. Questa realizzazione ci permette di rappresentare matematicamente il sistema in maniera semplificata, senza coinvolgere esplicitamente il treno di ingranaggi. Per chiarezza, si consideri un sistema in cui un motore aziona un carico attraverso un treno di ingranaggi. Questo sistema può essere rappresentato in modo equivalente come un motore che aziona un carico diretto, a patto di regolare opportunamente i parametri del carico per tenere conto degli effetti del treno di ingranaggi.\n\nMomento di inerzia equivalente sull’albero motore \\[J_{eq} = \\Big(J_M+n^2J_L\\Big)\\]\nCoefficiente di attrito viscoso equivalente \\[B_{eq} = \\Big(B_M+n^2B_L\\Big)\\]\n\nQui \\(J_M\\) e \\(B_M\\) rappresentano rispettivamente l’inerzia dovuta al rotore, agli ingranaggi, ecc. e il coefficiente di attrito sull’albero motore. \\(n\\) è il rapporto di trasmissione definito come il rapporto tra il numero di denti sui due ingranaggi, \\(N_1\\) e \\(N_2\\).\n\nL’equazione del motore:\n\n\\[\nT_M = J_{eq}\\ddot{\\theta_M} + B_{eq}\\dot{\\theta_M}+ nT_W\n\\]\nSi noti che \\(T_W\\) è il disturbo sull’albero del carico e \\(n\\) riflette questo disturbo sull’albero del motore.\nPer modellare il nostro sistema, iniziamo considerando il motore controllato dall’armatura. La variabile di controllo qui è la tensione di armatura \\(e_a\\), mentre la FEM opposta è \\(e_b\\). Stiamo trascurando l’induttanza dell’armatura come discusso in precedenza.\nIn questo caso, per il motore caricato tramite un treno di ingranaggi, il carico direttamente collegato ad esso ha i parametri \\(J\\) e \\(B\\) riflessi dal carico originale tramite il treno di ingranaggi. Se il carico è collegato tramite un treno di ingranaggi, \\(J\\) e \\(B\\) lo includeranno direttamente. Il disturbo in questo contesto è \\(nT_W\\).\n\n\n\n\n\n\n\nModello di diagramma a blocchi\nDall’immagine precedente possiamo generare il seguente diagramma a blocchi, partendo dall’ingresso \\(e_a\\) fino all’uscita \\(\\theta_M\\).\n\n\n\n\n\n\n\nFigura: diagramma a blocchi che mostra l’intero sistema, dal rilevatore di errori che confronta la tensione di armatura e la forza elettromagnetica di ritorno, al treno di ingranaggi e ai parametri di carico e infine all’uscita\nIn base a questo diagramma, applicando il principio di sovrapposizione (e quindi ponendo \\(T_W=0\\), la funzione di trasferimento che lega la velocità di uscita \\(\\omega\\) all’ingresso \\(e_a\\) è:\n\\[\n\\frac{\\omega(s)}{E_a(s)} = \\frac{\\frac{K_T/R_a}{Js+B}}{\\Big(1+\\frac{K_bK_T/R_a}{Js+B} \\Big)} = \\frac{K_T/R_a}{Js+B+K_bK_T/R_a}\n\\]\nNota dall’equazione sopra come la costante EMF posteriore \\(K_b\\) si aggiunge all’attrito meccanico nel sistema (il termine \\(B\\)), fornendo così ulteriore smorzamento, stabilizzando il sistema e rendendolo meno suscettibile alle oscillazioni. (quasi fornendo “attrito elettrico”)\nLa nostra funzione di trasferimento precedentemente derivata può essere interpretata nella sua forma standard per i sistemi del primo ordine come:\n\\[\n\\frac{\\omega(s)}{E_a(s)} = \\frac{K_m}{\\tau_m s + 1}\n\\]\nDove:\n\n\\(K_m\\) è il guadagno del sistema.\n\\(\\tau_m\\) è la costante di tempo meccanica, che può essere calcolata come:\n\n\\[\n\\tau_m = \\frac{J}{B+\\frac{K_TK_b}{R_a}}\n\\]\nSe siamo più interessati alla relazione tra la posizione \\(\\theta_M\\) e la tensione di ingresso \\(e_a\\), la funzione di trasferimento diventa:\n\\[\n\\frac{\\theta_M(s)}{E_a(s)} = \\frac{K_m}{s\\Big(\\tau_m s + 1\\Big)}\n\\]\n\n\n\nBarra laterale - Approfondimento sulla correlazione tra \\(K_T\\) e \\(K_b\\)\nL’interrelazione tra la costante di coppia \\(K_T\\) e la costante della forza controelettromotrice \\(K_b\\) è un aspetto fondamentale della dinamica dei motori CC. Queste costanti sono proprietà intrinseche del motore, che ne governano il comportamento elettrico e meccanico. Per apprezzare veramente il loro significato e la loro relazione, è essenziale comprenderli in dettaglio.\n\nCosa sono \\(K_T\\) e \\(K_b\\)?\n\nCostante di coppia \\(K_T\\): indica la coppia prodotta per unità di corrente. In termini semplici, fornisce una misura dell’efficacia del motore nel convertire la corrente elettrica in coppia meccanica. Un \\(K_T\\) più alto implica che il motore può generare più coppia per la stessa corrente. La sua unità è Newton metro per ampere (Nm/A).\nCostante EMF posteriore \\(K_b\\): La costante EMF posteriore determina la tensione prodotta per unità di velocità. Quando un motore ruota, genera intrinsecamente un EMF che si oppone alla tensione di pilotaggio; questo è chiamato EMF posteriore. \\(K_b\\) quantifica questo effetto, indicando essenzialmente quanta tensione genera il motore per ogni radiante/secondo di rotazione. La sua unità è volt per radiante al secondo (V/(rad/s)).\n\n\n\nDerivazione matematica della loro relazione:\nConsiderando la potenza sviluppata nel motore a causa della forza controelettromotrice:\n\\[\n\\begin{align}\nP &= e_b \\times i_a\\;\\;\\;\\; \\text{watt} \\\\\n  &= K_bw \\times i_a\\;\\;\\;\\; \\frac{\\text{volt}}{\\text{rad/s}}\\text{rad/s} \\times \\text{amp}\n\\end{align}\n\\]\nDal punto di vista meccanico la potenza è data anche da:\n\\[\n\\begin{align}\nP &= T_M \\times \\omega\\;\\;\\;\\; \\text{watt} \\\\\n   &= (\\text{Newton-m})(\\text{rad-s})\n\\end{align}\n\\]\nChe può essere espanso come: \\[\n\\begin{align}\nP &= K_Ti_a \\times \\omega\\;\\;\\;\\; \\text{watt} \\\\\n   &= \\frac{\\text{Newton-m}}{\\text{amp}} \\text{amp} \\times \\text{rad/s}\n\\end{align}\n\\]\nDato che entrambe le espressioni rappresentano la potenza sviluppata nel motore, le equiparamo:\n\\[\nK_b \\omega \\times i_a = K_T i_a \\times \\omega\n\\]\nSemplificando troviamo: \\[\n\\begin{align}\nK_b &= K_T \\\\\n\\frac{\\text{Newton-m}}{\\text{amp}} &= \\frac{\\text{volt}}{\\text{rad/s}}\n\\end{align}\n\\]\nPertanto, questa derivazione evidenzia che la costante di coppia $ K_T $ e la costante EMF posteriore $ K_b $ sono numericamente uguali quando $ K_T $ è misurato in Newton metro per ampere e $ K_b $ in volt per radiante al secondo. I loro valori numerici sono gli stessi. Questo è il caso quando li consideriamo utilizzando queste unità specifiche. Se utilizziamo unità diverse, queste possono essere correlate da una costante e quindi i loro valori numerici potrebbero essere diversi.\n\n\nImplicazioni pratiche\n\nQuesta equivalenza non è solo una curiosità matematica; ha implicazioni nel mondo reale. Ad esempio, quando si progettano controllori motore o quando si acquistano motori per applicazioni specifiche, sapere che \\(K_T\\) e \\(K_b\\) sono uguali (in unità coerenti) può semplificare i calcoli e fornire informazioni dettagliate sul comportamento del motore.\nDa un punto di vista sperimentale, misurare \\(K_b\\) è più semplice e potenzialmente più accurato che misurare \\(K_T\\). Ad esempio, per determinare \\(K_b\\) è necessario soltanto misurare la forza elettromotrice e la velocità, mentre per valutare \\(K_T\\) sono necessarie misurazioni della coppia. Data la suddetta relazione tra \\(K_T\\) e \\(K_b\\), è possibile misurare sperimentalmente \\(K_b\\) e ricavarne \\(K_T\\), offrendo un approccio più diretto.\nLa facilità di misurazione di \\(K_b\\) rispetto a \\(K_T\\) significa che gli ingegneri spesso determinano sperimentalmente \\(K_b\\) (si misurano la FEM e la velocità) e quindi deducono \\(K_T\\) (è necessario misurare una coppia). Ciò può portare a risparmi sui costi e caratterizzazioni dei motori più accurate in scenari pratici.\n\n– FINE DELLA BARRA LATERALE",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#motori-controllati-dal-campo",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#motori-controllati-dal-campo",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Motori controllati dal campo",
    "text": "Motori controllati dal campo\nDopo aver compreso i motori controllati dall’armatura, è giunto il momento di introdurre il concetto di motori controllati dal campo.\nIn questi motori la corrente di armatura \\(i_a\\) rimane costante, mentre la corrente di campo \\(i_f\\) viene variata per controllare la coppia \\(T_M\\).\n\n\n\n\n\n\n\n\nOra la resistenza di campo e l’induttanza non sono trascurabili.\n\n\n\n\n\n\n\nL’effetto ‘resistenza elettrica’ non è più presente.\n\nLa funzione di trasferimento risultante da \\(\\omega(s)\\) e \\(E_f(s)\\) è:\n\\[\n\\frac{\\omega(s)}{E_f(s)} = \\frac{K^{'}_m}{(\\tau_f s + 1)(\\tau^{'}_m s + 1)}\n\\]\nche è un modello del secondo ordine.\nLa funzione di trasferimento dalla posizione \\(\\theta_M(s)\\) e \\(E_f(s)\\) abbiamo un modello del terzo ordine:\n\\[\n\\frac{\\theta_M(s)}{E_f(s)} = \\frac{K^{'}_m}{s(\\tau_f s + 1)(\\tau^{'}_m s + 1)}\n\\]\nPiù alto è l’ordine del modello, più complessa sarà la progettazione. L’ulteriore complessità deriva dal fatto che \\(L_f\\) non può essere trascurato.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#commenti-aggiuntivi",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#commenti-aggiuntivi",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Commenti aggiuntivi:",
    "text": "Commenti aggiuntivi:\nI progressi hanno affrontato alcune delle sfide associate a questi azionamenti motore. Alcune tendenze chiave includono:\n\nMotori DC senza spazzole: una delle principali sfide con i motori discussi finora è l’attrito delle spazzole, che introduce la non linearità nei nostri modelli matematici. Sono ora disponibili motori CC senza spazzole, con commutazione elettronica, per mitigare gli effetti non lineari dovuti all’attrito delle spazzole.\nIngranaggi e gioco: la nostra discussione presuppone una relazione lineare tra l’ingresso e l’uscita del motore attraverso gli ingranaggi. Tuttavia, in realtà, il gioco degli ingranaggi introduce una non linearità. Ciò è dovuto al fatto che l’inversione degli ingranaggi non sarà istantanea (ad esempio, il tracciamento di oggetti richiede che il localizzatore si muova avanti e indietro). I motori a trasmissione diretta sono ora progettati per interfacciarsi direttamente con il carico, eliminando la necessità di treni di ingranaggi e le relative sfide non lineari.\nMeccanismi di feedback: sebbene i potenziometri forniscano un modo semplice per misurare la posizione angolare, presentano le proprie sfide. I sistemi moderni si stanno orientando verso sensori più avanzati che offrono maggiore precisione e migliore linearità.",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/hardware_and_case_studies_it.html#definizione-delle-variabili",
    "href": "IT_🇮🇹/hardware_and_case_studies_it.html#definizione-delle-variabili",
    "title": "Hardware dei sistemi di controllo e casi di studio",
    "section": "Definizione delle variabili",
    "text": "Definizione delle variabili\nLa variabile \\(\\theta_L\\) è il nostro attributo di interesse, quello che vogliamo controllare. A scopo illustrativo, supponiamo \\(\\theta_L\\) rappresenta la posizione di un’antenna. D’altra parte, \\(\\theta_R\\) è il segnale di comando, che in molte applicazioni del mondo reale può arrivare digitalmente o da vari dispositivi.\nAi fini di questo quaderno, rappresenteremo simbolicamente il segnale di comando, utilizzando un cursore su un potenziometro per regolare \\(\\theta_R\\). Mentre il tergicristallo si muove, regola la tensione (chiamiamola tensione \\(e_r\\)), che è direttamente proporzionale a \\(\\theta_R\\).\n\nPotenziometro\nLa relazione tra \\(\\theta_R\\) e \\(e_r\\) dipende dalla costante del potenziometro \\(K_p\\), che dipende dalla tensione fornita al potenziometro, e dal resistore:\n\\[e_r = K_P\\theta_R\\]\nNota che stiamo usando un altro potenziometro per rilevare l’uscita \\(\\theta_L\\).\nI potenziometri sono spesso utilizzati in questi sistemi. Tuttavia, possono introdurre non linearità a causa della loro risoluzione finita. Ad esempio, un potenziometro a filo avvolto cambia passo dopo passo, non consentendo regolazioni continue (ad esempio, potenziometro a filo avvolto). Nonostante ciò, per il nostro modello matematico, assumeremo per semplicità una relazione lineare.\nPer ora, utilizziamo i potenziometri come rappresentazioni di dispositivi che consentono di generare segnali di riferimento e feedback, ma il dispositivo reale potrebbe essere diverso da un potenziometro, con caratteristiche lineari migliori.\n\n\nDalla tensione al controllo della posizione\nConcentriamoci ora sul primo amplificatore operazionale.\nQuesto circuito fornisce una tensione di uscita proporzionale alla differenza \\(e_r−e_0\\), dove \\(e_0\\) è la tensione di feedback corrispondente a \\(\\theta_L\\). Questa operazione fa sì che l’Op-Amp si comporti come un amplificatore differenziale con un guadagno specifico (\\(\\frac{-R_f}{R}\\)). A seconda della disposizione, l’uscita di tensione può rappresentare la posizione o la velocità.\nL’amplificatore operazionale agisce come un amplificatore differenziale, producendo una tensione di uscita basata sulla differenza tra la tensione di riferimento e quella di feedback.\nDate le disposizioni specifiche con i potenziometri (\\(e_r\\) è una tensione negativa e \\(e_0\\) è una tensione positiva), abbiamo:\n\n\n\n\n\n\nSi noti che per rendere la rappresentazione semplice, abbiamo ristrutturato il nostro diagramma a blocchi invertendo i segni di queste tensioni.\n\nPossiamo poi sommare i potenziometri per avere la presenza esplicita dei due angoli:\n\n\n\n\n\nQuesto può anche essere scritto in modo equivalente come:\n\n\n\n\n\n\nAbbiamo spostato \\(K_P\\) all’interno del ciclo\nQuesto ora è un ciclo di feedback unitario\n\n\n\nIntegrazione del feedback della dinamo tachimetrica\nUna parte cruciale del nostro sistema è l’aggiunta di un generatore tachimetrico, che introduce un circuito di feedback secondario (o minore) per la velocità. La tensione della dinamo tachimetrica (\\(e_t\\)) svolge un ruolo fondamentale nelle prestazioni e nel controllo del sistema.\nIl secondo Op-Amp funziona anche come amplificatore differenziale con guadagno: \\(\\frac{-R^{'}_f}{R^{'}}\\). L’ingresso di questo amplificatore operazionale è \\(e^{'}-e_t\\).\n\n\n\n\n\n\nL’amplificatore operazionale finale viene utilizzato come amplificatore di potenza con guadagno: \\[-\\frac{R_{fp}}{R_p}\\]\nDa notare che, dato che abbiamo due amplificatori operazionali in cascata, i loro segni negativi si annullano e alla fine della catena abbiamo il segnale desiderato.\n\nPossiamo ora completare lo schema a blocchi:\n\n\n\n\n\n\nTieni presente che puoi dettagliare il diagramma a blocchi con una rappresentazione più dettagliata del motore che include il circuito EMF posteriore.\nRicordare che il rapporto di trasmissione è definito come:\n\n\\[n = \\frac{\\dot{\\theta}_L}{\\dot{\\theta}_M} = \\frac{\\theta_L}{\\theta_M}\\]\nIl sistema ha due cicli:\n\nCiclo primario (feedback di posizione): fornisce un feedback basato sulla posizione \\(\\theta_L\\).\nLoop secondario o minore (feedback di velocità): questo loop fornisce feedback in base alla velocità. Deriva il suo segnale da una dinamo tachimetrica, simboleggiata da \\(e_t\\). Questo circuito secondario ha uno scopo di smorzamento simile a quello della forza elettromotrice posteriore intrinseca nel motore, ma ha il vantaggio di essere regolabile.\nLoop interno al motore: la natura intrinseca del motore introduce un altro anello di feedback, la forza elettromotrice posteriore, che non è direttamente sotto il nostro controllo. Al contrario, l’uscita della dinamo tachimetrica può essere controllata, permettendoci di regolare lo smorzamento del sistema.\n\n\n\nRompere i loop\n\nRompere il loop di velocità\n\nSe rompiamo il feedback di velocità secondario, cosa succede alle prestazioni del sistema?\nLa dinamo tachimetrica fornisce intrinsecamente informazioni sulla velocità del sistema (stiamo restituendo la derivativa di \\(\\theta_M\\) attraverso il tachimetro).\nLa mancanza del circuito secondario porta ad una perdita di smorzamento\n\nIl sistema continuerà a funzionare come un sistema di controllo della posizione ma attraverso il circuito secondario stiamo controllando lo smorzamento del sistema. La dinamo tachimetrica generalmente fornisce un effetto smorzante al sistema, contribuendo a stabilizzarlo. Questo effetto di smorzamento è utile per ridurre al minimo le oscillazioni attorno al setpoint o al valore di riferimento. Senza questo feedback, il sistema potrebbe subire oscillazioni prolungate o addirittura sostenute in seguito a eventuali disturbi o modifiche del setpoint. Le prestazioni potrebbero peggiorare.\nNota che è simile a quello che è successo quando stavamo analizzando l’effetto della forza elettromagnetica posteriore. Anche la forza elettromotrice posteriore era proporzionale alla velocità ed era in grado di migliorare il nostro smorzamento. L’unica differenza è che la forza elettromotrice posteriore (\\(K_b\\)) è fuori dal nostro controllo (una volta selezionato il motore non è possibile modificare \\(K_b\\)). La \\(K_T\\) invece è qualcosa che puoi controllare esplicitamente selezionando la dinamo tachimetrica.\nConseguenze nel mondo reale: se il nostro sistema controllasse la posizione di un’antenna, una perdita di smorzamento potrebbe portare l’antenna a superare la posizione desiderata e quindi a oscillare avanti e indietro prima di stabilizzarsi. Ciò potrebbe causare segnali di comunicazione interrotti o degradati.\n\n\n\n\nRompere il loop di posizione\n\n\n\n\n\n\nQuando il circuito di retroazione primario (posizione) viene interrotto, ma il circuito secondario (velocità) rimane, il sistema si comporta come un sistema a velocità controllata.\nNota che l’ingresso effettivo che abbiamo è la tensione \\(e_r\\). In precedenza abbiamo interpretato questo segnale come una posizione.\nLa tensione \\(e_r\\) nel loop diretto, che in precedenza era interpretata come posizione, ora è indicativa della velocità, dato che il feedback proviene ora dalla dinamo tachimetrica che rappresenta la velocità.\nIl sistema diventa un sistema a velocità controllata. Possiamo anche ora esplicitare che la dinamo tachimetrica fornisce una velocità:",
    "crumbs": [
      "IT_🇮🇹",
      "Hardware dei sistemi di controllo e casi di studio"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html",
    "href": "IT_🇮🇹/index_it.html",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "",
    "text": "Il corso fornisce una vasta base di ingegneria del controllo, coprendo sia concetti teorici che applicazioni pratiche.\nÈ rivolto agli studenti universitari del secondo anno e a chiunque sia interessato a comprendere i principi dei controlli automatici.\nSemestre di insegnamento: primavera 2024\nLingua di insegnamento: italiano e inglese",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#coordinatore-del-corso",
    "href": "IT_🇮🇹/index_it.html#coordinatore-del-corso",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Coordinatore del corso",
    "text": "Coordinatore del corso\nAndrea Munafo",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#docentei",
    "href": "IT_🇮🇹/index_it.html#docentei",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Docente(i)",
    "text": "Docente(i)\nAndrea Munafo",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#come-usare",
    "href": "IT_🇮🇹/index_it.html#come-usare",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Come usare",
    "text": "Come usare\nOgni notebook è pensato per essere indipendente l’uno dall’altro, quindi è possibile eseguirli nell’ordine che preferisci.",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#installa",
    "href": "IT_🇮🇹/index_it.html#installa",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Installa",
    "text": "Installa\nI notebook funzionano con Python 3.9 e utilizzano le seguenti librerie Python: - controllo Python - insensato - panda - matplotlib\nPuoi facoltativamente installare ‘sympy’ per eseguire calcoli simbolici in Python.\nIl notebook 01_Getting_started_with_Python_and_Jupyter_Notebook.ipynb fornisce una breve introduzione su come configurare un ambiente anaconda per iniziare.\nPer utilizzare tutti i notebook potresti dover installare il pacchetto di controllo del feedback. Puoi farlo inserendo questo nel tuo terminale:\npip install -e '.[dev]'\nQuesto è il modo consigliato per rendere importabile un pacchetto Python da qualsiasi punto dell’ambiente corrente:\n\n-e – abbreviazione di “modificabile”, ti consente di utilizzare immediatamente le modifiche apportate al tuo pacchetto durante lo sviluppo.\n. – si riferisce alla directory corrente.\n[dev] – include i requisiti di “sviluppo”: altri pacchetti che i tuoi notebook utilizzano esclusivamente per documentazione o test.",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#ringraziamenti-e-riferimenti",
    "href": "IT_🇮🇹/index_it.html#ringraziamenti-e-riferimenti",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Ringraziamenti e riferimenti",
    "text": "Ringraziamenti e riferimenti\n\nI libri di testo rilevanti utilizzati per preparare questi quaderni sono riportati in 00_Syllabus.ipynb.",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/index_it.html#risorse-addizionali",
    "href": "IT_🇮🇹/index_it.html#risorse-addizionali",
    "title": "Syllabus - Fondamenti di Automatica",
    "section": "Risorse addizionali",
    "text": "Risorse addizionali\n\nAccademia dei sistemi di controllo\nDinamica e controllo dei processi in Python\nKarl J. Åström e Richard M. Murray, Sistemi di feedback: un’introduzione per scienziati e ingegneri\nSerie di conferenze sull’ingegneria dei controlli del Prof. Madan Gopal\nProgettazione di compensatori di anticipo e ritardo in Matlab e Simulink\nNozioni di base sui sistemi di controllo",
    "crumbs": [
      "IT_🇮🇹",
      "Syllabus - Fondamenti di Automatica"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html",
    "title": "Principi di controllo del feedback",
    "section": "",
    "text": "Per iniziare il nostro viaggio, rivisitiamo il diagramma di feedback di base di cui abbiamo discusso in precedenza. Ecco una visualizzazione:\n\n\n\n\n\n\n\\(G(s)\\): Rappresenta l’impianto, che per semplicità indicheremo come SG.\n\\(D\\): la funzione di trasferimento del nostro controller.\n\\(N\\): Un modello che cattura i disturbi che agiscono sul sistema.\n\\(H\\): La funzione di trasferimento del nostro sensore.\n\\(y\\): la nostra variabile controllata.\n\\(y_r\\): Il comando o il segnale di riferimento.\n\\(e = y_r - y\\): Il segnale di errore\n\nIl rilevatore di errori confronta il segnale di riferimento con il segnale di feedback per produrre il segnale di attuazione, \\(\\hat{e}\\). Il nostro segnale controllato è indicato con \\(u\\).\nIn generale, questo diagramma incapsula le caratteristiche della maggior parte dei sistemi di controllo che incontrerai.\n🤔 Domanda pop-up: cosa rappresentano i simboli G, D e H nel diagramma del sistema di controllo del feedback? - A. Variabile Controllata, Disturbo, Sensore - B. Impianto, Controller, Sensore - C. Segnale di attivazione, controller, errore\nRisposta: B. Impianto, controller, sensore",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#diagramma-del-sistema-di-controllo-del-feedback",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#diagramma-del-sistema-di-controllo-del-feedback",
    "title": "Principi di controllo del feedback",
    "section": "",
    "text": "Per iniziare il nostro viaggio, rivisitiamo il diagramma di feedback di base di cui abbiamo discusso in precedenza. Ecco una visualizzazione:\n\n\n\n\n\n\n\\(G(s)\\): Rappresenta l’impianto, che per semplicità indicheremo come SG.\n\\(D\\): la funzione di trasferimento del nostro controller.\n\\(N\\): Un modello che cattura i disturbi che agiscono sul sistema.\n\\(H\\): La funzione di trasferimento del nostro sensore.\n\\(y\\): la nostra variabile controllata.\n\\(y_r\\): Il comando o il segnale di riferimento.\n\\(e = y_r - y\\): Il segnale di errore\n\nIl rilevatore di errori confronta il segnale di riferimento con il segnale di feedback per produrre il segnale di attuazione, \\(\\hat{e}\\). Il nostro segnale controllato è indicato con \\(u\\).\nIn generale, questo diagramma incapsula le caratteristiche della maggior parte dei sistemi di controllo che incontrerai.\n🤔 Domanda pop-up: cosa rappresentano i simboli G, D e H nel diagramma del sistema di controllo del feedback? - A. Variabile Controllata, Disturbo, Sensore - B. Impianto, Controller, Sensore - C. Segnale di attivazione, controller, errore\nRisposta: B. Impianto, controller, sensore",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#obiettivi-del-design",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#obiettivi-del-design",
    "title": "Principi di controllo del feedback",
    "section": "Obiettivi del design",
    "text": "Obiettivi del design\nIl nostro obiettivo primario? Assicurati che la variabile controllata, \\(y\\), rispecchi fedelmente \\(y_r\\) per tutto il tempo \\(t \\ge t_0\\) (dove \\(t_0\\) segna il punto in cui inizia il controllo):\n\\[\ny(t) \\approx y_r(t)\\;\\;\\;t \\ge t_0\n\\]\nTuttavia, sorgono delle sfide. Immergiamoci più a fondo.\nUno scenario industriale comune è quando \\(y_r\\) rimane costante per un periodo prolungato (set-point) e l’obiettivo è che \\(y_r\\) si allinei rapidamente con \\(y_r\\) e mantenga quel valore.\nQuesto scenario è definito controllo del setpoint o problema del regolatore.\nEmergono due misure chiave di performance:\n\nTempo di assestamento: il tempo necessario a \\(y\\) per avvicinarsi a \\(y_r\\). Tempi di assestamento inferiori indicano una velocità di risposta superiore del sistema (risposta più rapida).\nPrecisione dello stato stazionario: una volta raggiunto l’equilibrio, \\(y\\) dovrebbe rimanere vicino a \\(y_r\\). La differenza, o errore di stato stazionario, idealmente dovrebbe essere zero.\n\nQuesti sono in sintesi i requisiti di controllo.\nTuttavia, il mondo reale è complesso e vari vincoli possono ostacolare i nostri obiettivi. Esploriamo questi:\n\n1. Stabilità\nUna considerazione fondamentale. Un sistema stabile non presenta grandi variazioni di risposta a cambiamenti minori nei segnali di comando, nei disturbi o nei parametri del sistema. Anche se in seguito approfondiremo la definizione quantitativa di stabilità, ricorda sempre che tutte le specifiche prestazionali devono essere soddisfatte sotto l’egida della stabilità.\n\n\n2. Vincoli di ampiezza di ingresso\nLa validità del nostro modello lineare dipende dalla garanzia che le ampiezze del segnale rimangano entro determinati limiti. Il superamento di questi limiti può rendere nulle le nostre ipotesi sul modello lineare.\nÈ essenziale capire che quando adottiamo un modello di funzione di trasferimento, presupponiamo che rappresenti accuratamente ogni componente del sistema. Ciò comprende l’impianto, il controller, il sensore e altro ancora. Ciò è convalidato dal tipo di diagramma a blocchi che utilizziamo per i nostri progetti.\nTuttavia, non tutto è semplice. Rifletti su questo: cosa succede se l’ampiezza dei vari segnali supera una certa soglia? Le ricadute sarebbero significative. Il presupposto della linearità, che è fondamentale per il nostro sistema, non reggerebbe più. Di conseguenza, il diagramma a blocchi fondamentale alla base del nostro progetto verrebbe reso impreciso. Questa deviazione potrebbe portare a risultati insoddisfacenti nelle applicazioni del mondo reale.\nÈ chiaro che il nostro design dovrebbe rimanere entro certi limiti di ampiezza. In caso contrario, il modello lineare del nostro sistema potrebbe essere invalidato, compromettendo l’affidabilità dell’intero sistema.\nQuesto vale anche quando simuli il tuo sistema in laboratorio. È necessario tenere conto dei limiti dei segnali in modo da poter rimanere sotto le proprie ipotesi lineari.\n🤔 Domanda pop-up: Cosa succede se l’ampiezza dei segnali supera un certo limite nel nostro sistema di controllo?\nRisposta: il presupposto della linearità diventa non valido, rendendo impreciso il nostro diagramma a blocchi fondamentale. Ciò può comportare che il progetto non funzioni come previsto nelle situazioni del mondo reale.\n\n\n3. Reiezione del disturbo:\nIl nostro sistema dovrebbe mantenere la sua precisione e velocità di risposta, anche di fronte a disturbi. Pertanto, una buona progettazione dovrebbe filtrare efficacemente gli effetti dei disturbi.\nOgni sistema di controllo aspira a due obiettivi primari:\n\nVelocità di risposta: si riferisce alla rapidità con cui un sistema reagisce a un segnale di ingresso.\nPrecisione dello stato stazionario: implica la precisione con cui il sistema può mantenere il suo stato in risposta a un segnale di comando.\n\nTuttavia, i disturbi pongono sfide. È fondamentale che il sistema riduca i disturbi in modo efficace per garantire che non mettano a repentaglio la velocità di risposta o la precisione dello stato stazionario. I disturbi sono particolarmente problematici perché in genere sono sconosciuti. Se potessimo prevederli, non rappresenterebbero una sfida così grande. Tuttavia, i disturbi del mondo reale sono spesso casuali e imprevedibili.\n🤔 Domanda popup: Perché i disturbi rappresentano una sfida per un sistema di controllo?\nRisposta: Solitamente sono sconosciuti, casuali e possono influire negativamente sulla velocità di risposta del sistema e sulla precisione in condizioni stazionarie.\n\nProssime discussioni\nOggi abbiamo toccato alcuni aspetti vitali della teoria del controllo del feedback. Man mano che proseguiamo, approfondiremo ciascun vincolo ed esploreremo le strategie per superarli. Inoltre, nelle nostre sessioni successive, esempi di applicazioni reali illustreranno ulteriormente questi concetti.\nPer ora, mantieni questi concetti freschi nella tua mente e, come sempre, sentiti libero di rivisitare i capitoli precedenti per rafforzare la tua comprensione.\n\n\nFiltro rumore\nUno svantaggio intrinseco del controllo del feedback è l’inevitabile uso di un sensore. In un mondo ideale, senza la necessità di feedback, non avremmo bisogno di sensori (non sarebbe richiesto alcun feedback). Ma i sensori, sebbene vitali, introducono rumore ad alta frequenza nel sistema. Se questo rumore prevale, il sistema potrebbe finire per rispondere più al rumore che al segnale reale, portando a risultati indesiderati. Per risolvere questo problema è necessario introdurre adeguati filtri ad alta frequenza all’interno del circuito di feedback.\n\n\nSensibilità e robustezza\nI concetti di sensibilità e robustezza sono intrecciati. L’impianto di un sistema di controllo è modellato da una funzione, \\(G(s)\\).\nQuesto modello comprende vari componenti fisici. Durante i nostri sforzi di modellazione, è evidente che non è possibile catturare ogni sfumatura di un sistema fisico all’interno di un modello. Ciò si traduce in errori di modellazione.\nAd esempio, quando modelliamo la temperatura in un serbatoio, presupponiamo che la temperatura sia uniforme in tutto il serbatoio. Tuttavia, il sistema attuale è distribuito e diverse parti del serbatoio possono trovarsi a temperature diverse. Oppure in un sistema meccanico l’effetto molla (torsione) dell’albero di un motore è solitamente considerato pari a zero.\nOra, sebbene sia possibile creare modelli più complessi per catturare meglio le sfumature, ciò spesso porta ad algoritmi di progettazione altrettanto complessi. E qui sta l’enigma. A volte, i modelli più semplici con algoritmi di progettazione più semplici si rivelano più efficaci delle loro controparti complesse.\nUno dei motivi è che disponiamo di strumenti di progettazione molto potenti per modelli lineari semplici. L’utilizzo di modelli complessi potrebbe significare che non disponiamo di un algoritmo di progettazione appropriato su cui è necessario ricercare e lavorare. Potrebbe diventare così complesso che potrebbe anche non valerne la pena.\nQuando parliamo del nostro modello di impianto \\(G(s)\\) dobbiamo sempre essere consapevoli che avremo: - Errori di modellazione. È necessario eseguire test appropriati sul progetto per verificare che le approssimazioni e le semplificazioni del modello siano valide. - il parametro cambia con il tempo.\nLa robustezza è la capacità del sistema di funzionare in modo soddisfacente nonostante i cambiamenti finiti nel suo modello, dovuti a errori o variazioni dei parametri.\nAl contrario, la sensibilità si riferisce al modo in cui un sistema risponde a cambiamenti differenzialmente piccoli. Un sistema insensibile alle variazioni dei parametri è spesso considerato robusto.\n🤔 Domanda popup: Cosa differenzia la robustezza dalla sensibilità in un sistema di controllo?\nRisposta: La robustezza riguarda le prestazioni di un sistema nonostante i cambiamenti limitati del modello, mentre la sensibilità si riferisce alla sua reazione a cambiamenti molto piccoli.\nIl termine “robustezza” è ancora oggetto di ricerca attiva. Anche se occasionalmente potremmo riferirci a un design come “robusto”, è essenziale ricordare che nel nostro contesto spesso denota una forma qualitativa di design basato sulla sensibilità.\n\n\nDefinire la risposta dinamica\nQuando parliamo di sistemi di controllo, uno degli aspetti essenziali da comprendere è la modellazione della risposta dinamica (o il miglioramento della sua risposta transitoria). Questo aspetto gioca un ruolo cruciale nel raggiungimento delle prestazioni desiderate per il nostro sistema.\nSebbene in teoria potremmo desiderare reazioni istantanee, i componenti fisici introducono sempre un certo ritardo. Questo ritardo si manifesta come un “tempo di assestamento”, il tempo impiegato dal sistema per stabilizzare la propria produzione. Inoltre, c’è l’errore di stato stazionario, la deviazione tra i risultati desiderati e quelli effettivi una volta che il sistema si è stabilizzato.\n\n\n\n\n\nCon riferimento all’immagine sopra: A t=0, immagina che al sistema venga dato un segnale di comando costante $ y_r $. Ora, idealmente, la variabile controllata $ y $ dovrebbe seguire il più fedelmente possibile $ y_r $, ottenendo una risposta quasi istantanea.\nMa ecco il problema! Ottenere una risposta istantanea non è pratico perché ogni componente del sistema ha un certo ritardo o ritardo. A causa di questi ritardi, il sistema impiega un tempo finito per raggiungere il valore desiderato $ y_r $.\nQuesti ritardi o ritardi nella risposta del sistema possono essere dovuti a vari fattori come la natura intrinseca dei componenti utilizzati, disturbi esterni e persino uno smorzamento intenzionale aggiunto per scopi di stabilità.\n\nTempo di assestamento e velocità di risposta\nSe la risposta del nostro sistema dovesse assomigliare a questa,\n\n\n\n\n\nFigura: la risposta della variabile controllata nel tempo, oscillando attorno al segnale desiderato $ y_r $ prima di stabilizzarsi definitivamente.\nIl tempo necessario affinché la risposta del sistema si stabilizzi attorno all’output desiderato è chiamato “tempo di assestamento”. Un tempo di assestamento inferiore indica una risposta del sistema più rapida, spesso definita “velocità di risposta”.\n\n\nPrecisione allo stato stazionario\nUna volta che il sistema si è stabilizzato, è fondamentale verificare la differenza tra la variabile controllata effettiva $ y $ e il segnale desiderato $ y_r $. Questa differenza è l’errore allo stato stazionario e minimizzare questo errore è una misura della precisione allo stato stazionario del sistema.\n🤔 Domanda popup: Cos’è l’errore di stato stazionario? Risposta: L’errore a regime è la differenza tra la variabile controllata effettiva e il segnale desiderato una volta che il sistema si è stabilizzato.\n\n\nOscillare o non oscillare?\nUna domanda chiave nei sistemi di controllo! Le oscillazioni possono essere utili in quanto possono aumentare la velocità di risposta. Tuttavia, ampie oscillazioni potrebbero portare alla saturazione del sistema o addirittura danneggiare i componenti.\nUna risposta oscillatoria può essere il segno di un sistema poco smorzato, che può avere una buona velocità di risposta ma rischia di andare oltre. Un sistema sovrasmorzato, d’altra parte, potrebbe avere una risposta più lenta ma non supererà l’uscita desiderata.\n🤔Domanda popup: Quali potrebbero essere i rischi di un sistema poco smorzato?\nRisposta: un sistema sottosmorzato può avere una risposta più rapida ma rischia di superare l’uscita desiderata e potrebbe portare a grandi oscillazioni, che possono danneggiare i componenti del sistema o portare alla saturazione del sistema.\nD’altro canto, un sistema fortemente smorzato o sovrasmorzato potrebbe sopprimere le oscillazioni e impiegare più tempo per raggiungere lo stato stazionario. Ciò si traduce in una velocità di risposta più lenta. Pertanto, nel design si cerca spesso un equilibrio o un compromesso.\nIl cliente potrebbe semplicemente dirti: “questa è l’ampiezza massima della risposta e questa è la velocità di risposta, e sarà tua responsabilità come ingegnere di controllo modellare la risposta dinamica per soddisfare i vincoli sull’ampiezza di ingresso/uscita e velocità di risposta (e qualsiasi altra tu possa avere).”\n\n\nTempo di assestamento - illustrazione\nPer chiarire, immagina due risposte:\n\nRisposta smorzata: impiega più tempo a stabilizzarsi, ma senza oscillazioni.\nRisposta poco smorzata: assesta più velocemente, ma con oscillazioni.\n\nIl tempo impiegato da ciascun sistema per stabilizzarsi entro un certo intervallo accettabile (come 2% o 5%) attorno al valore di stato stazionario definisce il tempo di assestamento. Questa definizione aiuta i progettisti a determinare se il sistema soddisfa i requisiti dell’utente.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time array\nt = np.linspace(0, 10, 1000)\n\n# Overdamped Response\n# Parameters for the overdamped system\na1, a2 = .5, 1\ny_overdamped = 1 - np.exp(-a1 * t)\n\n# Underdamped Response\n# Parameters for the underdamped system\nomega_d = 1.5  # damped frequency\nzeta = 0.2  # damping ratio (zeta &lt; 1 for underdamped)\ny_underdamped = 1- np.exp(-zeta * omega_d * t) * np.cos(omega_d * t)\n\nomega_d = 1.5  # damped frequency\nzeta = 0.05  # damping ratio (zeta &lt; 1 for underdamped)\ny_underdamped_1 = 1- np.exp(-zeta * omega_d * t) * np.cos(omega_d * t)\n\n\n# Create plots\nplt.figure(figsize=(12, 6))\n\n# Overdamped plot\nplt.subplot(1, 2, 1)\nplt.plot(t, y_overdamped, label='Overdamped')\nplt.title('Overdamped Response')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\n\n# Underdamped plot\nplt.subplot(1, 2, 2)\nplt.plot(t, y_underdamped, label=r'Underdamped $\\zeta=0.2$', color='r')\nplt.plot(t, y_underdamped_1, label=r'Underdamped $\\zeta=0.05$', color='g')\nplt.title('Underdamped Response with Oscillations')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.grid(True)\nplt.legend()\n\n# Display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPrecisione allo stato stazionario\nRequisito finale che consideriamo.\nL’accuratezza allo stato stazionario si riferisce alla capacità di un sistema (spesso un sistema di controllo) di raggiungere con precisione il valore di uscita desiderato (o set-point) allo stato stazionario, cioè dopo che eventuali effetti transitori sono diminuiti e il sistema si è stabilizzato. È una misura di quanto l’output in stato stazionario di un sistema è vicino al suo valore desiderato.\nNei sistemi di controllo, gli errori in stato stazionario sono specifiche comuni per valutare la capacità di un sistema di tracciare un ingresso di riferimento, come ingressi a gradino, rampa o parabolici. L’errore allo stato stazionario è la differenza tra l’output effettivo e l’output desiderato quando il tempo si avvicina all’infinito (dopo che tutti i comportamenti transitori sono scomparsi).\n\n\nConflitto nei requisiti di progettazione\nRaggiungere una progettazione ottimale è complesso a causa dei conflitti tra vari requisiti. Ad esempio:\n\nIl miglioramento della precisione in stato stazionario (che in genere comporta l’introduzione di azioni di controllo integrale) potrebbe comportare oscillazioni più ampie o addirittura instabilità.\nIl filtraggio dei disturbi potrebbe aumentare gli effetti del rumore sul sistema.\n\nDiventa evidente che questi requisiti non sono sempre armoniosi. Raggiungere uno potrebbe comprometterne un altro. Ecco perché il ruolo del progettista di sistema è così cruciale; devono trovare il giusto equilibrio tra questi requisiti contrastanti.\n🤔 Domanda popup: Perché non riusciamo sempre a soddisfare i requisiti migliori nella progettazione dei sistemi di controllo?\nRisposta: molti requisiti di progettazione sono in conflitto. Ad esempio, il miglioramento della precisione in stato stazionario potrebbe portare a oscillazioni o instabilità maggiori. Pertanto, è necessario un equilibrio e raggiungere il migliore dei mondi potrebbe non essere possibile.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#feedback-e-sistemi-a-circuito-aperto-nellanalisi-di-sensibilità",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#feedback-e-sistemi-a-circuito-aperto-nellanalisi-di-sensibilità",
    "title": "Principi di controllo del feedback",
    "section": "Feedback e sistemi a circuito aperto nell’analisi di sensibilità",
    "text": "Feedback e sistemi a circuito aperto nell’analisi di sensibilità\nI sistemi di feedback e ad anello aperto sono concetti fondamentali nell’ingegneria di controllo. In questa parte del quaderno approfondiremo l’analisi di sensitività di questi sistemi. L’analisi della sensibilità ci aiuta a capire come piccoli cambiamenti nei parametri del sistema possono influire sulle prestazioni complessive.\n\nRiepilogo rapido:\nSistema di feedback (sistema a circuito chiuso): un sistema in cui una parte dell’output viene restituita all’input per regolarne il comportamento.\nSistema a circuito aperto: un sistema che funziona senza considerare alcun feedback dal suo output.\nOra, sveliamo i problemi di sensibilità legati a questi sistemi.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#analisi-di-sensibilità",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#analisi-di-sensibilità",
    "title": "Principi di controllo del feedback",
    "section": "Analisi di sensibilità",
    "text": "Analisi di sensibilità\nLa sensibilità, nel contesto dei sistemi, si riferisce alla misura di come un cambiamento in un parametro di sistema influisce sulle prestazioni del sistema.\nMatematicamente, consideriamo $ J $ una misura di prestazione come la velocità di risposta, che è funzione di un parametro $ $ dell’impianto.\nSupponendo che $ $ abbia un valore nominale $ _n $ con una deviazione $ $, la sensibilità riguarda l’impatto delle piccole variazioni di $ $ su $ J $.\nIl valore nominale della tua prestazione (ad esempio, velocità di risposta) è:\n\\[\nJ_n = J( \\theta_n )\n\\]\nPoiché la sensibilità riguarda variazioni differenzialmente piccole, possiamo utilizzare l’espansione in serie di Taylor per \\(J\\) attorno al suo punto nominale.\nUtilizzando lo sviluppo in serie di Taylor, l’effetto delle variazioni di $ $ su $ J $ può essere rappresentato come:\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta + \\text{termini di ordine superiore }\n\\]\nPer la nostra analisi, trascuriamo i termini di ordine superiore, considerando solo la variazione del primo ordine, e quindi la nostra equazione diventa:\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#definizione-di-sensibilità-quantitativa",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#definizione-di-sensibilità-quantitativa",
    "title": "Principi di controllo del feedback",
    "section": "Definizione di sensibilità quantitativa",
    "text": "Definizione di sensibilità quantitativa\nLa sensibilità di $ J $ rispetto alle variazioni di $ $, simboleggiate da $ S^J_{} $, è definita come:\n\\[ S^J_{\\theta} = \\frac{\\Delta J / J_n}{\\Delta \\theta / \\theta_n} \\]\nQuesta formula rappresenta un modello di sensibilità input-output.\n\nQui $ / _n $ può essere considerato come input e $ J / J_n $ come output.\nQuesta funzione di sensibilità $ S^J_{} $ aiuta a determinare come il sistema risponde a varie variazioni di $ / _n $.\n\n\n\n\n\n\nUna volta disponibile il modello $ S^J_{} $, diventa un esercizio di simulazione per comprendere l’impatto delle variazioni dei parametri sulle prestazioni. Esattamente come lo facciamo per la pianta.\nSi noti che daremo variazioni finite ai parametri anche se il nostro modello è sviluppato per cambiamenti differenzialmente piccoli. Questo modello fortunatamente funziona anche per variazioni finite piccole.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/principles_of_feedback_control_it.html#sistema-di-feedback-e-sensibilità",
    "href": "IT_🇮🇹/principles_of_feedback_control_it.html#sistema-di-feedback-e-sensibilità",
    "title": "Principi di controllo del feedback",
    "section": "Sistema di feedback e sensibilità",
    "text": "Sistema di feedback e sensibilità\nCalcoliamo il nostro modello.\nDa\n\\[\nJ(\\theta_n + \\Delta \\theta) = J(\\theta_n) + \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]\notteniamo che:\n\\[\n\\Delta J = J(\\theta_n + \\Delta \\theta) - J(\\theta_n) = \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Delta \\theta\n\\]\nE quindi:\n\\[\nS^J_{\\theta} = \\frac{\\Big [ \\frac{d J}{d \\theta} \\Big|_{\\theta = \\theta_n} \\Delta \\theta \\Big]/J_n }{\\Delta \\ theta / \\theta_n} = \\Big [ \\frac{d J}{d \\theta} \\Bigg|_{\\theta = \\theta_n} \\Big]\\frac{\\theta_n}{J_n}\n\\]\nPer un sistema specifico dovrai valutare \\(\\frac{d J}{d \\theta} \\Big|_{\\theta = \\theta_n}\\), \\(\\theta_n\\) e \\(J_n\\) sono i valori nominali.\n\nEffetto del feedback sulla sensibilità\nData la nostra comprensione della sensibilità, esaminiamo l’effetto del feedback sulla sensibilità. Per questo, considera il ciclo di feedback di base (assumi che non ci siano disturbi):\n\n\n\n\n\nLa funzione di trasferimento di questo sistema è:\n\\[\nM = \\frac{Y}{R} = \\frac{D \\cdot G}{1 + D \\cdot G \\cdot H}\n\\]\nAnalisi:\n\nI parametri del controller $ D $ sono sotto il nostro controllo (è un sistema aperto quello che progettiamo), mentre $ G $ e $ H $ (hardware del sistema) potrebbero cambiare.\nPer capire come le variazioni di $ G $ (o $ H $) influenzano l’output $ Y $, possiamo derivare due funzioni di sensibilità:\n\n\\[ S^M_{G} \\] e \\[ S^M_{H} \\]\nSia \\(G\\) che \\(H\\) dipendono dalle variazioni dei parametri: - \\(G\\) è una funzione di \\(\\theta\\), \\(G(\\theta)\\) e - \\(H\\) è una funzione di \\(\\alpha\\), \\(H(\\alpha)\\).\nVorremmo studiare: - l’effetto delle variazioni di \\(\\theta\\) su \\(Y\\) (usando \\(S^M_{G}\\)): equivalente a studiare gli effetti delle variazioni di \\(G\\) su \\(M\\) - l’effetto delle variazioni di \\(\\alpha\\) su \\(Y\\) (usando \\(S^M_{H}\\)): equivalente a studiare gli effetti delle variazioni di \\(H\\) su \\(M\\)\nA questo punto, esplicitando la presenza del parametro \\(\\theta\\) possiamo scrivere:\n\\[\nM(\\theta_n, s) = \\frac{D(s)G(\\theta_n,s)}{1 + D(s) \\cdot G(\\theta_n, s) \\cdot H(s)}\n\\]\nUtilizzando la definizione di sensibilità, possiamo ora calcolare la sensibilità di $ M $ rispetto a $ G $, \\(S^M_{G}\\).\nPer prima cosa dobbiamo calcolare:\n\\[\n\\begin{align}\n\\frac{dM}{d\\theta}\\Bigg|_{\\theta = \\theta_n} = \\frac{D}{(1+D\\cdot G\\cdot H)^2}\\frac{dG(\\theta, s)}{d\\theta}\\Bigg|_{\\theta=\\theta_n}\n\\end{align}\n\\]\nDa questa espressione possiamo trovare \\(S^M_{G}\\).\nPer prima cosa possiamo convertire le modifiche differenziali in modifiche finite e calcolare \\(\\frac{\\Delta M}{M}\\) - dividendo l’espressione precedente (1) per \\(M\\):\n\\[\n\\frac{\\Delta M}{M} \\Bigg|_{\\theta=\\theta_n} = \\frac{D}{1+D\\cdot G\\cdot H} \\times \\frac{1+D\\cdot G\\ cdot H}{DG} \\frac{dG}{d\\theta}\\Bigg|_{\\theta=\\theta_n} = \\frac{1}{1+D\\cdot G\\cdot H}\\frac{dG}{ G}\\Bigg|_{\\theta=\\theta_n}\n\\]\nda questa espressione possiamo ottenere:\n\\[\nS^M_{G} = S(\\theta_n, s) = \\frac{1}{1 + D(s) \\cdot G(\\theta_n,s) \\cdot H(s)}\n\\]\nChe si ottiene semplicemente dividendo \\(\\frac{\\Delta M}{M}\\) per \\(\\frac{dG}{G}\\).\n\nCommenti\n\nDall’espressione precedente l’interpretazione è chiara: controllando opportunamente il guadagno del controller $ D \\(, possiamo regolare il guadagno dell'anello (\\)D(s) G(_n,s) H(s) $) e quindi ridurre la sensibilità al livello desiderato. In sostanza, un guadagno del circuito più elevato si traduce in una sensibilità inferiore.\n$ D(s) $ rappresenta il controller. La particolarità di $ D(s) $ è che è sotto il nostro controllo; possiamo modificarlo secondo le nostre esigenze.\nControllando abilmente il guadagno di $ D $, possiamo manipolare questo guadagno del circuito per regolare la sensibilità del sistema come desiderato. Il principio di base è semplice: maggiore è il guadagno del circuito, minore è la sensibilità del sistema.\n\n🤔 Domanda popup: Qual è la sensibilità di un sistema a circuito aperto? Risposta: In un sistema a ciclo aperto, poiché non c’è feedback, $ H = 0 $. Pertanto, la sensibilità del sistema rispetto a $ G $ sarebbe 1, indicando che qualsiasi variazione di $ G $ si tradurrebbe in una variazione proporzionale nella produzione.\nSensibilità dei sistemi ad anello aperto e ad anello chiuso Sorge una domanda chiave: qual è la sensibilità di un sistema a circuito aperto? Per capirlo, valutiamo il diagramma di feedback.\nNello scenario in cui $ H $ è impostato a zero (cioè $ H = 0 $), eliminando di fatto il ciclo di feedback, la sensibilità del sistema rispetto a $ G $ diventa 1:\n\\[\nS^M_{G} = 1\\;\\;\\; \\text{per il sistema a ciclo aperto}\n\\]\nQuesta conclusione può essere derivata dalla nostra espressione iniziale. Quando si elimina $ H $, l’espressione indica chiaramente che la sensibilità è pari a 1.\nCiò indica una comprensione fondamentale: un sistema a ciclo aperto è altamente sensibile alle variazioni di $ G $ con una sensibilità pari a 1.\nTuttavia, qui emerge la bellezza del controllo del feedback. Progettando giudiziosamente il controllo del feedback, in particolare il controller $ D(s) $, possiamo gestire e ridurre questa sensibilità secondo le nostre esigenze.\nSensibilità rispetto al Sensore\nApprofondiamo un’altra dimensione della sensibilità: la sensibilità di $ M $ rispetto a $ H $, il sensore.\nLa sensibilità di $ M $ rispetto a $ H $ può essere espressa come (la sua derivazione è lasciata al lettore):\n\\[ S^M_{H} = \\frac{-D(s) \\cdot G(s) \\cdot H(s)}{1 + D(s) \\cdot G(s) \\cdot H(\\alpha, s)} \\]\n\nAumentando il guadagno dell’anello diminuisce la sensibilità del sistema alle variazioni dei parametri dell’impianto. Ciò significa però anche che il sistema diventa molto sensibile alle variazioni dei parametri del sensore.\nQuando il guadagno del loop aumenta \\(S^M_{H}\\rightarrow 1\\).\n\n🤔 Domanda popup: Come cambia la sensibilità del sistema con variazioni di $ H $ (quando aumentiamo il guadagno del loop)?\nRisposta: Il sistema diventa più sensibile al sensore man mano che aumenta il guadagno del circuito. L’entità della sensibilità si avvicina a 1.\nCiò significa che introducendo un sensore nel sistema, abbiamo inavvertitamente introdotto anche un potenziale punto di elevata sensibilità. Ciò sottolinea l’importanza del design del sensore. La progettazione dell’hardware deve tenere conto dei problemi di sensibilità, garantendo che il sensore sia appropriato per l’impianto specifico in esame.\nSull’importanza della progettazione dei sensori L’introduzione del meccanismo di feedback, pur essendo cruciale per il controllo, porta con sé la sfida della sensibilità dovuta alle variazioni dei parametri del sensore. Ciò sottolinea la necessità di una progettazione meticolosa del sensore.\nTieni presente che ciò è dovuto al fatto che abbiamo un sensore per chiudere il circuito. L’introduzione del feedback ha portato un potenziale nuovo problema. Ciò significa che quando selezioniamo un sensore dobbiamo assicurarci che i parametri del sensore non cambieranno.\nSebbene modificare un impianto, spesso un vasto ambiente industriale, sia un compito arduo, se non impossibile, modificare un sensore è più fattibile. Pertanto, la progettazione del sensore deve essere tale che i suoi parametri rimangano coerenti e affidabili. In caso contrario, il sensore potrebbe introdurre sfide impreviste nel circuito, minando potenzialmente l’intero sistema di controllo.\nVale la pena notare che nelle applicazioni industriali il costo per la modifica di un intero impianto può essere esorbitante, ma i sensori sono componenti relativamente più economici e più flessibili. Pertanto, investire tempo e risorse nel perfezionamento della progettazione del sensore ripaga nel lungo termine.\n🤔 Domanda popup: Perché la progettazione del sensore è così cruciale nei sistemi di controllo?\nRisposta: Perché l’introduzione del feedback rende il sistema altamente sensibile al sensore e garantire che i parametri del sensore non cambino è spesso più fattibile che modificare un intero impianto.\n\n\n\n\nBarra laterale - derivata di \\(M\\) rispetto a \\(\\theta\\)\nData la funzione $ M(, s) $ come:\n$ M(, s) = $\nVuoi la derivata parziale rispetto a $ $.\n\nDifferenziare un quoziente: se hai una funzione $ f(x) = $, la sua derivata è data da\n\n$ f’(x) = $\nDove $ u’ $ e $ v’ $ sono rispettivamente le derivate di $ u $ e $ v $.\n\nOra, applicandolo alla nostra funzione, lasciamo:\n\n\\[ u(\\theta, s) = D(s)G(\\theta,s) \\]\n\\[ v(\\theta, s) = 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\]\nAllora le derivate parziali sono:\n\\[ \\frac{\\partial u}{\\partial \\theta} = D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\]\nPoiché $ D(s) $ non è una funzione di $ $.\n\\[ \\frac{\\partial v}{\\partial \\theta} = D(s) \\cdot H(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\]\nAncora una volta, questo è dovuto al fatto che solo $ G(,s) $ dipende da $ $.\n\nOra, inseriscili nella nostra regola del quoziente:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{\\left( D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\right) \\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right) - \\left( D(s)G(\\theta,s) \\right) \\left( D(s) \\cdot H(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} \\right)}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\n\nOra, semplificando, otteniamo:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} + D (s)^2 \\frac{\\partial G(\\theta,s)}{\\partial \\theta} G(\\theta, s) H(s) - D(s)^2 G(\\theta,s) H (s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta}}{\\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right )^2} \\]\n\nCombinazione dei termini con fattori comuni:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta} (1 + D(s) G(\\theta, s) H(s) - D(s) G(\\theta,s) H(s))}{\\left( 1 + D(s) \\cdot G(\\theta , s) \\cdot H(s) \\right)^2} \\]\n\nContinuando a semplificare:\n\n\\[ \\frac{\\partial M(\\theta, s)}{\\partial \\theta} = \\frac{D(s) \\frac{\\partial G(\\theta,s)}{\\partial \\theta}}{ \\left( 1 + D(s) \\cdot G(\\theta, s) \\cdot H(s) \\right)^2} \\]\nQuesta è la derivata parziale di $ M(, s) $ rispetto a $ $.\n– FINE DELLA BARRA LATERALE",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_systems_and_their_effects_it.html",
    "href": "IT_🇮🇹/feedback_systems_and_their_effects_it.html",
    "title": "Sistemi di feedback e loro effetti",
    "section": "",
    "text": "Con questo notebook esploreremo più in profondità i principi base del controllo del feedback. Ricordiamo le nostre precedenti discussioni sui problemi di sensibilità e robustezza nei sistemi di controllo. Ora approfondiremo questo argomento con maggiore dettaglio.\nDiagramma a blocchi di base\nDobbiamo prima tracciare lo schema a blocchi di base. Ecco una descrizione:\nQuesto ci dà il segnale di errore $e$ e il segnale di controllo $u$.\nIl segnale di errore, indicato come \\(e_{cap}\\), e il segnale di controllo, rappresentato come \\(u\\), sono parti intrinseche di questo diagramma.\nLa relazione tra l’output \\(y\\) e l’input di riferimento \\(r\\) può essere espressa come il rapporto \\(\\frac{Y(s)}{R(s)}\\). Questa relazione è indicata con \\(M(s)\\) ed è data dalla seguente equazione:\n\\[\nM(s)=\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1 + D(s)G(s)H(s)}\n\\]\nQuesta equazione rappresenta la funzione di trasferimento complessiva del sistema a circuito chiuso.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di feedback e loro effetti"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#modellazione-della-risposta-dinamica-nei-sistemi-di-controllo-del-feedback",
    "href": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#modellazione-della-risposta-dinamica-nei-sistemi-di-controllo-del-feedback",
    "title": "Sistemi di feedback e loro effetti",
    "section": "Modellazione della risposta dinamica nei sistemi di controllo del feedback",
    "text": "Modellazione della risposta dinamica nei sistemi di controllo del feedback\nRicordare che quando si parla di modellazione della risposta dinamica si stabiliscono i requisiti sulla risposta in stato transitorio e stazionario del sistema.\nAd esempio, nel notebook 13_Principles_of_Feedback_Control, abbiamo visto che potremmo desiderare una risposta oscillatoria o una risposta sovrasmorzata (a seconda dell’applicazione):\n\n\n\n\n\n\nModellare la risposta dinamica\nConsideriamo la funzione di trasferimento di un sistema ad anello chiuso:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1+D(s)G(s)H(s)}\n\\]\nLa risposta dinamica di un sistema è influenzata in modo significativo dai suoi poli e dai suoi zeri.\nRicordiamo, i poli di un sistema determinano la natura della risposta del sistema, come il comportamento oscillatorio o non oscillatorio, mentre gli zeri influenzano l’entità di queste risposte.\n\nFunzione di trasferimento e poli e zeri del sistema\n\nPoli: determinano la natura della risposta del sistema (oscillatoria, non oscillatoria, di primo ordine, di secondo ordine, ecc.).\nZeri: influenza l’entità della risposta. Ad esempio, gli zeri influenzano solo il residuo dell’espansione della frazione parziale.\n\nEsempio: - Un polo del primo ordine (ad esempio, $$) influisce sulla velocità di risposta del sistema. - Uno zero influenza l’ampiezza (\\(A_1\\)) di una modalità specifica nella risposta.\n\n\n\nEsempio\nConsideriamo due risposte all’impulso:\n\nRisposta rapida: se \\(\\tau\\) è piccolo, la risposta si stabilizza rapidamente.\nRisposta lenta: se \\(\\tau\\) è grande, la risposta richiede più tempo per stabilizzarsi.\n\nPossiamo creare grafici per mostrare l’impatto della variazione dei valori di polo e zero sulla risposta di un sistema utilizzando Python, in particolare con librerie come Matplotlib e SciPy.\nEcco uno schema concettuale di come potremmo strutturare il nostro codice Python per generare questi grafici:\n\nConfigura l’ambiente: importa le librerie necessarie.\nDefinisci le funzioni di trasferimento: crea funzioni per rappresentare funzioni di trasferimento con poli e zeri variabili.\nSimula la risposta: utilizza la funzione di risposta al gradino per simulare il modo in cui il sistema risponde nel tempo.\nTraccia le risposte: utilizza Matplotlib per creare grafici che mostrano la risposta del sistema.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import TransferFunction, impulse, step\n\ndef plot_responses(systems, title):\n    plt.figure(figsize=(10, 6))\n    for sys, label, color in systems:\n        t_imp, y_imp = impulse(sys)\n        t_step, y_step = step(sys)\n        plt.plot(t_imp, y_imp, label=f'Impulse - {label}', linestyle='--', color=color)\n        #plt.plot(t_step, y_step, label=f'Step - {label}', linestyle='-', color=color)\n\n    plt.title(title)\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \ndef print_transfer_function(sys, label):\n    num, den = sys.num, sys.den\n    tf_expression = ' + '.join([f'{n}s^{len(num)-i-1}' for i, n in enumerate(num)])\n    tf_expression += ' / '\n    tf_expression += ' + '.join([f'{d}s^{len(den)-i-1}' for i, d in enumerate(den)])\n    print(f'{label}: {tf_expression}')\n    \n\n# User specified poles and zeros for first order systems\n# Example 1\npole1 = [-3]\nzero1 = []  # No zero\n\npole2 = [-5]\nzero2 = []  # No zero\n\n# Example 2\n# Compare what happens to the impulse response when we have the same pole but different zeros.\n# pole1 = [-5]\n# zero1 = [-1]  # Zero in -1\n\n# pole2 = [-5]\n# zero2 = [-2]  # Zero in -2\n\n\n# Creating transfer function systems\nsystem1 = TransferFunction(np.poly(zero1), np.poly(pole1))\nsystem2 = TransferFunction(np.poly(zero2), np.poly(pole2))\n\nprint_transfer_function(system1, 'System 1')\nprint_transfer_function(system2, 'System 2')\n\n# Plotting\nplot_responses([\n    (system1, 'System with Pole at s=-3', 'blue'),\n    (system2, 'System with Pole at s=-5 and Zero at s=0', 'red')\n], 'Comparison of First Order Systems')\n\nSystem 1: 1.0s^0 / 1.0s^1 + 3.0s^0\nSystem 2: 1.0s^0 / 1.0s^1 + 5.0s^0\n\n\n\n\n\n\n\n\n\n\nBarra laterale - Effetto degli zeri sulla risposta all’impulso\nIl comportamento della risposta all’impulso in un sistema con zeri è strettamente legato alla funzione di trasferimento del sistema, in particolare al modo in cui interagiscono gli zeri e i poli. Parliamo del motivo per cui la risposta all’impulso inizia da un numero negativo quando si ha uno zero e di come la posizione dello zero influisce su questo comportamento.\n\nImpatto degli zeri sulla risposta all’impulso:\n\nIn una funzione di trasferimento, uno zero introduce essenzialmente un termine al numeratore che può cambiare la fase della risposta del sistema. Quando viene applicato un impulso, la risposta immediata del sistema è influenzata dal numeratore della funzione di trasferimento.\nSe uno zero è posto sulla metà sinistra del piano s (parte reale negativa), tende a introdurre uno sfasamento che può far sì che la risposta all’impulso parta da un valore negativo.\n\nPosizione dello zero e della risposta:\n\nL’effetto di uno zero sulla risposta all’impulso non riguarda solo la sua presenza ma anche la sua posizione rispetto ai poli.\nPiù lo zero è vicino all’origine (o al polo), più significativo è il suo impatto sulla risposta iniziale. Tuttavia, il segno dello zero (che sia -1 o 1) non cambia la direzione iniziale della risposta. Ciò che conta di più è la posizione relativa dello zero rispetto ai poli.\n\nRisposta positiva all’impulso iniziale:\n\nPer avere una risposta all’impulso che parta da un numero positivo, è necessario posizionare lo zero in modo tale che non domini la risposta iniziale del sistema. Ciò significa tipicamente posizionare lo zero più lontano dall’origine rispetto a qualsiasi polo, in particolare in un sistema del primo ordine.\n\nComprensione attraverso la sperimentazione:\n\nPuoi sperimentare il posizionamento dello zero nella tua funzione di trasferimento per osservare come influisce sulla risposta all’impulso. Spostare lo zero ulteriormente nel semipiano sinistro (più negativo) spesso riduce il suo impatto immediato sulla risposta all’impulso.\n\n\nEcco un rapido esperimento Python che puoi provare per osservare questi effetti. Regola il valore “zero2” nel seguente frammento di codice per vedere come i diversi posizionamenti influenzano la risposta all’impulso:\n\nfrom scipy.signal import TransferFunction, impulse\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef create_system(pole, zero):\n    if zero:  # If zero list is not empty\n        numerator = np.poly(zero)\n    else:  # If zero list is empty, use a gain of 1\n        numerator = [1]\n    denominator = np.poly(pole)\n    return TransferFunction(numerator, denominator)\n\npole = [-3]\n# Place zeros at different locations and observe\nzero1 = []  # Zero at -1\nzero2 = [-10]    # No zero\n\n# Creating transfer function systems\nsystem1 = create_system(pole, zero1)\nsystem2 = create_system(pole, zero2)\n\n# Generating impulse responses\nt1, y1 = impulse(system1)\nt2, y2 = impulse(system2)\n\n# Plotting\nplt.plot(t1, y1, label=f'System with Zero at {zero1}')\nplt.plot(t2, y2, label=f'System with Zero at {zero2}')\nplt.title('Impulse Response of Systems with Different Zero Locations')\nplt.xlabel('Time')\nplt.ylabel('Response')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n— FINE DELLA BARRA LATERALE\n\n\n\nRuolo del feedback nel modellare la risposta dinamica\nConsideriamo la funzione di trasferimento di un sistema ad anello chiuso:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1+D(s)G(s)H(s)}\n\\]\nConsideriamo $D(s)$, $G(s)$ e $H(s)$ come rapporti di due polinomi:\n\\[\nD(s) = \\frac{D_1}{D_2}, \\quad G(s) = \\frac{G_1}{G_2}, \\quad H(s) = \\frac{H_1}{H_2}\n\\]\nSostituendoli nella nostra funzione di trasferimento \\(M(s)\\):\n\\[\nM(s) = \\frac{D_1 G_1 H_1}{D_2 G_2 H_2 + D_1 G_1 H_1}\n\\]\n\nModellare la risposta dinamica significa renderla diversa da quella in anello aperto.\nLa risposta ad anello aperto è guidata da \\(G_2(s)\\), ovvero i poli di \\(G\\). Ciò significa che i poli di \\(G\\) non sono accettabili date le tue esigenze.\n\n\nProgettare il controller per la dinamica desiderata\n\nObiettivo: modificare i poli del sistema a circuito chiuso per ottenere una risposta dinamica specifica.\nStrategia: regola il controller ($D_1$ e $D_2$) per ottenere la posizione dei poli desiderata per $M(s)$.\n\nPossiamo modificare $D_1$ e $D_2$ in modo che le radici del denominatore \\(D_2 G_2 H_2 + D_1 G_1 H_1\\) si trovino in posizioni adatte nel piano \\(s\\).\n\n\n\nProblema di progettazione\nObiettivo: tradurre la risposta dinamica desiderata in specifiche posizioni dei poli.\nPassaggi: 1. Determinare le posizioni dei poli corrispondenti alla risposta dinamica desiderata. 2. Progettare $D_1$ e $D_2$ nel controller per realizzare queste posizioni dei poli nel sistema a circuito chiuso.\nSupponiamo che desideri avere questa risposta dinamica:\n\n\n\n\n\nLa strategia progettuale sarebbe quella di posizionare i poli dove possiamo ottenere la risposta desiderata. Attraverso la progettazione di \\(D(s)\\) del controller, saremo in grado di spostare i poli del sistema ad anello chiuso nella posizione desiderata in modo che la risposta dinamica sia quella che desideriamo.\nÈ possibile modellare la risposta dinamica progettando opportunamente il controllore (e quindi il numeratore e il denominatore) in modo che i poli in anello chiuso di \\(M(s)\\) siano quelli della forma dinamica richiesta.\n🤔 Domanda pop-up: Perché non possiamo ottenere la dinamica desiderata attraverso il controllo a circuito aperto? Risposta: Sebbene il controllo ad anello aperto possa teoricamente ottenere la dinamica desiderata (posizionando i poli dove vorremmo), non ha la capacità di adattarsi ai cambiamenti dei parametri del sistema nel tempo, portando a potenziale instabilità e prestazioni degradate.\n\n\nI limiti del controllo ad anello aperto nella modellatura dinamica\n\n\n\n\n\nI poli di \\(G(s)\\) non sono accettabili, non ci danno la risposta desiderata. Vorremmo spostare i poli là dove ci danno la risposta che vogliamo.\n\nStrategia di controllo ad anello aperto\n\nIdea: cancella i poli di $G(s)$ e sostituiscili con i poli desiderati.\nImplementazione: Progettare $D(s)$ in modo tale da annullare i poli di $G(s)$ e introdurre i poli prescritti.\n\n\\[\nD(s) = \\frac{1}{G(s)} \\times \\hat{D}(s)\n\\]\nDove \\(\\hat{D}(s)\\) ha i poli desiderati, ad esempio:\n\\[\n\\hat{D}(s) = \\frac{1}{s^2 + 2\\xi\\omega_n s + \\omega_n^2}\n\\]\nIn questo caso,\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{1}{s^2 + 2\\xi\\omega_n s + \\omega_n^2}\n\\]\nChe è esattamente ciò che vogliamo.\nQuesto è il modo più ovvio per raggiungere il nostro obiettivo. Tuttavia, non scegliamo mai questa soluzione… perché?\n\n\nSfide con il controllo a circuito aperto\n\nGap modello-impianto: Il controller progettato sulla base di $G(s)$ potrebbe non annullare in modo efficace la dinamica dell’impianto fisico reale. Possiamo utilizzare solo un modello e quindi abbiamo delle imprecisioni, quindi la dinamica dell’impianto non verrà mai annullata. La cancellazione è possibile solo rispetto al modello e non alla pianta. Inoltre, poiché non c’è feedback, il controller non viene a conoscenza di questo errore.\nMancanza di adattabilità: il controller non si adatta ai cambiamenti dei parametri di sistema nel tempo. Se l’impianto cambia nel tempo (e cambierà) questo potrebbe non essere catturato nel modello, il che significa che le prestazioni si deteriorano nel tempo.\nProblemi di robustezza: il controllo ad anello aperto è sensibile ai disturbi e agli errori di modellazione, che portano a potenziale instabilità.\n\nNonostante la complessità, il controllo del feedback è preferito per la sua capacità di gestire la robustezza e la reiezione dei disturbi. La regolazione dei poli a circuito chiuso, sebbene impegnativa, è fondamentale per garantire la stabilità del sistema e le prestazioni desiderate nel tempo.\n🤔 Domanda popup: Perché un controller a circuito aperto, nonostante sembri semplice, non viene spesso utilizzato per la modellazione dinamica? Risposta: i controller a circuito aperto non possono adattarsi ai parametri mutevoli dell’impianto reale nel tempo e qualsiasi divario tra il modello dell’impianto e l’impianto reale può portare a problemi di prestazioni e instabilità.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di feedback e loro effetti"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#precisione-dello-stato-stazionario-nel-controllo-del-feedback",
    "href": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#precisione-dello-stato-stazionario-nel-controllo-del-feedback",
    "title": "Sistemi di feedback e loro effetti",
    "section": "Precisione dello stato stazionario nel controllo del feedback",
    "text": "Precisione dello stato stazionario nel controllo del feedback\nConsideriamo un sistema di controllo con feedback unitario, in cui il fattore di feedback è 1. In questo sistema, il segnale di errore, indicato come $e$, gioca un ruolo critico nel determinare le prestazioni del sistema.\n\n\n\n\n\n\nFunzione di trasferimento e segnale di errore\nLa funzione di trasferimento $Y(s)/R(s)$ per il nostro sistema è data da:\n\\[\n\\frac{Y(s)}{R(s)} = \\frac{D(s)G(s)}{1 + D(s)G(s)}\n\\]\nE la funzione di trasferimento del segnale di errore $E(s)/R(s)$ è:\n\\[\n\\frac{E(s)}{R(s)} = \\frac{1}{1 + D(s)G(s)}\n\\]\nQuesta relazione è cruciale in quanto getta le basi per comprendere l’errore di stato stazionario.\n\n\nTeorema del valore finale ed errore a regime\nUtilizzando il teorema del valore finale, l’errore di stato stazionario $e_{ss}$ è determinato da:\n\\[\ne_{ss} = \\lim_{s \\to 0} sE(s) = \\lim_{s \\to 0} \\frac{sR(s)}{1 + D(s)G(s)} = \\lim_{ t \\to \\infty} e(t)\n\\]\nQuesta equazione mostra come l’errore in stato stazionario è correlato all’input $R(s)$ e alla funzione di trasferimento del sistema.\n\n\nCaso di studio: risposta all’input passo-passo\nAnalizziamo un caso specifico in cui $R(s) = $ (un passo in ingresso).\nPer un input a gradini, l’errore di stato stazionario $e_{ss}$ diventa:\n\\[\ne_{ss} = \\frac{1}{1 + D(0)G(0)}\n\\]\nQui, $D(0)G(0)$ rappresenta il guadagno DC del loop. Questo è il guadagno del loop alle basse frequenze.\n\nProgettando il controller \\(D(s)\\) in modo appropriato, possiamo manipolare questo guadagno per ridurre l’errore in stato stazionario, migliorando così la precisione in stato stazionario.\nAumentando il guadagno dell’anello si ottiene una migliore precisione a regime.\n\n\n\nConfronto con il controllo ad anello aperto\nIn un sistema a circuito aperto, l’errore è: \\[\nE(s) = R(s) - Y(s) = R(s) - D(s)G(s)R(s) = R(s)\\Big[ 1 - D(s)G(s) \\Big]\n\\]\ne quindi l’errore a regime per un ingresso a gradino (\\(R(s) = 1/s\\)) può essere espresso come:\n\\[\ne_{ss} = 1 - D(0)G(0)\n\\]\ndove abbiamo nuovamente applicato il Teorema del Valore Finale.\nÈ interessante notare che, nel controllo ad anello aperto, è possibile eliminare completamente l’errore di stato stazionario impostando $D(0)G(0) = 1$. Tuttavia, questo approccio manca di robustezza e di capacità di reiezione dei disturbi.\nIn anello chiuso possiamo ottenere un errore stazionario nullo solo al limite.\n\n\nOsservazioni conclusive sull’accuratezza dello stato stazionario\nAbbiamo visto che il controllo del feedback, utilizzato principalmente per la sua robustezza e qualità di reiezione dei disturbi, ci consente anche di ottimizzare la precisione dello stato stazionario. Tuttavia, il raggiungimento del perfetto equilibrio tra robustezza, precisione e stabilità richiede un’attenta progettazione e la considerazione di tutti gli aspetti del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di feedback e loro effetti"
    ]
  },
  {
    "objectID": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#guadagno-ad-anello-elevato-vantaggi-e-sfide",
    "href": "IT_🇮🇹/feedback_systems_and_their_effects_it.html#guadagno-ad-anello-elevato-vantaggi-e-sfide",
    "title": "Sistemi di feedback e loro effetti",
    "section": "Guadagno ad anello elevato: vantaggi e sfide",
    "text": "Guadagno ad anello elevato: vantaggi e sfide\nIl guadagno di anello elevato è uno strumento di progettazione fondamentale nel controllo automatico, ma presenta una serie di vantaggi e sfide.\nVantaggi dell’elevato guadagno del loop\n\nRiduzione della sensibilità: l’elevato guadagno del loop riduce la sensibilità del sistema alle variazioni dei parametri.\nRifiuto disturbi: migliora la capacità del sistema di respingere i disturbi esterni.\nPrecisione allo stato stazionario: l’aumento del guadagno del circuito può migliorare la precisione allo stato stazionario del sistema.\n\nSfide e compromessi\n\nProblemi di rumore: un guadagno del loop elevato può amplificare il rumore ad alta frequenza, riducendo il rapporto segnale/rumore.\nVincoli di saturazione e ampiezza di ingresso: un guadagno eccessivo potrebbe causare la saturazione dei componenti del sistema.\nProblemi di stabilità: un guadagno del loop più elevato può rendere il sistema più oscillatorio e incline all’instabilità.\n\nQuesti compromessi evidenziano la complessità della progettazione del sistema di controllo. Raggiungere il giusto equilibrio tra questi fattori è essenziale per ottenere prestazioni ottimali del sistema.\n🤔 Domanda pop-up: Perché non possiamo sempre utilizzare un guadagno del circuito elevato per migliorare le prestazioni del sistema?\nRisposta: sebbene un guadagno di anello elevato migliori la sensibilità, la reiezione dei disturbi e la precisione dello stato stazionario, può introdurre problemi come l’amplificazione del rumore, la saturazione del sistema e problemi di stabilità. Pertanto, è necessario trovare un equilibrio nel design.\n\nNecessità di andare oltre il controllo proporzionale\nUna semplice amplificazione (guadagno) potrebbe non soddisfare tutti i requisiti di controllo (ad esempio, aumentando semplicemente il guadagno dell’amplificatore nel controller $D(s)$), potrebbe non soddisfare tutti i requisiti di controllo. Pertanto, dobbiamo esplorare ulteriori azioni di controllo, vale a dire, per esempio, azioni derivate e integrali.\n\nControllo derivato e integrale\n\nControllo derivativo: comporta l’iniezione di un segnale proporzionale alla derivata dell’errore nel loop.\nControllo integrale: implica l’utilizzo dell’integrale del segnale di errore.\n\nQueste strategie di controllo aiutano a superare i limiti del controllo proporzionale, portando a un sistema di controllo più robusto e versatile.",
    "crumbs": [
      "IT_🇮🇹",
      "Sistemi di feedback e loro effetti"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "",
    "text": "Nella discussione di oggi, approfondiremo i fondamenti dei sistemi di controllo del feedback. Cominciamo con alcuni semplici esempi del mondo reale per illustrare la struttura di feedback sottostante.\n\n\nConsidera un oggetto domestico comune: il serbatoio del WC del bagno. Lo scopo principale di questo sistema è mantenere il livello dell’acqua all’interno del serbatoio.\nObiettivo: controllare il livello dell’acqua nel serbatoio fino a un livello preimpostato.\n\nVariabile controllata: Livello dell’acqua nel serbatoio.\nSegnale di comando: Altezza preimpostata, \\(\\bar{H}\\)\nDisturbo: Deflusso dal serbatoio.\nVariabile manipolata: afflusso al serbatoio.\n\n\n\n\n\n\n\nSe c’è qualche deviazione dal livello dell’acqua desiderato, la differenza (errore, \\(e\\)) attiverà il controller: il meccanismo a galleggiante e leva. Questo controller regola la posizione della valvola, \\(u\\), proporzionale al segnale di errore.\n\\[\nu = \\frac{l_1}{l_1+l_2}e = Ke\n\\]\nMan mano che l’acqua entra, l’errore diminuisce, fino a raggiungere lo zero, provocando la chiusura della valvola. Nota che possiamo cambiare \\(K\\) cambiando la posizione del punto \\(B\\).\n\n\n\n\n\n\n\n\n\no in una forma più generale:\n\n\n\n\n\n\nDa Raymond T. Stefani, Bahram Shahian e Clement J. Savant, “Design of feedback control Systems”, 4a edizione, Oxford University Press, 2001.\nSi noti che il disturbo è l’acqua che fuoriesce dal serbatoio dell’acqua.\nTerminologia: - Set-point: segnale di comando costante - Regolatore: sistema di controllo che mira a mantenere la variabile controllata al set-point.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html#nozioni-di-base-sul-controllo-del-feedback",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html#nozioni-di-base-sul-controllo-del-feedback",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "",
    "text": "Nella discussione di oggi, approfondiremo i fondamenti dei sistemi di controllo del feedback. Cominciamo con alcuni semplici esempi del mondo reale per illustrare la struttura di feedback sottostante.\n\n\nConsidera un oggetto domestico comune: il serbatoio del WC del bagno. Lo scopo principale di questo sistema è mantenere il livello dell’acqua all’interno del serbatoio.\nObiettivo: controllare il livello dell’acqua nel serbatoio fino a un livello preimpostato.\n\nVariabile controllata: Livello dell’acqua nel serbatoio.\nSegnale di comando: Altezza preimpostata, \\(\\bar{H}\\)\nDisturbo: Deflusso dal serbatoio.\nVariabile manipolata: afflusso al serbatoio.\n\n\n\n\n\n\n\nSe c’è qualche deviazione dal livello dell’acqua desiderato, la differenza (errore, \\(e\\)) attiverà il controller: il meccanismo a galleggiante e leva. Questo controller regola la posizione della valvola, \\(u\\), proporzionale al segnale di errore.\n\\[\nu = \\frac{l_1}{l_1+l_2}e = Ke\n\\]\nMan mano che l’acqua entra, l’errore diminuisce, fino a raggiungere lo zero, provocando la chiusura della valvola. Nota che possiamo cambiare \\(K\\) cambiando la posizione del punto \\(B\\).\n\n\n\n\n\n\n\n\n\no in una forma più generale:\n\n\n\n\n\n\nDa Raymond T. Stefani, Bahram Shahian e Clement J. Savant, “Design of feedback control Systems”, 4a edizione, Oxford University Press, 2001.\nSi noti che il disturbo è l’acqua che fuoriesce dal serbatoio dell’acqua.\nTerminologia: - Set-point: segnale di comando costante - Regolatore: sistema di controllo che mira a mantenere la variabile controllata al set-point.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html#sistema-di-controllo-della-guida-dellautomobile",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html#sistema-di-controllo-della-guida-dellautomobile",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "Sistema di controllo della guida dell’automobile",
    "text": "Sistema di controllo della guida dell’automobile\nUn altro esempio familiare è un sistema di guida automobilistica, che può controllare sia la direzione (rotta) che la velocità.\nObiettivo: controllare la direzione e la velocità del veicolo.\n\nVariabili controllate: direzione e velocità.\nSegnali di comando: direzione dell’autostrada e limiti di velocità.\nDisturbi: forza del vento, condizioni della strada e del traffico.\nVariabili manipolate: posizione dello sterzo e dell’acceleratore/freno.\n\n\n\n\n\n\n\nDa. Gopal, “Principi e progettazione del sistema di controllo”, McGraw-Hill, 3a edizione._\nQuesto sistema presenta un aspetto interessante: ha più variabili di input e output. Tali sistemi sono comunemente indicati come MIMO (Multi-Input Multi-Output) o sistemi multivariabili. Ciò è in contrasto con l’esempio del serbatoio, che era un SISO (Single Input Single Output) o un sistema scalare.\nLa complessità nella progettazione dei sistemi MIMO spesso deriva dalle interazioni (o accoppiamenti) tra input e output. Ad esempio, mentre lo sterzo influisce principalmente sulla direzione del veicolo, l’applicazione dei freni, che potrebbe bloccare la ruota, potrebbe influire sia sulla velocità che sulla direzione.\nIn molti casi, tuttavia, queste interazioni possono essere trascurabilmente piccole. Quando ciò accade, il sistema può essere trattato come due sistemi SISO (single input single output) separati. Per esempio:\n\nSistema 1: dove l’input è un comando di sterzo e l’output è la direzione del veicolo.\nSistema 2: dove l’input è l’accelerazione o la posizione del freno e l’output è la velocità del veicolo.\n\nLa scomposizione di un sistema multivariabile in sistemi SISO può semplificare notevolmente il processo di progettazione. Questo è il motivo per cui, nonostante la prevalenza dei sistemi multivariabili nel settore industriale, molti progetti si concentrano sui sistemi SISO. Sono fondamentali e cruciali.\nCi concentriamo principalmente sulla progettazione di sistemi a singolo ingresso e singola uscita. Questo approccio non implica che le industrie si occupino solo dei sistemi SISO. Invece, evidenzia i casi frequenti in cui le interazioni in un sistema multivariabile possono essere trascurate, consentendo di trattarlo come sistemi SISO multipli.\nTorniamo al sistema di controllo dell’automobile e approfondiamo i vari componenti:\n\nAttuatore: trasforma un segnale elettrico in un’azione meccanica. Nel nostro sistema automobilistico, possiamo pensare al pedale dell’acceleratore come a un attuatore. Allo stesso modo, per frenare, il nostro piede funge da attuatore.\nRilevatore di errori: essenziale per i sistemi di feedback, questo blocco rileva la differenza tra lo stato desiderato e quello reale. Nel contesto della guida, i nostri occhi fungono da rilevatore di errori.\nLogica di controllo: situata nel cervello del conducente, elabora le informazioni per prendere decisioni.\nComandi: sono dinamici e cambiano in base a fattori esterni come i segnali stradali e le indicazioni stradali.\n\nQuando lo scopo del sistema è fare in modo che la variabile controllata (come la velocità o la direzione) segua comandi che variano nel tempo, viene definito sistema di tracciamento o sistema che segue i comandi.\nCi riferiamo ai regolatori quando il loro scopo è seguire un segnale che non varia nel tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html#meccanismo-del-servosterzo-idraulico",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html#meccanismo-del-servosterzo-idraulico",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "Meccanismo del servosterzo idraulico",
    "text": "Meccanismo del servosterzo idraulico\nIl servosterzo idraulico offre un esempio intuitivo di sistema di feedback.\nIl meccanismo del servosterzo idraulico è un componente vitale in molti veicoli, poiché consente al conducente di sterzare l’auto con facilità. Sfrutta la pressione idraulica per assistere l’azione dello sterzo, garantendo così un controllo più fluido, soprattutto durante il parcheggio o la navigazione in spazi ristretti.\n\nCome funziona\n\nMovimento del volante: quando il conducente gira il volante, la scatola dello sterzo ruota.\nFlusso del fluido idraulico: questa rotazione agisce sulla valvola di controllo, che dirige il fluido idraulico a sinistra o a destra del pistone.\nMovimento del pistone: La pressione del fluido idraulico agisce sul pistone all’interno del cilindro, facendolo spostare lateralmente. Questo movimento aiuta a girare le ruote dell’auto.\nFeedback: il movimento delle ruote genera un feedback che regola il flusso del fluido idraulico, garantendo che il volante e le ruote effettive del veicolo siano allineati.\n\n\n\n\n\n\n\nPer analizzare e progettare correttamente un sistema di questo tipo:\n\nModellare il sistema: sviluppare una rappresentazione matematica. Ad esempio, un modello fisico per questo sistema meccanico potrebbe interconnettere elementi di massa, molla e attrito.\nCostruisci un diagramma a blocchi: questo rappresenterebbe il modo in cui interagiscono diversi componenti come il segnale di comando, il rilevatore di errori, l’impianto (come il pistone e il carico) e altri.\nConsiderare i disturbi: ogni meccanismo di feedback dovrebbe tenere conto dei disturbi esterni. Nel contesto della guida, potrebbe trattarsi del vento o di variazioni di carico sul veicolo.\n\nIl sistema precedente può essere approssimato con:\n\n\n\n\n\n\ne rappresentato tramite il seguente schema a blocchi:\n\n\n\n\n\n\nNotare che: - La parte feedback è evidenziata all’interno della linea tratteggiata - Il segnale di riferimento (o variabile di riferimento) \\(x\\) è proporzionale al segnale di comando \\(\\theta_r\\) e lo sterzo è nel mezzo. - Il segnale di comando e la variabile di riferimento in un particolare sistema possono essere la stessa cosa, ma potrebbero essere diversi - Il segnale di uscita \\(\\theta_0\\) dipende dalla variabile controllata \\(y\\). Parliamo di una variabile controllata indirettamente.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html#impianto-di-riscaldamento-residenziale",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html#impianto-di-riscaldamento-residenziale",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "Impianto di riscaldamento residenziale",
    "text": "Impianto di riscaldamento residenziale\nUn sistema di controllo del feedback regola il comportamento di un sistema confrontando la sua uscita con un segnale di comando (o riferimento) desiderato. La differenza tra questi due segnali forma un segnale di errore, che il sistema di controllo utilizza per regolare la propria uscita per ridurre al minimo o eliminare l’errore. Approfondiremo ora questo concetto prendendo come esempio un impianto di riscaldamento residenziale.\n\n\n\n\n\n\n\n\n\n\n\n\nFigura: controllo della temperatura a circuito aperto (dai principi e dalla progettazione dei sistemi di controllo)\n\nIn un sistema a circuito aperto, non è prevista la regolazione automatica di eventuali errori nella temperatura di uscita che potrebbero verificarsi.\nSe c’è qualche errore, deve essere individuato dal gestore dell’impianto di riscaldamento e quindi la modifica necessaria deve essere apportata manualmente.\nNel controllo ad anello aperto, dobbiamo ripristinare i valori di ingresso del controller o convivere con le conseguenze di ambienti surriscaldati, uso eccessivo di energia, ecc. Il modo per correggere questo problema è informare il controller in linea su cosa non va.\n\nComponenti del sistema di feedback\n\nSegnale di comando: questa è l’uscita del sistema desiderata. Nel nostro esempio di riscaldamento residenziale, è la temperatura preimpostata che l’utente desidera per la stanza.\nVariabile di riferimento: traduce il segnale di comando in una forma che il sistema può utilizzare. Per l’impianto di riscaldamento è lo spostamento di una vite di fissaggio che regola la distanza tra il termostato e un interruttore a scatto (o la portata del vapore, tuttavia possiamo considerarla anche come una variabile controllata indirettamente).\nImpianto: radiatore ambiente\nVariabile controllata: è la temperatura ambiente.\nVariabile controllata indirettamente: questa è una traslazione della variabile controllata per ottenere il lavoro desiderato. Per il sistema di riscaldamento, potrebbe essere la quantità di flusso di vapore o l’apertura della valvola.\n\n\n\n\n\n\n\n\n\nUn quadrante imposta la temperatura ambiente desiderata (Segnale di comando).\nLa temperatura desiderata imposta la distanza tra il termostato e un interruttore a scatto (Variabile di riferimento).\nIl termostato, costituito da una striscia bimetallica, si arriccia a causa delle variazioni di temperatura. L’arricciatura della striscia controlla l’interruttore a scatto, che a sua volta controlla il solenoide e lo stantuffo, regolando l’apertura della valvola e il flusso di vapore.\nLa temperatura ambiente effettiva è influenzata da questo flusso di vapore (variabile controllata).\nSe la temperatura ambiente sale al di sopra o al di sotto della temperatura impostata, la lamina bimetallica si muove provocando una serie di azioni che regolano il flusso di vapore per riportare la temperatura al livello desiderato.\n\nIl sistema descritto funziona secondo una logica di controllo “on-off”. La valvola è completamente aperta (on) o completamente chiusa (off). Questo approccio può far sì che la temperatura ambiente oscilli tra due setpoint attorno alla temperatura desiderata.\nUn simile comportamento oscillatorio è spesso accettabile per il riscaldamento residenziale. L’intervallo di fluttuazione della temperatura può essere regolato in base alle preferenze dell’utente o alla progettazione del sistema.\nL’importanza del feedback\nIl sistema funzionerà perfettamente purché non vi siano disturbi sul sistema. Un sistema di feedback può adattarsi e adattarsi a disturbi o cambiamenti nell’ambiente. Ad esempio: - Se la temperatura ambientale cambia, un sistema di riscaldamento a circuito aperto potrebbe non mantenere la temperatura ambiente desiderata. Ma un sistema di feedback regolerebbe la sua uscita (il flusso di vapore nel nostro caso) per contrastare questi disturbi. - Il design e l’efficienza del radiatore possono cambiare nel tempo a causa dell’usura, dell’invecchiamento e di altri fattori. Un sistema di feedback può adattarsi a questi cambiamenti e mantenere prestazioni costanti.\nDisturbi: Due tipi di disturbi possono influenzare un sistema:\n\nDisturbi interni: cambiamenti all’interno del sistema stesso, come l’invecchiamento dei tubi del radiatore.\nDisturbi esterni: fattori esterni che influenzano il sistema, come la temperatura ambientale esterna.\n\nUn sistema di feedback è particolarmente utile in ambienti con disturbi frequenti o significativi. Si regola e si adatta continuamente per mantenere l’output desiderato, garantendo prestazioni costanti.\nScriviamo uno script Python per simulare e tracciare il controllo della temperatura di una stanza utilizzando un controller on-off\n\nLa stanza ha una temperatura desiderata (set_point).\nIl controller on-off accenderà il riscaldatore quando la temperatura scende al di sotto del set_point - delta e si spegne quando la temperatura supera il set_point + delta (dove delta è una piccola differenza di temperatura per evitare frequenti accensioni e spegnimenti).\nLa temperatura aumenterà quando il riscaldatore è acceso e diminuirà a causa degli effetti ambientali quando il riscaldatore è spento.\nPer semplicità, modelleremo la variazione di temperatura con equazioni lineari.\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Parameters\nset_point = 20  # Desired room temperature in degrees Celsius\ndelta = 1   # Tolerance in degrees Celsius. This is simulating the time it takes for the thermostat to kick in.\nduration = 300  # Simulation time in minutes\nheating_rate = 0.1  # Temperature rise per minute when heater is on\ncooling_rate = 0.05  # Temperature drop per minute when heater is off\ninitial_temp = 18  # Initial room temperature\n\n# Initialize lists to store results\ntimes = np.arange(0, duration, 1)\ntemperatures = [initial_temp]\nheater_status = [0]  # 0: off, 1: on\n\n# On-off controller simulation\nfor t in times[1:]:\n    current_temp = temperatures[-1]\n    if current_temp &lt; set_point - delta:\n        heater_status.append(1)\n        temperatures.append(current_temp + heating_rate)\n    elif current_temp &gt; set_point + delta:\n        heater_status.append(0)\n        temperatures.append(current_temp - cooling_rate)\n    else:\n        heater_status.append(heater_status[-1])\n        if heater_status[-1] == 1:\n            temperatures.append(current_temp + heating_rate)\n        else:\n            temperatures.append(current_temp - cooling_rate)\n\n# Plotting\nfig, ax1 = plt.subplots()\n\nax1.set_xlabel('Time (minutes)')\nax1.set_ylabel('Temperature (°C)', color='tab:blue')\nax1.plot(times, temperatures, label='Room Temperature', color='tab:blue', linewidth=3)\nax1.axhline(y=set_point, color='r', linestyle='--', label='Set Point')\nax1.tick_params(axis='y', labelcolor='tab:blue')\nax1.legend(loc='upper left')\n\nax2 = ax1.twinx()\nax2.set_ylabel('Heater Status', color='tab:orange')\nax2.step(times, heater_status, label='Heater Status', color='tab:orange')\nax2.tick_params(axis='y', labelcolor='tab:orange')\n\nplt.title('On-Off Temperature Controller')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nIn un’applicazione di riscaldamento residenziale l’oscillazione (ad esempio, 20 gradi centigradi più meno 1 grado) potrebbe essere tollerata\nQuesto tipo di logica di controllo è chiamata controllo on/off (o controllo bang/bang)\n\nPossiamo collocarlo all’interno di uno schema a blocchi più generale:\n\n\n\n\n\n\n\nIl circuito di regolazione della temperatura può essere suddiviso in più componenti:\n\nAzione di feedback (sensore): rappresentata dal termostato. La temperatura ambiente desiderata, θ, viene continuamente confrontata con la temperatura effettiva da questo termostato.\nController: la combinazione del termostato e dell’interruttore funziona come controller. Il ruolo del controller è modulare la corrente in base al feedback.\nAttuatore: questo è un componente vitale che produce un segnale manipolato adatto per l’impianto, spesso amplificando l’ingresso a un livello adatto per azionare l’impianto. Nel nostro sistema di riscaldamento, l’attuatore è una combinazione di solenoide e valvola. La sua uscita è il flusso di vapore che riscalda l’ambiente.\nImpianto: questo è il sistema che vogliamo controllare, in questo caso il radiatore della stanza.\nDisturbo: fattori esterni, come la temperatura ambientale, che potrebbero influenzare la pianta.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/basics_of_feedback_control_it.html#diagramma-a-blocchi-della-struttura-di-feedback-di-base",
    "href": "IT_🇮🇹/basics_of_feedback_control_it.html#diagramma-a-blocchi-della-struttura-di-feedback-di-base",
    "title": "Introduzione ai sistemi di controllo del feedback",
    "section": "Diagramma a blocchi della struttura di feedback di base",
    "text": "Diagramma a blocchi della struttura di feedback di base\n\n\n\n\n\n\n\n\\(y_r\\): il segnale di comando. Ciò potrebbe rappresentare la temperatura, lo spostamento, il livello dell’acqua, ecc.\n\\(A\\): Blocco per gli elementi di ingresso di riferimento responsabili della generazione del segnale di riferimento, \\(r\\).\n\\(b\\): segnale di feedback confrontato con \\(r\\) per produrre un segnale di errore di attuazione, \\(\\hat{e}\\)\n\\(D\\): Il controller o blocco logico di controllo che genera un segnale di controllo \\(u\\) basato su \\(\\hat{e}\\).\n\\(w\\): disturbo agente sull’impianto\n\\(G_A\\): Il blocco attuatore, aumentando il livello di potenza del segnale per pilotare l’impianto, producendo un segnale manipolato.\n\\(G_P\\): L’impianto o processo che riceve il segnale manipolato \\(m\\) e i disturbi \\(w\\) per produrre l’uscita \\(y\\).\n\\(y\\): variabile manipolata (output)\n\\(H\\): elemento del sistema di feedback (sensore)\n\\(Z\\): sistema controllato indirettamente (non parte del feedback\n\\(q\\): uscita controllata indirettamente\n\nNota: non tutti i sistemi includeranno tutti i blocchi o le variabili elencate, ma questa struttura funge da base per comprendere il flusso di informazioni nei sistemi di controllo del feedback.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione ai sistemi di controllo del feedback"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html",
    "title": "Introduzione al problema del controllo",
    "section": "",
    "text": "Una tipica applicazione radar prevede il governo di un’antenna in modo tale che rimanga allineata con un bersaglio, come nel seguire un aereo in volo. Questo meccanismo di allineamento e tracciamento si ottiene utilizzando un servomeccanismo.\n\n\n\n \n\n\n\n\nsegnale di comando per il servo: deviazione tra l’asse dell’antenna e la posizione del bersaglio\nquesto è necessario per orientare l’antenna e ridurre l’errore a zero\n\nCome osservi nel diagramma sopra, la configurazione della nostra antenna ha due principali gradi di libertà:\n\nAngolo di elevazione attorno all’asse orizzontale.\nAngolo di azimut (indicato come \\(\\beta\\)) attorno all’asse verticale.\n\nCiò rende il nostro sistema multivariabile. Ma aspetta, c’è un modo per semplificarlo?\n\nBolla di pensiero: ricordi uno scenario in cui possiamo trattare un sistema multivariabile quasi come una serie di sistemi a singolo input e singolo output? Corretto! Se l’interazione (o l’accoppiamento) tra queste variabili può essere trascurata, possiamo progettare i nostri sistemi di controllo separatamente per ciascun grado di libertà.\n\nPer chiarire, ingrandiamo il controllo dell’azimut (\\(\\beta\\)).\n\n\n\n\n\n\n\n\nFigura: Servomeccanismo azimutale per il governo dell’antenna (da Principi e progettazione dei sistemi di controllo)\n\nL’angolo di azimut è \\(\\beta\\) (angolo controllato)\nSegnale di comando dato dal sensore radar: \\(\\beta_r\\)\nIl ‘Computer’ esegue il rilevamento e il controllo degli errori, il che significa che abbiamo bisogno di un sensore adatto per leggere l’angolo \\(\\beta\\).\n\nl’uscita dell’elemento di calcolo è \\(u\\) (segnale manipolato)\n\nEncoder angolare: trasforma il segnale analogico \\(\\beta\\) (spostamento angolare) in un segnale digitale\nL’amplificatore di potenza ha generato il segnale che aziona il motore (motore di controllo dell’armatura CC) - modificare il livello di potenza per soddisfare i requisiti del motore\nTra l’albero del motore e l’antenna abbiamo un treno di ingranaggi perché la coppia richiesta per spostare l’antenna è maggiore della coppia prodotta da un tipico motore.\n\n\n\n\nC’è una svolta nella nostra storia. Come avrai notato nel diagramma, abbiamo introdotto un ulteriore meccanismo di feedback tramite una dinamo tachimetrica.\nLa dinamo tachimetrica, fissata all’albero motore, produce un segnale di tensione proporzionale alla velocità dell’albero. Ciò ci consente non solo di fornire feedback sulla posizione dell’antenna ma anche sul suo tasso di cambiamento (o velocità).\n\nla velocità è la derivata della variabile controllata \\(\\beta\\).\n\nPop Quiz: Riesci a pensare al motivo per cui il feedback sulla velocità potrebbe essere utile nel nostro sistema di controllo?\nQuesto doppio meccanismo di feedback è ciò che chiamiamo “controllo proporzionale più derivato”. È un concetto essenziale nella progettazione del sistema di controllo, poiché aiuta a ottenere un controllo preciso considerando sia la posizione che la velocità di variazione.\nPossiamo inserirlo nel nostro modulo di diagramma a blocchi standard:\n\n\n\n\n\n\nFigura: Servomeccanismo azimutale per il governo dell’antenna (da Principi e progettazione dei sistemi di controllo)\n\nIl carico è l’antenna.\nL’antenna, l’ingranaggio e l’albero motore rappresentano tutto il progetto. Se vogliamo elaborare un modello del sistema dobbiamo modellare tutto questo, il che in pratica significherà:\n\nConoscere il momento d’inerzia \\(J\\) e l’attrito \\(B\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#servomeccanismo-per-il-governo-dellantenna",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#servomeccanismo-per-il-governo-dellantenna",
    "title": "Introduzione al problema del controllo",
    "section": "",
    "text": "Una tipica applicazione radar prevede il governo di un’antenna in modo tale che rimanga allineata con un bersaglio, come nel seguire un aereo in volo. Questo meccanismo di allineamento e tracciamento si ottiene utilizzando un servomeccanismo.\n\n\n\n \n\n\n\n\nsegnale di comando per il servo: deviazione tra l’asse dell’antenna e la posizione del bersaglio\nquesto è necessario per orientare l’antenna e ridurre l’errore a zero\n\nCome osservi nel diagramma sopra, la configurazione della nostra antenna ha due principali gradi di libertà:\n\nAngolo di elevazione attorno all’asse orizzontale.\nAngolo di azimut (indicato come \\(\\beta\\)) attorno all’asse verticale.\n\nCiò rende il nostro sistema multivariabile. Ma aspetta, c’è un modo per semplificarlo?\n\nBolla di pensiero: ricordi uno scenario in cui possiamo trattare un sistema multivariabile quasi come una serie di sistemi a singolo input e singolo output? Corretto! Se l’interazione (o l’accoppiamento) tra queste variabili può essere trascurata, possiamo progettare i nostri sistemi di controllo separatamente per ciascun grado di libertà.\n\nPer chiarire, ingrandiamo il controllo dell’azimut (\\(\\beta\\)).\n\n\n\n\n\n\n\n\nFigura: Servomeccanismo azimutale per il governo dell’antenna (da Principi e progettazione dei sistemi di controllo)\n\nL’angolo di azimut è \\(\\beta\\) (angolo controllato)\nSegnale di comando dato dal sensore radar: \\(\\beta_r\\)\nIl ‘Computer’ esegue il rilevamento e il controllo degli errori, il che significa che abbiamo bisogno di un sensore adatto per leggere l’angolo \\(\\beta\\).\n\nl’uscita dell’elemento di calcolo è \\(u\\) (segnale manipolato)\n\nEncoder angolare: trasforma il segnale analogico \\(\\beta\\) (spostamento angolare) in un segnale digitale\nL’amplificatore di potenza ha generato il segnale che aziona il motore (motore di controllo dell’armatura CC) - modificare il livello di potenza per soddisfare i requisiti del motore\nTra l’albero del motore e l’antenna abbiamo un treno di ingranaggi perché la coppia richiesta per spostare l’antenna è maggiore della coppia prodotta da un tipico motore.\n\n\n\n\nC’è una svolta nella nostra storia. Come avrai notato nel diagramma, abbiamo introdotto un ulteriore meccanismo di feedback tramite una dinamo tachimetrica.\nLa dinamo tachimetrica, fissata all’albero motore, produce un segnale di tensione proporzionale alla velocità dell’albero. Ciò ci consente non solo di fornire feedback sulla posizione dell’antenna ma anche sul suo tasso di cambiamento (o velocità).\n\nla velocità è la derivata della variabile controllata \\(\\beta\\).\n\nPop Quiz: Riesci a pensare al motivo per cui il feedback sulla velocità potrebbe essere utile nel nostro sistema di controllo?\nQuesto doppio meccanismo di feedback è ciò che chiamiamo “controllo proporzionale più derivato”. È un concetto essenziale nella progettazione del sistema di controllo, poiché aiuta a ottenere un controllo preciso considerando sia la posizione che la velocità di variazione.\nPossiamo inserirlo nel nostro modulo di diagramma a blocchi standard:\n\n\n\n\n\n\nFigura: Servomeccanismo azimutale per il governo dell’antenna (da Principi e progettazione dei sistemi di controllo)\n\nIl carico è l’antenna.\nL’antenna, l’ingranaggio e l’albero motore rappresentano tutto il progetto. Se vogliamo elaborare un modello del sistema dobbiamo modellare tutto questo, il che in pratica significherà:\n\nConoscere il momento d’inerzia \\(J\\) e l’attrito \\(B\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#controllo-della-velocità-nellindustria",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#controllo-della-velocità-nellindustria",
    "title": "Introduzione al problema del controllo",
    "section": "Controllo della velocità nell’industria",
    "text": "Controllo della velocità nell’industria\nIl controllo della velocità è vitale in molti settori, soprattutto dove la coerenza è cruciale. Pensa alle cartiere o agli impianti di produzione dell’acciaio, dove i rulli devono mantenere una velocità costante per produrre un prodotto uniforme, garantendo qualità e sicurezza del prodotto.\n\n\n\n\n\n\nPer garantire una velocità costante, nonostante disturbi come la variazione dello spessore del materiale o le fluttuazioni di potenza, utilizziamo un sistema di controllo.\n\n\n\n\n\n\n\nPosizione velocità comandata: la posizione della velocità comandata è rappresentata da \\(\\omega_r\\). Nel diagramma illustrato, ciò indica la velocità comandata. Questo è il segnale di riferimento che viene confrontato con l’effettivo segnale di feedback proveniente dal sistema \\(\\omega\\).\nMeccanismo di feedback:\n\nLa dinamo tachimetrica, fissata all’albero motore, fornisce il feedback in questo sistema. Questo meccanismo cattura la velocità effettiva e invia un segnale di feedback al sistema principale. Per fornire un’immagine più chiara, immagina un motore CC (come illustrato nel nostro diagramma). La dinamo tachimetrica è accoppiata all’albero di questo motore. Il carico collegato a questo motore ha determinati parametri: \\(J\\) (momento di inerzia) e \\(B\\) (attrito viscoso).\n\nTraduzione della velocità in tensione:\n\nLa dinamo tachimetrica non genera direttamente un segnale di velocità. Genera invece un segnale di tensione proporzionale alla velocità. Questo è fondamentale perché significa che anche il nostro segnale di riferimento, \\(\\omega_r\\), sarà una tensione proporzionale alla velocità desiderata. Pertanto, in questo sistema, il rilevatore di errori potrebbe essere un amplificatore operazionale (spesso chiamato amplificatore operazionale). Questo circuito operazionale accetta i segnali di tensione che rappresentano la velocità comandata e quella effettiva, li confronta e quindi genera un segnale proporzionale all’errore tra questi due segnali.\n\n\nDomanda: Perché in questo sistema la velocità viene tradotta in tensione?\nRisposta: Serve per garantire che il feedback e i segnali di riferimento siano nello stesso formato (tensione) per il confronto da parte del rilevatore di errori.\n\nAdattamento del controllo digitale: Per gli appassionati di uno schema di controllo digitale, l’introduzione di un blocco convertitore da A a D (da analogico a digitale) può digitalizzare il segnale analogico generato dal rilevamento dell’errore. Questo segnale digitale può quindi essere elaborato da un sistema informatico.\nControllo dell’erogazione di potenza:\n\nLo scopo principale di questo schema di controllo è modulare la potenza fornita al motore in base alla differenza (errore) tra la posizione comandata e quella effettiva.\nNello schema fornito, questo è gestito da un raddrizzatore di controllo al silicio (SCR). Senza entrare ancora nelle specifiche dell’hardware, la struttura di feedback inerente allo schema di controllo rivela un controllo del trigger SCR. L’attivazione dell’SCR determina l’alimentazione del motore, influenzando così la coppia generata dal motore per raggiungere \\(\\omega=\\omega_r\\).\nSia che \\(\\omega_r\\) sia un segnale che cambia nel tempo o un set point fisso, lo schema di controllo può funzionare sia come sistema di tracciamento che come regolatore. Approfondiremo più avanti questi tipi di applicazioni e i relativi controlli di velocità.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#perché-i-modelli-matematici",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#perché-i-modelli-matematici",
    "title": "Introduzione al problema del controllo",
    "section": "Perché i modelli matematici?",
    "text": "Perché i modelli matematici?\nDefinizione: un modello matematico è una rappresentazione astratta di un sistema fisico sotto forma di equazioni matematiche. Descrive il comportamento del sistema e come risponde ai vari input.\nBenefici:\n\nAnalisi predittiva: consente previsioni sul comportamento futuro.\nOttimizzazione del sistema: facilita le regolazioni per prestazioni ottimali.\nSimulazione: consente la simulazione del sistema prima dell’effettiva implementazione.\nConveniente: riduce la necessità di test nel mondo reale costosi e dispendiosi in termini di tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#tipi-di-sistemi-fisici",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#tipi-di-sistemi-fisici",
    "title": "Introduzione al problema del controllo",
    "section": "Tipi di sistemi fisici:",
    "text": "Tipi di sistemi fisici:\nI sistemi fisici possono essere ampiamente classificati in base alla loro natura intrinseca:\n\nSistemi lineari e non lineari: i sistemi lineari obbediscono al principio di sovrapposizione e omogeneità, mentre i sistemi non lineari no.\nSistemi invarianti rispetto al tempo rispetto a sistemi variabili nel tempo: nei sistemi invarianti nel tempo, i parametri non cambiano con il tempo. Al contrario, lo fanno nei sistemi con varianti temporali.\nSistema a tempo continuo e a tempo discreto: i sistemi a tempo continuo operano in un intervallo di tempo continuo, mentre i sistemi a tempo discreto operano a intervalli specifici.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#passaggi-nella-formulazione-di-modelli-matematici",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#passaggi-nella-formulazione-di-modelli-matematici",
    "title": "Introduzione al problema del controllo",
    "section": "Passaggi nella formulazione di modelli matematici:",
    "text": "Passaggi nella formulazione di modelli matematici:\n\nIdentificazione del sistema: determinare il tipo di sistema (ad esempio, meccanico, elettrico, termico).\nSemplificazione: fare approssimazioni ragionevoli e trascurare gli effetti insignificanti.\nSelezione delle variabili: scegliere le variabili di stato appropriate per descrivere il sistema.\nApplicazione delle leggi fondamentali: applicare le leggi fondamentali (come la legge di Ohm per i sistemi elettrici, le leggi di Newton per i sistemi meccanici) per derivare le equazioni.\nRappresentazione: utilizzare equazioni differenziali, funzioni di trasferimento o modelli nello spazio degli stati secondo necessità.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#sistemi-lineari-invarianti-nel-tempo",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#sistemi-lineari-invarianti-nel-tempo",
    "title": "Introduzione al problema del controllo",
    "section": "Sistemi lineari invarianti nel tempo",
    "text": "Sistemi lineari invarianti nel tempo\nNelle nostre prossime discussioni, tutti i sistemi saranno lineari invarianti nel tempo. Pertanto, la nostra attenzione si concentrerà sulla modellazione di questi tipi di sistemi. Si presume che ad un certo punto dei tuoi studi ti sia imbattuto nella modellazione di vari sistemi, come sistemi elettrici, meccanici, fluidici o termici.\nQuando risolviamo il modello matematico di un sistema fisico in diversi scenari di input, il risultato descrive il comportamento dinamico del sistema.\n\n Il modello matematico di un sistema è considerato lineare se aderisce ai principi di sovrapposizione e omogeneità.\n\nse un modello di sistema ha risposte \\(y_1(t)\\) e \\(y_2(t)\\) a due input qualsiasi \\(x_1(t)\\) e \\(x_2,(t)\\), la risposta del sistema alla combinazione lineare di questi input:\n\\[ \\alpha_1 x_1(t) + \\alpha_2 x_2(t) \\]\nè data dalla combinazione lineare delle singole risposte:\n\\[ \\alpha_1 y_1(t) + \\alpha_2 y_2(t) \\]\nPrima di approfondire ulteriormente, sarà utile un riepilogo delle leggi fisiche fondamentali, così come si applicano ai sistemi lineari invarianti nel tempo. Sebbene possa sembrare ripetitivo, ciò garantirà che tutti siano sulla stessa pagina e comprendano la terminologia.\n\nL’applicazione delle leggi fondamentali della fisica fornirà equazioni differenziali. Tuttavia, queste equazioni potrebbero non essere direttamente utilizzabili per l’analisi o la progettazione e devono essere trasformate in una forma più utile per il controllo.\n\nEsistono due forme principali nei sistemi di controllo che spesso vengono sfruttati: 1. modelli a variabili di stato 2. funzioni di trasferimento.\n\n Le equazioni differenziali spesso caratterizzano le rappresentazioni matematiche di molti sistemi fisici. Un modello è considerato lineare quando l’equazione differenziale che lo definisce possiede coefficienti che dipendono esclusivamente dalla variabile indipendente o rimangono costanti. Se questi coefficienti cambiano nel tempo (dove il tempo è la variabile indipendente), il modello è descritto come variabile nel tempo lineare. Al contrario, se i coefficienti rimangono costanti, il modello è etichettato come lineare invariante nel tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#modelli-delle-variabili-di-stato",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#modelli-delle-variabili-di-stato",
    "title": "Introduzione al problema del controllo",
    "section": "Modelli delle variabili di stato",
    "text": "Modelli delle variabili di stato\nUtilizzando un semplice circuito elettrico come esempio possiamo illustrare il concetto di modelli con variabili di stato.\nIn questo circuito, la variabile di input è \\(e_i\\). La variabile di output, in qualsiasi sistema, è l’attributo del focus. Nel nostro esempio, potrebbe essere la corrente attraverso un elemento o la tensione attraverso un elemento.\n\n\n\n\n\n\nIn questo caso, se conosciamo la tensione attraverso il condensatore \\(e(t)\\) e la corrente attraverso l’induttore \\(i(t)\\), possiamo ricavare qualsiasi altra variabile di interesse.\n\nVariabili caratterizzanti: \\(e(t)\\) e \\(i(t)\\) caratterizzano completamente il sistema (una semplice rete elettrica in questo caso)\n\nQualsiasi output di interesse può essere ottenuto in funzione di queste variabili - Ad esempio l’energia immagazzinata nel condensatore è data da: \\[ \\frac{1}{2}Ce^2\\]\n\nAd esempio l’energia immagazzinata nell’induttore è data da: \\[ \\frac{1}{2}Li^2\\]\n\nI cambiamenti dinamici nelle nostre variabili caratterizzanti, \\(e(t)\\) e \\(i(t)\\), indicano la ridistribuzione dell’energia all’interno del sistema. Il riconoscimento di queste variabili, che rappresentano lo stato energetico, fornisce una visione completa del comportamento del sistema.\nCome ottengo \\(e(t)\\) e \\(i(t)\\): - \\(e(t)\\) e \\(i(t)\\) in qualsiasi momento \\(t \\ge 0\\) sono a mia disposizione se: - Sono noti \\(e(0), i(0)\\) a \\(t = 0\\) (stato energetico iniziale del sistema) - L’input esterno \\(e_i(t)\\) è noto per \\(t \\ge 0\\)\nChiamiamo \\(e(t)\\) e \\(i(t)\\) variabili di stato.\n\nDefinizione (informale) della variabile di stato\n\nLe variabili di stato sono un insieme di variabili caratterizzanti che forniscono in ogni momento l’informazione totale sul sistema, a condizione dello stato iniziale e dell’input esterno.\n\nTornando al nostro impianto elettrico:\n\nParametro di resistenza: \\(R\\)\nCapacità: \\(C\\)\nInduttanza: \\(L\\)\nCorrente: \\(i\\)\n\nApplicazione delle leggi fondamentali:\nL’equazione del ciclo è data da: \\[\ne_i= R i + e + \\frac{Ldi}{dt}\n\\]\nE anche:\n\\[\ni = C\\frac{de}{dt}\n\\]\nQueste due equazioni costituiscono il nostro modello di sistema matematico.\n\nModello delle variabili di stato del circuito\nUna volta adottato il nostro modello matematico, procediamo al modello delle variabili di stato.\nL’obiettivo qui è fare in modo che il modello esprima le derivate delle nostre variabili caratterizzanti. Per questo sistema le variabili caratterizzanti sono \\(e(t)\\) e \\(i(t)\\).\nQuesto significa:\n\\[\n\\frac{de(t)}{dt} = \\frac{1}{C}i(t)\n\\]\n\\[\n\\frac{di(t)}{dt} = \\frac{R}{L}i(t) + \\frac{1}{L}e(t) + \\frac{1}{L}e_i(t)\n\\]\nPer facilità di rappresentazione e standardizzazione, definiamo:\n\\[x_1=e(t)\\] \\[x_2=i(t)\\]\ne chiamo la variabile di input:\n\\[\nr=e_i(t)\n\\]\nQuindi il modello del sistema in forma di variabile di stato è:\n\\[\n\\begin{align}\n    \\frac{dx_1}{dt} &= \\frac{1}{C} x_2 \\\\\n    \\frac{dx_2}{dt} &= \\frac{R}{L} x_2 + \\frac{1}{L} x_1 + \\frac{1}{L} R\n\\end{align}\n\\]\nQueste equazioni insieme rappresentano le equazioni di stato del sistema.\nInformazioni in uscita: È fondamentale sapere quali informazioni ci interessano o cosa desideriamo osservare dal sistema.\nSupponiamo di essere interessati alla tensione ai capi dell’induttore \\(y(t)\\). Utilizzando le variabili di stato fornite, possiamo esprimere:\n\\[\ny(t) = -Ri - e + e_i = -Rx_2 - x_1+r\n\\]\nQuesta equazione è un’equazione di output, che mostra come l’output dipende dal nostro stato e dalle variabili di input.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#modello-standard-delle-variabili-di-stato",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#modello-standard-delle-variabili-di-stato",
    "title": "Introduzione al problema del controllo",
    "section": "Modello standard delle variabili di stato",
    "text": "Modello standard delle variabili di stato\nIl modello generalizzato delle variabili di stato per un sistema con variabili di stato $ n $, un input e un output è rappresentato dalle seguenti equazioni differenziali matrice-vettore:\n\\[\\begin{align}\n\\dot{\\mathbf{x}}(t) &= \\mathbf{A} \\mathbf{x}(t) + \\mathbf{b} u(t) \\\\\ny(t) &= \\mathbf{c} \\mathbf{x}(t) + d u(t)\n\\end{align}\\]\nDove:\n\n$ (t) $ è il vettore di stato di dimensione $ n $:\n\n\\[\n\\mathbf{x}(t) = \\begin{bmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_n(t)\n\\end{bmatrix}\n\\]\n\n$ u(t) $ è un input scalare\n$ y(t) $ è un output scalare\n$ $ è la matrice di sistema di dimensione $ n n $\n$ $ è il vettore di input della dimensione $ n $\n$ $ è il vettore di output di dimensione $ 1 n $\n$ d $ è la matrice di trasmissione diretta di dimensione $ 1 $.\n\nPossiamo generalizzarlo a un sistema con variabili di stato $ n $, input $ m$ e output $ p $\n\\[\\begin{align}\n\\dot{\\mathbf{x}}(t) &= \\mathbf{A} \\mathbf{x}(t) + \\mathbf{B} \\mathbf{u}(t) ​​\\\\\n\\mathbf{y}(t) &= \\mathbf{C} \\mathbf{x}(t) + \\mathbf{D} \\mathbf{u}(t)\n\\end{align}\\]\nDove:\n\n$ (t) $ è il vettore di stato di dimensione $ n $:\n\n\\[\n\\mathbf{x}(t) = \\begin{bmatrix}\nx_1(t) \\\\\nx_2(t) \\\\\n\\vdots \\\\\nx_n(t)\n\\end{bmatrix}\n\\]\n\n$ $ è la matrice del sistema di dimensione $ n n $.\n$ $ è la matrice di input di dimensione $ n m $ (assumendo che ci siano $ m $ input).\n$ $ è la matrice di output di dimensione $ p n $ (assumendo che ci siano output $ p $).\n$ $ è la matrice di trasmissione diretta di dimensione $ p m $.\n$ (t) ​​$ è il vettore di input.\n$ (t) $ è il vettore di output.\n\nQuesto formato viene spesso definito come la rappresentazione “nello spazio degli stati” dei sistemi dinamici. Fornisce un modo compatto e modulare per descrivere il comportamento di un’ampia gamma di sistemi, inclusi quelli elettrici, meccanici, termici e altri.\n\nTerminologia\n\nLe lettere minuscole in grassetto o le lettere minuscole sottolineate indicano i vettori.\nLe lettere maiuscole in grassetto o le lettere maiuscole sottolineate indicano le matrici.\nNessuna sottolineatura indica uno scalare.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_control_problem_it.html#comprensione-delle-variabili-di-stato",
    "href": "IT_🇮🇹/introduction_to_control_problem_it.html#comprensione-delle-variabili-di-stato",
    "title": "Introduzione al problema del controllo",
    "section": "Comprensione delle variabili di stato",
    "text": "Comprensione delle variabili di stato\nNegli esempi finora abbiamo considerato le variabili fisiche come variabili di stato del sistema.\nTuttavia, è importante notare che le variabili di stato vengono introdotte principalmente per comodità matematica.\nLe variabili di stato non devono essere sempre variabili fisiche. Possono essere definiti in base a esigenze matematiche o di modellazione.\n\nLe variabili di input e output devono essere variabili fisiche.\n\nNell’esempio del carrello sopra, possiamo definire $ x_1 $ come $ x(t) + v(t) $ e $ x_2 $ solo come $ v(t) $?\nLa risposta è, teoricamente, sì.\n\n\\(x_2\\) rimane la velocità, \\(x_1\\) - la somma di spostamento e velocità - non corrisponde a una variabile fisica distinta.\nLa somma dello spostamento e della velocità è un valore numerico, senza significato fisico.\nQuindi, sebbene \\(x_1\\) e \\(x_2\\) non siano variabili fisiche indipendenti, le equazioni di stato possono comunque essere definite nei loro termini.\nL’output risultante può essere rappresentato utilizzando \\(x_1\\) e \\(x_2\\), sebbene l’equazione di output potrebbe differire dal caso precedente. Tuttavia, per ogni input, l’output rimane definito in modo univoco.\n\nLe variabili di stato, come \\(x_1\\) e \\(x_2\\), non sono univoche. Possono essere ridefiniti in innumerevoli modi, ma per ogni input specifico è garantito un output unico. Queste variabili di stato sono in gran parte questioni di convenienza. A seconda delle esigenze di analisi e progettazione, le variabili di stato possono variare.\nSe torniamo al nostro esempio di circuito elettrico.\nIn precedenza abbiamo impostato la tensione del condensatore come variabile di stato.\nTuttavia, non esiste alcun vincolo che ci impedisca di selezionare la carica immagazzinata nel condensatore come variabile di stato.\nIndipendentemente dal fatto che la variabile di stato sia designata come \\(q\\) (carica) o \\(e\\) (tensione), per un dato input, l’output rimane coerente in tutte le definizioni delle variabili di stato.\nFin.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione al problema del controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html",
    "title": "Progettazione del compensatore",
    "section": "",
    "text": "Un compensatore è un componente del sistema di controllo totale progettato per compensare le carenze dell’impianto. Se un sistema di controllo con impianto, sensore e circuito di feedback soddisfa le vostre esigenze, non avete bisogno di alcun compenso. Tuttavia, in caso contrario, viene aggiunto un compensatore, un dispositivo hardware o software in un computer digitale, per migliorare le prestazioni.\nCon riferimento all’immagine qui sotto:\n\n\n\n\n\nSe non viene incluso il controller \\(D(s)\\), lo schema rappresenta comunque un sistema di controllo completo. Se questo soddisfa le tue esigenze, non è necessario alcun ulteriore compenso.\nIl nostro obiettivo primario è progettare un compensatore efficace, rappresentato come $ D(s) $ nella terminologia della funzione di trasferimento, per garantire che il nostro sistema di controllo aderisca a specifici criteri di prestazione.\nProcederemo partendo dal presupposto che l’architettura fondamentale del sistema rimanga costante. Ciò implica che elementi come l’impianto ed il sensore non subiranno alcuna modifica. L’unica variabile suscettibile di alterazione è il compensatore, $ D(s) $. Questa restrizione si basa sulla relativa semplicità della modifica di $ D(s) $: di solito comporta l’aggiornamento del software nei controller digitali o la regolazione del circuito dell’amplificatore operazionale (OpAmp).\nNel campo dei sistemi di controllo, un compensatore gioca un ruolo fondamentale. Serve a regolare il comportamento del sistema per soddisfare le specifiche mirate, che possono includere stabilità migliorata, tempi di risposta più rapidi o errori di stato stazionario ridotti. In sostanza, un compensatore mette a punto le dinamiche del sistema per ottenere i risultati desiderati.\nPer illustrare, si consideri un sistema di controllo dotato di un circuito di feedback di base. Qualora questo sistema non riuscisse a soddisfare i suoi parametri di riferimento prestazionali, introduciamo un compensatore. Ad esempio, in uno scenario in cui la risposta del sistema è più lenta del necessario, è possibile progettare un compensatore appositamente per accelerare i tempi di risposta del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#cosè-un-compensatore",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#cosè-un-compensatore",
    "title": "Progettazione del compensatore",
    "section": "",
    "text": "Un compensatore è un componente del sistema di controllo totale progettato per compensare le carenze dell’impianto. Se un sistema di controllo con impianto, sensore e circuito di feedback soddisfa le vostre esigenze, non avete bisogno di alcun compenso. Tuttavia, in caso contrario, viene aggiunto un compensatore, un dispositivo hardware o software in un computer digitale, per migliorare le prestazioni.\nCon riferimento all’immagine qui sotto:\n\n\n\n\n\nSe non viene incluso il controller \\(D(s)\\), lo schema rappresenta comunque un sistema di controllo completo. Se questo soddisfa le tue esigenze, non è necessario alcun ulteriore compenso.\nIl nostro obiettivo primario è progettare un compensatore efficace, rappresentato come $ D(s) $ nella terminologia della funzione di trasferimento, per garantire che il nostro sistema di controllo aderisca a specifici criteri di prestazione.\nProcederemo partendo dal presupposto che l’architettura fondamentale del sistema rimanga costante. Ciò implica che elementi come l’impianto ed il sensore non subiranno alcuna modifica. L’unica variabile suscettibile di alterazione è il compensatore, $ D(s) $. Questa restrizione si basa sulla relativa semplicità della modifica di $ D(s) $: di solito comporta l’aggiornamento del software nei controller digitali o la regolazione del circuito dell’amplificatore operazionale (OpAmp).\nNel campo dei sistemi di controllo, un compensatore gioca un ruolo fondamentale. Serve a regolare il comportamento del sistema per soddisfare le specifiche mirate, che possono includere stabilità migliorata, tempi di risposta più rapidi o errori di stato stazionario ridotti. In sostanza, un compensatore mette a punto le dinamiche del sistema per ottenere i risultati desiderati.\nPer illustrare, si consideri un sistema di controllo dotato di un circuito di feedback di base. Qualora questo sistema non riuscisse a soddisfare i suoi parametri di riferimento prestazionali, introduciamo un compensatore. Ad esempio, in uno scenario in cui la risposta del sistema è più lenta del necessario, è possibile progettare un compensatore appositamente per accelerare i tempi di risposta del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#introduzione-al-metodo-del-luogo-delle-radici",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#introduzione-al-metodo-del-luogo-delle-radici",
    "title": "Progettazione del compensatore",
    "section": "Introduzione al metodo del luogo delle radici",
    "text": "Introduzione al metodo del luogo delle radici\nIl metodo del luogo delle radici è un approccio grafico utilizzato nei sistemi di controllo per determinare la stabilità e la risposta transitoria di un sistema in funzione di un parametro variabile, tipicamente un guadagno.\n\nIndicatori chiave delle prestazioni: tradurre le prestazioni in poli\nRicordiamo le principali misure di prestazione nei sistemi di controllo:\n\n\\(T_r\\) (Tempo di salita)\n\\(T_p\\) (Ora di punta)\n\\(\\zeta\\) (rapporto di smorzamento)\n\\(\\omega_n\\) (Frequenza naturale)\n\\(M_p\\) (Picco massimo)\nTempo di assestamento\nErrore allo stato stazionario\n\nAbbiamo osservato che le misure di performance spesso presentano conflitti; tuttavia, la risposta transitoria del sistema è governata principalmente da due parametri chiave: \\(\\zeta\\) (rapporto di smorzamento) e \\(\\omega_n\\) (frequenza naturale). Questi parametri influenzano le prestazioni del sistema, poiché determinano il comportamento del sistema durante gli stati transitori, quei periodi temporanei prima di raggiungere lo stato stazionario.\nDi conseguenza, comprendere e controllare la risposta transitoria si traduce nel posizionamento strategico di una coppia di poli dominanti a circuito chiuso nel piano s. In sostanza, i parametri \\(\\zeta\\) e \\(\\omega_n\\) sono importanti nel definire le prestazioni complessive di un sistema di controllo.\nIl metodo del luogo delle radici prevede di tracciare le possibili posizioni (luogo) dei poli del sistema a circuito chiuso al variare di un parametro del sistema (solitamente un guadagno). Questo grafico aiuta a visualizzare come i poli del circuito chiuso si muovono in risposta ai cambiamenti di questo parametro.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#comprensione-del-diagramma-del-luogo-delle-radici",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#comprensione-del-diagramma-del-luogo-delle-radici",
    "title": "Progettazione del compensatore",
    "section": "Comprensione del diagramma del luogo delle radici",
    "text": "Comprensione del diagramma del luogo delle radici\nConsideriamo un sistema con la funzione di trasferimento ad anello aperto\n\\[G(s) = \\frac{K}{(s + 1)(s + 2)}\\]\ndove \\(K\\) è un guadagno variabile.\nCiò corrisponde a\n\n\n\n\n\nPassaggio 1: derivare la funzione di trasferimento ad anello chiuso\nLa funzione di trasferimento ad anello chiuso è data da:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{K}{s^2 + 3s + 2 + K} \\]\nPassaggio 2: determinare la posizione dei poli\nLe radici delle equazioni caratteristiche sono:\n\\[\ns_{1,2} = \\frac{-3}{2} \\pm \\frac{1}{2}\\sqrt{1-4K}\n\\]\nOra possiamo verificare come si comporta il sistema quando cambiamo \\(K\\) da 0 a \\(\\infty\\). Dopotutto questo è il cambiamento totale che possiamo apportare.\nPer valori diversi di K cambiano i poli del circuito chiuso, che sono le radici dell’equazione caratteristica.\n\nInizialmente, quando K = 0, i poli si trovano nelle posizioni dei poli ad anello aperto, -1 e -2.\nAll’aumentare di K, questi poli si muovono lungo percorsi specifici nel piano s. Questo movimento può essere tracciato e analizzato.\nAd esempio, considera \\(K = 1/4\\):\n\n\\[ s_{1,2} = -\\frac{3}{2} \\pm \\frac{1}{2}\\sqrt{1 - 4K} \\] \\[ = -1.5 \\text{ (poli ripetuti)} \\]\nMan mano che \\(K\\) aumenta ulteriormente, i poli diventano complessi coniugati.\n\nVisualizzandolo in Python\nPer illustrare come si muovono i poli di un sistema al variare del parametro \\(K\\), possiamo scrivere uno script Python.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, FloatSlider\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    discriminant = 1 - 4 * K\n\n    # Check if the discriminant is negative (complex poles)\n    if discriminant &lt; 0:\n        real_part = -1.5\n        imaginary_part = 0.5 * np.sqrt(-discriminant)\n        poles = [real_part + 1j * imaginary_part, real_part - 1j * imaginary_part]\n    else:\n        # Real poles\n        poles = [-1.5 + 0.5 * np.sqrt(discriminant), -1.5 - 0.5 * np.sqrt(discriminant)]\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'bo')  # Blue dots for poles\n\n    plt.xlim(-3, 1)\n    plt.ylim(-2, 2)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=1, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nPossiamo visualizzarlo graficamente in questo modo:\n\n\n\n\n\nRicorda che i poli sono:\n\\[\ns_{1,2} = -\\frac{3}{2} \\pm \\frac{1}{2}\\sqrt{1-4K}.\n\\]\n\nNel diagramma del luogo delle radici di questo sistema, vediamo due rami che iniziano rispettivamente a -1 e -2 sull’asse reale.\nAll’aumentare di $ K $, questi rami convergerebbero verso -1,5.\nOltre $ K = $, i rami si spezzano nelle metà superiore e inferiore del piano complesso, formando un’immagine speculare rispetto all’asse reale.\nI rami continuano verticalmente rispettivamente verso l’alto e verso il basso, indicando il movimento dei poli coniugati complessi. I poli devono giacere sulla linea verticale perché la parte reale è sempre \\(-\\frac{3}{2}\\).\nIn un diagramma del luogo delle radici, il termine “ramo” si riferisce al percorso che un polo del sistema ad anello chiuso compie nel piano complesso al variare di un particolare parametro (in questo caso, $ K $).\nPer il sistema dato ci sono due rami perché è un sistema del secondo ordine, risultando in due poli. Ogni ramo rappresenta la traiettoria di uno di questi poli.\n\n\nCondizione iniziale: $ K = 0 $\n\nQuando $ K = 0 $, i poli del sistema a circuito chiuso sono gli stessi dei poli del sistema ad anello aperto.\nLa funzione di trasferimento ad anello aperto è $ $, e i suoi poli sono $ s = -1 $ e $ s = -2 $.\nQuindi, a $ K = 0 $, i poli del circuito chiuso iniziano in queste posizioni dei poli del circuito aperto: un polo a -1 e l’altro a -2.\n\n\n\nAll’aumentare di $ K $\n\nQuando $ K $ inizia ad aumentare da 0, i poli del circuito chiuso iniziano a spostarsi da queste posizioni iniziali.\nCon un leggero aumento di $ K $, i poli si muovono lungo percorsi specifici nel piano s.\n\n\n\nA $ K = $\n\nQuando $ K $ raggiunge $ $, si verifica un cambiamento critico.\nSostituendo $ K = $ nella formula, troviamo che il discriminante diventa zero, rendendo i poli reali e ripetuti, entrambi posti a $ s = -1,5 $.\n\n\n\nVisualizzazione del movimento dei poli\n\nUna radice si muove da -2 verso -1,5 e l’altra radice si muove da -1 verso -1,5.\nQuesti movimenti possono essere visualizzati come due rami del luogo delle radici convergenti in $ s = -1,5 $.\n\n\n\nOltre $ K = $\n\nPer $ K &gt; $, il discriminante diventa negativo, risultando in poli coniugati complessi.\nLa parte reale di questi poli rimane costante a $ - $, mentre la parte immaginaria aumenta all’aumentare di $ K $, indicando che i poli si muovono verticalmente sul piano s.\nQuesti poli giacciono sempre su una linea verticale nel piano s e la parte reale è sempre $ -1,5 $.\n\n\n\nImplicazioni sulle prestazioni del sistema\n\nIl grafico del luogo delle radici rappresenta visivamente il modo in cui le caratteristiche dinamiche del sistema come il tempo di salita, il tempo di assestamento, il superamento del picco e il rapporto di smorzamento $ $ e la frequenza naturale $ _n $ sono influenzati dalla variazione di $ K $.\nFondamentalmente, il sistema rimane stabile per tutti i valori di $ K $ poiché i poli non attraversano mai l’asse immaginario (asse Jω). Ciò è evidente dal grafico del luogo delle radici.\n\n\n\n\nCorrelazione del luogo delle radici alle prestazioni del sistema\n\nVisualizzazione dei parametri prestazionali\n\nIl grafico del luogo delle radici non è solo una rappresentazione del movimento dei poli; è un potente strumento per visualizzare parametri chiave delle prestazioni come tempo di salita, tempo di assestamento, superamento del picco, rapporto di smorzamento ($ \\() e frequenza naturale (\\) _n $).\nLa posizione e il movimento dei poli su questo grafico sono direttamente correlati a come questi parametri si manifesteranno nella risposta del sistema.\n\n\n\nAnalisi di stabilità\n\nUn aspetto critico del grafico del luogo delle radici è la sua capacità di fornire informazioni rapide sulla stabilità del sistema.\nPer il sistema dato, finché i poli (rappresentati dai rami) non si incrociano nella metà destra del piano complesso (l’asse immaginario, o asse \\(j\\omega\\)), il sistema rimane stabile.\nPoiché i poli in questo sistema non attraversano mai l’asse immaginario per nessun valore di $ K $, possiamo concludere che il sistema rimane stabile per tutti i valori di $ K $ da 0 a infinito.\n\n\n\n\nSemplificazione dell’analisi complessa\n\nIl metodo del luogo delle radici semplifica l’analisi di sistemi complessi. Anche negli scenari in cui le dinamiche del sistema sono più complesse, il grafico del luogo delle radici fornisce una comprensione chiara e immediata di come i cambiamenti in un parametro (come $ K $) influenzeranno le prestazioni e la stabilità del sistema.\n\n\n\nComprensione e applicazione del metodo del luogo delle radici nella progettazione di sistemi di controllo\nIl grafico del luogo delle radici fornisce una rappresentazione completa del comportamento di un sistema di controllo in base alla variazione di un singolo parametro di progettazione scelto. Questo parametro di progettazione potrebbe essere, ad esempio, la costante derivativa in un controller proporzionale-derivativo (PD), la costante integrale in un controller proporzionale-integrale (PI), il guadagno di un amplificatore o altri elementi simili del sistema. Inizialmente è possibile concentrarsi su un solo parametro, anche se in pratica più parametri possono influenzare il comportamento del sistema.\nIl processo che utilizza il metodo del luogo delle radici prevede due passaggi principali:\n\nIdentificare il parametro di progettazione: determinare quale parametro del sistema di controllo si desidera regolare. Questo parametro è ciò che utilizzerai per valutare e modificare le prestazioni del sistema.\nTraccia il luogo delle radici: crea un grafico del luogo delle radici variando il parametro scelto (tipicamente da 0 a infinito). Questo grafico rappresenta visivamente il modo in cui i poli del sistema, e quindi il suo comportamento, cambiano quando il parametro viene regolato.\n\nIl grafico del luogo delle radici funge da strumento dinamico, consentendo di correlare visivamente le variazioni nel parametro di progettazione scelto con i cambiamenti nelle prestazioni del sistema. Esaminando questo grafico è possibile determinare il valore ottimale del parametro di progettazione che si allinea ai requisiti prestazionali specifici, come velocità di risposta, stabilità o superamento.\nIl root locus plot è una rappresentazione grafica essenziale e completa che consente di comprendere e ottimizzare la risposta di un sistema di controllo in base a un parametro chiave di progettazione.\nPossiamo ad esempio discutere cosa succede allo smorzamento del sistema quando aumentiamo \\(K\\):",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-2",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-2",
    "title": "Progettazione del compensatore",
    "section": "Esempio 2",
    "text": "Esempio 2\nConsideriamo un sistema con la funzione di trasferimento ad anello aperto\n\\[G(s) = \\frac{K}{s(s + 1)(s + 2)}\\]\ndove \\(K\\) è un guadagno variabile.\n\n\n\n\n\n\nL’impianto dispone ora di un integratore.\n\nIl luogo delle radici in questo caso è:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\n# Define the transfer function G(s) = K / (s^3 + 3s^2 + 2s + K)\n# where K is the gain that will be varied.\ndef transfer_function(K):\n    numerator = [K]\n    denominator = [1, 3, 2, K]\n    return ctl.tf(numerator, denominator)\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    \n    if K == 0:\n        poles = np.roots([1, 3, 2, K])\n    else:\n        system = transfer_function(K)\n        poles = ctl.pole(system)\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(poles), np.imag(poles), 'bo')  # Blue dots for poles\n\n    plt.xlim(-3, 1)\n    plt.ylim(-2, 2)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K:.2f}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=20, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nO:\n\n\n\n\n\n\nPunti iniziali: Il diagramma inizia con tre punti sull’asse reale, che rappresentano i poli ad anello aperto in $ K = 0 $.\nRami: da questi punti emergono tre linee (rami), ciascuna delle quali mostra il percorso di una radice all’aumentare di $ K $.\n\nRamo 1 e 2: due rami potrebbero mostrare radici che si muovono l’una verso l’altra, diventando reali e ripetute, per poi dividersi in complesse coppie coniugate mentre si avvicinano all’asse immaginario.\nRamo 3: Il terzo ramo rappresenta il percorso della terza radice, che può muoversi indipendentemente dagli altri due.\n\nIndicatori di direzione: le frecce lungo i rami indicano la direzione del movimento man mano che $ K $ aumenta.\nPunti critici:\n\nPunti in cui le radici diventano complesse coniugate.\nPunti in cui il sistema diventa oscillatorio e quindi instabile.\n\n\n\nCondizioni iniziali\n\nA $ K = 0 $, le radici del sistema si trovano ai poli dell’anello aperto. Questi sono i punti di partenza per i rami del luogo delle radici.\nMan mano che $ K $ aumenta da 0, le radici iniziano a muoversi lungo percorsi distinti. Per un sistema del terzo ordine, ci sono tre rami nel diagramma del luogo delle radici.\n\n\n\nRami del luogo delle radici\n\nOgni ramo rappresenta il percorso di una radice nel piano complesso.\nUna radice si muove in una direzione, la seconda radice in un’altra e la terza radice segue un percorso separato.\nAd un valore specifico di \\(K\\), le due radici diventano reali e si ripetono, mentre la terza radice si trova in una posizione diversa.\n\n\n\nL’emergere di radici coniugate complesse\n\nCon un ulteriore aumento di $ K $, il sistema presenta radici coniugate complesse.\nDue radici si avvicinano all’asse immaginario, indicando una tendenza verso un comportamento oscillatorio e una potenziale instabilità.\n\n\n\nSignificato della terza radice\n\nSe questa radice è sufficientemente lontana dalla parte reale delle radici complesse coniugate (di un fattore da quattro a cinque volte), il suo impatto sulla dinamica del sistema è trascurabile (condizione di dominanza).\n\n\n\nStabilità e oscillazioni del sistema\n\nMan mano che $ K $ continua ad aumentare, il sistema si avvicina all’asse immaginario.\nUn certo valore di $ K $ fa sì che il sistema diventi oscillatorio. Ulteriori aumenti di $ K $ portano all’instabilità.\n\n\n\nCommenti\n\nVisibilità del comportamento del sistema: il grafico del luogo delle radici illustra chiaramente come il comportamento del sistema cambia con $ K $, mostrando stabilità, tendenze oscillatorie e instabilità.\nConfronto con il criterio di stabilità di Routh: mentre il criterio di stabilità di Routh fornisce anche intervalli di stabilità, il grafico del luogo delle radici offre una visualizzazione più dettagliata dei poli del sistema all’interno di questi intervalli. Ti dice dove sono le radici e questo migliora la nostra comprensione della dinamica del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-aggiunta-di-uno-zero",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-aggiunta-di-uno-zero",
    "title": "Progettazione del compensatore",
    "section": "Esempio: aggiunta di uno zero",
    "text": "Esempio: aggiunta di uno zero\nIn questa sezione del quaderno esploreremo il concetto di analisi del luogo delle radici concentrandoci su un sistema con zero. Ciò equivale ad avere un controllo proporzionale-derivativo (PD).\nConsideriamo un sistema di controllo rappresentato dalla funzione di trasferimento:\n\\[ G(s) = \\frac{K (s + 5)}{(s + 1)(s + 2)} \\]\nQui, $ K $ è il guadagno e il sistema include uno zero in $ s = -5 $, simile all’aggiunta di un controller PD. Questo sistema è un sistema di tipo 0 con controllo PD. Potrebbe rappresentare vari sistemi del mondo reale come il controllo della temperatura o il controllo del livello del liquido.\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\nfrom ipywidgets import interact, FloatSlider\n\n\n# Define the transfer function G(s) = K (s+5)/ (s^2 + 3s +  Ks + 2 + 5K)\n# where K is the gain that will be varied.\ndef transfer_function(K):\n    numerator = [K, 5*K]\n    denominator = [1, 3 + K, 2 + 5*K]\n    return ctl.tf(numerator, denominator)\n\n# Function to calculate and plot poles for a given K\ndef plot_poles(K):\n    \n    if K == 0:\n        poles = np.roots([1, 3 + K, 2 + 5*K])\n    else:\n        system = transfer_function(K)\n        poles = ctl.pole(system)\n\n    # Clear the previous plot\n    plt.clf()\n\n    # Plot the poles\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'bo')  # Blue dots for poles\n\n    # Plot the zero at s = -5\n    plt.plot(-5, 0, 'rx')  # Red 'x' for zero\n\n    plt.xlim(-12, 1)\n    plt.ylim(-5, 5)\n    plt.xlabel('Real Part')\n    plt.ylabel('Imaginary Part')\n    plt.title(f'Movement of Poles for K = {K:.2f}')\n    plt.grid(True)\n    plt.axhline(0, color='black')  # X-axis\n    plt.axvline(0, color='black')  # Y-axis\n    plt.show()\n\n# Create an interactive slider for K\ninteract(plot_poles, K=FloatSlider(value=0, min=0, max=20, step=0.01, description='Gain K:'))\n\n\n\n\n&lt;function __main__.plot_poles(K)&gt;\n\n\nE il diagramma del luogo delle radici risultante è:\n\n\n\n\n\n\nSchizzo del luogo delle radici\n\nIdentificare poli e zeri\n\nPoli: $ s = -1, -2 $\nZero: $ s = -5 $\n\n\n\nEquazione caratteristica\nCon $ K $ come parametro corrente, l’equazione caratteristica è:\n\\[ 1 + K \\cdot \\frac{1}{(s + 5)(s + 1)(s + 2)} = 0 \\]\n\n\n\nAnalisi del luogo delle radici\n\nCondizione iniziale in $ K = 0 $\n\nInizia con i poli ad anello aperto a $ s = -1 $ e $ s = -2 $.\nA $ K = 0 $ il sistema si comporta esclusivamente in base a questi poli ad anello aperto.\n\n\n\nAll’aumentare di $ K $\n\nDue rami emergono dai poli ad anello aperto.\nRamo 1: Si sposta da $ s = -1 $ verso destra.\nRamo 2: Si sposta da $ s = -2 $ verso destra.\n\n\n\nAnalisi dei punti critici\n\nMan mano che $ K $ aumenta ulteriormente, le radici diventano complesse coniugate.\nIl punto in cui le radici sono reali e ripetute è critico, indicando una transizione nella dinamica del sistema.\nNota che ci sono due valori di \\(K\\) per i quali le radici sono reali e ripetute.\nA $ K = $, osserva il comportamento delle radici.\n\n\n\n\nImpatto del controllo PD sulla stabilità del sistema\n\nL’aggiunta di uno zero (controllo PD) sposta il luogo delle radici verso sinistra, il che implica una migliore stabilità.\nLa stabilità del sistema può essere visualizzata attraverso il grafico del luogo delle radici, dove le radici si avvicinano o si allontanano dall’asse immaginario.\nConfronta questo con quello che è successo quando abbiamo aggiunto l’integratore che invece tira i rami verso il lato destro.\n\n\n\nComprendere le dinamiche del sistema\n\nNel diagramma fornito, man mano che $ K $ aumenta in modo incrementale, i due poli si spostano verso sinistra sull’asse reale, indicando un aumento delle loro componenti reali negative. Allo stesso tempo, si osserva un aumento delle parti immaginarie di questi poli, sebbene questo effetto sia meno pronunciato rispetto ai cambiamenti nelle parti reali.\nLa componente reale dei poli, rappresentata da $ _n $, è direttamente legata al tempo di assestamento del sistema, che può essere espresso matematicamente come $ t_s = $.\nCon l’aumento di $ K $ si ha un notevole aumento della parte reale $ _n $ dei poli. Ciò porta ad una riduzione del tempo di assestamento, facendo sì che il sistema risponda più rapidamente.\n\nDomanda pop-up: In che modo l’aggiunta di un controller PD influenza il tempo di superamento e assestamento del sistema?\nRisposta: Lo zero del controller PD tipicamente riduce l’overshoot e migliora il tempo di assestamento spostando il luogo delle radici a sinistra, aumentando così il rapporto di smorzamento $ $.\n\n\nTraduzione delle specifiche prestazionali in posizioni dei poli\n\nLo schema del luogo delle radici e le prestazioni del sistema\n\nL’analisi del luogo delle radici traduce le misure chiave delle prestazioni come tempo di salita (\\(t_r\\)), tempo di assestamento (\\(t_s\\)), tempo di picco (\\(t_p\\)) e superamento massimo (\\(M_p\\)) in specifiche posizioni dei poli a circuito chiuso nel s-aereo.\nQueste misure di prestazione sono essenziali per determinare la rapidità e la precisione con cui un sistema risponde a cambiamenti o disturbi.\n\n\n\nObiettivi di progettazione\n\nL’obiettivo principale di questo processo di progettazione è determinare dove posizionare i poli del circuito chiuso per soddisfare le prestazioni del sistema desiderate.\nUna volta identificate queste posizioni ottimali dei poli, è possibile calcolare il valore corrispondente del parametro $ K $. Questo passaggio essenzialmente “progetta” il parametro di sistema $ K $.\n\n\n\n\nRitornando all’esempio: Considerando lo Zero a $ s = -5 $\n\nIl sistema include uno zero in $ s = -5 $, che è sia uno zero ad anello aperto che uno zero ad anello chiuso.\nLa posizione di questo zero rispetto alle posizioni dei poli influisce in modo significativo sulla risposta del sistema.\n\n\nImpatto dello Zero sulla dinamica del sistema\n\nLo zero a $ s = -5 $ introduce un effetto di picco nella risposta del sistema. Questo effetto si manifesta come un picco precoce e un superamento potenzialmente maggiore nell’output del sistema.\nPer mitigare questo effetto di picco, il progetto dovrebbe puntare ad un rapporto di smorzamento maggiore ($ $). Un valore $ $ più alto corrisponde solitamente a una risposta meno oscillatoria e a un ridotto overshoot.\n\n\n\nStrategia di progettazione per il rapporto di smorzamento\n\nModifica della posizione dei poli\n\nSe lo zero in $ s = -5 $ è vicino ai poli del circuito chiuso, influenza in modo significativo la risposta del sistema.\nPer controbilanciare l’effetto di questo zero, il progetto dovrebbe “tirare” i poli del circuito chiuso verso una posizione che aumenti $ $.\nAumentare $ $ significa spostare i poli ulteriormente nella metà sinistra del piano s.\n\n\n\nImplicazioni pratiche di progettazione\n\nIn questo esempio, l’esatto posizionamento dei poli del circuito chiuso per una risposta ottimale dipende dal significato relativo dello zero in $ s = -5 $.\nSe l’effetto dello zero è sostanziale, i poli dovrebbero essere posizionati più a destra rispetto ad uno scenario in cui l’influenza dello zero è meno pronunciata. Questo perché la forza di picco dello zero compenserà questa azione.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#costruzione-e-analisi-dei-grafici-del-luogo-delle-radici",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#costruzione-e-analisi-dei-grafici-del-luogo-delle-radici",
    "title": "Progettazione del compensatore",
    "section": "Costruzione e analisi dei grafici del luogo delle radici",
    "text": "Costruzione e analisi dei grafici del luogo delle radici\nQuesto capitolo esplora la costruzione e l’analisi dei grafici del luogo delle radici nei sistemi di controllo, concentrandosi su come possono essere utilizzati per valutare e progettare le risposte del sistema.\nConsideriamo un sistema di controllo generale con un circuito di feedback. La funzione di trasferimento ad anello chiuso è rappresentata come:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{Sol(s)}{1 + G(s)H(s)} \\]\nQui, $ G(s) $ è la funzione di trasferimento del percorso in avanti e $ H(s) $ è la funzione di trasferimento del percorso di feedback.\n\n\n\n\n\n\nDefinizione della funzione di trasferimento ad anello o ad anello aperto\nLa funzione di trasferimento $ G(s)H(s) $ può essere interpretata come il prodotto delle funzioni di trasferimento del percorso in avanti e del percorso di feedback quando il ciclo di feedback è aperto:\n\\[\n\\frac{B(s)}{R(s)} = G(s)H(s)\n\\]\nQuesta funzione di trasferimento è chiamata: funzione di trasferimento open-loop o loop.\nCorrisponde a quanto segue:\n\n\n\n\n\n\nSe interrompiamo il circuito dopo il sensore, il segnale \\(B\\) è l’uscita del sensore e la funzione di trasferimento tra l’ingresso e l’uscita del sensore è la funzione di trasferimento del circuito: \\(G(s)H(s)\\) .\nPer un sistema a retroazione unitaria, dove $ H(s) = 1 $, la funzione di trasferimento ad anello aperto si semplifica nella funzione di trasferimento del percorso in avanti $ G(s) $.\n\n\n\nEquazione caratteristica del sistema\nL’equazione caratteristica, cruciale per determinare la stabilità del sistema, è data da:\n\\[ 1 + G(s)H(s) = 0 \\]\ndove $ G(s)H(s) $ è la funzione di trasferimento ad anello aperto.\nSiamo interessati alle radici di questa equazione. Sono i poli del circuito chiuso e ci forniranno il comportamento transitorio del sistema.\n\n\nFattorizzazione della funzione di trasferimento ad anello aperto\nUna funzione di trasferimento ad anello aperto può generalmente essere espressa nella forma (che risulta più conveniente per tracciare il luogo delle radici):\n\\[ G(s)H(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) } \\]\nQui, $ K $ è il guadagno, $ z_i $ sono gli zeri e $ p_j $ sono i poli della funzione di trasferimento. Ovviamente, $ z_i, p_j $ sono positivi se si trovano nella LHP e negativi altrimenti.\nDa notare che non escludiamo che i poli possano trovarsi nella destra. Un sistema a ciclo aperto può essere instabile, nel qual caso il ciclo di feedback dovrà renderlo stabile.\nIl concetto chiave da sottolineare qui è la distinzione tra le posizioni ammissibili dei poli nei sistemi ad anello aperto e ad anello chiuso:\n\nPoli ad anello chiuso: affinché un sistema sia stabile, i suoi poli ad anello chiuso devono risiedere nella metà sinistra del piano complesso. Questo è un requisito fondamentale perché i poli nel semipiano destro indicherebbero una risposta instabile del sistema nel funzionamento a circuito chiuso.\nPoli ad anello aperto: al contrario, il sistema ad anello aperto, che è il sistema senza il circuito di feedback impegnato, può avere poli nel semipiano destro. Ciò non implica necessariamente che il sistema complessivo sia instabile. Il processo di progettazione spesso implica prendere un sistema a circuito aperto che potrebbe essere instabile (o meno stabile di quanto desiderato) e applicare il controllo del feedback per ottenere stabilità nel sistema a circuito chiuso.\n\nLa distinzione è fondamentale nella progettazione del sistema di controllo: mentre possiamo tollerare e lavorare con i poli del semipiano destro in un contesto a circuito aperto, garantire la stabilità nel sistema a circuito chiuso richiede che tutti i poli si trovino nel semipiano sinistro.\n\n\nComprensione dei grafici del luogo delle radici\nOra chiamiamo:\n\\[ F(s) = G(s)H(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} ( s + p_j) }\\]\ne l’equazione caratteristica diventa:\n\\[\n1 + F(s) = 0\n\\]\n\nCostruire il diagramma del luogo delle radici: scansione dell’intero piano S\n\nIl metodo del luogo delle radici prevede la scansione dell’intero piano s, che comprende tutti i possibili valori di $ s = + j$, dove $ $ è la parte reale e $ $ è la parte immaginaria.\nQuesto processo di scansione identifica quei punti nel piano s in cui è soddisfatta l’equazione caratteristica $ 1 + F(s) = 0 $.\nUna volta identificati questi punti, vengono uniti per creare il grafico del luogo delle radici.\nQuesto grafico rappresenta la traiettoria dei poli del sistema poiché un parametro specifico (spesso il guadagno $ K $) varia da 0 a infinito.\n\n\n\n\nCondizioni matematiche per il luogo delle radici\n\nCriterio per i punti del luogo delle radici\n\n\n\n\n\n\nUn punto sul piano s è parte del luogo delle radici se soddisfa la condizione $ 1 + F(s) = 0 $. Questo può essere riformulato come $ F(s) = -1 $.\nMatematicamente, questo si traduce in due condizioni:\n\nCondizione di magnitudo: $ |F(s)| = 1$\nCondizione dell’angolo: l’angolo di $ F(s) $ deve essere un dispari multiplo di 180 gradi. Formalmente, $ F(s) = (2q + 1) ^$, dove $ q =0,1,2,…$\n\n\n\n\nCriterio per il luogo delle radici\nDato che abbiamo preso:\n\\[ F(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\\]\nUn punto nel piano s fa parte del luogo delle radici se soddisfa sia le condizioni di magnitudo che quelle di angolo:\n\nCondizione di magnitudo:\n\n\\[ \\frac{K \\prod_{i=1}^{m} |s + z_i| }{ \\prod_{j=1}^{n} |s + p_j| } = 1\\]\n\nCondizione dell’angolo:\n\n\\[ \\sum_{i=1}^{m} \\angle (s + z_i) - \\sum_{j=1}^{n} \\angle (s + p_j) = \\pm (2q + 1)180^\\ circo \\]\ndove $ q $ è un numero intero.\nQualsiasi punto che soddisfa queste due condizioni è un punto nel grafico del luogo delle radici.\n\n\n\nEsplorazione delle condizioni di grandezza e angolo nel luogo delle radici\nQuesta parte discute come determinare i punti sul piano s che soddisfano le condizioni di modulo e angolo di una data funzione di trasferimento. Utilizzeremo un approccio semplificato e grafico per renderlo più facile da comprendere.\n\nFunzione di trasferimento\nConsideriamo la funzione di trasferimento:\n\\[\nF(s) = \\frac{K}{s(s+1)(s+2)}\n\\]\nQui, $ F(s) $ è una funzione della variabile complessa $ s $ e $ K $ è un fattore di guadagno.\n\n\nCondizione di grandezza\nLa condizione di magnitudo per il luogo delle radici può essere espressa come:\n\\[\n\\frac{K}{|s||s+1||s+2|} = 1\n\\]\nCiò significa che per ogni punto $ {s} = {} + j{} $ sul piano s, se moltiplichiamo le distanze da $ {s} $ a ciascuno dei poli (a $ s=0 $, $ s=-1 $ e $ s=-2 $) e aggiusta $ K $ in modo tale che questo prodotto sia uguale a 1, il punto soddisfa la condizione di magnitudo.\n\n\n\n\n\n\n\nVisualizzazione della condizione di magnitudo\n\nPer visualizzarlo su un grafico, immagina di tracciare delle linee dal tuo punto $ {s} $ a ciascuno dei poli.\nLa lunghezza di ciascuna linea rappresenta la magnitudo (distanza) di ciascun polo.\nGraficamente, se puoi regolare $ K $ in modo tale che il prodotto di queste lunghezze sia uguale a 1, allora $ {s} $ soddisfa la condizione di grandezza.\n\n\n\n\n\n\n\n\nCondizione dell’angolo\nLa condizione angolare è data da:\n\\[\n-\\angle{s}-\\angle{s+1}-\\angle{s+2} = \\pm(2q+1)180^o\n\\]\nCiò implica che la somma degli angoli formati dalle linee da $ {s} $ a ciascun polo, rispetto all’asse reale positivo, dovrebbe sommarsi ad un multiplo dispari di 180 gradi.\n\n\n\n\n\n\n\nInterpretazione grafica della condizione angolare\n\nPer calcolare questi angoli, immagina di tracciare delle linee dal tuo punto $ {s} $ a ciascun polo.\nCiò di cui abbiamo bisogno è l’angolo che ciascuna linea forma con l’asse reale positivo.\nQuesti angoli possono essere calcolati utilizzando la trigonometria (in particolare, la tangente inversa).\nSe la somma di questi angoli (considerando i loro segni) è uguale a un multiplo dispari di 180 gradi, allora $ {s} $ soddisfa la condizione dell’angolo.\n\n\n\n\nMettere tutto insieme\nCombinando queste due condizioni, possiamo determinare i punti sul piano s che appartengono al luogo delle radici del sistema. Questi punti ci aiutano a capire come si comporterà il sistema per diversi valori di $ K $, soprattutto in termini di stabilità e tempo di risposta.\nNelle prossime sezioni applicheremo questi principi a esempi specifici, rafforzando i concetti e dimostrando la loro applicazione pratica nella progettazione di sistemi di controllo.\n\n\nTitolo: Comprensione del luogo delle radici: condizioni di grandezza e angolo\n\nSpiegare la condizione di magnitudo\nApprofondiamo il metodo del luogo delle radici e comprendiamo come ci aiuta nell’analisi del sistema di controllo. Il metodo del luogo delle radici prevede l’analisi di come i poli della funzione di trasferimento del sistema si muovono nel piano s quando si varia un parametro, tipicamente il guadagno $ K $.\nConsideriamo la forma generale di una funzione di trasferimento:\n\\[\nF(s) = \\frac{K \\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j) }\n\\]\ndove $ z_i $ sono gli zeri e $ p_j $ sono i poli della funzione.\nLa condizione di grandezza: - Per ogni punto $ s $ sul piano s, possiamo trovare un valore particolare di $ K $ che soddisfa la condizione di magnitudo. Nello specifico, $ K $ deve essere l’inverso della grandezza che assume la funzione di trasferimento $ F(s) $ in quel punto. - Tuttavia, soddisfare solo la condizione di magnitudo non garantisce che il punto $ s $ si trovi nel luogo delle radici del sistema.\n\n\nLa condizione angolare: chiave per il luogo delle radici\nPerché non tutti i punti soddisfano i criteri del luogo delle radici: - Il grafico del luogo delle radici non serve solo a soddisfare la condizione di magnitudo. Dipende anche in modo cruciale dalle condizioni dell’angolo. - Non tutti i punti del piano s soddisfano la condizione dell’angolo, motivo per cui non possiamo assumere che ogni punto faccia parte del luogo delle radici.\nCalcolo del luogo delle radici: - Per costruire il grafico del luogo delle radici, ci concentriamo principalmente sulla condizione dell’angolo. Scansioniamo l’intero piano s, identificando i punti in cui è soddisfatta la condizione dell’angolo. - Una volta trovati questi punti, possiamo essere certi che la condizione di magnitudo sarà soddisfatta anche per un valore di $ K $, confermando così la loro posizione nel luogo delle radici. - Questa scansione porta a un grafico perché $ K $ varia da 0 a infinito, permettendoci di tracciare il percorso dei poli attraverso il piano s al variare di $ K $.\n\n\nConclusione\nIl luogo delle radici viene costruito considerando sia la magnitudo che le condizioni angolari, e la condizione angolare è particolarmente importante.\nCon riferimento alla trama qui sotto\n\n\n\n\n\n\nTutti i punti sulle linee rosse soddisfano i criteri dell’angolo. Qualsiasi altro punto non lo soddisfa.\n\n\n\n\nEsercizio sull’analisi del luogo delle radici\n\nDomanda:\nData una funzione di trasferimento $ G(s) = $, determina il raggio e il centro del diagramma del luogo delle radici.\n\n\nRisposta:\nCome esercizio, puoi dimostrare che il grafico del luogo delle radici in questo caso avrà un centro in \\(( -b, 0 )\\) e un raggio determinato da $ $.\n\nApprofondiremo ora il metodo del luogo delle radici. Ci concentreremo sulla descrizione del luogo delle radici e lasceremo la sua interpretazione per dopo.\n\n\n\nComprensione dell’equazione del luogo delle radici\nRivisitiamo l’equazione del luogo delle radici:\n\\[1 + F(s) = 0\\]\nDove $ F(s) $ può essere rappresentato come:\n\\[\nF(s) = K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)}\n\\]\nQui, $ K $ è il guadagno del luogo delle radici, $ z_i $ sono gli zeri e $ p_j $ sono i poli.\n\nEsempio: il modello dell’impianto\nConsideriamo un impianto con una funzione di trasferimento definita come:\n\\[\nG(s) = \\frac{1}{(s+1)(s+2)}\n\\]\nIn questo contesto, $ G(s) $ modella il comportamento del nostro sistema. Esploriamo cosa succede quando incorporiamo un amplificatore in questo sistema. L’amplificatore è caratterizzato da un guadagno, indicato come $ K $.\nQuando viene introdotto questo amplificatore con guadagno $ K $, il sistema diventa un sistema a circuito chiuso. L’equazione caratteristica di questo sistema ad anello chiuso è quindi rappresentata come segue:\n\\[\n1 + \\frac{K}{(s+1)(s+2)} = 0\n\\]\nIn questa equazione, $ F(s) $ è definito dall’espressione:\n\\[\nF(s) = \\frac{K}{(s+1)(s+2)}\n\\]\nQui, $ F(s) $ cattura l’effetto combinato della pianta e dell’amplificatore. Il termine “guadagno del luogo della radice” in questo contesto si riferisce al guadagno dell’amplificatore $ K $.\nApprofondiamo il concetto di poli ad anello aperto. I poli ad anello aperto di un sistema sono i valori di $ s $ dove la funzione di trasferimento ad anello aperto, in questo caso $ F(s) $, va all’infinito. Per la nostra funzione $ F(s) $, questi poli si trovano nei valori in cui il denominatore è uguale a zero. Pertanto, per $ F(s) $, i poli dell’anello aperto sono:\n-\\(s_1 = -1\\) -\\(s_2 = -2\\)\nÈ importante notare che in questo esempio $ F(s) $ si allinea perfettamente con la forma generale discussa in precedenza per i grafici del luogo delle radici. Questo allineamento ci consente di applicare efficacemente la tecnica del luogo delle radici per analizzare come i cambiamenti nel guadagno dell’amplificatore $ K $ influenzano il comportamento del sistema, in particolare la sua stabilità.\n\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the transfer function G(s)\nnumerator = [1]  # Coefficients of the numerator\ndenominator = [1, 3, 2]  # Coefficients of the denominator (s^2 + 3s + 2)\nG_s = ctl.TransferFunction(numerator, denominator)\n\n# Get poles from the transfer function\npoles = ctl.pole(G_s)\n\n# Plotting\nplt.figure()\nplt.scatter(poles.real, poles.imag, marker='x', color='r')  # Plot poles as red 'x'\nplt.axhline(y=0, color='k', linestyle='-')  # x-axis\nplt.axvline(x=0, color='k', linestyle='-')  # y-axis\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Pole-Zero Plot on the s-plane')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nEsempio: feedback tachimetrico\nConsideriamo un sistema di controllo con un impianto specifico. Questa pianta è caratterizzata dalla sua funzione di trasferimento:\n\\[\n\\frac{25}{(s+1)(s+2)}\n\\]\n\n\n\n\n\nIn questo sistema abbiamo anche un ciclo di feedback. Questo ciclo è caratterizzato da un parametro $ s $, e questo tipo di feedback è noto come feedback tachimetrico. Il feedback tachimetrico è comunemente utilizzato nei sistemi di controllo della posizione per migliorare le prestazioni e la stabilità.\nOltre al feedback tachimetrico, il sistema include un circuito di feedback principale, noto come feedback unitario. La configurazione completa di questo sistema può essere visualizzata attraverso lo schema fornito (fare riferimento all’immagine collegata nel testo originale per una rappresentazione visiva).\nQuando analizziamo questo sistema, prestiamo particolare attenzione al circuito di feedback minore che include il feedback tachimetrico. Semplificando questa parte del sistema possiamo rappresentarne la dinamica con la seguente espressione:\n\\[\n\\frac{25}{s^2 + 3s + 2 + 25\\alpha s}\n\\]\nQuesta espressione è il risultato della combinazione della funzione di trasferimento dell’impianto con il parametro di feedback tachimetrico $ $.\nPer comprendere la stabilità e il comportamento del sistema a circuito chiuso, esaminiamo la sua equazione caratteristica:\n\\[\ns^2 + 3s + 2 + 25\\alpha s + 25 = 0\n\\]\nIn questa equazione, la variabile $ $, che rappresenta la costante tachimetrica, è fondamentale. La modifica di $ $ influenzerà la stabilità del sistema e il modo in cui risponde agli input.\nPer l’analisi del luogo delle radici, che è un metodo utilizzato per studiare la stabilità del sistema, dobbiamo riscrivere questa equazione caratteristica in una forma standard. Questa forma standard è $ 1 + F(s) = 0 $. Qui, $ F(s) $ rappresenta un rapporto di polinomi derivati ​​dalla dinamica del sistema, inclusa la funzione di trasferimento e il parametro di feedback $ $. Per il nostro sistema, la riformulazione è simile alla seguente:\n\\[\n1 + \\frac{25\\alpha s}{s^2 + 3s + 27} = 0\n\\]\nÈ importante capire che $ F(s) $ è generalmente rappresentato come:\n\\[\nF(s) = K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)}\n\\]\nNel nostro caso specifico, possiamo esprimere $ F(s) $ come:\n\\[\nF(s) = 1+\\frac{K(s+z_1)}{(s+p_1)(s+p_2)}\n\\]\nQui, $ z_1 = 0 $ (che indica uno zero nell’origine), e i poli $ p_1 $ e $ p_2 $ sono le radici del denominatore $ s^2 + 3s + 27 $. È fondamentale notare che i poli e gli zeri di $ F(s) $ possono differire da quelli del sistema ad anello aperto.\nIn questa equazione riformulata, il guadagno del luogo delle radici, indicato come $ K $, è equivalente a $ 25$. Questa formulazione si allinea con la forma standard del luogo delle radici ed è essenziale per applicare il metodo del luogo delle radici nella nostra analisi.\n\n\nCommenti sul guadagno del luogo delle radici\nQuando si studia un sistema di controllo utilizzando il metodo del luogo delle radici, un aspetto chiave da considerare è il parametro che si desidera analizzare. La cosa importante da ricordare è che l’equazione caratteristica del tuo sistema deve essere riformulata. In questa equazione riformulata, il parametro di interesse dovrebbe essere introdotto come moltiplicatore. Questo parametro specifico, che introduciamo come moltiplicatore, è noto come “guadagno del luogo delle radici”.\nMentre andiamo avanti con esempi e applicazioni di progettazione, tenete presente un’importante distinzione riguardante i poli e gli zeri. Quando parliamo di poli e zeri nel contesto del metodo del luogo delle radici, è essenziale capire che potrebbero non sempre corrispondere ai poli e agli zeri della funzione di trasferimento ad anello aperto del sistema. Sebbene in molte situazioni pratiche siano allineati, ci sono casi in cui differiscono.\nQueste differenze sorgono perché a volte è necessario manipolare i poli e gli zeri per riformattare l’equazione caratteristica originale in un formato specifico adatto all’analisi del luogo delle radici. Questa manipolazione viene eseguita per inserire il parametro di interesse (il guadagno del luogo delle radici) nell’equazione in modo da consentirci di applicare il metodo del luogo delle radici in modo efficace.\nAd esempio, quando abbiamo esplorato esempi di progettazione che coinvolgevano la costante tachimetrica, abbiamo visto come si applicava questo principio. La costante tachimetrica faceva parte del guadagno del luogo delle radici e abbiamo osservato come influenzava il comportamento del sistema attraverso il grafico del luogo delle radici.\nLa conclusione fondamentale è che, sebbene i poli e gli zeri nel metodo del luogo delle radici siano cruciali per l’analisi, dovrebbero essere intesi nel contesto di come viene riformulata l’equazione caratteristica per questo specifico metodo di analisi.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#linee-guida-per-disegnare-il-luogo-delle-radici",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#linee-guida-per-disegnare-il-luogo-delle-radici",
    "title": "Progettazione del compensatore",
    "section": "Linee guida per disegnare il luogo delle radici",
    "text": "Linee guida per disegnare il luogo delle radici\n\nIntroduzione\nLa nostra equazione primaria è:\n\\[\n1 + F(s) = 0\n\\]\no in forma estesa:\n\\[\n1+ K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)} = 0\n\\]\nDove:\n\n\\(K\\) è il guadagno del luogo delle radici (non necessariamente il guadagno del sistema).\nL’attenzione è focalizzata su \\(K \\ge 0\\) a causa della sua frequente presenza nei sistemi di controllo.\nLa realizzabilità richiede che \\(m \\le n\\). Ciò garantisce che il sistema descritto da \\(F(s)\\) sia fisicamente realizzabile.\n\n\nCriterio di magnitudo:\n\nLa condizione di magnitudo è data da:\n\n\\[\nK \\frac{\\prod_{i=1}^{m} \\left|s + z_i\\right|}{\\prod_{j=1}^{n} \\left|s + p_j\\right|} = 1\n\\]\nCriterio dell’angolo:\n\nLa condizione dell’angolo è:\n\n\\[\n\\sum_{i=1}^{m} \\angle(s + z_i) - \\sum_{j=1}^{n} \\angle(s + p_j) = \\pm (2q + 1)180^\\circ, \\quad q = 0, 1, 2, \\ldots\n\\]\n\n\n\nScansione dell’aereo-s\n\nIdentificazione dei punti che soddisfano la condizione dell’angolo:\nScansiona l’intero piano s per individuare i punti che soddisfano la condizione dell’angolo.\nCostruzione del luogo delle radici:\nCollega questi punti per formare i rami del luogo delle radici. I punti che soddisfano la condizione angolare, una volta uniti tra loro, formano i rami del luogo delle radici.\nUtilizza il calcolo della magnitudine:\nPer ogni punto su questi rami esiste un valore di \\(K\\) tale che siano soddisfatte sia la condizione della grandezza che quella dell’angolo.\n\nDomanda pop-up: Perché è importante considerare sia le condizioni di magnitudo che quelle di angolo nell’analisi del luogo delle radici?\nRisposta: entrambe le condizioni devono essere soddisfatte per garantire che i punti sul luogo delle radici rappresentino risposte valide del sistema al variare di $ K $. La condizione di ampiezza garantisce la corretta amplificazione, mentre la condizione di angolo garantisce la stabilità di fase.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#linee-guida-per-disegnare-il-luogo-delle-radici-1",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#linee-guida-per-disegnare-il-luogo-delle-radici-1",
    "title": "Progettazione del compensatore",
    "section": "Linee guida per disegnare il luogo delle radici",
    "text": "Linee guida per disegnare il luogo delle radici\nIn questa sezione esploreremo il metodo del luogo delle radici. Sebbene i tuoi libri di testo offrano dimostrazioni dettagliate, la nostra attenzione qui sarà più focalizzata sull’applicazione pratica.\nEcco come procederemo:\n\nComprensione delle regole: questa parte presenta le regole per costruire un diagramma del luogo delle radici. Non approfondiremo le dimostrazioni matematiche, ma applicheremo piuttosto queste regole attraverso esempi, concentrandoci in particolare sulla soddisfazione della condizione angolare.\nScansione del piano s: il metodo prevede la scansione dell’intero piano s per trovare punti che soddisfino la condizione dell’angolo. Immagina il piano s pieno di punti, ciascuno dei quali rappresenta una parte potenziale del luogo delle radici.\nIl metodo della forza bruta: questo metodo è semplice ma richiede molto lavoro. Per ogni punto sul piano s (chiamiamolo $ s_0 $), misuriamo gli angoli formati disegnando vettori da tutti i poli e zeri ad anello aperto della funzione $ F(s) $ a $ s_0 $. Sommando questi angoli, determiniamo se il totale è un multiplo dispari di -180 gradi, il che indica che $ s_0 $ è un punto sul luogo delle radici.\n\n\n\n\n\n\n\n\n\n\n\n\nGrafica assistita da computer: sebbene il metodo della forza bruta sia efficace, richiede anche molto tempo. Fortunatamente, gli strumenti di progettazione assistita da computer possono automatizzare questo processo, generando rapidamente un grafico del luogo delle radici. Questi strumenti possono gestire calcoli complessi e rappresentazioni grafiche, rendendo il processo di progettazione molto più efficiente.\nUtilizzo delle linee guida: esistono alcune linee guida che possono aiutarci a identificare rapidamente potenziali punti sul piano s per il criterio dell’angolo. Queste linee guida non ti forniranno immediatamente il grafico completo del luogo delle radici, ma ti guideranno vicino ai punti reali. Questo approccio, combinato con schizzi approssimativi, può essere molto istruttivo per le considerazioni iniziali sulla progettazione.\nIl ruolo dei computer nella progettazione: i software moderni hanno notevolmente semplificato questi processi. Inserendo diversi valori dei parametri di sistema come $ $ o $ K $, il software può fornire immediatamente un grafico del luogo delle radici. Questa visualizzazione aiuta in modo significativo a prendere decisioni di progettazione informate.\n\nSebbene comprendere la teoria alla base dei grafici del luogo delle radici sia importante, gli strumenti informatici di oggi aiutano notevolmente negli aspetti pratici della progettazione. Il nostro obiettivo è fondere le conoscenze teoriche con le competenze pratiche per progettare in modo efficiente sistemi di controllo.\nSe dovessi riscontrare difficoltà con i calcoli, ricorda che possono essere estesi e non è previsto che vengano eseguiti manualmente, soprattutto in un contesto di esame. Abbiamo accesso a computer in grado di eseguire questi calcoli complessi per noi. Il nostro obiettivo qui è quello di cogliere gli aspetti qualitativi dei metodi di progettazione nell’ingegneria del controllo.\nEcco il punto chiave: questo quaderno fornisce le linee guida di base per creare uno schizzo approssimativo del luogo delle radici. Questo schizzo, anche se approssimativo, è molto utile. Ti aiuta a prendere decisioni fondamentali sulla progettazione del sistema di controllo senza addentrarti in calcoli complessi. Ad esempio, sulla base di questo schizzo approssimativo, puoi decidere se utilizzare un controller proporzionale-integrale (PI), un controller proporzionale-derivativo (PD) o un controller proporzionale-integrale-derivativo (PID), tra le altre opzioni. Questo processo decisionale iniziale, guidato da una conoscenza di base del diagramma del luogo delle radici, può essere effettuato anche prima di utilizzare un computer per un’analisi dettagliata.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#come-disegnare-il-luogo-delle-radici-regole-di-disegno",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#come-disegnare-il-luogo-delle-radici-regole-di-disegno",
    "title": "Progettazione del compensatore",
    "section": "Come disegnare il luogo delle radici: regole di disegno",
    "text": "Come disegnare il luogo delle radici: regole di disegno\n\nRegola 1: regola di simmetria\nIl diagramma del luogo delle radici deve essere simmetrico rispetto all’asse reale. Questa simmetria è dovuta al fatto che in qualsiasi sistema reale le radici complesse si presentano in coppie coniugate, risultando in coefficienti reali per l’equazione caratteristica.\nSe costruisci accuratamente metà del luogo delle radici (sopra l’asse reale), l’altra metà (sotto l’asse reale) è la sua immagine speculare. Questa simmetria semplifica il processo di stampa.\n\n\nRegola 2: rami del luogo delle radici\nI rami del luogo delle radici iniziano ai poli ad anello aperto della funzione $ F(s) $ (dove $ K = 0 $) e terminano agli zeri ad anello aperto di $ F(s) $ o all’infinito (dove \\(K = \\infty\\)).\nIl numero di rami del luogo delle radici è pari a \\(n\\), il numero di poli ad anello aperto di $ F(s) $. I punti terminali di questi rami sono gli zeri di $ F(s) $ oppure i punti all’infinito.\nCiò significa che i rami \\(m\\) terminano negli zeri di \\(F(s)\\) e \\((n-m)\\) terminano all’infinito.\n\n\nRegola 3: Segmenti dell’asse reale\nPer determinare se un segmento sull’asse reale fa parte del luogo delle radici, conta il numero di poli e zeri a destra di qualsiasi punto su quel segmento. Se il conteggio è dispari, il segmento fa parte del luogo delle radici.\nQuesta regola aiuta a identificare rapidamente i segmenti dell’asse reale che appartengono al luogo delle radici. Ad esempio, se c’è un polo a destra di un punto e non ci sono zeri, il segmento a sinistra di questo punto fa parte del luogo delle radici.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPunti iniziali: In questo esempio, iniziamo con tre punti in cui $ K = 0 $. Questi punti sono i punti di partenza dei nostri rami del luogo delle radici. Ricorda, il luogo delle radici inizia dai poli ad anello aperto del sistema, che sono rappresentati da questi punti.\nPunti terminali: Per ogni ramo, c’è un punto terminale dove $ K $ si avvicina all’infinito. Nel nostro schizzo ci sono tre punti terminali di questo tipo corrispondenti a ciascun ramo.\nCapire i rami: Uno dei rami in questo grafico si estende da un punto iniziale (dove $ K = 0 $) a un punto terminale (dove $ K = $). Questo mostra un ramo completo del luogo delle radici. Tuttavia, è importante notare che questo segmento del grafico rappresenta solo un ramo dell’intero luogo delle radici.\nSegmento sul luogo delle radici: sebbene il segmento più a sinistra di questo luogo delle radici faccia parte del grafico del luogo delle radici, non costituisce necessariamente un singolo ramo indipendente. Il grafico del luogo delle radici è una combinazione di tutti questi segmenti e ciascun segmento è definito da dove inizia e finisce in termini di guadagno $ K $.\nCompletezza del ramo: Il completamento di questo ramo da $ K = 0 $ a $ K = $ suggerisce che si tratta di una rappresentazione completa di come uno dei poli del sistema si muove nel piano complesso come $ K $ varia. Tuttavia, per validare pienamente questo ramo, applicheremmo regole aggiuntive del metodo del luogo delle radici, di cui parleremo più avanti.\n\nVedremo come completare il diagramma mentre esaminiamo il resto delle regole.\n\n\nRegola 4: Direzioni degli asintoti\n\nComprendere le direzioni degli asintoti\nPer un sistema con $ n $ poli e $ m $ zeri, i rami $ n - m $ del luogo delle radici vanno all’infinito. Le direzioni in cui questi rami si avvicinano all’infinito sono determinate da una formula specifica.\n\n\nLa formula\nLa formula per la direzione degli asintoti è data da:\n\\[\n\\Phi_A = (2q + 1) \\times \\frac{180^\\circ}{n - m}\n\\]\ndove $ q = 0, 1, 2, …, n - m - 1 $.\nQuesta formula fornisce gli angoli ai quali i rami del luogo delle radici si avvicinano all’infinito. Aiuta a delineare il comportamento asintotico del grafico del luogo delle radici.\n\n\n\nRegola 5: Centroide degli asintoti\nIl baricentro degli asintoti è un punto cruciale sull’asse reale da cui vengono misurate le direzioni degli asintoti. Si calcola come:\n\\[\n\\sigma_A = \\frac{\\sum \\text{parti reali dei poli} - \\sum \\text{parti reali degli zeri}}{n - m}\n\\]\nQuesto è il punto sull’asse reale dove tutti gli asintoti si uniscono.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#applicare-le-regole-un-esempio",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#applicare-le-regole-un-esempio",
    "title": "Progettazione del compensatore",
    "section": "Applicare le regole: un esempio",
    "text": "Applicare le regole: un esempio\nApplichiamo queste regole alla funzione di trasferimento\n\\[ F(s) = \\frac{K}{s(s+1)(s+2)} \\]\nQui, $ n = 3 $ e $ m = 0 $.\nNessuno zero finito, quindi tutti i rami andranno all’infinito.\n\nAngoli asintotici e baricentro\n\nCalcolo degli angoli asintotici:\nApplicando la formula per $ n - m = 3$ direzioni:\n\\[\n\\Phi_A = (2q + 1) \\times \\frac{180^\\circ}{n - m}\n\\]\ndove \\(q = 0, 1, 2\\).\nTroviamo gli angoli in \\(\\Phi_A=\\) 60°, 180° e 240°.\nDeterminazione del centroide:\nIl baricentro $ _A $ viene calcolato come:\n\\[\n\\sigma_A = \\frac{\\sum \\text{parti reali dei poli} - \\sum \\text{parti reali degli zeri}}{n - m} = \\frac{0-1-2}{3} = -1\n\\]\n\nUtilizzando le informazioni che abbiamo per ora, possiamo iniziare a delineare il luogo delle radici:\n\n\n\n\n\n\n\n\n\nRegola 6: punto di fuga\n\nConcetto di punti di fuga\nI punti di distacco sul luogo delle radici sono posizioni critiche in cui più rami delle radici convergono o divergono sull’asse reale.\n\n\nDefinizione del punto di distacco\nIn un punto di rottura sull’asse reale, il valore del guadagno di controllo \\(K\\) è al suo massimo rispetto a quel segmento (vedi ad esempio il grafico sopra). Quando \\(K\\) aumenta oltre questo punto, le radici diventano coniugate complesse.\n\n\nCalcolo dei punti di fuga\nUsando questa comprensione intuitiva di un punto di rottura che massimizza il valore di \\(K\\), per trovare un punto di rottura, usiamo la condizione:\n\\[\n\\frac{dK}{ds} = 0\n\\]\nQuesta condizione rappresenta l’estremizzazione di $ K $ rispetto a $ s $.\nQuesto processo comporta la differenziazione di $ K $ in funzione di $ s $, ottenuta dall’equazione caratteristica del sistema. Risolviamo quindi per $ s $ dove questa derivata è uguale a zero.\nUsiamo l’espressione di \\(K\\) dall’equazione:\n\\[\n1+ K \\frac{\\prod_{i=1}^{m} (s + z_i) }{ \\prod_{j=1}^{n} (s + p_j)} = 0\n\\]\n\n\nApplicazione del concetto\nConsideriamo ancora il nostro esempio:\n\\[ 1+F(s) = 1+\\frac{K}{s(s+1)(s+2)} = 0\\]\nRicaveremo $ K $ in funzione di $ s $ e troveremo la sua derivata:\n\\[\nK = -\\Big(s^3+3s^2+2s\\Big)\n\\]\nE\n\\[\n\\frac{dK}{ds} = -\\Big( 3s^2 + 6s + 2 \\Big)=0\n\\]\nRisolvere l’equazione quadratica da \\(\\frac{dK}{ds} = 0\\) fornisce potenziali punti di rottura.\n\\[\ns_1 = -0,423,\\;\\;\\; s_2 = -1.577\n\\]\nNon tutte le soluzioni però sono valide; devono soddisfare il criterio dell’angolo per essere considerati veri e propri punti di distacco.\nQuesto è mostrato nel diagramma seguente:\n\n\n\n\n\n\n\n\n\n\nCondizioni più complesse\nConsidera la funzione\n\\[ 1+ F(s) = 1 + \\frac{K}{s(s+4)(s^2 + 4s + 20)} \\]\nIl luogo delle radici inizia dai poli $ s = 0, -4 $ e i poli complessi coniugati sono \\(s = -2\\pm j4\\).\n\nTrovare punti di fuga\n\nIdentificazione dei candidati: Risolvi $ = 0 $ per i $ F(s) $ dati per identificare potenziali punti di rottura.\nConvalida dei candidati: controllare ciascun candidato rispetto al criterio dell’angolo per confermare se si tratta di un punto di fuga valido.\n\n\n\n\n\n\n\n\nQuesto esempio mostra che i punti di distacco non si trovano sempre sull’asse reale. Si verificano punti di rottura complessi, specialmente nei sistemi con poli o zeri complessi.\nSpesso i punti di rottura mostrano simmetria, specialmente nei sistemi con configurazioni polo-zero simmetriche.\nUn altro esempio più semplice con punti di distacco è:\n\\[\n1 + F(s) = 1 + \\frac{Ks}{s^2 + 2s + 2}\n\\]\n\n\n\n\n\n\n\nAncora una volta, il punto di rottura soddisfa \\(\\frac{dK}{ds} = 0\\) e la condizione dell’angolo.\nNota: i punti di rottura sono chiamati punti di rottura quando le radici si uniscono.\n\n\n\nRadici Angoli di distacco\nQuando si analizzano i grafici del luogo delle radici, un concetto importante è l’angolo al quale le radici si staccano dall’asse reale. Questo angolo, indicato come $ $, è determinato dalla formula:\n\\[\n\\phi = \\frac{180^\\circ}{r}\n\\]\nQui, $ r $ rappresenta il numero di rami che si incontrano nel punto di separazione. Ad esempio, se due rami si incontrano, l’angolo di distacco è $ 90^$.\n\n\nEsempio di analisi:\nConsideriamo la funzione di trasferimento data da:\n\\[\n1 + F(s) = 1 + \\frac{K}{s (s + 4) (s^2 + 4s + 8)}\n\\]\nPer trovare i punti di rottura, risolviamo l’equazione derivata ponendo a zero la derivata di $ K $ rispetto a $ s $, ovvero $ = 0 $. Tra le soluzioni, solo quelle che soddisfano la condizione angolare sono considerate validi punti di distacco.\nNel nostro caso troviamo:\n\\[\n\\phi = \\frac{180^\\circ}{4} = 45^\\circ\n\\]\nCiò implica che, per questa particolare funzione di trasferimento, le radici si staccano con un angolo di $ 45^$.\n\n\nGrafico del luogo delle radici\nLo script seguente può essere utilizzato per visualizzare il grafico del luogo delle radici per questa funzione di trasferimento, illustrando i punti di rottura e i loro angoli corrispondenti.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\ns = ctl.tf('s')\n\nG_modified = 1 / (s * (s + 4) * (s**2 + 4*s + 8))\n\n# Plot root locus for the modified transfer function\nplt.figure()\nctl.root_locus(G_modified, plot=True)\nplt.title(\"Root Locus of Modified Transfer Function\")\n\nplt.show()\n\n\n# Go deeper and see what happens when you \n# modify the transfer function to change the root locus once more.\n\n# Original transfer function\n# s = ctl.tf('s')\n# G_original = 1 / (s * (s + 4) * (s**2 + 4*s + 20))\n\n# # Plot root locus for the original transfer function\n# plt.figure()\n# ctl.root_locus(G_original, Plot=True)\n# plt.title(\"Root Locus of Original Transfer Function\")\n\n# Let's change the quadratic term to s^2 + 6s + 25\n# G_modified = 1 / (s * (s + 4) * (s**2 + 6*s + 25))",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#domande",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#domande",
    "title": "Progettazione del compensatore",
    "section": "Domande",
    "text": "Domande\nDomanda pop-up: Perché il grafico del luogo delle radici è simmetrico rispetto all’asse reale?\nRisposta: La simmetria è dovuta alla complessa natura coniugata delle radici nei sistemi reali. Per ogni polo o zero complesso esiste una controparte coniugata, risultando in grafici simmetrici.\nDomanda pop-up: In che modo il numero di poli e zeri influisce sul numero di rami nel grafico del luogo delle radici?\nRisposta: Il numero di rami nel diagramma del luogo delle radici è uguale al numero di poli ad anello aperto del sistema. I rami partono da questi poli e si muovono verso gli zeri o verso l’infinito.\nDomanda pop-up: Perché abbiamo bisogno di conoscere le direzioni degli asintoti nell’analisi del luogo delle radici?\nRisposta: conoscere le direzioni degli asintoti aiuta a prevedere come si comportano i rami del luogo delle radici mentre si muovono verso l’infinito, il che è fondamentale per comprendere la stabilità e la progettazione del sistema.\nDomanda pop-up: In che modo la posizione del baricentro influisce sul grafico del luogo delle radici?\nRisposta: Il baricentro è il punto di partenza degli asintoti sull’asse reale. La sua posizione influenza il modo in cui i rami del luogo delle radici divergono verso l’infinito, influenzando la forma complessiva dell’appezzamento.\nDomanda pop-up: In che modo i punti di distacco influiscono sulla stabilità di un sistema di controllo?\nRisposta: I punti di breakaway indicano il punto in cui le radici del sistema (poli della funzione di trasferimento ad anello chiuso) passano da reale a complesso o viceversa, influenzando la stabilità del sistema e il comportamento oscillatorio.\nDomanda pop-up: I punti di distacco possono verificarsi fuori dall’asse reale?\nRisposta: Sì, soprattutto nei sistemi con poli o zeri complessi, possono verificarsi punti di rottura fuori dall’asse reale, indicando una transizione nella traiettoria della radice.\nDomanda pop-up: Perché il valore massimo di $ K $ è significativo nei punti di fuga?\nRisposta: il valore massimo di $ K $ in un punto di rottura indica la transizione dalle radici coniugate reali a quelle complesse (o viceversa), segnando un cambiamento critico nella dinamica del sistema.\nDomanda pop-up: Come determiniamo quali soluzioni per i punti di fuga sono valide?\nRisposta: Dopo aver calcolato i potenziali punti di distacco, dobbiamo confrontarli ciascuno con il criterio dell’angolo. Solo quelli che soddisfano questo criterio sono punti di fuga validi.\n\nRiepilogo\nEcco un riepilogo delle regole del luogo delle radici trattate finora:\n\nRegola di simmetria: il grafico del luogo delle radici è sempre simmetrico rispetto all’asse reale. Questa simmetria nasce perché i poli o gli zeri complessi nelle equazioni polinomiali con coefficienti reali si verificano in coppie coniugate.\nRami del luogo delle radici - Punti iniziale e finale:\n\nI rami del luogo delle radici iniziano ai poli ad anello aperto (dove il guadagno $ K = 0 $).\nTerminano con gli zeri ad anello aperto o vanno all’infinito se ci sono meno zeri che poli.\n\nSegmenti dell’asse reale: Un segmento sull’asse reale è una parte del luogo delle radici se il numero totale di poli e zeri a destra di qualsiasi punto su quel segmento è dispari.\nDirezioni degli asintoti: quando il numero di poli è maggiore del numero di zeri, i rami del luogo delle radici vanno all’infinito lungo gli asintoti. Le direzioni di questi asintoti sono date da $ = (2q + 1) $, dove $ q $ varia da 0 a $ n - m - 1 $.\nCentroide degli asintoti: Il punto sull’asse reale da cui provengono gli asintoti (il baricentro) viene calcolato utilizzando la formula: $ _A = $.\nPunti di rottura e di rottura: questi punti sul luogo delle radici sono i punti in cui i rami divergono o convergono verso l’asse reale. Possono essere trovati risolvendo $ = 0 $ per $ s $ e selezionando i punti che soddisfano il criterio dell’angolo.\n\nAngoli di rottura: L’angolo al quale i rami si staccano o convergono verso l’asse reale è $ = $, dove $ r $ è il numero di rami che si incontrano nel punto .\n\n\n\n\nRegola 7: L’angolo di partenza e di arrivo\nL’angolo di partenza da un polo complesso e l’angolo di arrivo ad uno zero complesso sono importanti per capire come si comportano i rami del luogo delle radici in prossimità di questi punti.\n\nAngolo di partenza da un polo complesso\nRegola per l’angolo di partenza: l’angolo al quale un luogo delle radici si allontana da un polo complesso è determinato dalla somma dei contributi angolari di tutti gli altri poli e degli zeri a questo polo, meno 180 gradi moltiplicati per (2q + 1) , dove q è un numero intero.\nSpiegazione di esempio: Considera un sistema con due poli e uno zero. Lo schizzo del luogo delle radici mostra la traiettoria dei poli del sistema al variare del guadagno \\(K\\). Quando \\(K\\) aumenta da 0, i poli si muovono lungo il percorso del luogo delle radici, staccandosi infine dall’asse reale. La direzione in cui si staccano (l’angolo di partenza) è essenziale per comprendere il comportamento del sistema.\n\n\n\n\n\n\n\nPassaggi per l’angolo di partenza: 1. Identificare il complesso polo di interesse. 2. Calcolare il contributo angolare, \\(\\theta_1\\), dovuto allo zero e \\(\\theta_2\\) dovuto all’altro polo. 3. Il contributo dell’angolo netto a questo polo è \\(\\theta_1 - \\theta_2\\) (il contributo zero è positivo e quello dei poli è negativo). 4. L’angolo di partenza \\(\\phi_p\\) è dato dalla formula: \\(\\phi_p = \\pm 180^\\circ \\times (2q + 1) + \\phi\\), dove \\(\\phi_p\\) è il contributo dell’angolo netto.\nAd esempio, nel caso seguente, guarda l’angolo di partenza dovuto al contributo di tutti gli zeri e i poli:\n\n\n\n\n\n\n\n\n\nAngolo di arrivo allo zero complesso\nRegola per l’angolo di arrivo: l’angolo al quale un luogo delle radici arriva a uno zero complesso viene determinato in modo simile, considerando la somma dei contributi angolari di tutti gli altri poli e zeri a questo zero.\nPassaggi per l’angolo di arrivo: 1. Identificare lo zero complesso di interesse. 2. Calcola il contributo angolare totale, \\(\\phi_z\\), da tutti i poli e gli zeri a questo zero. 3. L’angolo di arrivo è dato da \\(\\phi_z = \\pm 180^\\circ \\times (2q + 1) - \\phi\\).\nPer esempio:\n\n\n\n\n\n\n\nE l’angolo di avvicinamento allo zero è \\(\\phi_z = 180^\\circ - (\\theta_2 - 2\\theta_1)\\)\n\n\n\nRegola 8: criterio di Routh-Hurwitz e intersezione dell’asse immaginario\nConsideriamo ancora una volta:\n\\[ 1+F(s) = 1+\\frac{K}{s(s+1)(s+2)} = 0\\]\nAbbiamo determinato il seguente grafico del luogo delle radici:\n\n\n\n\n\n\n\nL’ultima regola di cui parleremo prevede l’utilizzo del criterio di Routh-Hurwitz per determinare il punto in cui il luogo delle radici interseca l’asse immaginario.\nPassaggi per utilizzare il criterio di Routh-Hurwitz: 1. Formare l’equazione caratteristica del sistema. 2. Costruisci l’array Routh. 3. Identificare la condizione per cui una riga dell’array Routh diventa zero. 4. Utilizzare questa condizione per trovare il valore di \\(K\\) in corrispondenza del quale il luogo delle radici interseca l’asse immaginario.\nEsempio:\nConsideriamo un sistema con l’equazione caratteristica \\[ G(s) = \\frac{K}{s(s+1)(s+2)} \\]\nL’equazione caratteristica è:\n\\[s^3 +3s^2 +2s+K=0\\]\nPer costruire l’array Routh per l’equazione $ s^3 + 3s^2 + 2s + K = 0 $, dobbiamo organizzare i coefficienti del polinomio in formato tabellare. L’array Routh ci aiuta a determinare il numero di radici con parti reali positive, il che rende possibile comprendere la stabilità del sistema.\nEcco come costruire l’array Routh per il polinomio dato:\n\nDisponi i coefficienti: inizia scrivendo i coefficienti del polinomio in potenze decrescenti di $ s $.\nPrime due righe: posiziona i coefficienti delle potenze pari di $ s $ nella prima riga e quelli delle potenze dispari di $ s $ nella seconda riga.\nRighe successive: calcola ogni elemento delle righe inferiori utilizzando la formula: \\[\nR_{i,j} = -\\frac{1}{R_{i-1,1}} \\left( R_{i-1,1}R_{i-2,j+1} - R_{i-2 ,1}R_{i-1,j+1} \\right)\n\\] dove $ R_{i,j} $ è l’elemento nella $ i $-esima riga e $ j $-esima colonna.\nCompletamento dell’array: continua questo processo finché non avrai riempito l’array. Se una riga qualsiasi inizia con zero, per procedere vengono utilizzate tecniche speciali come la divisione polinomiale o l’utilizzo di un piccolo numero positivo (ε).\n\nPer il polinomio dato $ s^3 + 3s^2 + 2s + K = 0 $, l’array Routh sarà:\n\n\n\n$ s^3 $\n\\(1\\)\n\\(2\\)\n\n\n$ s^2 $\n\\(3\\)\n\\(K\\)\n\n\n$ s^1 $\n$ $\n\\(0\\)\n\n\n$ s^0 $\n\\(K\\)\n\n\n\n\n\nLa prima colonna dell’array Routh indica il numero di radici con parti reali positive. Se c’è un cambiamento di segno in questa colonna, indica una radice con una parte reale positiva, il che implica instabilità nel sistema.\nLa stabilità del sistema dipende dal valore di $ K $. Affinché il sistema sia stabile, tutti gli elementi nella prima colonna devono essere positivi. Pertanto, le condizioni per la stabilità possono essere derivate garantendo valori positivi in ​​questa colonna.\n\n\n\nDeterminazione delle condizioni di stabilità\nDalla terza riga abbiamo $ $. Per la stabilità, questo termine deve essere positivo, portando alla condizione:\n\\[ K &lt; 6 \\]\nAnd from the last row, since it’s just $ K $, for stability, we must also have:\n\\[ K &gt; 0 \\]\nPertanto il sistema è stabile per:\n\\[ 0 &lt; K &lt; 6 \\]\nQuando il fattore di guadagno $ K $ è impostato su 6, incontriamo una situazione speciale nell’array Routh. Nello specifico, la riga corrispondente a $ s^1 $ diventa tutta zeri. Questo evento è significativo perché indica una certa condizione nell’analisi dei sistemi di controllo.\n\n\nComprensione del polinomio ausiliario\nQui entra in gioco il concetto di polinomio ausiliario. Deriva dalla riga appena sopra la riga tutta zero nell’array Routh. Nel nostro caso, poiché la riga $ s^1 $ è tutta zeri, esaminiamo la riga $ s^2 $.\nDalla riga $ s^2 $, il polinomio ausiliario è formato come segue:\n\\[ 3s^2 + K\\]\nPonendo $ K = 6 $, come nel nostro caso particolare, il polinomio diventa:\n\\[ 3s^2 + 6 = 0 \\]\n\n\nTrovare le radici\nLe radici di questo polinomio ausiliario sono anche le radici dell’equazione caratteristica originale in $ K = 6 $. Risolviamo questa equazione:\nIniziare con:\n\\[ 3s^2 + 6 = 0 \\]\nLo semplifichiamo in:\n\\[ s^2 + 2 = 0 \\]\nPer trovare le radici $ s_{1,2} $, risolviamo per $ s $:\n\\[ s_{1,2} = \\pm j\\sqrt{2} \\]\nQueste sono radici complesse, dove $ j $ rappresenta l’unità immaginaria.\n\n\nVisualizzazione sul diagramma del luogo delle radici\nCon queste radici, ora possiamo aggiornare il nostro diagramma del luogo delle radici. Questi punti, $ j $, rappresentano le intersezioni del luogo delle radici con l’asse immaginario. L’aggiunta di queste intersezioni ci consente di completare lo schizzo approssimativo del diagramma del luogo delle radici.\n\n\n\n\n\n\n\nDiagramma che mostra il grafico del luogo delle radici con le intersezioni in $ j $.\nQuesto passaggio è importante nella progettazione del sistema di controllo poiché ci aiuta a visualizzare come si muovono i poli del sistema nel piano complesso, in particolare quando cambia il guadagno $ K $. I punti di intersezione con l’asse immaginario forniscono preziose informazioni sulla stabilità del sistema a valori di guadagno specifici.",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-1",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-1",
    "title": "Progettazione del compensatore",
    "section": "Esempio 1",
    "text": "Esempio 1\nIn questa parte ci concentreremo su un esempio completo per comprendere l’applicazione del metodo del luogo delle radici.\nConsideriamo un sistema a retroazione unitaria con una funzione di trasferimento ad anello aperto data da:\n\\[ G(s) = K \\cdot \\frac{1}{s(s+3)(s^2+2s+2)} \\]\nIl nostro obiettivo è applicare le regole del luogo delle radici a questa funzione di trasferimento e analizzare il grafico del luogo delle radici risultante.\n\nPassaggio 1: identificazione dei poli e degli zeri ad anello aperto\nPer prima cosa dobbiamo identificare i poli e gli zeri del sistema ad anello aperto. Per la nostra data funzione di trasferimento, i poli sono a:\n-\\(s = 0\\) -\\(s = -3\\) - Le radici di $ s^2 + 2s + 2 $, che sono complesse: $ s = -1 j $\n\n\nPassaggio 2: tracciare il diagramma Polo-Zero\nSuccessivamente, tracciamo questi poli e zeri sul piano complesso $ s $. Questo ci aiuta a visualizzare i punti di partenza del nostro luogo delle radici.\n\n\n\n\n\n\n\nPossiamo ottenere il diagramma sopra in Python:\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_pole_zero_diagram(poles, zeros):\n    \"\"\"\n    Plots the pole-zero diagram.\n    \n    Parameters:\n    poles (list): List of complex numbers representing poles.\n    zeros (list): List of complex numbers representing zeros.\n    \"\"\"\n\n    # Setting up the plot\n    plt.figure(figsize=(8, 6))\n    plt.axhline(y=0, color='k')  # Horizontal axis\n    plt.axvline(x=0, color='k')  # Vertical axis\n    plt.grid(True, which='both')\n\n    # Plot poles as 'x' and zeros as 'o'\n    for pole in poles:\n        plt.plot(np.real(pole), np.imag(pole), 'rx', markersize=10)  # Poles\n    for zero in zeros:\n        plt.plot(np.real(zero), np.imag(zero), 'bo', markersize=10)  # Zeros\n\n    plt.title('Pole-Zero Diagram')\n    plt.xlabel('Real')\n    plt.ylabel('Imaginary')\n    plt.show()\n\n# Define poles and zeros for the example transfer function\npoles = [0, -3, complex(-1, 1), complex(-1, -1)]  # s=0, s=-3, s=-1±j\nzeros = []  # No zeros in this example\n\n# Call the function to plot the diagram\nplot_pole_zero_diagram(poles, zeros)\n\n\n\n\n\n\n\n\n\n\nPasso 3: Determinazione dei rami del luogo delle radici\nPoiché ci sono quattro poli e nessuno zero, ci aspettiamo quattro rami del luogo delle radici che iniziano da ciascun polo. Da questi poli si origineranno i rami in quanto il guadagno \\(K\\) varia da 0 a infinito.\nDomanda pop-up: Perché in questo caso ci aspettiamo quattro rami del luogo delle radici?\nRisposta: il numero di rami del luogo delle radici è uguale al numero di poli ad anello aperto. Qui abbiamo quattro poli, quindi quattro rami.\n\n\nPassaggio 4: calcolo degli angoli di partenza (\\(\\phi_p\\))\nLa direzione in cui il luogo delle radici si allontana dai poli complessi è importante. Questo è determinato dall’angolo di partenza, calcolato utilizzando la formula:\n\\[ \\phi_p = \\pm 180^\\circ - (\\text{somma degli angoli dovuti ad altri poli e zeri}) \\]\nEsempio di calcolo: Per i nostri poli complessi a $ s = -1 j $, calcoliamo gli angoli dovuti ad altri poli e applichiamo la formula per trovare $ _p $.\ne quindi:\n\\[ \\phi_p = \\pm 180^\\circ - \\theta_1 - \\theta_2 - \\theta_3 = -71,6^o\\]\nPer calcolare l’angolo di partenza \\(\\phi_p\\) del polo \\(-1 + j\\) per la nostra funzione di trasferimento di esempio, dobbiamo seguire questi passaggi:\n\nIdentificare il Polo e gli Altri Elementi: Ci stiamo concentrando sul polo a \\(-1 + j\\). Gli altri elementi del sistema includono i poli \\(0\\), \\(-3\\) e \\(-1 - j\\). Non ci sono zeri in questo sistema.\nCalcola i contributi angolari: il contributo angolare di ciascun polo/zero al polo a \\(-1 + j\\) è calcolato dall’angolo del vettore da ciascun polo/zero al polo a $-1 + j $.\nSomma degli angoli: somma questi contributi angolari, tenendo presente che gli angoli dovuti ai poli vengono sottratti (come sono nel denominatore della funzione di trasferimento).\nApplica la formula: usa la formula \\(\\phi_p = \\pm 180^\\circ - (\\text{somma degli angoli dovuti ad altri poli e zeri})\\).\n\nCalcoliamolo passo dopo passo:\n\n\nPassaggio 1: identificazione dei poli\n\nPoli: \\(0, -3, -1 - j\\)\nPolo di interesse: \\(-1 + j\\)\n\n\n\nPassaggio 2: calcolo dei contributi angolari\nPer ogni polo \\(s_i\\) l’angolo \\(\\theta_i\\) formato con il polo di interesse \\(-1 + j\\) si calcola come segue:\n\nPolo in \\(0\\):\n\\[\\theta_{0} = \\angle(-1 + j - 0) = \\tan^{-1}\\left(\\frac{\\text{Parte immaginaria}}{\\text{Parte reale}}\\right) = \\tan^{-1}\\left(\\frac{1}{-1}\\right) = -135^\\circ\\]\nPolo in \\(-3\\):\n\\[\\theta_{-3} = \\angle(-1 + j - (-3)) = \\tan^{-1}\\left(\\frac{1}{2}\\right) \\approx 26,57^\\circ \\]\nPolo in \\(-1 - j\\):\n\\[\\theta_{-1-j} = \\angle(-1 + j - (-1 - j)) = \\tan^{-1}\\left(\\frac{2}{0}\\right) = 90 ^\\circ\\]\n\n\n\nPassaggio 3: applicazione della formula\nInfine, applica la formula per \\(\\phi_p\\): $$ _p = ^- 135^- 26.57^- 90^ $\nCiò produce due possibili valori per \\(\\phi_p\\):\n\n\\(\\phi_{p1} = 180^\\circ - 251,56^\\circ = -71,57^\\circ\\)\n\\(\\phi_{p2} = -180^\\circ - 251,56^\\circ = 288,43^\\circ\\)\n\nQuindi, entrambi i calcoli portano allo stesso angolo di partenza, \\(-71,57^\\circ\\). Questo è l’angolo al quale il luogo delle radici si allontanerà dal polo complesso a \\(-1 + j\\).\n\n\n\n\n\n\n\n\n\nPassaggio 5: asintoti e centroide\nGli asintoti forniscono un’idea approssimativa delle direzioni in cui tenderanno i rami del luogo delle radici. Calcoliamo gli angoli degli asintoti (φA) e il baricentro (σA) utilizzando:\n\\[ \\phi_A = \\frac{(2q+1) \\times 180^\\circ}{n-m} = 45, 135, 225, 315\\]\n\\[ \\sigma_A = \\frac{\\text{somma delle parti reali dei poli - somma delle parti reali degli zeri}}{n-m} = -1,25 \\]\nDove $ n $ è il numero di poli, $ m $ il numero di zeri e $ q $ varia da 0 a $ n-m-1 = 3$.\n\n\n\n\n\n\n\nDomanda pop-up: cosa rappresenta il baricentro nel grafico del luogo delle radici?\nRisposta: il baricentro rappresenta la posizione media degli asintoti sull’asse reale, fornendo un punto di riferimento centrale per la direzione dei rami del luogo delle radici.\n\n\nPassaggio 6: punti di fuga\nI punti di breakaway sono i punti in cui i rami del luogo delle radici si allontanano dall’asse reale. Li calcoliamo utilizzando la condizione:\n\\[ \\frac{dK}{ds} = 0 \\]\nDove $ K $ è il guadagno ad anello aperto.\n\nTrova la funzione di trasferimento ad anello aperto:\n\nLa funzione di trasferimento ad anello aperto data è $ 1+F(s) = 1+ $.\n\nEsprimi $ K $ in termini di $ s $:\n\nRiscrivi $ F(s) $ in modo che $ K = -s(s+3)(s^2+2s+2) = -(s4+5s3+8s^2+6s)$.\n\nDifferenziare $ K $ rispetto a $ s $:\n\nCalcola $ $. Questo da:\n\\[\n   \\frac{dK}{ds} = -4(s^3+3,75s^2+4s+1,5)\n   \\]\n\nRisolvi per $ s $ dove $ = 0 $:\n\nQuesto passaggio richiede la ricerca delle radici dell’equazione derivata.\nRisolvere questa equazione ci darà i potenziali punti di fuga.\nQuesto è un polinomio cubico in $ s $ e le sue radici possono essere i potenziali punti di rottura. Risolvere questa equazione analiticamente può essere complesso, quindi viene spesso risolto utilizzando metodi numerici o strumenti computazionali come MATLAB o Python.\n\nnp.roots(np.dot(-4,[1, 3.75, 4, 1.5]))\n\narray([-2.28858435+0.j        , -0.73070783+0.34855858j,\n       -0.73070783-0.34855858j])\n\n\n\nTrovare una soluzione approssimativa\nPossiamo anche tentare di trovare la soluzione manualmente, utilizzando lo schizzo iniziale del luogo delle radici. Da quello schizzo vediamo che un punto di rottura deve trovarsi tra 0 e -3 sull’asse reale. Attraverso una procedura per tentativi ed errori, possiamo scoprire che \\(s=-2,3\\) soddisfa l’equazione con una precisione ragionevole.\n\n\n\nIdentificazione dei punti di fuga validi:\nDopo aver risolto l’equazione cubica, non tutte le radici saranno punti di separazione validi. I punti di distacco validi devono: - Sdraiati sull’asse reale. - Rientrare nell’intervallo dei poli e degli zeri ad anello aperto sull’asse reale. - Soddisfa il criterio dell’angolo del luogo delle radici.\n\n\nIntersezioni con l’asse immaginario\nI punti in cui il luogo delle radici interseca l’asse immaginario sono fondamentali per comprendere il comportamento oscillatorio del sistema. Questi possono essere determinati utilizzando il criterio di Routh-Hurwitz.\nApplicazione del criterio di Routh-Hurwitz: per questo sistema, i punti di intersezione risultano essere a \\(\\pm 1,1\\) e il corrispondente valore di guadagno \\(K = 8,16\\).\n\n\n\n\n\n\n\n\n\nComprendere lo schizzo del luogo delle radici\nQuando si analizzano i sistemi di controllo utilizzando il metodo del luogo delle radici, è importante distinguere tra analisi qualitativa e quantitativa. Questa distinzione è cruciale sia per creare che per interpretare i grafici del luogo delle radici.\n\n\nAnalisi qualitativa del luogo delle radici\nLo schizzo del luogo delle radici che creiamo inizialmente è una rappresentazione qualitativa. Ci dà una comprensione visiva di come i poli del sistema si muovono nel piano complesso al variare del guadagno, \\(K\\). Questo schizzo qualitativo è prezioso per cogliere il comportamento generale del sistema, come ad esempio:\n\nIndividuare i percorsi lungo i quali si muovono i poli.\nComprendere la stabilità del sistema cambia al variare del guadagno.\nOsservazione della tendenza dei poli a convergere o divergere.\n\nNota: ricorda, questo schizzo è qualitativo. Fornisce una guida visiva al comportamento del sistema ma non offre valori numerici precisi o posizioni esatte dei poli, ad eccezione di quei pochi punti che abbiamo calcolato esplicitamente.\n\n\nImportanza delle informazioni quantitative\nMentre uno schizzo qualitativo è utile per una comprensione generale, ottenere informazioni quantitative è fondamentale per un’analisi e una progettazione dettagliate. Ciò comporta:\n\nPosizioni precise dei poli per valori di guadagno specifici.\nValori esatti di guadagno dove cambia il comportamento del sistema (come attraversare l’asse immaginario).\nMargini di stabilità dettagliati e criteri di prestazione.\n\n\n\nIl ruolo della condizione angolare\nPer ricavare informazioni quantitative, ci basiamo sulla condizione dell’angolo, una parte fondamentale del metodo del luogo delle radici. La condizione dell’angolo ci aiuta a determinare:\n\nI punti esatti sul luogo delle radici che soddisfano il criterio dell’angolo, fornendoci posizioni dei poli specifiche per determinati valori di guadagno.\nLa verifica se un punto si trova nel luogo delle radici oppure no.\n\nL’applicazione della condizione dell’angolo implica il calcolo della somma degli angoli di fase forniti da tutti i poli e gli zeri in un punto nel piano complesso e l’assicurazione che questa somma sia uguale a un multiplo dispari di 180 gradi.\n\n\nProblema di progettazione: regolazione del guadagno per lo smorzamento desiderato\nUn problema di progettazione comune nei sistemi di controllo è la regolazione del guadagno, $ K $, per ottenere il livello di smorzamento desiderato, indicato come $ $. Diciamo che puntiamo a un rapporto di smorzamento di 0,5.\n\nTracciare la linea di smorzamento: tracciamo una linea corrispondente a $ = 0.5 $ nel piano $ s $ per trovare dove interseca il luogo delle radici.\n\n\\[\n\\theta = \\cos^{-1}(\\zeta) = 60^o\n\\]\n\n\n\n\n\n\n\n\nTrovare il valore di guadagno adatto: Una volta trovato il punto di intersezione, applichiamo il criterio dell’angolo per confermare che si trova sul luogo delle radici. Quindi, calcoliamo il guadagno corrispondente, $ K $, utilizzando il criterio della grandezza.\n\nSe il punto che proviamo in base al nostro schizzo approssimativo non soddisfa la condizione dell’angolo, proviamo più punti per adattare la nostra trama. Tenere presente che in questo caso sono interessati solo i punti sulla linea di smorzamento desiderata.\n\nCriterio dell’angolo: per confermare se un punto candidato si trova effettivamente nel luogo delle radici, controlla se il contributo totale dell’angolo di fase da tutti i poli e zeri a questo punto è un multiplo dispari di 180 gradi.\nVerifica: Se il criterio dell’angolo è soddisfatto, il punto si trova nel luogo delle radici. In caso contrario, regolare lo schizzo per trovare un punto di intersezione valido lungo la linea di smorzamento.\n\nFacendo il calcolo otteniamo un punto di intersezione di:\n\\[\ns = -0,4\\pm j0,7\n\\]\nQuesti sono i poli ad anello chiuso desiderati del sistema.\n\nCalcolo del guadagno $ K $\n\nCriterio di magnitudine: Una volta confermato un punto di intersezione valido, calcolare il guadagno corrispondente $ K $ utilizzando il criterio di magnitudine:\n\n\\[ K = \\left| \\frac{\\text{Prodotto delle distanze dal punto selezionato agli zeri}}{\\text{Prodotto delle distanze dal punto selezionato ai poli}} \\right| \\]\ne più formalmente:\n\\[\nK = \\frac{\\left| \\prod_{j=1}^{m} (s + p_j) \\right| }{ \\left| \\prod_{i=1}^{n} (s + z_i) \\right|}\n\\]\nPer il punto $s = -0.4 j0.7 $, misuriamo le distanze di ciascun polo (diciamo $ p_1, p_2, p_3 $) e calcoliamo $ K $:\n\\[ K = |(-0,4 \\pm j0,7 + p_1)(-0,4 \\pm j0,7 + p_2)(-0,4 \\pm j0,7 + p_3)| \\]\nSupponendo di aver misurato queste distanze e di averle calcolate, $ K $ risulta essere 2,91. Pertanto, $ K = 2,91 $ è il guadagno al quale il sistema raggiunge un rapporto di smorzamento pari a 0,5.\nTieni presente che puoi anche calcolare graficamente i \\(K\\) corrispondenti, misurando le distanze dai punti agli zeri e ai poli per avere un numero approssimativo. Dividi il prodotto delle distanze dagli zeri per il prodotto delle distanze dai poli per trovare $ K $. Poiché in questo esempio non ci sono zeri, il denominatore diventa 1.\n\n\n\nConsiderazioni aggiuntive\nCi concentreremo ora sulla ricerca dei rimanenti poli a circuito chiuso nel nostro sistema di controllo del quarto ordine.\nAbbiamo già individuato due poli, ma per completare la nostra analisi dobbiamo individuare gli altri due. Questo passaggio è cruciale per comprendere il comportamento generale del sistema, in particolare la sua stabilità e le caratteristiche di risposta.\nIl disegno che abbiamo realizzato ha senso solo se i poli che abbiamo individuato sono dominanti, e gli altri due poli sono trascurabili.\nSolo in questo caso infatti i poli dominanti a $s = -0.4 j0.7 $ sono rappresentativi del comportamento del sistema e quindi corrispondono ad avere un rapporto di smorzamento $ = 0.5 $ .\nIl nostro obiettivo ora è trovare questi poli rimanenti per garantire che siano effettivamente non dominanti.\nUtilizzo del valore di guadagno: - Abbiamo un valore di guadagno specifico di interesse, $ K = 2,91 $, che corrisponde ai nostri poli dominanti. - Il nostro compito è trovare punti sugli altri rami del luogo delle radici che corrispondono a questo stesso valore di guadagno.\n\n\nMetodologia per la localizzazione dei poli\n\nApproccio grafico:\n\nTracciando graficamente il luogo delle radici, possiamo stimare la posizione dei poli in $ K = 2,91 $.\nQuesto metodo prevede tentativi ed errori, aggiustando i punti sul luogo delle radici fino a quando il criterio della magnitudo conferma $ K = 2,91 $.\nProviamo un punto sugli altri rami del grafico e applichiamo la condizione di magnitudo per calcolare il valore di \\(K\\) finché non troviamo un punto che approssimativamente ci dia il guadagno corretto.\n\nCriterio di magnitudo:\n\nQuesto criterio viene utilizzato per verificare se un punto sul luogo delle radici corrisponde al valore di guadagno desiderato.\nFormula:\n\n\\[ K = \\frac{ \\left| \\prod_{j=1}^{n} (s + p_j) \\right| }{ \\left| \\prod_{i=1}^{m} (s + z_i) \\right| } \\]\n\nApplicando queste considerazioni vedremo che le altre due radici quando $ K = 2,91 $ si trovano a $ s_3 = -1,4 $ e $ s_4 = -2,85 $ e si trovano sull’asse reale.\nSi noti che in questo caso la condizione di dominanza non è verificata perché il rapporto tra 0,4 e 1,4 è solo di circa 3 volte (e noi vogliamo 4 o 5 volte).\nIl superamento effettivo sarà superiore a quello corrispondente a \\(\\zeta=0,5\\). Ciò è dovuto al fatto che l’influenza degli altri poli non è trascurabile.\nDovremo fare delle simulazioni per capire come si comporta il sistema.\n\n\n\n\n\n\n\n\n\n\nFigura: A sinistra: tentativi ed errori finché non troviamo il valore di guadagno desiderato. A destra: poli finali ottenuti come quadrati neri.\nE la funzione di trasferimento ad anello chiuso finale è:\n\\[\nF(s) = \\frac{2,91}{(s + 1,4)(s + 2,85)(s + 0,4 + j0,7)(s + 0,4 - j0,7)}\n\\]\n\n\nTracciare il luogo delle radici con Python\nPer tracciare il luogo delle radici per il sistema descritto, possiamo usare Python insieme alla libreria matplotlib per i grafici e alla libreria control, che fornisce funzioni specifiche per l’analisi dei sistemi di controllo, inclusi i grafici del luogo delle radici.\nDi seguito è riportato uno script Python per tracciare il luogo delle radici per il sistema dato.\nQuesto script imposta la funzione di trasferimento del tuo sistema e quindi utilizza la funzione “root_locus” dalla libreria “control” per tracciare il luogo delle radici. Il grafico del luogo delle radici mostrerà come i poli del sistema a circuito chiuso si muovono nel piano complesso al variare del guadagno \\(K\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctl\n\n# Define the transfer function\nnumerator = [1]\ndenominator = [1, 5, 8, 6, 0]  # s^4 + 5s^3 + 8s^2 + 6s\nsystem = ctl.TransferFunction(numerator, denominator)\n\n# Plot the root locus\nfig, ax = plt.subplots()\nrl, k = ctl.root_locus(system, plot=True, ax=ax)\n\n# Improve plot aesthetics\nax.set_title('Root Locus Plot')\nax.set_xlabel('Real Axis')\nax.set_ylabel('Imaginary Axis')\nax.axhline(y=0, color='k', lw=1)\nax.axvline(x=0, color='k', lw=1)\nax.grid(True, which='both', ls='--', lw=0.5)\n\n# Adjust plot limits if necessary\nax.set_xlim([-4, 1])\nax.set_ylim([-3, 3])\n\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-2-1",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#esempio-2-1",
    "title": "Progettazione del compensatore",
    "section": "Esempio 2",
    "text": "Esempio 2\nIn questo esempio, approfondiamo l’applicazione dell’analisi del luogo delle radici per la progettazione di sistemi di controllo con parametri multipli. Ci concentreremo su un esempio specifico che coinvolge un sistema di controllo della posizione con feedback tachimetrico.\n\nComprendere la configurazione del sistema\nConsideriamo un sistema con una funzione di trasferimento ad anello aperto della forma:\n\\[ G(s) = K_A \\cdot \\frac{s}{s(s+2)} \\]\nDove $ K_A $ è il guadagno dell’amplificatore. Il nostro obiettivo è progettare questo sistema per un valore specificato del rapporto di smorzamento $ $.\n\n\n\n\n\n\n\n\n\nRisoluzione in una configurazione a ciclo singolo\nLa prima cosa che vogliamo fare è convertire il sistema in una configurazione a loop singolo:\n\\[ F(s) = \\frac{K_A}{s^2 + (2 + K_A K_T) s} \\]\nDove $ K_t $ rappresenta la costante tachimetrica.\n\n\n\n\n\n\n\n\nDeterminazione dell’equazione caratteristica\nL’equazione caratteristica di questo sistema è:\n\\[ s^2 + (2 + K_A K_T) s + K_A = 0 \\]\nCome abbiamo discusso, i poli e gli zeri del sistema potrebbero essere diversi da quelli ad anello aperto.\n\n\nPassaggio 1: formulazione della funzione del luogo delle radici\nEsprimiamo l’equazione caratteristica in una forma adatta per l’analisi del luogo delle radici:\nPer fare ciò possiamo riscrivere l’equazione caratteristica in questa forma:\n\\[ s^2 + 2s + K_A + K_AK_T s = 0 \\]\n\\[ K_A + K_AK_T s = -s^2 - 2s \\]\n\\[ K_AK_T s = -s^2 - 2s -K_A\\]\ne infine possiamo scrivere l’equazione del luogo delle radici:\n\\[ 1 + \\frac{K_A K_Ts}{s^2 + 2s + K_A} = 0 \\]\nQui, $ K = K_A K_T $ funge da guadagno del luogo delle radici. Se ad esempio voglio capire come \\(K_T\\) influenza le mie prestazioni, devo avere l’equazione in modo che \\(K_T\\) sia il mio guadagno del luogo delle radici:\n\\[\n1 + KF(s) = 0, \\;\\;\\; K = K_A K_T\n\\]\n\n\n\nProblema di progettazione: specificare il rapporto di smorzamento\nSupponiamo di avere \\(K_A=60\\) e di voler progettare \\(K_T\\) in modo che il sistema abbia un rapporto di smorzamento $ = 0,5 $.\nQuesto specializza la nostra equazione:\n\\[ 1 + \\frac{60 K_Ts}{s^2 + 2s + 60} = 0 \\]\n\nPassaggio 1: schizzo del luogo delle radici\n\nIl grafico del luogo delle radici ci aiuta a visualizzare come si muovono i poli del sistema al variare di $ K $.\nIdentifichiamo i poli, gli zeri e i punti di rottura sul luogo delle radici.\n\n\n\nPassaggio 2: calcolo di $ K_T $ per lo smorzamento desiderato\n\nDisegniamo una linea nel piano s corrispondente a $ = 0,5 $.\nTrova l’intersezione di questa linea con il luogo delle radici per identificare il valore corrispondente di $ K $.\nCalcola $ K_T $ da $ K $ usando $ K_T = $.\n\n\n\n\n\n\n\n\n\n\n\nComprendere i contorni delle radici\nI contorni delle radici rappresentano i grafici del luogo delle radici per vari valori di un parametro mantenendo costante l’altro. Questo concetto è cruciale per i sistemi con più parametri variabili.\n\nContorni radice per variare $ K_A $\n\nTracciamento dei contorni delle radici: per ciascun valore di $ K_A $, traccia il luogo delle radici corrispondente.\nAnalisi: Osserva come cambiano i rami del luogo delle radici con diversi valori di $ K_A $.\n\n\n\n\n\n\n\n\nInfatti la linea tratteggiata verticale nel diagramma sopra è il luogo delle radici dell’equazione:\n\\[\ns^2 + 2s + K_A = 0\n\\]\nSe hai più parametri come avevamo prima:\n\\[ 1 + \\frac{K_A K_Ts}{s^2 + 2s + K_A} = 0 \\]\n\nConcentrati sul denominatore, che è funzione di un solo parametro. Le radici del denominatore sono i poli ad anello aperto della funzione totale.\n\n\nPrima di tutto studia: \\(s^2 + 2s + K_A=0\\), includendo se necessario (e potrebbe essere per una funzione complessa) mettilo nella forma del luogo delle radici:\n\n\\[\n1 + \\frac{K_A}{s(s+2)}\n\\]\ne tracciare il luogo delle radici (che è una linea verticale tra 0 e -2).\n\nQuesto luogo delle radici fornisce i poli ad anello aperto per la funzione completa. Ciò significa che puoi prendere due punti qualsiasi su questo luogo delle radici e rappresentano i tuoi poli ad anello aperto (per un valore specifico del tuo parametro \\(K_A\\)).\nDisegna il luogo delle radici per l’altro parametro (\\(K_T\\) nel nostro caso).",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/compensator_design_using_root_locus_it.html#analisi-del-luogo-delle-radici-per-sistemi-con-tempi-morti",
    "href": "IT_🇮🇹/compensator_design_using_root_locus_it.html#analisi-del-luogo-delle-radici-per-sistemi-con-tempi-morti",
    "title": "Progettazione del compensatore",
    "section": "Analisi del luogo delle radici per sistemi con tempi morti",
    "text": "Analisi del luogo delle radici per sistemi con tempi morti\nCi occupiamo ora dell’analisi del luogo delle radici dei sistemi di controllo che includono tempi morti, uno scenario comune nelle applicazioni del mondo reale. Utilizzeremo l’approssimazione di Pade per semplificare l’elemento del tempo morto e analizzare il suo impatto sul grafico del luogo delle radici.\n\nComprendere i tempi morti nei sistemi di controllo\nIl tempo morto nei sistemi di controllo si riferisce a un ritardo tra la risposta di ingresso e quella di uscita. È spesso rappresentato da un termine come $ e^{-s_D} $ nella funzione di trasferimento, dove $ _D $ è il tempo morto.\n\nEsempio: funzione di trasferimento con tempo morto\nConsideriamo una funzione di trasferimento con tempi morti:\n\\[ G(s) = \\frac{K \\cdot e^{-s\\tau_D} }{ s }\\]\n\n\n\nApprossimazione del tempo morto: approssimazione di Pade\nIl tempo morto può essere approssimato utilizzando l’approssimazione di Pade, che converte il ritardo esponenziale in una funzione razionale. L’approssimazione per un Pade del primo ordine è:\n\\[ e^{-s\\tau_D} \\approx \\frac{1 - \\frac{\\tau_D}{2} s}{1 + \\frac{\\tau_D}{2} s} \\]\n\n\nTrasformazione della funzione di trasferimento\nApplicando l’approssimazione di Pade a $ G(s) $, la funzione di trasferimento diventa:\n\\[ G(s) = \\frac{K}{s} \\frac{1 - \\frac{\\tau_D}{2} s}{1 + \\frac{\\tau_D}{2} s} = -K \\cdot \\frac{s - \\frac{2}{\\tau_D}}{s(s + \\frac{2}{\\tau_D})} \\]\nSi noti il segno negativo che deriva dall’approssimazione.\nCiò corrisponde all’equazione:\n\\[\n1-G(s) = 0\n\\]\n\nCriteri di angolo e grandezza\n\nCriterio di magnitudo: rimane invariato; $ |G(s)| = 1$.\nCriterio angolo: modifica in base al segno negativo. Il criterio cambia da un multiplo dispari di 180 gradi a un multiplo pari: \\[ \\angle G(s) = \\pm 2q \\times 180^\\circ \\]\nQuesto perché l’equazione ora è \\(G(s)=1\\) (prima era \\(G(s)=-1\\)).\n\n\n\nCostruire il luogo delle radici\n\nIdentificare poli e zeri:\n\nPolo a $ s = 0 $\nZero a $ s = $\nPolo aggiuntivo a $ s = - $ dovuto all’approssimazione di Pade.\n\nTracciamento del luogo delle radici:\n\nRispetto alle regole che abbiamo visto ci sono solo due modifiche: - I segmenti dell’asse reale che fanno parte del luogo delle radici cambiano a causa del segno negativo. - Utilizzare il criterio dell’angolo modificato per determinare quali segmenti dell’asse reale appartengono al luogo delle radici.\n\n\n\nTracciamento del luogo delle radici con Python\nQuesto codice genera il grafico del luogo delle radici per un sistema con tempi morti, considerando le modifiche richieste a causa dell’approssimazione di Pade. Fornisce una rappresentazione visiva di come i poli del sistema si muovono nel piano complesso come guadagno \\(K\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\n\n# Define the system parameters\nK = -1  # Gain\ntau_D = 1  # Dead time\n\n# Transfer function with Pade's approximation for dead time\nnumerator = [1, -tau_D/2]\ndenominator = [1, tau_D/2, 0]\n\nG_s = ctrl.TransferFunction(K * np.array(numerator), np.array(denominator))\n\n# Plotting the root locus\nplt.figure(figsize=(8, 6))\nrlist, klist = ctrl.root_locus(G_s, plot=True)\nplt.xlabel('Real Axis')\nplt.ylabel('Imaginary Axis')\nplt.title('Root Locus of System with Dead Time (Pade Approximation)')\nplt.grid(True)\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Progettazione del compensatore"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "",
    "text": "Nei notebook precedenti abbiamo approfondito le prestazioni dei sistemi di feedback. Questo notebook si concentra su due aree chiave: precisione in condizioni stazionarie e un esempio di progettazione completo.\nIl nostro obiettivo è consolidare la tua comprensione di questi concetti attraverso un approccio pratico.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#precisione-allo-stato-stazionario",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#precisione-allo-stato-stazionario",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Precisione allo stato stazionario",
    "text": "Precisione allo stato stazionario\nLa precisione allo stato stazionario è un aspetto cruciale dei sistemi di controllo, poiché indica la capacità del sistema di mantenere un output costante quando sottoposto a un input costante. Abbiamo già esaminato questo concetto e ora lo rivisiteremo, aggiungendo una prospettiva quantitativa.\n\n\n\n\n\nApprofondiamo la descrizione quantitativa dell’accuratezza in stato stazionario utilizzando il diagramma a blocchi.\nCi concentreremo sulla relazione tra il modello dell’impianto $ G(s) $, il controller $ D(s) $ e come interagiscono con l’input del comando $ R $, l’output $ Y $ e l’errore $ E $.\nLa presenza di un disturbo può essere analizzata in modo simile.\nCome abbiamo già visto più volte:\n\nModello impianto $ G(s) $:\n\nRappresenta la funzione di trasferimento del sistema che stiamo controllando. È un modello matematico del comportamento dinamico del sistema.\n\nController $ D(s) $:\n\n$ D(s) $ è la funzione di trasferimento del controller nel sistema. Definisce come il controller agirà sul segnale di errore per regolare il comportamento del sistema.\n\nConfigurazione del sistema di feedback:\n\nIl sistema è configurato in un circuito di feedback in cui l’uscita viene confrontata con l’ingresso per generare un segnale di errore $ E $.\n\nSegnale di errore $ E(s) $:\n\nQuesta è una parte fondamentale del ciclo di feedback. $ E(s) $ rappresenta la differenza tra l’output desiderato (ingresso di comando $ R(s) $) e l’output effettivo $ Y(s) $ del sistema.\n\nInput di comando $ R(s) $:\n\n\nQuesto è l’output del sistema desiderato nel dominio di Laplace. Potrebbe essere un gradino, una rampa o qualsiasi altro modulo di input.\n\n\nUscita del sistema $ Y(s) $:\n\n\nL’output effettivo del sistema, rappresentato anche nel dominio di Laplace.\n\n\nDinamica degli errori\nIn un sistema di controllo, spesso esprimiamo l’errore $ E(s) $ come $ E(s) = R(s) - Y(s) $. In un ciclo di feedback, questo diventa $ E(s) = R(s) - G(s)D(s)E(s) $.\nRiorganizzazione per $ E(s) $: Riorganizzando l’equazione di cui sopra, otteniamo\n\\[ E(s) = \\frac{R(s)}{1 + D(s)G(s)} \\]\nQui, $D(s)G(s) $ rappresenta il guadagno totale del circuito del sistema.\n\nPerché dividere $ G(s) $ e $ D(s) $?\n\nConsiderando separatamente $ G(s) $ e $ D(s) $, possiamo studiare il sistema in modo più flessibile, soprattutto quando si considerano diversi tipi di controllori (PD, PI, PID).\nQuesta separazione consente un approccio modulare alla progettazione del sistema, in cui l’impianto e il controller possono essere progettati e analizzati in modo indipendente prima di essere combinati.\n\n\n\nImplicazioni pratiche\n\nFlessibilità di progettazione: diversi controllori (PD, PI, PID) possono essere modellati e testati semplicemente modificando $ D(s) $ senza alterare il modello dell’impianto $ G(s) $.\nAnalisi del sistema: è possibile valutare facilmente l’impatto delle modifiche del controller sulle prestazioni del sistema, tra cui stabilità, risposta ai transitori ed errore stazionario.\nOttimizzazione del controller: manipolando $ D(s) $, il controller può essere ottimizzato per ottenere le specifiche prestazionali desiderate come errore minimo in stato stazionario, risposta transitoria desiderata e margini di stabilità.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#rivisitazione-del-teorema-del-valore-finale",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#rivisitazione-del-teorema-del-valore-finale",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Rivisitazione del teorema del valore finale",
    "text": "Rivisitazione del teorema del valore finale\nIl teorema del valore finale è uno strumento che usiamo per calcolare l’errore stazionario di un sistema. Ricordiamo il teorema:\n\\[ e_{ss} = \\lim_{s \\to 0} sE(s) \\]\nDove $ E(s) $ è il segnale di errore nel dominio di Laplace.\nNel nostro caso:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{sR(s)}{(1 + D(s)G(s))} \\]\n\nErrore di stato stazionario per ingressi standard\nConsideriamo tre input standard: gradino, rampa e parabola.\nAnalizzeremo ogni caso:\n\nInserimento passo-passo $ R(s) = $:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s(1 + D(s)G(s))} = \\lim_{s \\to 0} \\frac{1}{ 1 + D(s)G(s)} = \\frac{1}{1 + \\lim_{s \\to 0} D(s)G(s)}\\]\nQuesto si semplifica in \\[ e_{ss} = \\frac{1}{1 + K_p} \\]\ndove $ K_p $ è chiamato costante errore di posizione.\nInvece di specificare l’errore di stato stazionario del sistema su un ingresso di passo unitario, è possibile fare riferimento in modo equivalente alla costante dell’errore di posizione.\n\nÈ importante sottolineare che nell’ambito dei sistemi di controllo della posizione, un ingresso a gradino è sinonimo di un ingresso di posizione. Questo concetto, tuttavia, non si limita ai soli scenari di controllo della posizione. Il principio può essere esteso a vari tipi di sistemi di controllo. Ad esempio, nei sistemi di controllo della temperatura o di controllo del livello del liquido, l’ingresso della fase può rappresentare un cambiamento improvviso della temperatura o del livello desiderati. La costante di errore di posizione diventa quindi uno strumento versatile, fornendo una metrica universale per quantificare e confrontare la precisione a regime di diversi sistemi di controllo in diverse applicazioni.\n\nIngresso rampa $ R(s) = $:\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s^2(1 + D(s)G(s))} = \\lim_{s \\to 0} \\frac{1 }{s(1 + D(s)G(s))} \\]\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} \\]\nCiò porta a \\[ e_{ss} = \\frac{1}{K_v} \\]\ndove $ K_v = _{s } sD(s)G(s)$ è la costante di errore di velocità.\nNei sistemi di controllo della posizione, un ingresso di rampa equivale a un comando di velocità. Quando si parla della costante dell’errore di velocità, resta inteso che il sistema sta rispondendo a un ingresso di rampa.\nIngresso parabolico $ R(s) = $:\n\n\\[ e_{ss} = \\lim_{s \\to 0} \\frac{s}{s^3(1 + D(s)G(s))} = \\lim_{s \\to 0} \\frac{1 }{s^2(1 + D(s)G(s))} \\]\n$ e_{ss} = _{s } $\nIl risultato è \\[ e_{ss} = \\frac{1}{K_a} \\]\ndove $ K_a = _{s }s^2D(s)G(s)$ è la costante di errore di accelerazione.\nNei sistemi di controllo della posizione, un ingresso di rampa equivale a un comando di accelerazione. Quando si discute della costante di errore di accelerazione, resta inteso che il sistema sta rispondendo a un input parabolico.\nLa conclusione della nostra discussione sull’accuratezza in stato stazionario è piuttosto significativa. Esistono due modi principali per descrivere la precisione a regime di un sistema:\n\nErrore in stato stazionario con un ingresso specificato: questo approccio prevede la specifica diretta dell’errore in stato stazionario per un dato tipo di segnale di ingresso.\nCostanti di errore $ K_p, K_v, $ e $ K_a $: In alternativa, possiamo descrivere la precisione a regime stazionario del sistema utilizzando costanti di errore:\n\n$ K_p $ per la costante dell’errore di posizione,\n$ K_v $ per la costante dell’errore di velocità,\n$ K_a $ per la costante dell’errore di accelerazione.\n\n\nQueste costanti di errore sono definite specificamente per i tipi di ingresso standard: gradino unitario, rampa unitaria, parabola unitaria.\nTuttavia, è importante comprendere che se l’input nel sistema differisce da questi moduli standard, sarà necessario applicare un ridimensionamento appropriato alle costanti di errore. Questa messa in scala è necessaria per rappresentare accuratamente l’errore a regime per ingressi non standard. In questo modo, è possibile estendere l’applicazione di queste costanti di errore a una gamma più ampia di segnali di ingresso, mantenendo la pertinenza e l’accuratezza della descrizione dell’accuratezza dello stato stazionario del sistema. Il processo di ridimensionamento, una volta compreso, diventa semplice, consentendo un adattamento flessibile a vari tipi di input.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#espressione-generale-della-funzione-di-trasferimento",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#espressione-generale-della-funzione-di-trasferimento",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Espressione generale della funzione di trasferimento",
    "text": "Espressione generale della funzione di trasferimento\nLa funzione di trasferimento di un sistema di controllo, sia esso il modello di impianto $ G(s) $ o il sistema combinato $ D(s)G(s) $, può generalmente essere rappresentata come\n\\[ \\frac{\\prod_i (s - z_i)}{s^N \\prod_j (s - p_j)} \\]\nIn questa rappresentazione, $ z_i $ e $ p_j $ indicano rispettivamente gli zeri e i poli della funzione di trasferimento.\nIl termine $ s^N $ è particolarmente importante poiché indica la presenza di poli nell’origine (s = 0) sul piano s.\nPer la nostra analisi, ci concentriamo sui casi in cui $ N $, il che non implica potenze negative di $ s $ al denominatore.\nEventuali zeri nell’origine possono essere rappresentati tramite $ z_i = 0 $. Tuttavia, in questa rappresentazione tutte le potenziali cancellazioni dei poli zero all’origine sono già prese in considerazione.\n\nComprensione del ruolo dei poli a $ s = 0 $ nell’analisi dello stato stazionario\n\nApprofondimenti chiave su $ s^N $ nella funzione di trasferimento del sistema:\nIl termine $ s^N $ nella funzione di trasferimento $ D(s)G(s) $ è fondamentale nel modellare il comportamento stazionario di un sistema di controllo. Influisce direttamente sul modo in cui il sistema risponde a vari input, determinati dal valore di $ N $, il numero di poli nell’origine.\n\nAnalizzare l’impatto quando $ s $ si avvicina allo zero:\n\nL’attenzione qui è sul comportamento del sistema in una condizione stazionaria.\nQuando $ s $ si avvicina allo zero, ogni termine nella funzione di trasferimento, come $ (s - z_i) $ e $ (s - p_j) $, mantiene un valore definito.\nIl comportamento di $ D(s)G(s) $ dipende in gran parte da $ N $, il numero di poli in $ s = 0 $. Nello specifico, valori diversi di $ N $ possono far sì che alcuni termini della funzione diventino infiniti quando $ s = 0 $. Questo è cruciale perché determina se il sistema può raggiungere uno stato stazionario per determinati input. Ad esempio, un sistema di tipo 0 (con $ N = 0 $) ha un errore finito per gli ingressi a gradino ma errori infiniti per gli ingressi a rampa e parabolici.\nL’importanza di $ s^N $ risiede nella sua influenza primaria sul comportamento in stato stazionario del sistema, decidendo essenzialmente se il sistema presenterà errori in stato stazionario finiti o infiniti per vari tipi di input.\n\nConsiderando valori negativi di $ N $:\n\nNegli scenari in cui $ N $ è negativo, indicando uno zero all’origine, l’analisi rimane priva di problemi. Questo perché qualsiasi termine che coinvolga $ s $ risulterebbe in una grandezza zero in tali casi, portando a un comportamento definito e prevedibile nella funzione di trasferimento.\n\n\nIn sostanza, il termine $ s^N $ è un determinante chiave nella funzione di trasferimento, modellando la precisione dello stato stazionario del sistema di controllo. Comprendere come si comporta questo termine, in particolare quando $ s $ converge a zero, è fondamentale per ottenere informazioni sulla capacità del sistema di mantenere uno stato stazionario in diverse condizioni di input.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#classificazione-del-sistema-e-comportamento-in-stato-stazionario-basati-su-n",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#classificazione-del-sistema-e-comportamento-in-stato-stazionario-basati-su-n",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Classificazione del sistema e comportamento in stato stazionario basati su \\(N\\)",
    "text": "Classificazione del sistema e comportamento in stato stazionario basati su \\(N\\)\n\nClassificazione dei sistemi in base a $ N $ e considerazione dei tipi di input:\nI sistemi di controllo sono classificati in base al valore di $ N $, che indica il numero di poli nell’origine. Questo è equivalente al numero di integratori nel percorso di andata del sistema. In questa classificazione:\n\nUn sistema di tipo 0, dove $ N = 0 $, non ha integratori all’origine.\nUn sistema di tipo 1 ha un integratore, che indica un singolo polo all’origine, e questo modello continua per tipi di sistema superiori.\n\nÈ fondamentale comprendere, tuttavia, che l’influenza di $ N $ sulla risposta del sistema non è assoluta ma varia a seconda del tipo di input. Se il numeratore del sistema ha termini che contrastano l’effetto $ s^N $ nel denominatore, il sistema potrebbe non mostrare un comportamento infinito per determinati input.\nIl valore di $ N $ è generalmente un forte indicatore del potenziale di precisione del sistema in condizioni stazionarie. Tuttavia, l’effettivo comportamento in condizioni stazionarie dipende anche dalla natura dell’input. In alcuni casi, tipi di input specifici possono portare a cancellazioni nella funzione di trasferimento, alterando l’errore di stato stazionario atteso indipendentemente da $ N $. Quindi, la risposta in stato stazionario del sistema è determinata non solo da $ N $, ma anche dall’interazione di $ N $ con la particolare funzione di input $ R(s) $. Questa comprensione sfumata è vitale per prevedere e progettare con precisione le risposte del sistema.\n\n\nInfluenza del controller e gestione dei diversi input\nIl controller $ D(s) $ ha la capacità di modificare il conteggio degli integratori nel percorso di andata di un sistema, modellando così in modo significativo il suo comportamento in stato stazionario.\nAd esempio, l’utilizzo di un controller PI è un modo strategico per integrare un integratore aggiuntivo nel percorso in avanti. Questa aggiunta deliberata è fondamentale per ottimizzare le prestazioni del sistema per allinearlo a requisiti operativi specifici.\nAnche la natura del segnale di ingresso, che sia a gradino, a rampa o di tipo parabolico, gioca un ruolo fondamentale nell’influenzare la reazione del sistema. Nel caso di un sistema di tipo 1 (un integratore), ci si può aspettare un errore finito a regime quando si ha a che fare con un ingresso a gradino. Tuttavia, la risposta potrebbe avere un errore infinito per un ingresso a rampa o parabolico, a meno che non vi sia una cancellazione nella funzione di trasferimento che altera questo comportamento.\n\n\nDigitare il numero del sistema\nLa tabella seguente illustra la relazione tra il valore di \\(N\\) e la corrispondente tipologia di sistema di controllo:\n\n\n\n\n\n\n\n\nValore di $ N $\nTipo di sistema\nDescrizione\n\n\n\n\n0\nSistema di tipo 0\nIl sistema non ha integratori nel percorso in avanti, il che significa che non ci sono poli all’origine.\n\n\n1\nSistema di tipo 1\nIl sistema include un integratore nel percorso in avanti, equivalente ad un singolo polo all’origine.\n\n\n2\nSistema di tipo 2\nIl sistema contiene due integratori nel percorso in avanti, che indicano due poli nell’origine.\n\n\n3\nSistema di tipo 3\nIl sistema ha tre integratori nel percorso in avanti, corrispondenti a tre poli nell’origine.\n\n\n…\n…\nAll’aumentare di $ N $, il numero di integratori nel percorso in avanti aumenta di conseguenza.\n\n\n\nQuesta tabella classifica i sistemi di controllo in base al numero di integratori (poli all’origine), che è un fattore chiave nel determinare la loro risposta in stato stazionario a diversi tipi di segnali di ingresso.\nIl sistema caratterizzato dalla funzione di trasferimento\n\\[ \\frac{s}{s^2} = \\frac{1}{s} \\]\nè identificato come un sistema di Tipo 1.\nQuesto sistema agisce effettivamente come un integratore, ma è anche importante riconoscere che questo comportamento deriva da un’imperfetta cancellazione del polo zero.\nSebbene i suoi effetti operativi imitino da vicino quelli di un integratore ideale, la presenza di imperfezioni pratiche significa che non raggiunge l’esatto comportamento di un integratore perfetto. Questa distinzione evidenzia i limiti del sistema nel mondo reale rispetto all’ideale teorico che rappresentiamo matematicamente.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#esplorazione-dei-tipi-di-sistema-e-dei-loro-comportamenti-in-base-a-n",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#esplorazione-dei-tipi-di-sistema-e-dei-loro-comportamenti-in-base-a-n",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Esplorazione dei tipi di sistema e dei loro comportamenti in base a $ N $",
    "text": "Esplorazione dei tipi di sistema e dei loro comportamenti in base a $ N $\nLa funzione di trasferimento di un sistema di controllo, sia esso il modello di impianto $ G(s) $ o il sistema combinato $ D(s)G(s) $, può tipicamente essere rappresentata come:\n\\[\nD(s)G(s) = \\frac{K \\prod_{i}(s - z_i)}{(s^N \\prod_{j}(s - p_j))}\n\\]\nEcco una tabella che delinea diversi tipi di sistema in base al valore di $ N$, insieme ad esempi e caratteristiche chiave:\n\n\n\n\n\n\n\n\n\nValore di $ N $\nTipo di sistema\nDescrizione\nEsempio\n\n\n\n\n0\nSistema di tipo 0\nNessun integratore nel percorso in avanti. Tipicamente, errore stazionario finito per ingressi a gradino ma errore infinito per ingressi a rampa o parabolici.\nSistemi di controllo della temperatura modellati come $ $, Sistemi di controllo del livello di liquidi.\n\n\n1\nSistema di tipo 1\nUn integratore nel percorso in avanti. Errore stazionario zero per gli ingressi a gradino, finito per gli ingressi a rampa, ma infinito per gli ingressi parabolici.\nSistemi di controllo motore in applicazioni di controllo della velocità, modellati come $ $.\n\n\n2\nSistema di tipo 2\nDue integratori nel percorso in avanti. Errore stazionario zero sia per gli ingressi a gradino che per quelli a rampa, finito per gli ingressi parabolici.\nControllo dell’assetto di un satellite, modellato come $ $.\n\n\n≥3\nSistema di tipo 3\nTre o più integratori nel percorso in avanti. Applicazioni altamente specializzate che richiedono precisione statica avanzata.\nSistemi avanzati di controllo radar o antenna che tracciano bersagli in rapido movimento.\n\n\n\nQuesta tabella fornisce una panoramica di come il numero di integratori nel percorso in avanti, indicato da $ N$, classifica il sistema e influenza la sua risposta a vari input.\n\nAnalisi dell’errore allo stato stazionario nei sistemi di tipo 0\nIn un sistema di tipo 0, la costante di errore di posizione $ K_p $ è data da:\n\\[ K_p = \\frac{K \\prod_{i}(s - z_i)}{\\prod_{j}(s - p_j)}\\Big|_{s=0} \\]\nPer questo tipo di sistema, l’errore stazionario ( e_{ss} ) in risposta a un ingresso passo viene calcolato come:\n\\[ e_{ss} = \\frac{1}{1 + K_p} \\]\nQuesto valore è finito, indicando che i sistemi di tipo 0 possono gestire efficacemente gli input di gradini con un errore finito allo stato stazionario.\nTuttavia, quando si tratta di ingressi a rampa e parabolici, lo scenario cambia radicalmente:\n\nPer ingressi rampa: \\[ e_{ss}^{rampa} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} = \\frac{1}{K_v} = \\infty \\] Il sistema presenta un errore infinito in stato stazionario, dimostrando la sua incapacità di mantenere la precisione con gli ingressi a rampa.\nPer ingressi parabolici: \\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} = \\frac{1}{K_a} = \\infty \\] Analogamente agli ingressi a rampa, anche per gli ingressi parabolici l’errore è infinito.\n\n\nImplicazioni per i sistemi di tipo 0\nQuesta analisi rivela che i sistemi di tipo 0 sono limitati nella loro capacità di raggiungere un’elevata precisione in condizioni stazionarie, in particolare per ingressi a rampa e parabolici. Sebbene possano fornire prestazioni ragionevoli per gli input a gradini, la loro utilità è limitata quando si confrontano con tipi di input più complessi.\nPer migliorare il comportamento in condizioni stazionarie e soddisfare requisiti di precisione più elevati, è necessario introdurre intenzionalmente degli integratori nella progettazione del controller. L’aggiunta di integratori aumenta effettivamente il tipo del sistema, migliorando così la sua capacità di gestire una gamma più ampia di tipi di input con una migliore precisione in condizioni stazionarie.\n\n\n\nAnalisi dell’errore allo stato stazionario nei sistemi di tipo 1\n\n\nComprensione dell’errore allo stato stazionario nei sistemi di tipo 1\nNei sistemi di tipo 1, caratterizzati da un integratore nel cammino diretto, la funzione di trasferimento \\(D(s)G(s)\\) è:\n\\[\nD(s)G(s) = \\frac{K \\prod_{i}(s - z_i)}{s\\prod_{j}(s - p_j)}\n\\]\nla costante di errore di posizione $ K_p $ diventa infinita:\n\\[ K_p = \\infty \\]\nA causa di questa caratteristica, l’errore di stato stazionario $ e_{ss} $ per un input a gradino è:\n\\[ e_{ss} = \\frac{1}{1 + K_p} = 0 \\]\nCiò si traduce in un errore di stato stazionario pari a zero per gli input di gradino, a significare un tracciamento perfetto di tali input.\n\nRisposte agli ingressi rampa e parabolici:\n\nPer ingressi rampa: La costante dell’errore di velocità $ K_v $ è finita e l’errore a regime per un ingresso di rampa viene calcolato come:\n\\[ e_{ss}^{rampa} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} = \\frac{1}{K_v} \\]\nE\n\\[\nK_v = \\lim_{s \\to 0} s \\frac{K \\prod_{i}(s - z_i)}{s\\prod_{j}(s - p_j)} = \\frac{K \\prod_{i}( s - z_i)}{\\prod_{j}(s - p_j)} \\Big|_{s=0}\n\\]\nIn questo caso, $ e_{ss}^{ramp} $ è finito, indicando che i sistemi di tipo 1 possono gestire input di rampa con un errore finito in stato stazionario.\nPer ingressi parabolici: La costante di errore di accelerazione $ K_a $ è zero per i sistemi di tipo 1, il che porta a:\n\\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} = \\frac{1}{K_a} = \\infty \\]\nPertanto, l’errore in stato stazionario per gli input parabolici è infinito, dimostrando che i sistemi di tipo 1 non possono tracciare accuratamente tali input in stato stazionario.\n\n\n\nImplicazioni pratiche per i sistemi di tipo 1\nI sistemi di tipo 1 eccellono nel tracciare perfettamente gli input di gradino con un errore di stato stazionario pari a zero e offrono prestazioni ragionevoli per input di rampa con errore finito. Tuttavia, non riescono a tracciare gli input parabolici, come indicato dall’infinito errore stazionario.\nQuesta analisi sottolinea che i sistemi di tipo 1 sono adatti per applicazioni in cui prevalgono gli ingressi a gradino o a rampa, ma potrebbero non essere adeguati per scenari che richiedono un tracciamento accurato di tipi di ingresso più complessi come i segnali parabolici. In tali casi, potrebbero essere necessarie ulteriori modifiche o un tipo di sistema diverso per ottenere prestazioni ottimali.\n\n\n\nAnalisi dell’errore allo stato stazionario nei sistemi di tipo 2\nI sistemi di tipo 2 sono caratterizzati dall’avere due integratori nel percorso in avanti. Questa caratteristica influenza in modo significativo la loro risposta a diversi tipi di input.\n\nErrore di stato stazionario per diversi ingressi:\n\nInserimento passo:\n\nPer un input a gradini, l’errore a regime $ e_{ss} $ è dato da: \\[ e_{ss} = \\frac{1}{1 + K_p} \\] Poiché $ K_p = \\(, l'errore a regime per un input a gradino è:\\)$ e_{ss} = = 0 $$ Ciò indica un errore di stato stazionario pari a zero per gli input di passaggio, dimostrando una perfetta capacità di tracciamento.\n\nIngresso rampa:\n\nPer un ingresso a rampa, anche la costante dell’errore di velocità $ K_v $ è infinita per un sistema di tipo 2. L’errore a regime per un ingresso di rampa viene calcolato come: \\[ e_{ss}^{rampa} = \\lim_{s \\to 0} \\frac{1}{sD(s)G(s)} \\] Dato che $ K_v = \\(, l'errore a regime per un ingresso a rampa diventa:\\)$ e_{ss}^{rampa} = = = 0 $$ Pertanto, i sistemi di tipo 2 presentano anche un errore di stato stazionario pari a zero per gli ingressi di rampa.\n\nIngresso parabolico:\n\nPer gli ingressi parabolici, consideriamo la costante di errore di accelerazione $ K_a $. In un sistema di tipo 2, $ K_a $ è finito. L’errore a regime per un ingresso parabolico è dato da: \\[ e_{ss}^{parabola} = \\lim_{s \\to 0} \\frac{1}{s^2D(s)G(s)} \\] Ciò produce un valore finito per $ e_{ss}^{parabola} $, il che implica che i sistemi di tipo 2 hanno un errore a stato stazionario finito per gli input parabolici.\n\n\n\n\nRiepilogo e implicazioni per i sistemi di tipo 2\nI sistemi di tipo 2 sono altamente capaci in termini di prestazioni stazionarie. Dimostrano un errore in stato stazionario pari a zero sia per gli ingressi a gradino che per quelli a rampa, indicando eccellenti capacità di tracciamento per questi tipi di ingresso. Per gli ingressi parabolici, i sistemi di tipo 2 mantengono un errore a stato stazionario finito, rendendoli adatti per applicazioni in cui è richiesto il tracciamento preciso di tali ingressi.\nIn sintesi, i sistemi di tipo 2 offrono un livello avanzato di controllo, in particolare in scenari in cui gli input possono variare da semplici passaggi a forme paraboliche più complesse. I loro doppi integratori nel percorso in avanti forniscono loro la capacità di gestire una gamma più ampia di tipi di input in modo efficace rispetto ai sistemi di tipo 0 e tipo 1. Tuttavia, due integratori nel percorso successivo renderanno il sistema più vicino all’instabilità. C’è un compromesso progettuale da fare.\n\n\n\nCommento sui sistemi di tipo 3\nI sistemi di tipo 3 sono caratterizzati dall’avere tre integratori nel percorso in avanti. Sebbene meno comuni dei sistemi di tipo 0, tipo 1 o tipo 2, sono significativi in ​​alcune applicazioni di controllo avanzato.\nLa necessità di un sistema di tipo 3 nasce quando l’applicazione richiede un errore di stato stazionario pari a zero anche per ingressi di tipo accelerazione. Ciò è fondamentale negli scenari in cui l’input subisce rapidi cambiamenti, come nei sistemi radar militari che tracciano gli aerei in rapido movimento.\n\nQuando potrebbe essere necessario un sistema di tipo 3?\n\nRequisiti ad alte prestazioni: I sistemi di tipo 3 sono generalmente richiesti in scenari che richiedono un controllo estremamente preciso e livelli elevati di accuratezza in stato stazionario per una varietà di tipi di input, inclusi ingressi a gradino, a rampa e parabolici.\nMonitoraggio degli obiettivi in ​​rapido movimento: Sono particolarmente utili in applicazioni come radar avanzati o sistemi di controllo di antenne, dove è fondamentale tracciare bersagli in rapido movimento con elevata precisione. In queste applicazioni, gli input possono essere piuttosto complessi e comportare cambiamenti rapidi e imprevedibili.\nApplicazioni industriali sofisticate: Alcuni sistemi di automazione di fascia alta o controlli robotici potrebbero anche utilizzare sistemi di tipo 3 per ottenere caratteristiche di risposta dinamica superiori e ridurre al minimo gli errori in un’ampia gamma di condizioni operative.\n\n\n\nPotenziali problemi con i sistemi di tipo 3\n\nComplessità nel design e nella messa a punto: La presenza di più integratori aumenta la complessità della progettazione del sistema di controllo. La messa a punto di un sistema di tipo 3 per ottenere le prestazioni desiderate senza compromettere la stabilità può essere impegnativa.\nPreoccupazioni per la stabilità: Uno dei problemi significativi con i sistemi di tipo 3 è l’aumento del rischio di instabilità. Maggiore è il numero di integratori, più difficile diventa mantenere la stabilità del sistema, soprattutto in condizioni operative variabili.\nLimitazioni pratiche: L’implementazione di un sistema di tipo 3 può incontrare vincoli pratici. Questi includono i limiti fisici dei componenti del sistema, i fattori ambientali, il rumore intrinseco e le non linearità presenti nei sistemi del mondo reale.\n\nSebbene i sistemi di tipo 3 offrano capacità di controllo avanzate e possano gestire un’ampia gamma di tipi di input con elevata precisione, la loro progettazione, implementazione e manutenzione richiedono una comprensione sofisticata della teoria del controllo e considerazioni pratiche. Sono generalmente riservati ad applicazioni specializzate in cui le loro caratteristiche avanzate sono essenziali e giustificano la complessità aggiuntiva e i rischi potenziali.\n\n\nRiepilogo\nLa risposta del sistema ai vari input (gradino, rampa, parabolico) dipende dalla sua tipologia.\n\nUn sistema di tipo 0 avrà un errore a regime finito per un ingresso a gradino, ma un errore infinito per un ingresso a rampa o parabolico.\nUn sistema di tipo 1 ha un errore stazionario pari a zero per un ingresso a gradino, ma finito per un ingresso a rampa e infinito per un ingresso parabolico.\n\n\n\n\nIllustrare le risposte dei sistemi di tipo 0, tipo 1 e tipo 2\nPer illustrare le risposte dei sistemi Type-0, Type-1 e Type-2 a diversi input, possiamo usare Python con librerie come matplotlib per la stampa e scipy per l’analisi del sistema di controllo.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\n\n# Define the time range for simulation\nt = np.linspace(0, 10, 2000)\n\n# Open-loop transfer functions\n# Type-0 system: K/(s + 0.8)\nK_0 = 10\ntype_0_ol = ctrl.TransferFunction([K_0], [1, 0.8])\n\n# Type-1 system: K/(s(s + 1))\nK_1 = 1\ntype_1_ol = ctrl.TransferFunction([K_1], [1, 1, 0])\n\n# Type-2 system: Double Integrator with damping (1/s^2)\n# Adding a small damping factor to stabilize the response\nK_2 = 10\ndamping_factor = 1\ntype_2_ol = ctrl.TransferFunction([K_2, 1], [1, damping_factor, 0, 0]) # note that we are adding a zero.\n\n\n# Closed-loop transfer functions\ntype_0_sys = ctrl.feedback(type_0_ol)\ntype_1_sys = ctrl.feedback(type_1_ol)\ntype_2_sys = ctrl.feedback(type_2_ol)\n\n\n\n# Function to plot system responses, input signal, and tracking error\ndef plot_responses_and_errors(systems, t, input_signal, input_type):\n    plt.figure(figsize=(12, 6))\n\n    # Plotting system responses and errors\n    for i, sys in enumerate(systems):\n        t_out, y_out = ctrl.forced_response(sys, T=t, U=input_signal)\n        error = input_signal - y_out\n\n        # Plotting response\n        plt.subplot(2, 1, 1)\n        plt.plot(t_out, y_out, label=f'{[\"Type-0\", \"Type-1\", \"Type-2\"][i]} System Response')\n        plt.title(f'Response of Systems to {input_type} Input')\n        plt.ylabel('Response/Signal Value')\n        plt.grid(True)\n\n        # Plotting error\n        plt.subplot(2, 1, 2)\n        plt.plot(t_out, error, label=f'{[\"Type-0\", \"Type-1\", \"Type-2\"][i]} Error')\n        plt.title(f'Tracking Error of Systems for {input_type} Input')\n        plt.xlabel('Time (seconds)')\n        plt.ylabel('Error')\n        plt.grid(True)\n\n    # Adding the input signal plot to the response subplot\n    plt.subplot(2, 1, 1)\n    plt.plot(t, input_signal, label='Input Signal', color='black', linestyle='--')\n    plt.legend()\n\n    # Adding the input signal plot to the error subplot (as zero line)\n    plt.subplot(2, 1, 2)\n    plt.plot(t, np.zeros_like(t), label='Zero Error', color='grey', linestyle='--')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Input signals: unit step, unit ramp, and unit parabola\nstep_input = np.ones_like(t)\nramp_input = t\nparabola_input = 0.5 * t**2\n\n# Systems list and plotting responses with errors\nsystems = [type_0_sys, type_1_sys, type_2_sys]\nplot_responses_and_errors(systems, t, step_input, 'Step')\nplot_responses_and_errors(systems, t, ramp_input, 'Ramp')\nplot_responses_and_errors(systems, t, parabola_input, 'Parabola')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUlteriori commenti\n\nGeneralmente, i requisiti del sistema di controllo presuppongono l’obiettivo di raggiungere un errore di stato stazionario pari a zero per gli ingressi di gradino dell’unità e di mantenere errori finiti per gli ingressi di rampa, a meno che non vengano fornite altre specifiche.\nNella scelta dei controllori, le caratteristiche intrinseche del sistema guidano la scelta:\n\nSe il sistema include naturalmente un integratore, spesso è appropriato utilizzare un controller proporzionale-derivativo (PD). Questa scelta mantiene la tipologia esistente del sistema, migliorandone il controllo senza alterarne il comportamento fondamentale.\nAl contrario, per i sistemi privi di integratore integrato, un controller Proporzionale-Integrale (PI) è in genere più efficace. Un controller PI introduce un integratore aggiuntivo, aumentando di fatto il numero di tipo del sistema e migliorando così la sua capacità di gestire una gamma più ampia di tipi di input, soprattutto in termini di precisione a regime.",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#esempio-di-progettazione-uno-schema-di-controllo-pid",
    "href": "IT_🇮🇹/steady_state_accuracy_and_design_principles_it.html#esempio-di-progettazione-uno-schema-di-controllo-pid",
    "title": "Precisione dello stato stazionario e principi di progettazione",
    "section": "Esempio di progettazione: uno schema di controllo PID",
    "text": "Esempio di progettazione: uno schema di controllo PID\nApplichiamo la nostra conoscenza per progettare un controller PID per un dato impianto. Esamineremo passo dopo passo il processo di progettazione.\n\n\n\n\n\n\nProgettazione di un sistema di controllo della posizione con un controller proporzionale\nIn un problema di controllo di posizione, il nostro obiettivo è progettare un controllore adeguato $ D(s) $ che garantisca le prestazioni desiderate del sistema. Dato che l’impianto incorpora già un integratore, possiamo iniziare il nostro processo di progettazione con un semplice controllore proporzionale rappresentato come $ D(s) = K_A $.\n\nAnalisi del sistema combinato\nPer un controllore proporzionale $ D(s) = K_A $, la funzione di trasferimento del sistema combinato (controllore e impianto) è:\n\\[ D(s)G(s) = \\frac{4500 K_A}{s(s+361,2)} \\]\n\n\nEquazione caratteristica\nL’equazione caratteristica di questo sistema a circuito chiuso è:\n\\[ s^2 + 361,2 s + 4500 K_A = 0 \\]\nDa questa equazione caratteristica possiamo ricavare importanti parametri di sistema come funzioni di $ K_A $:\n\nFrequenza naturale ($ _n $): $ _n = $\nRapporto di smorzamento ($ $): $ = $\nPoli del sistema: $ s_{1,2} = -180,6 j $\nErrore a regime per l’ingresso della rampa unitaria: $ e_{ss} = $\n\nPer un ingresso a gradino unitario, l’errore a regime è zero a causa della presenza dell’integratore nell’impianto.\n\n\nSelezione di $ K_A $ per lo smorzamento critico\nPer ottenere uno smorzamento critico ($ = 1 $), scegliamo:\n\\[ K_A = 7.247 \\]\nQuesto valore specifico di $ K_A $ si traduce in una risposta criticamente smorzata, ideale per il controllo della posizione poiché garantisce una risposta rapida senza oscillazioni.\nScegliere un guadagno tale che $ = 1 $ potrebbe portare ad un tempo di assestamento elevato. Si noti inoltre che il tempo di salita è infinito (il sistema arriva a 1 solo quando \\(t\\) va all’infinito).\nPer calcolare il tempo di assestamento ricordiamo che l’approssimazione che abbiamo ricavato era valida quando \\(0&lt;\\zeta&lt;0.7\\).\n\n\n\nSelezionare \\(K_A\\) per ridurre il rapporto di smorzamento \\(\\zeta\\).\nPer ottenere uno smorzamento critico ($ = 0,707 $), scegliamo:\n\\[ K_A = 14,5 \\]\nIl che porta ad un superamento massimo:\n\\[\nM_p = 4,3\\%\n\\]\nIl tempo di salita in questo caso è inferiore rispetto a prima, e in effetti potrebbe essere il più basso (non ho fatto i calcoli formali).\n\\(M_p = 4,3\\%\\) è il prezzo che stiamo pagando per un tempo di salita inferiore e potrebbe essere accettabile.\nRicordati che \\[\n   M_p = y(t_p) - 1 = e^{-\\zeta\\omega_n(\\pi/\\omega_d)}.\n   \\]\nL’errore a regime è:\n\\[\ne_{ss} = \\frac{0,0803}{K_A}\n\\]\nil che significa che se vogliamo ridurlo dobbiamo ridurre il valore di \\(\\zeta\\) e il picco di superamento aumenta.\nSupponiamo ora che la tua esigenza sia:\n\\[M_p\\le25\\%\\]\nCiò corrisponde ad un rapporto di smorzamento minimo di:\n\\[\n\\zeta= 0,4\n\\]\nper cui si ottiene\n\\[\nK_A = 45,3\n\\]\nCiò riduce l’errore di stato stazionario, ma stiamo anche spostando il sistema verso l’instabilità.\nNon c’è nient’altro che possiamo fare con un controller proporzionale senza violare i nostri requisiti.\n\n\nSimulazione Python del sistema criticamente smorzato\nOra simuleremo questo sistema criticamente smorzato in Python per visualizzare la sua risposta a un input di passaggio:\nQuesto script simula e traccia la risposta al gradino del sistema di controllo della posizione con un controller proporzionale impostato per lo smorzamento critico. Il valore scelto di $ K_A $ garantisce che il sistema venga smorzato in modo critico, ottenendo così una risposta rapida e stabile ai cambiamenti nell’input senza overshooting.\nUsa il codice qui sotto per provare:\n\n\\(K_A = 7.247\\)\n\\(K_A = 14.5\\)\n\nverificare qual è il tempo di salita associato, l’errore di stato stazionario e il superamento massimo.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for a given K_A\ndef plot_step_response(K_A):\n    # Transfer function of the system\n    G_s = ctrl.TransferFunction([4500 * K_A], [1, 361.2, 4500 * K_A])\n\n    # Time range for simulation\n    t = np.linspace(0, 0.4, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(G_s, T=t)\n    \n    # steady state error\n    e_ss = 0.0803/K_A\n    \n    # Peak overshoot\n    omega_n = np.sqrt(4500*K_A)\n    zeta = 2.692/np.sqrt(K_A)\n    omega_d = omega_n * np.sqrt(1 - zeta**2)\n    #M_p = np.exp(-zeta*omega_n*np.pi/omega_d)\n    M_p = np.exp(-np.pi*zeta/(np.sqrt(1-zeta**2)))\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with Proportional Gain K_A = {K_A:.2f}, e_ss = {e_ss:.4f}, M_p % = {M_p*100:.1f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Create a slider for K_A\nK_A_slider = widgets.FloatSlider(\n    value=7.247,\n    min=0.1,\n    max=47.0,\n    step=0.1,\n    description='K_A Slider:',\n    continuous_update=False\n)\n\n# Create a text box for K_A\nK_A_text = widgets.FloatText(\n    value=7.247,\n    description='K_A Text:',\n)\n\n# Function to synchronize slider and text box values\ndef on_value_change(change):\n    K_A_slider.value = change.new\n    K_A_text.value = change.new\n\nK_A_slider.observe(on_value_change, names='value')\nK_A_text.observe(on_value_change, names='value')\n\n# Use `interactive` to bind the plot function to both the slider and the text box\ndisplay(widgets.interactive(plot_step_response, K_A=K_A_slider))\ndisplay(K_A_text)\n\n\n\n\n\n\n\n\n\nMiglioramento delle prestazioni: progettazione migliorata del sistema di controllo con controller PD e PI\n\nControllo PD:\n\nPanoramica: L’aggiunta di un termine derivato nel controllo PD influenza in modo significativo le caratteristiche di smorzamento del sistema. Anche se non riduce direttamente l’errore in stato stazionario, l’azione derivativa gioca un ruolo cruciale nel migliorare la stabilità e la risposta del sistema.\nImpatto sulla progettazione: Incorporando un termine derivato, il controllo PD consente un aumento del guadagno proporzionale $ K_A $ senza violare i vincoli di superamento massimo. Nello specifico, lo smorzamento potenziato fornito dal termine derivato consente al sistema di tollerare un $ K_A $ più elevato, consentendo di mantenere l’overshoot entro il limite desiderato del 25%.\nFormula del controller: $ D(s) = K_C + K_Ds $, dove $ K_C $ è il guadagno proporzionale e $ K_D $ è il guadagno derivativo.\n\nControllo PI:\n\nPanoramica: Il controllo PI introduce un integratore nello schema di controllo, mirato direttamente alla riduzione dell’errore in stato stazionario, particolarmente efficace nell’eliminare gli errori di offset in varie applicazioni di controllo.\nBilanciamento delle prestazioni transitorie e stazionarie: sebbene un controller PI sia in grado di ridurre al minimo l’errore allo stato stazionario, è necessaria un’attenta regolazione per garantire che siano soddisfatti anche i criteri delle prestazioni transitorie, come il tempo di assestamento e il superamento.\nPer il caso di controllo PI (proporzionale-integrale), il controller $ D(s) $ è tipicamente formulato come una combinazione di un termine proporzionale e di un termine integrale. La forma generale di un controller PI nel dominio di Laplace è:\n\n\n\\[ D(s) = K_P + \\frac{K_I}{s} \\]\nDove: - $ K_P $ è il guadagno proporzionale. - $ K_I $ è il guadagno integrale.\nIl termine proporzionale $ K_P $ fornisce un’azione di controllo proporzionale al segnale di errore, offrendo una risposta immediata ai cambiamenti nel sistema. Il termine integrale $ $ accumula l’errore nel tempo, con l’obiettivo di eliminare l’errore a regime. La combinazione di queste due azioni consente al controller PI di reagire tempestivamente ai cambiamenti del sistema e di ridurre metodicamente qualsiasi errore persistente.\nIn un sistema di controllo pratico, la regolazione dei valori di $ K_P $ e $ K_I $ è fondamentale per raggiungere l’equilibrio desiderato tra risposta rapida e precisione a regime, garantendo che il sistema soddisfi effettivamente le specifiche prestazionali.\n\n\nProgettazione avanzata di controllori: metodi del luogo delle radici e della risposta in frequenza\nNelle nostre prossime discussioni, approfondiremo metodi più formalizzati per la progettazione dei controller, vale a dire il metodo del luogo delle radici e il metodo della risposta in frequenza. Queste tecniche forniscono potenti strumenti per analizzare e progettare sistemi di controllo, permettendoci di:\n\nModella con precisione la risposta del sistema regolando i parametri del controller.\nValutare visivamente i compromessi in termini di stabilità e prestazioni.\nOttimizzare i controller per ottenere un equilibrio desiderabile tra risposta ai transitori e precisione allo stato stazionario.\n\nAttraverso questi metodi, possiamo sviluppare una comprensione più profonda della dinamica dei sistemi di controllo e progettare controller che si adattano in modo ottimale ai requisiti specifici delle nostre applicazioni.\n\nPD control\nPer modificare il codice per utilizzare un controller descritto da $ D(s) = K_C + K_Ds $, che è un controller proporzionale-derivativo (PD), dobbiamo aggiornare di conseguenza la funzione di trasferimento del sistema combinato (controller e impianto).\nSupponendo che la funzione di trasferimento dell’impianto rimanga la stessa dell’esempio precedente, la funzione di trasferimento combinata del sistema con il controllore PD sarà:\n\\[ D(s)G(s) = \\frac{(K_C + K_Ds) \\cdot 4500K_A}{s(s+361.2)} \\]\nAggiorniamo lo script Python per incorporare questo controller PD. Aggiungeremo cursori sia per $ K_C $ (guadagno proporzionale) che per $ K_D $ (guadagno derivativo) per osservare in modo interattivo la risposta del sistema.\nLo script seguente consente di regolare dinamicamente il guadagno proporzionale $ K_C $ e il guadagno derivativo $ K_D $ del controller PD utilizzando i cursori. La risposta al gradino del sistema si aggiornerà in base a questi valori, aiutandoti a visualizzare come il controller PD influisce sul comportamento del sistema. Ricorda, questa funzionalità interattiva funziona in un ambiente notebook Jupyter.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for given K_C and K_D\ndef plot_step_response(K_C, K_D):\n    # PD controller transfer function\n    D_s = ctrl.TransferFunction([K_D, K_C], [1])\n\n    # Plant transfer function\n    G_s = ctrl.TransferFunction([4500], [1, 361.2, 0])\n\n    # Combined system transfer function\n    system = ctrl.series(D_s, G_s)\n    closed_loop_system = ctrl.feedback(system)\n\n    # Time range for simulation\n    t = np.linspace(0, 2, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(closed_loop_system, T=t)\n\n    # Peak overshoot (M_p) and steady-state error (e_ss) calculations\n    e_ss = 0.0803 / K_C  # Assuming K_C is dominant for steady-state error\n    peak = np.max(y)\n    M_p = ((peak - 1) / 1) * 100  # Peak overshoot in percentage\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with K_C = {K_C:.2f}, K_D = {K_D:.2f}, e_ss = {e_ss:.4f}, M_p % = {M_p:.1f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Sliders for K_C and K_D\nK_C_slider = widgets.FloatSlider(value=1.0, min=0.1, max=10, step=0.1, description='K_C:')\n# K_D_slider = widgets.FloatSlider(value=1.0, min=0.1, max=10, step=0.1, description='K_D:')\nK_D_slider = widgets.FloatSlider(value=.1, min=0, max=2, step=0.1, description='K_D:')\n\n# Interactive plot\nwidgets.interactive(plot_step_response, K_C=K_C_slider, K_D=K_D_slider)\n\n\n\n\n\n\nControllo PI\nPer modificare il codice per un controllo PI, dobbiamo cambiare la funzione di trasferimento del controller per rappresentare un controller PI e regolare i calcoli di conseguenza. Il controller PI ha la forma $ D(s) = K_P + $, dove $ K_P $ è il guadagno proporzionale e $ K_I $ è il guadagno integrale.\nPer semplicità, supponiamo che $ K_P $ e $ K_I $ siano uguali e rappresentati dalla stessa variabile $ K_A $ nello script. La funzione di trasferimento del controller PI sarà quindi $ D(s) = K_A + $. Dobbiamo anche aggiornare la funzione di trasferimento del sistema combinato e regolare i calcoli per l’errore di stato stazionario e il superamento del picco.\nL’errore a regime per un ingresso a gradino è zero a causa dell’integratore nel controller PI. Il calcolo analitico del superamento del picco per un controller PI può essere complesso e viene spesso eseguito utilizzando metodi numerici o graficamente dal grafico della risposta. Lo script ora utilizza cursori interattivi per consentire di regolare $ K_A $ e osservare la risposta del sistema.\nEcco lo script modificato:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport control as ctrl\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Function to plot the step response for a given K_A\ndef plot_step_response(K_A):\n    # PI controller transfer function: D(s) = K_A + K_A/s\n    D_s = ctrl.TransferFunction([K_A, K_A], [1, 0])\n\n    # Plant transfer function: G(s) = 4500/(s(s+361.2))\n    G_s = ctrl.TransferFunction([4500], [1, 361.2, 0])\n\n    # Combined system transfer function\n    system = ctrl.series(D_s, G_s)\n    closed_loop_system = ctrl.feedback(system)\n\n    # Time range for simulation\n    t = np.linspace(0, 2, 500)\n\n    # Simulate step response\n    t, y = ctrl.step_response(closed_loop_system, T=t)\n    \n    # Steady-state error is zero for a step input due to the integrator in PI controller\n    e_ss = 0.0\n    \n    # Peak overshoot calculation is not straightforward for a PI controller\n    # and typically requires numerical methods or graphically from the plot\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(t, y)\n    plt.title(f'Step Response with PI Gain K_A = {K_A:.2f}, e_ss = {e_ss:.4f}')\n    plt.xlabel('Time (seconds)')\n    plt.ylabel('Response')\n    plt.grid()\n    plt.show()\n\n# Create a slider for K_A\nK_A_slider = widgets.FloatSlider(\n    value=1.0,\n    min=0.1,\n    max=10.0,\n    step=0.1,\n    description='K_A Slider:',\n    continuous_update=False\n)\n\n# Create a text box for K_A\nK_A_text = widgets.FloatText(\n    value=1.0,\n    description='K_A Text:',\n)\n\n# Function to synchronize slider and text box values\ndef on_value_change(change):\n    K_A_slider.value = change.new\n    K_A_text.value = change.new\n\nK_A_slider.observe(on_value_change, names='value')\nK_A_text.observe(on_value_change, names='value')\n\n# Use `interactive` to bind the plot function to both the slider and the text box\ndisplay(widgets.interactive(plot_step_response, K_A=K_A_slider))\ndisplay(K_A_text)",
    "crumbs": [
      "IT_🇮🇹",
      "Precisione dello stato stazionario e principi di progettazione"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_response_it.html",
    "href": "IT_🇮🇹/dynamic_response_it.html",
    "title": "Risposta dinamica dei sistemi di controllo",
    "section": "",
    "text": "Oggi approfondiamo la comprensione della risposta dinamica dei sistemi di controllo.\nDopo aver introdotto la funzione di trasferimento di un impianto, che si riferisce alla modellizzazione dell’impianto, e ai modelli di disturbi e segnali di test, siamo pronti ad esplorare la risposta dinamica del sistema. Visualizziamo il nostro modello.\nRicorda, la forma generale per l’output del sistema nel dominio di Laplace è \\(Y(s)=G(s)R(s)\\). Questa relazione trasforma la convoluzione nel dominio del tempo in moltiplicazione nel dominio s.\nQuando siamo interessati alla risposta temporale \\(y(t)\\), dovremo ottenere \\(G(s)\\) e \\(R(s)\\), calcolare \\(Y(s)\\) e infine invertire per ottenere \\(y(t )\\).\nConsiderando l’inversione di Laplace, è tabulato in vari libri di testo, quindi non approfondiremo le sue derivazioni. Utilizzeremo piuttosto queste tabelle per scopi di inversione.\nRicordiamo che \\(R(s)\\) sono modellati tipicamente attraverso impulso, gradino, rampa e parabole.",
    "crumbs": [
      "IT_🇮🇹",
      "Risposta dinamica dei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_response_it.html#coppie-comuni-di-trasformata-di-laplace",
    "href": "IT_🇮🇹/dynamic_response_it.html#coppie-comuni-di-trasformata-di-laplace",
    "title": "Risposta dinamica dei sistemi di controllo",
    "section": "Coppie comuni di trasformata di Laplace",
    "text": "Coppie comuni di trasformata di Laplace\n\n\n\n\n\n\nDomanda pop-up: Ricordi il significato della funzione di trasferimento nei sistemi di controllo?\nRisposta: La funzione di trasferimento, \\(G(s)\\), rappresenta la relazione tra l’input e l’output di un sistema nel dominio di Laplace. È uno strumento cruciale per l’analisi e la progettazione dei sistemi di controllo.\nPer maggiore chiarezza, analizziamo alcuni esempi:\n\nEsempio 1\n\\[\nG(s) = \\frac{1}{s^2+3s+2}\n\\]\nSi osserva che il polinomio del numeratore è di ordine zero e il polinomio del denominatore è di secondo ordine, il che implica un sistema di secondo ordine. Per rappresentarlo nella forma polo zero:\n\\[\nG(s) = \\frac{1}{(s+1)(s+2)}\n\\]\nDato l’input $ r(t) = 5 (t) $, un input a gradino di grandezza 5, sappiamo che $ R(s) = $.\nPertanto, $ Y(s) = G(s) R(s) $ diventa: \\[ Y(s) = \\frac{5}{s(s+1)(s+2))} \\]\nOra abbiamo tre poli nel trasferimento della risposta.\nDeriviamo la risposta \\(y(t)\\) da \\(Y(s)\\).\nPer sistemi come questo, l’uso della scomposizione parziale delle frazioni aiuta a scomporre espressioni complesse, che possono quindi essere facilmente trasformate in senso inverso nel dominio del tempo.\nAnalizziamo come eseguire questa operazione: 06_inverse_laplace_transform\nApplicando l’espansione delle frazioni otteniamo:\n\\[ Y(s) = \\frac{5}{s(s+1)(s+2))} = \\frac{5/2}{s} - \\frac{5}{s+1} + \\ frac{5/2}{(s+2)}\\]\nNota: - \\(- \\frac{5}{s+1} + \\frac{5/2}{(s+2)}\\) sono dovuti ai poli del sistema - \\(\\frac{5/2}{s}\\) è dovuto al polo di eccitazione\nInvertendo \\(Y(s)\\) otteniamo:\n\\[\ny(t) = \\frac{5}{2} - 5e^{-t} + \\frac{5/2}e^{-2t}\n\\]\n\nI termini \\(- 5e^{-t} + \\frac{5/2}e^{-2t}\\) vengono generati quando il sistema è eccitato dall’input del passo. Questi due termini svaniscono con l’aumentare del tempo. Questa è la risposta transitoria del sistema\nIl termine \\(\\frac{5}{2}\\) è dovuto al polo di eccitazione e la sua natura è simile all’ingresso stesso. Tuttavia la sua ampiezza è stata modificata e ciò dipende dalla risposta del sistema all’input. Poiché l’input persiste per sempre, questa risposta specifica persisterà per sempre. Questa è chiamata la risposta allo stato stazionario.\n\n\n\nIl teorema del valore finale\nIl teorema del valore finale è uno strumento indispensabile per determinare il valore in stato stazionario della risposta di un sistema senza dover calcolare l’intera risposta nel dominio del tempo.\n\\[\ny_{ss} = \\lim_{t \\to \\infty} y(t) = \\lim_{s \\to 0} s Y(s)\n\\]\nÈ essenziale notare che il Teorema del Valore Finale è applicabile se e solo se sono soddisfatte le seguenti condizioni:\n\nI poli di \\(Y(s)\\) si trovano nella metà sinistra del piano s, garantendo la stabilità della funzione.\n\nCiò significa che \\(s Y(s)\\) non ha poli sull’\\(asse j\\omega\\) e/o sul semipiano destro.\nDomanda pop-up: Perché ci concentriamo sulla metà sinistra del piano s per l’applicazione del Teorema del valore finale?\nRisposta: I sistemi con poli nella metà destra del piano s sono instabili e le loro risposte tendono all’infinito come \\(t→∞\\). Il teorema richiede che la funzione si stabilizzi o raggiunga un valore stazionario quando il tempo si avvicina all’infinito.\nNel nostro caso:\n\\[\ns Y(s) = \\frac{5s}{s(s+1)(s+2))}\n\\]\ne quindi:\n\\[\ny_{ss} = \\lim_{s \\to 0} s Y(s) = \\frac{5}{2}\n\\]\nPossiamo ora tracciare la risposta al gradino del sistema, ovvero \\(y(t)\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\n# Python code to obtain time response\nsys = lti([5], [1, 3, 2])\nt, y = step(sys)\nplt.plot(t, y, label='y(t)')\nplt.plot(t, np.linspace(5,5,num=len(t)), label='input')\nplt.plot(t, np.linspace(5/2,5/2,num=len(t)), label='y_{ss}')\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nEsempio 2\nConsideriamo la stessa pianta di prima:\n\\[\nG(s) = \\frac{1}{s^2+3s+2}\n\\]\nma ora con un ingresso rampa:\n\\[\nr(t) = 5t\\mu(t)\n\\]\nla cui trasformata di Laplace è\n\\[\nR(s) = \\frac{5}{s^2}\n\\]\ne la trasformazione della risposta è:\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)}\n\\]\nPossiamo calcolare la trasformata inversa con la scomposizione della frazione parziale.\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)} = \\\\\n\\frac{5/2}{s^2} + \\frac{K}{s} + \\frac{5}{s+1} - \\frac{5/4}{s+2}\n\\]\nDove\n\\[\nK= \\frac{d}{ds}\\Big[\\frac{5}{(s+1)(s+2)}\\Big]\\Big|_{s=0} = \\frac{d}{ds }\\Big[\\frac{5}{(s^2+3s+2)}\\Big]\\Big|_{s=0} = - \\frac{5(2s+3)}{(s^2+ 3s+2)^2)}\\Big|_{s=0} = \\frac{-15}{4}\n\\]\ne quindi l’espressione completa è:\n\\[\nY(s) = \\frac{5}{s^2(s+1)(s+2)} = \\\\\n\\frac{5/2}{s^2} - \\frac{15/4}{s} + \\frac{5}{s+1} - \\frac{5/4}{s+2}\n\\]\nPossiamo invertire:\n\\[\ny(t) = \\frac{5}{2}t - \\frac{15}{4} + 5e^{-t} - \\frac{5}{4}e^{-2t}\n\\]\nAnche in questo caso i termini dovuti ai poli del sistema vanno a zero (componente transitoria). L’altra componente è dovuta alla presenza dell’ingresso rampa specifico.\n\\[\ny_{ss} = \\frac{5}{2}t - \\frac{15}{4}\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nsys = lti([5], [1, 3, 2])\nt, y = step(sys)\n\n# Python code to obtain time response\ny = 5/2*t-15/4 + 5*np.exp(-t) - 5/4*np.exp(-2*t)\nplt.plot(t, y, label='y(t)')\nplt.plot(t, 5*t, label='input')\nplt.plot(t, 5/2*t-15/4, label='y_{ss}')\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Amplitude\")\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nPossiamo applicare il teorema del valore finale?\n\\[\ny_{ss} = \\lim_{t \\to \\infty} y(t) = \\lim_{s \\to 0} s Y(s) = \\lim_{s \\to 0} \\frac{5s}{s^2 (s+1)(s+2)} = \\inf\n\\]\nTuttavia c’è un polo all’origine e il teorema del valore finale non è applicabile. Lo stato stazionario inizia non appena il transitorio si esaurisce. I due valori corrispondono all’infinito, ma l’espressione dello stato stazionario totale non è ottenuta dal teorema del valore finale a causa della presenza di un polo nell’origine in \\(sY(s)\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Risposta dinamica dei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_response_it.html#sistemi-del-primo-ordine",
    "href": "IT_🇮🇹/dynamic_response_it.html#sistemi-del-primo-ordine",
    "title": "Risposta dinamica dei sistemi di controllo",
    "section": "Sistemi del primo ordine",
    "text": "Sistemi del primo ordine\nConsideriamo un semplice sistema meccanico: un carico inerziale con un momento di inerzia, \\(J\\). Questo carico è collegato a un albero rigido, il che implica che la costante elastica per questo albero è zero (non è flessibile).\n\n\n\n\n\n\nL’ambiente di attrito del sistema può essere schematicamente illustrato attraverso due cuscinetti di forza caratterizzati da un coefficiente di attrito viscoso, \\(B\\).\nIn questo sistema:\n\nVariabile di ingresso: Coppia, \\(T(t)\\)\nVariabile di output: Velocità, \\(ω(t)\\)\nParametri costanti: \\(J\\) e \\(B\\)\n\nIn base alle leggi di Newton, l’equazione governante diventa:\n\\[\nJ\\dot\\omega(t)+B\\omega(t)(t)=T(t)\n\\]\nDopo aver applicato la trasformazione di Laplace:\n\\[\nJs\\omega(s)+B\\omega(s)=T(s)\n\\]\nNota: nelle nostre discussioni, i sistemi saranno considerati “rilassati”, il che significa che le condizioni iniziali non compaiono nell’equazione trasformata.\nDa ciò si deriva la funzione di trasferimento \\(G(s)\\):\n\\[\nG(s)=\\frac{\\omega(s)}{T(s)} = \\frac{1}{Js+B}\n\\]\nche è un modello del primo ordine, con parametri \\(J\\) e \\(B\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Risposta dinamica dei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_response_it.html#un-modello-generale-per-i-sistemi-del-primo-ordine",
    "href": "IT_🇮🇹/dynamic_response_it.html#un-modello-generale-per-i-sistemi-del-primo-ordine",
    "title": "Risposta dinamica dei sistemi di controllo",
    "section": "Un modello generale per i sistemi del primo ordine",
    "text": "Un modello generale per i sistemi del primo ordine\nOgni sistema del primo ordine, indipendentemente dal suo dominio (meccanico, elettrico, termico, ecc.), può essere generalizzato utilizzando la seguente forma:\n\\[\nG(s) = \\frac{K}{(\\tau s+1)}\n\\]\nCon parametri: - \\(K\\): guadagno del sistema. - \\(\\tau\\): costante di tempo del sistema.\nIl termine “guadagno del sistema” si riferisce alla variazione di stato stazionario dell’output per una variazione unitaria dell’input. Nel frattempo, la costante di tempo descrive la velocità con cui il sistema risponde ai cambiamenti.\nAd esempio, se applichiamo un input di passo unitario:\n\\[\nT(s)=\\frac{1}{s},\n\\]\nla risposta diventa:\n\\[\n\\omega(s) = \\frac{K}{s(\\tau s+1)}\n\\]\nLa risposta nel dominio del tempo, \\(\\omega(t)\\), dopo l’inversione, caratterizza il comportamento dinamico del sistema:\n\\[\n\\omega(t) = K \\Big[ 1 - e^{-t/\\tau}\\Big]\n\\]\n\nDecodifica dei parametri:\n\nGuadagno del sistema, \\(K\\): Quando \\(t→∞\\), \\(\\omega(t)\\) si avvicina a \\(K\\), illustrando il motivo per cui \\(K\\) è definito guadagno del sistema.\n\nLa velocità del nostro sistema (il carico inerziale) cambia al valore \\(K\\) in risposta ad un passo unitario. Cambia l’output del sistema di \\(K\\).\n\nCostante di tempo, \\(\\tau\\): la costante di tempo indica la velocità di risposta del sistema. Per capirlo, abbozziamo la risposta del sistema:\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\ntau = 1\n\nt = np.linspace(0, 5, 50)\nw_t = K*(1-np.exp(-t/tau))\ntransient = -K*np.exp(-t/tau)\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\n\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\nax.plot(t, transient, label=r'$-K*e^{(-t/\\tau)}$', linewidth=3)\nax.plot(t, w_t, label=r'$\\omega(t)=K*(1-e^{(-t/\\tau)})$', linewidth=3)\nax.plot(t[0:11], K/tau*t[0:11]-K)\n\nfor t_bar in [tau, 2*tau, 3*tau, 4*tau, 5*tau]:\n    ax.plot(t_bar, -K*np.exp(-t_bar/tau), markersize=15, marker='.', color='k')\n\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"w(t)\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(tau, 0.03, r'$\\tau$', fontsize=14)\nax.text(0.2, K, 'K', fontsize=14)\nax.text(0.2, -K, '-K', fontsize=14)\n\nax.text(tau+0.1, -K*0.3629, '-.3629K', fontsize=14)\nax.text(4*tau+0.1, -K*0.0183-0.1, '-.0183K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIl valore finale della risposta è \\(K\\).\nPer quanto riguarda il termine transitorio \\(-Ke^{-t/\\tau}\\), esso diminuisce fino a zero quando \\(t\\) si avvicina all’infinito.\nImmergiamoci nel transitorio. Valutando:\n\\[\n\\frac{d}{dt}\\Big( -Ke^{-t/\\tau} \\Big) \\Big|_{t=0} = \\frac{K}{\\tau}\n\\]\nne deduciamo che il tasso di variazione iniziale del transitorio a \\(t=0\\) è \\(\\frac{K}{\\tau}\\).\nSe il transitorio mantenesse il suo tasso di diminuzione iniziale, svanirebbe in una durata di \\(\\tau\\).\nQuesta costante di tempo ci dà un’idea della durata necessaria affinché il transitorio diminuisca se il declino fosse guidato esclusivamente dal suo tasso di variazione iniziale \\(\\frac{K}{\\tau}\\).\nTuttavia, questo tasso non è statico. Osservando i valori specifici:\n\n\n\n\\(t\\)\n\\(e^{-t/\\tau}\\)\n\n\n\n\n\\(\\tau\\)\n0,3679\n\n\n\\(4\\tau\\)\n0,0183\n\n\n\\(5\\tau\\)\n0,0067\n\n\n\nVediamo che tra \\(4\\tau\\) e \\(5\\tau\\) il transitorio è quasi inesistente, indicando il tempo necessario affinché il sistema si stabilizzi. Ricorda, tuttavia, che diventa veramente zero solo quando \\(t\\) si avvicina all’infinito.\nDa un punto di vista pragmatico è ragionevole affermare che il sistema ha raggiunto lo stato stabile in \\(5\\tau\\).\nDomanda pop-up: Perché la costante di tempo è cruciale nella progettazione del sistema di controllo?\nRisposta: la costante di tempo indica la velocità di risposta del sistema. Per risposte rapide desiderate, è preferibile una costante di tempo più piccola. Costanti di tempo maggiori potrebbero rallentare la risposta del sistema, il che è spesso indesiderabile nelle applicazioni di controllo.\nNella dinamica dei sistemi di controllo, la velocità di risposta con cui un sistema reagisce è cruciale. All’introduzione di un input, uno dei nostri obiettivi è (tipicamente) che l’impianto risponda senza ritardi.\nConsiderando la costante di tempo del sistema – dove sono necessari tra $ 4$ e $ 5$ per raggiungere lo stato stazionario – una costante di tempo più breve implica una risposta più rapida. Al contrario, una costante di tempo più lunga suggerisce la tendenza del sistema a rispondere più lentamente.\n\nSistemi lenti e veloci:\nUn sistema definito “lento” possiede tipicamente una grande costante di tempo. Sistemi che gestiscono il controllo della temperatura, i livelli dei liquidi, la pressione o le composizioni chimiche: questi sono gli ambiti delle applicazioni di controllo dei processi e la maggior parte di queste applicazioni di solito hanno costanti di tempo elevate; in sostanza, sono “lenti”.\nCiò è in contrasto con sistemi come il controllo della velocità o il tracciamento radar. Questi ultimi sistemi hanno costanti di tempo più piccole, il che li contrassegna come sistemi “veloci”.\nGiusto per fornire una scala, la costante di tempo dei sistemi può variare da semplici millisecondi (come si vede nei sistemi di tracciamento radar o di controllo della velocità) a pochi minuti, comunemente osservati, tra gli altri, nelle configurazioni di controllo della temperatura.\n\n\nRitardo del primo ordine\nLa funzione di trasferimento che abbiamo visto prima\n\\[\nG(s) = \\frac{K}{(\\tau s+1)}\n\\]\nè noto come ritardo del primo ordine. In sostanza, quando vediamo questo termine, suggerisce che il sistema non consente una risposta istantanea.\nQuesto sistema, chiamato ritardo del primo ordine o semplicemente ‘ritardo semplice’, è completamente caratterizzato da due parametri: \\(K\\) (guadagno del sistema) e \\(\\tau\\) (costante di tempo).",
    "crumbs": [
      "IT_🇮🇹",
      "Risposta dinamica dei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/dynamic_response_it.html#un-modello-generale-per-i-sistemi-del-secondo-ordine",
    "href": "IT_🇮🇹/dynamic_response_it.html#un-modello-generale-per-i-sistemi-del-secondo-ordine",
    "title": "Risposta dinamica dei sistemi di controllo",
    "section": "Un modello generale per i sistemi del secondo ordine",
    "text": "Un modello generale per i sistemi del secondo ordine\nSebbene i termini \\(J\\), \\(B\\) e \\(k\\) siano specifici del nostro esempio, nel contesto più ampio del sistema di controllo, spesso utilizziamo tre parametri generali per descrivere il comportamento di un sistema di secondo ordine:\n\n\\(\\omega_n\\): frequenza naturale,\n\\(\\zeta\\): rapporto di smorzamento,\n\\(K\\): guadagno del sistema.\n\nIl modello generale della funzione di trasferimento diventa:\n\\[\nG(s) = \\frac{K}{\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1}\n\\]\ndove, nel nostro esempio:\n\n\\(K = \\frac{1}{k}\\)\n\\(\\omega_n = \\sqrt{\\frac{k}{J}}\\)\n\\(\\zeta = \\frac{1}{2}\\frac{B}{\\sqrt{kJ}}\\)\n\nOra approfondiremo le complessità dei sistemi del secondo ordine esaminando la loro risposta a un input passo-passo. Una profonda comprensione di questo comportamento aiuta a delineare il ruolo significativo svolto dai parametri: \\(\\omega_n\\) (frequenza naturale), \\(\\zeta\\) (rapporto di smorzamento), \\(K\\) (guadagno del sistema).\n\nParametro \\(K\\)\nIl parametro \\(K\\) determina, come prima, il guadagno del sistema. Il teorema del valore finale può essere utilizzato per convalidare che per un input a gradino unitario, il valore finale del valore di risposta è governato da \\(K\\).\n\\[\nY(s) = \\frac{K}{s\\Big(\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 \\Big)}\n\\]\n\\[\nsY(s) = \\frac{K}{\\Big(\\frac{1}{\\omega_n^2}s^2 + \\frac{2\\zeta}{\\omega_n} s + 1 \\Big)}\n\\]\nSupponendo che i valori di \\(\\omega_n\\) (frequenza naturale) e \\(\\zeta\\) (rapporto di smorzamento) siano tali che le radici del denominatore si trovino nel semipiano sinistro, possiamo applicare il Teorema del valore finale:\n\\[\nlim_{s \\rightarrow 0} sY(s) = K\n\\]\n\n\nParametri \\(\\omega_n\\) e \\(\\zeta\\)\n\\[\n\\frac{\\theta(s)}{T(s)} = \\frac{K\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\n\\]\nPoiché \\(T(s)=\\frac{1}{s}\\) (passo input):\n\\[\n\\theta(s) = \\frac{K\\omega_n^2}{s\\Big(s^2 + 2\\zeta\\omega_n s + \\omega_n^2\\Big)}\n\\]\nLa risposta nel dominio del tempo, \\(\\theta(t)\\), dopo l’inversione, caratterizza il comportamento dinamico del sistema:\n\\[\n\\theta(t) = \\mathcal{L}^{-1}\\Big[\\theta(s)\\Big]\n\\]\nConsideriamo quattro casi:\n\ncaso 1: \\(\\zeta=0\\)\ncaso 2: \\(0&lt;\\zeta&lt;1\\)\ncase 3 \\(\\zeta=1\\)\ncase 4 \\(\\zeta&gt;1\\)\n\nIl caso 1, nel nostro esempio, corrisponde a \\(B=0\\) (nessuno smorzamento). Tutti gli altri casi corrispondono a \\(B\\ne0\\) (smorzamento)\n\n\nCaso 1, \\(\\zeta=0\\)\n\\[\n\\theta(t) = K(1-\\cos(\\omega_nt))\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\n\nt = np.linspace(0, 15, 50)\ntheta_t = K*(1-np.cos(omega_n*t))\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\n\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\nax.plot(t, theta_t, label=r'$K(1-\\cos(\\omega_nt))$', linewidth=3)\n\nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn questo scenario, il sistema presenta oscillazioni attorno al valore di \\(K\\). Queste oscillazioni, a causa dell’assenza di smorzamento, vengono chiamate oscillazioni non smorzate. La frequenza di queste oscillazioni, \\(\\omega_n\\), è definita frequenza naturale non smorzata.\nNota: questo è in genere un comportamento indesiderato, ma dipende dai requisiti.\nDomanda pop-up: Perché il comportamento oscillante non è preferibile nella maggior parte dei sistemi di controllo? Risposta: nella maggior parte degli scenari industriali, le oscillazioni possono portare a inefficienze, usura del sistema o risultati indesiderati. Esempio: pensa al riscaldamento residenziale con un sistema di controllo on/off. La temperatura oscilla entro un certo intervallo, che potrebbe essere accettabile per il riscaldamento ma non per i processi controllati con precisione.\n\n\nCaso 2, \\(0&lt;\\zeta&lt;1\\), Underdamped Case\nThe response, in this case, showcases damped oscillations. In our example, this corresponds to \\(B\\ne0\\).\nThis case corresponds, in our example, to the case where:\n\\[\n\\frac{k}{J} &gt; \\Big(\\frac{B}{2J}\\Big)^2\n\\]\ncon risposta:\n\\[\n\\theta(t) = K\\Big[1 - \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}} \\sin\\Big(\\omega_d t + \\tan^{ -1} \\frac{\\sqrt{1-\\zeta^2}}{\\zeta}\\Big)\\Big]\n\\]\nDove: - \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\), è detta frequenza naturale smorzata.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzetas = [0.1, 0.3, 0.6, 0.999]\n\nt = np.linspace(0, 15, 50)\n\n# Create a new figure and axis\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\nfor zeta in zetas:\n    omega_d = omega_n*np.sqrt(1-zeta**2)\n    theta_t = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2)*np.sin(omega_d*t + np.arctan(np.sqrt(1-zeta**2)/zeta)))\n    #theta_t = K*(1 - (1/np.sqrt(1-zeta**2)) * np.exp(-zeta*omega_n*t) * np.sin(omega_d*t+np.arccos(zeta)))\n    ax.plot(t, theta_t, label=r'$\\theta_t$='+f\"{zeta}\", linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nIn questo regime la risposta del sistema è oscillatoria. Tuttavia, queste oscillazioni non sono illimitate. Invece, si estinguono nel tempo, il che viene spesso descritto come “oscillazioni smorzate”, e diminuiscono quando \\(\\zeta\\) aumenta.\nQuando \\(\\zeta=1\\) è la situazione limite in cui le oscillazioni si sono appena estinte. L’altro caso limite è ovviamente quello in cui \\(\\zeta=0\\), che abbiamo appena visto, e per il quale le oscillazioni non sono smorzate.\nNota dal grafico sopra come il sistema diventa lento all’aumentare del valore di \\(\\zeta\\): il tempo di assestamento, la velocità di risposta, aumenta. Se il \\(\\zeta\\) diminuisce però aumentano le oscillazioni.\n\n\nImplicazioni pratiche:\n\nComportamento del sistema: nei sistemi di controllo industriale, il comportamento sottosmorzato è solitamente desiderato perché consente di ottenere una risposta rapida senza oscillazioni prolungate. Le oscillazioni sono generalmente considerate indesiderabili nei sistemi di controllo poiché indicano instabilità o inefficienze.\nBilanciare velocità e oscillazione: c’è un delicato equilibrio da raggiungere. Se \\(\\zeta\\) è troppo piccolo (vicino a 0), il sistema può essere troppo oscillatorio, portando a potenziale instabilità. D’altra parte, se \\(\\zeta\\) è troppo grande (si avvicina a 1), il sistema può diventare lento.\nEsempi di applicazione: Per le applicazioni che possono tollerare alcune oscillazioni in cambio di una risposta rapida (ad esempio, alcuni processi di produzione), un sistema leggermente sottosmorzato potrebbe essere l’ideale. Negli scenari in cui la precisione dell’assestamento è vitale (ad esempio, il posizionamento del braccio robotico), è fondamentale progettare il sistema in modo che le oscillazioni siano minime, anche a costo di una risposta più lenta.\n\nLa scelta del livello di smorzamento nella progettazione del sistema spesso comporta dei compromessi. Anche se spesso si preferisce il caso sottosmorzato, è fondamentale comprendere le esigenze esatte di una particolare applicazione o processo. Ciò garantisce che il sistema risponda in modo ottimale, bilanciando velocità, oscillazione e stabilità.\nDiamo ora una visione più dettagliata delle oscillazioni, osservando una tipica risposta sotto-smorzata:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzeta = 0.3\n\nt = np.linspace(0, 15, 50)\n\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\n\nomega_d = omega_n*np.sqrt(1-zeta**2)\ntheta_t = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2)*np.sin(omega_d*t + np.arctan(np.sqrt(1-zeta**2)/zeta)))\n\nenvelope_plus = K*(1 + np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2))\nenvelope_minus = K*(1 - np.exp(-zeta*omega_n*t)/np.sqrt(1-zeta**2))\n\nax.plot(t, envelope_plus, linewidth=3, color='b')\nax.plot(t, envelope_minus, linewidth=3, color='b')    \n\nax.plot(t, theta_t, label=r'$\\theta_t$='+f\"{zeta}\", linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\nax.text(6, 1.5, r'$K (1+\\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})$', fontsize=14)\n\nax.text(6, 0.5, r'$K (1-\\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})$', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nLe linee blu rappresentano l’inviluppo della risposta:\n\\[\nK (1 \\pm \\frac{e^{-\\zeta\\omega_nt}}{\\sqrt{1-\\zeta^2}})\n\\]\nIl decadimento delle oscillazioni è determinato dall’inviluppo della risposta oscillatoria. Il decadimento dell’inviluppo dipende dal fattore esponenziale:\n\\[\ne^{-\\zeta\\omega_nt}\n\\]\nLa sua costante di tempo è:\n\\[\ne^{-t/\\tau} = e^{-\\zeta\\omega_nt}\n\\]\nO\n\\[\n\\tau = \\frac{1}{\\zeta\\omega_n}\n\\]\nPiù alto è il valore di \\(\\zeta\\omega_n\\), più velocemente si estinguono le oscillazioni.\nIl sistema oscilla ad una frequenza naturale smorzata, \\(\\omega_d\\), che si esprime come:\n\\[\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\]\ne dove \\(\\omega_n\\) è la frequenza naturale non smorzata.\n\nCaso 3, \\(\\zeta=1\\), Smorzato in modo critico\nQui il sistema è sull’orlo dell’oscillazione. La risposta mostra uno scenario in cui le oscillazioni vengono semplicemente eliminate.\nNel nostro esempio ciò corrisponde a:\n\\[\n\\frac{k}{J} = \\Big(\\frac{B}{2J}\\Big)^2\n\\]\ncon risposta:\n\\[\n\\theta(t) = K\\Big[1 - e^{-\\omega_n t} - \\omega_n t e^{-\\omega_n t} \\Big]\n\\]\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import lti, step, impulse\n\nK = 1\nomega_n = 1\nzeta = 1\n\nt = np.linspace(0, 10, 50)\n\nfig, ax = plt.subplots()\nax.plot(t, K*np.ones((len(t))), linewidth=3, label='K')\n\n\ntheta_t = K*(1 - np.exp(-zeta*omega_n*t)  -omega_n*t*np.exp(-zeta*omega_n*t))\n\n\nax.plot(t, theta_t, label=r'$\\theta_t$', linewidth=3)\n\n    \nplt.title(\"Step Response\")\nplt.xlabel(\"Time\")\nplt.ylabel(r\"$\\theta(t)$\")\nplt.grid(True)\n\n# Plot the x=0 and y=0 axes\nax.axhline(0, color='black', linewidth=2)  # Horizontal line at y=0\nax.axvline(0, color='black', linewidth=2)  # Vertical line at x=0\n\nax.text(0.2, K+0.02, 'K', fontsize=14)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nRaggiungere uno smorzamento critico è impegnativo, poiché richiede una messa a punto precisa. Anche piccole deviazioni possono portare il sistema a uno smorzamento eccessivo o insufficiente.\nI sistemi criticamente smorzati ritornano all’equilibrio o al valore di stato stazionario senza superamento (oscillazione) e nel più breve tempo possibile.\nMentre i sistemi sottosmorzati oscillano attorno all’equilibrio prima di stabilizzarsi, i sistemi criticamente smorzati no. Si avvicinano direttamente all’equilibrio, con il tempo di risposta più rapido che evita l’oscillazione.\nPer un’equazione differenziale omogenea lineare del secondo ordine che descrive un sistema, lo stato criticamente smorzato produce due radici reali uguali. Ciò si traduce in una soluzione che è una combinazione di termini di decadimento esponenziale.\n\nEsempi di applicazione: - Sospensioni del veicolo: nelle auto, gli ammortizzatori mirano ad essere smorzati in modo critico per fornire una guida confortevole assorbendo rapidamente gli urti senza far oscillare l’auto. - Elettronica: nella progettazione dei circuiti, le risposte criticamente smorzate sono preferite per l’elaborazione del segnale in cui il segnale deve stabilizzarsi rapidamente senza sovraelongazione.\n\n\nCaso 4, \\(\\zeta&gt;1\\), eccessivamente smorzato\n\nIl caso di smorzamento eccessivo rappresenta una situazione in cui lo smorzamento è eccessivo, portando ad un lento ritorno all’equilibrio.\nI sistemi sovrasmorzati ritornano all’equilibrio più lentamente sia dei sistemi criticamente smorzati che di quelli sottosmorzati, senza superamento.\nPer l’equazione differenziale omogenea lineare del secondo ordine che descrive un tale sistema, lo stato sovrasmorzato produce due radici reali distinte. Ciò si traduce in una risposta che combina due distinti termini di decadimento esponenziale.\nCi sono casi in cui lo smorzamento eccessivo è intenzionale. In alcune apparecchiature o processi sensibili, l’oscillazione (anche se lieve) può essere dannosa o indesiderabile, rendendo un ritorno più lento all’equilibrio un compromesso accettabile. Il case eccessivamente smorzato sottolinea la necessità di un’attenta considerazione nel controllo e nella progettazione del sistema. Sebbene possa sembrare non ottimale a causa della sua risposta lenta, in alcuni contesti questo ritardo deliberato è fondamentale per mantenere la sicurezza e la funzionalità\n\nEsempi di applicazione: - Chiudiporta: molti chiudiporta commerciali sono eccessivamente smorzati per garantire che le porte si chiudano completamente senza sbattere o rimbalzare. - Sistemi di sicurezza: alcuni meccanismi di sicurezza potrebbero impiegare uno smorzamento eccessivo per garantire un ritorno graduale, anche se più lento, a uno stato sicuro.",
    "crumbs": [
      "IT_🇮🇹",
      "Risposta dinamica dei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/06_inverse_laplace_transform_it.html",
    "href": "IT_🇮🇹/06_inverse_laplace_transform_it.html",
    "title": "Trasformata di Laplace inversa: scomposizione parziale di frazioni",
    "section": "",
    "text": "Per trovare la trasformata di Laplace inversa di una funzione complicata, possiamo convertire la funzione in una somma di termini più semplici di cui conosciamo la trasformata di Laplace di ciascun termine. Il risultato è chiamato espansione di frazioni parziali.\nDato:\n\\[Y(s) = G(s)R(s) = \\frac{N(s)}{D(s)}R(s)\\]\ndove l’ordine di \\(N(s)\\) è inferiore all’ordine di \\(D(s)\\), è possibile effettuare un’espansione per frazione parziale.\nSe l’ordine di \\(N(s)\\) è maggiore o uguale all’ordine di \\(D(s)\\), allora \\(N(s)\\) deve essere diviso per \\(D(s)\\) in successione finché il risultato non ha resto il cui numeratore è di ordine inferiore al denominatore.\nVogliamo espandere \\(G(s)\\) nella somma delle funzioni di cui conosciamo già la trasformata inversa, poi grazie alla linearità potremo semplicemente sommarle tutte per ottenere l’inversa dell’intera funzione.\n\nCaso 1. Le radici del denominatore di F(s) sono reali e distinte\nSupponiamo di avere tutti poli distinti:\n\\[ D(s) = \\prod^{n}_{k=1}{(s-p_k)}\\]\nvogliamo trovare il coefficiente \\(P_k\\) tale che:\n\\[ \\frac{N(s)}{\\prod^{n}_{k=1}{(s-p_k)}} = \\sum^{n}_{k=1}\\frac{P_k}{ s-p_k}\\]\nMoltiplicando per \\((s-p_i)\\):\n\\[ (s-p_i)\\frac{N(s)}{\\prod^{n}_{k=1}{(s-p_k)}} = (s-p_i)\\sum^{n}_{ k=1}\\frac{P_k}{s-p_k}\\]\npossiamo ottenere:\n\\[P_i = [(s-p_i)G(s)] \\big|_{s=p_i}\\]\ne infine:\n\\[ g(t) = \\mathcal {L}^{-1}[G(s)]=\\mathcal {L}^{-1} \\bigg[\\sum^{n}_{k=1}\\ frac{P_k}{s-p_k}\\bigg] = \\sum^{n}_{k=1} P_k e^{p_kt}\\]\nPer esempio:\n\\[G(s) = \\frac{s-10}{(s+2)(s+5)}\\]\n\\[P_1=(s+2)\\frac{s-10}{(s+2)(s+5)}\\bigg|_{s=-2}=-\\frac{12}{3}=- 4\\] \\[P_2=(s+5)\\frac{s-10}{(s+2)(s+5)}\\bigg|_{s=-5}=\\frac{-15}{-3}= 5\\]\nche significa che:\n\\[G(s) = \\frac{-4}{(s+2)} + \\frac{5}{(s+5)}\\]\ne infine:\n\\[ g(t) = \\mathcal {L}^{-1}[G(s)] = -4e^{-2t} + 5e^{-5t}\\]\n\n\nCaso 2. Le radici del denominatore di F(s) sono reali e ripetute\nSe abbiamo poli multipli la scomposizione è simile.\nConsideriamo, ad esempio\n\\[\nY(s) = \\frac{2}{(s+1)(s+2)^2}\n\\]\nLe radici di \\((s+2)^2\\) nel denominatore vengono ripetute, poiché il fattore viene elevato a una potenza intera maggiore di 1. In questo caso, la radice del denominatore in \\(-2\\) è una radice multipla di molteplicità 2 .\nPossiamo scrivere l’espansione delle frazioni parziali come una somma di termini, dove ciascun fattore del denominatore forma il denominatore di ciascun termine.\nInoltre, ciascuna radice multipla genera termini aggiuntivi costituiti da fattori denominatori di molteplicità ridotta.\nNel nostro caso\n\\[\nY(s) = \\frac{2}{(s+1)(s+2)^2} = \\frac{K_1}{(s+1)} + \\frac{K_2}{(s+2)^ 2} + \\frac{K_3}{(s+2)}\n\\]\n\nOtteniamo \\(K_1\\) come prima. In questo caso \\(K_1=2\\)\nOtteniamo \\(K_2\\) moltiplicando l’equazione precedente per \\((s+2)^2\\):\n\n\\[\n\\frac{2}{(s+1)} = \\frac{K_1(s+2)^2}{(s+1)} + K_2 + K_3(s+2)\n\\]\nQuando \\(s \\rightarrow -2\\), \\(K_2=-2\\)\n\nOtteniamo \\(K_3\\) differenziando l’equazione precedente rispetto a \\(s\\):\n\n\\[\n\\frac{-2}{(s+1)^2} = \\frac{2(s+2)K_1}{(s+1)^2} + K_3\n\\]\nDa cui \\(K_3\\) può essere isolato e trovato se lasciamo \\(s \\rightarrow -2\\). Quindi, \\(K_3=-2\\).\nIn questo caso quindi:\n\\[\nY(s) = \\frac{2}{(s+1)(s+2)^2} = \\frac{2}{(s+1)} + \\frac{-2}{(s+2) ^2} + \\frac{-2}{(s+2)}\n\\]\ne la trasformata inversa è:\n\\[\ny(t) = 2e^{-t} - 2te^{-2t} -2e^{-2t}\n\\]\nSe la radice del denominatore ha molteplicità maggiore di 2, la differenziazione successiva isolerebbe ciascun residuo nell’espansione della radice multipla.\nIn generale, dato un \\(H(s)\\) il cui denominatore ha radici reali e ripetitive:\n\\[H(s) = \\frac{N(s)}{(s+p_1)^r(s+p_2)...(s+p_n)}\\]\nPossiamo trovare l’espressione generale per \\(K_1\\) (il coefficiente delle radici con molteplicità maggiore di 1):\n\\[\nK_i = \\frac{1}{(i-1)!}\\frac{d^{i-1}(F(s)(s+p_1)^r)}{ds^{i-1}}\\Big |_{s\\rightarrow-p_1} \\;\\; i=1,2,...,r\n\\]\n\n\nCaso 3. Le radici del denominatore di F(s) sono complesse o immaginarie\nLa tecnica utilizzata per l’espansione in frazioni parziali di \\(F(s)\\) con radici reali al denominatore può essere utilizzata per radici complesse e immaginarie.\nTuttavia, i residui delle radici complesse e immaginarie sono essi stessi coniugati complessi.\nIn questo caso i termini risultanti possono essere identificati come:\n\\[\n\\frac{e^{j\\theta}+e^{-j\\theta}}{2} = \\cos{\\theta}\n\\]\nE\n\\[\n\\frac{e^{j\\theta}-e^{-j\\theta}}{2j} = \\sin{\\theta}\n\\]\nPer esempio:\n\\[\nF(s) = \\frac{3}{s(s^2+2s+5)} = \\frac{3}{s(s+1+j2)(s+1-j2)} = \\frac{K_1 }{s} + \\frac{K_2}{s+1+j2} + \\frac{K_3}{s+1-j2}\n\\]\n\\(K_1\\) viene trovato come al solito e trovato \\(K_1=3/5\\).\nPer trovare \\(K_2\\):\n\\[\nK_2 = \\frac{3}{s(s+1-j2)}\\Big|_{s\\rightarrow -1-j2} = \\frac{-3}{20}(2+j1)\n\\]\nRisulta che \\(K_3\\) è il complesso coniugato di \\(K_2\\).\n\\[\nF(s) = \\frac{3/5}{s} - \\frac{3}{20}\\Big(\\frac{2+j1}{s+1+2j} + \\frac{2-j1}{ s+1-2j}\\Big)\n\\]\nche possiamo trasformare in senso inverso per ottenere:\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{20}\\Big[ (2+j1)e^{-(1+j2)t} + (2-j1)e^{ -(1-j2)t} \\Big]\n\\]\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{20} e^{-t}\\Big[4 \\Big( \\frac{e^{j2t}+e^{-j2t} }{2}\\Big) + 2 \\Big(\\frac{e^{j2t}-e^{-j2t}}{2j} \\Big) \\Big]\n\\]\n\\[\nf(t) = \\frac{3}{5} - \\frac{3}{5} e^{-t} \\Big( cos(2t) + \\frac{1}{2}sin(2t) \\Big ) = 0,6 - 0,671e^tcos(2t-\\phi)\n\\]\ndove \\(\\phi = arctan0.5=26.57^o\\)",
    "crumbs": [
      "IT_🇮🇹",
      "Trasformata di Laplace inversa: scomposizione parziale di frazioni"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "",
    "text": "Concetto 1: comprendere il cambiamento di prospettiva\n\nAnalisi nel dominio del tempo: in precedenza, abbiamo discusso il metodo del luogo delle radici, che si concentra principalmente sul dominio del tempo. Questo metodo è intuitivo per visualizzare le prestazioni transitorie attraverso i poli a circuito chiuso.\nAnalisi nel dominio della frequenza: ora sposteremo la nostra attenzione sull’analisi nel dominio della frequenza. Questo approccio offre una prospettiva diversa, enfatizzando la risposta in stato stazionario dei sistemi di controllo agli input sinusoidali.\n\n\n\n\nContesto storico: Storicamente, i metodi nel dominio della frequenza sono stati sviluppati prima del luogo delle radici, ma per ragioni pedagogiche abbiamo iniziato con quest’ultimo.\nPrestazioni transitorie e stazionarie: nell’analisi nel dominio della frequenza, la comprensione delle prestazioni transitorie è meno diretta rispetto al metodo del luogo delle radici. Comprendere il transitorio in termini di zeri e poli è molto semplice.\n\nNell’analisi nel dominio della frequenza, la comprensione dei risultati richiede un approccio più astratto, poiché il metodo presenta un modo indiretto di interpretare il comportamento del sistema. Ciò contrasta con il metodo del luogo delle radici, in cui l’interpretazione delle prestazioni del sistema è più semplice e diretta, principalmente perché rappresenta visivamente le dinamiche del sistema nel dominio del tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#transizione-dallanalisi-nel-dominio-del-tempo-allanalisi-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#transizione-dallanalisi-nel-dominio-del-tempo-allanalisi-nel-dominio-della-frequenza",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "",
    "text": "Concetto 1: comprendere il cambiamento di prospettiva\n\nAnalisi nel dominio del tempo: in precedenza, abbiamo discusso il metodo del luogo delle radici, che si concentra principalmente sul dominio del tempo. Questo metodo è intuitivo per visualizzare le prestazioni transitorie attraverso i poli a circuito chiuso.\nAnalisi nel dominio della frequenza: ora sposteremo la nostra attenzione sull’analisi nel dominio della frequenza. Questo approccio offre una prospettiva diversa, enfatizzando la risposta in stato stazionario dei sistemi di controllo agli input sinusoidali.\n\n\n\n\nContesto storico: Storicamente, i metodi nel dominio della frequenza sono stati sviluppati prima del luogo delle radici, ma per ragioni pedagogiche abbiamo iniziato con quest’ultimo.\nPrestazioni transitorie e stazionarie: nell’analisi nel dominio della frequenza, la comprensione delle prestazioni transitorie è meno diretta rispetto al metodo del luogo delle radici. Comprendere il transitorio in termini di zeri e poli è molto semplice.\n\nNell’analisi nel dominio della frequenza, la comprensione dei risultati richiede un approccio più astratto, poiché il metodo presenta un modo indiretto di interpretare il comportamento del sistema. Ciò contrasta con il metodo del luogo delle radici, in cui l’interpretazione delle prestazioni del sistema è più semplice e diretta, principalmente perché rappresenta visivamente le dinamiche del sistema nel dominio del tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#formalismo-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#formalismo-nel-dominio-della-frequenza",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Formalismo nel dominio della frequenza",
    "text": "Formalismo nel dominio della frequenza\nConcetto 2: Fondamenti dell’analisi nel dominio della frequenza\n\nRobustezza dei metodi nel dominio della frequenza: un vantaggio significativo dell’analisi nel dominio della frequenza è la sua robustezza, il che significa una minore dipendenza dall’accuratezza del modello del sistema. Questo è fondamentale poiché ottenere un modello accurato può essere difficile. Questo è uno dei motivi principali per cui è probabilmente il metodo di controllo più utilizzato.\nFacilità di analisi e progettazione: un altro vantaggio è la relativa facilità di analisi e progettazione nel dominio della frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#risposta-in-frequenza-di-sistemi-lineari",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#risposta-in-frequenza-di-sistemi-lineari",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Risposta in frequenza di sistemi lineari",
    "text": "Risposta in frequenza di sistemi lineari\nConcetto 3: Ingresso sinusoidale e risposta in stato stazionario\n\nRisposta del sistema all’ingresso sinusoidale:\n\nConsideriamo un sistema lineare descritto da una funzione di trasferimento $ G(s) $. Quando questo sistema è soggetto a un ingresso sinusoidale $ r(t) = R_0 (t) $, l’uscita avrà componenti sia transitorie che stazionarie.\n\nPresupposto del sistema stabile: per un sistema stabile, i componenti transitori si estinguono, lasciando solo la risposta allo stato stazionario. L’output in stato stazionario può essere rappresentato come $ y(t) = Y_0 (t + ) $.\n\nAnche la risposta stazionaria di un sistema lineare è sinusoidale, l’unico cambiamento è nell’ampiezza e nell’angolo di fase.\nCiò implica che comprendendo il rapporto di ampiezza \\(\\frac{Y_0}{R_0}\\) e l’angolo di fase \\(\\phi\\), possiamo descrivere completamente la relazione ingresso-uscita per la risposta in stato stazionario del sistema. Nello specifico, la chiave per questa comprensione sta nell’osservare come \\(\\frac{Y_0}{R_0}\\) e \\(\\phi\\) cambiano in funzione della frequenza.\n\n\n\n\n\n\n\n\nRappresentazione matematica\n\nAmpiezza e cambiamento di fase: anche la risposta in stato stazionario a un ingresso sinusoidale è sinusoidale, con cambiamenti di ampiezza e fase.\n\n\\[ \\text{Rapporto di ampiezza} = \\frac{Y_0}{R_0} \\]\n\\[ \\text{Angolo di fase} = \\phi \\]\n\n\nDefinizione della risposta in frequenza\nPossiamo ora definire formalmente la risposta in frequenza.\nConcetto 4: Definizione della risposta in frequenza\n\nComponenti della risposta in frequenza: La risposta in frequenza di un sistema può essere caratterizzata da come questi parametri (rapporto di ampiezza e angolo di fase) variano con la frequenza \\(\\omega\\).\n\\[ \\text{Frequency Response} = \\left\\{ \\frac{Y_0}{R_0}(\\omega), \\phi(\\omega) \\right\\} \\]\n\n\nRelativo alla funzione di trasferimento\n\nCollegamento alla funzione di trasferimento:\n\nIl rapporto di ampiezza $ $ è il modulo della funzione di trasferimento $ G(s) $ valutato in $ s = j$, e $ $ è l’angolo di fase di $ G(j ) $:\n\\[\n\\frac{Y_0}{R_0} = |G(s)|\\Big|_{s=j\\omega} = |G(j\\omega)|\n\\]\nE\n\\[\n\\phi = \\angle{G(j\\omega)}\n\\]\nciò significa che la risposta in frequenza è completamente contenuta nel modello matematico del sistema.\nDefinizione della risposta in frequenza\nl’ampiezza \\(|G(j\\omega)|\\) e la \\(\\angle{G(j\\omega)}\\) costituiscono la risposta in frequenza del sistema\nGrafici di risposta in frequenza\nQuando tracciamo \\(|G(j\\omega)|\\) e \\(\\angle{G(j\\omega)}\\) rispetto a \\(\\omega\\) otteniamo i grafici della risposta in frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#caratterizzazione-completa-del-sistema",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#caratterizzazione-completa-del-sistema",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Caratterizzazione completa del sistema",
    "text": "Caratterizzazione completa del sistema\nConcetto 5: Risposta in frequenza come caratterizzazione completa del sistema\n\nOltre l’analisi dello stato stazionario: sebbene la risposta in frequenza derivi dalla risposta sinusoidale allo stato stazionario, incapsula l’intero comportamento del sistema, inclusa la risposta ai transitori. Ciò è dovuto alla capacità della trasformata di Fourier di collegare la risposta in frequenza al comportamento nel dominio del tempo.\nVantaggi sperimentali: i grafici della risposta in frequenza possono essere ottenuti sperimentalmente, fornendo una caratterizzazione completa del sistema, anche quando un modello matematico non è disponibile.\n\nNella nostra analisi, esaminiamo due relazioni chiave: l’ampiezza della funzione di trasferimento, indicata come $ G(j) $, poiché varia con la frequenza \\(\\omega\\), e l’angolo di fase di $ G(j) $ poiché cambia anche con la frequenza. Queste relazioni possono essere rappresentate graficamente, dandoci i cosiddetti grafici della risposta in frequenza. Questi grafici descrivono visivamente il modo in cui il sistema risponde alle diverse frequenze.\nInizialmente, potrebbe sembrare che questi grafici della risposta in frequenza descrivano solo il comportamento del sistema in uno scenario stazionario, ovvero come si comporta il sistema dopo che si è stabilizzato in seguito a eventuali disturbi iniziali. Tuttavia, c’è di più di quanto sembri.\nIn realtà, questi grafici della risposta in frequenza offrono una caratterizzazione completa del sistema, comprendendo sia le risposte stazionarie che quelle transitorie (temporanee). Questa comprensione completa è possibile grazie a un potente strumento matematico noto come trasformata di Fourier. La trasformata di Fourier ci consente di correlare la risposta in frequenza alla risposta temporale del sistema. In sostanza, ciò significa che dai dati della risposta in frequenza possiamo prevedere come il sistema reagirà a qualsiasi dato input nel tempo. Per fare ciò per diversi tipi di segnali di ingresso, utilizziamo la serie di Fourier per segnali periodici (ripetuti) o la trasformata di Fourier per segnali non periodici (una tantum). In questo modo, otteniamo un quadro completo del comportamento del sistema sia nel dominio della frequenza che in quello del tempo.\nMan mano che progrediamo, la nostra attenzione si sposterà principalmente sull’esame dei grafici della risposta in frequenza.\nÈ importante capire che questi grafici, derivati ​​sperimentalmente o con altri mezzi dalla risposta sinusoidale del sistema in una condizione stazionaria, rappresentano in realtà l’intero comportamento matematico del sistema. Ciò include sia le risposte transitorie (a breve termine) che quelle stazionarie (a lungo termine).\nLa chiave per questa comprensione globale risiede nella trasformata di Fourier. La trasformata di Fourier funge da collegamento cruciale, collegando la risposta transitoria del sistema con la sua risposta in frequenza a stato stazionario. Questa connessione ci consente di utilizzare i grafici della risposta in frequenza come una rappresentazione completa del comportamento del sistema, comprendendo tutti gli aspetti della sua risposta nel tempo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#implicazioni-pratiche",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#implicazioni-pratiche",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Implicazioni pratiche",
    "text": "Implicazioni pratiche\nConcetto 6: Applicazioni pratiche e vantaggi\n\nIndipendenza dal modello: l’approccio nel dominio della frequenza dipende meno da un modello matematico preciso, il che è vantaggioso quando tali modelli sono difficili da ottenere o incerti.\nAccessibilità sperimentale: la risposta in frequenza può essere misurata direttamente, evitando la necessità di un modello di sistema dettagliato. Ciò è particolarmente utile per i sistemi in cui il modello è sconosciuto o complesso.\n\nConsidera una situazione in cui hai accesso all’hardware fisico di un sistema, ma il suo modello matematico è sconosciuto. In queste circostanze, non è possibile utilizzare direttamente il metodo del luogo delle radici per l’analisi o la progettazione, poiché il luogo delle radici richiede un modello matematico noto del sistema. Questo modello assume tipicamente la forma di una funzione di trasferimento o di un modello polo zero.\nTuttavia, se passiamo all’analisi nel dominio della frequenza, il processo diventa più semplice. In questo approccio è possibile iniziare con il test sinusoidale del sistema. Ciò comporta l’applicazione di ingressi sinusoidali all’hardware e la misurazione dell’uscita del sistema in termini di grandezza e angolo di fase. In questo modo, raccogli i dati sulla risposta in frequenza direttamente dall’hardware.\nUna volta ottenuti questi dati sulla risposta in frequenza, è possibile tracciare i grafici della risposta in frequenza. Questi grafici forniscono una caratterizzazione completa del comportamento del sistema, catturandone sia le risposte stazionarie che quelle transitorie. Il vantaggio qui è che non è necessario un modello matematico prestabilito, come una funzione di trasferimento, per l’analisi e la progettazione. Questo aspetto è particolarmente significativo perché creare un modello matematico accurato di un sistema può essere un compito impegnativo.\nSupponiamo che tu voglia ancora utilizzare il metodo del luogo delle radici, ma tutto ciò che hai sono i dati della risposta in frequenza. Per procedere, è necessario inserire questi dati in un modello polo zero, che può poi essere utilizzato per la progettazione del luogo delle radici. Tuttavia, è importante riconoscere che questo processo di adattamento è approssimativo. È quasi impossibile ottenere una corrispondenza perfetta tra i dati sperimentali della risposta in frequenza e il modello teorico del polo zero. Di conseguenza, il modello che si ottiene per il metodo del luogo delle radici è un’approssimazione.\nAl contrario, l’analisi nel dominio della frequenza non richiede questo passaggio di adattamento intermedio. Lavori direttamente con i dati grezzi ottenuti dai tuoi test sinusoidali. Questo uso diretto dei dati sperimentali nell’analisi nel dominio della frequenza semplifica il processo ed evita le approssimazioni e i potenziali errori coinvolti nell’adattamento dei dati a un modello polo zero.\nSpero che sia chiaro il motivo per cui l’approccio nel dominio della frequenza è così vitale per gli ingegneri di controllo. Questo approccio non è solo importante, è essenziale. È interessante notare che alcuni dei concetti di prestazione del sistema che utilizziamo nell’ingegneria dei controlli sono comuni anche nella teoria della comunicazione. Gli ingegneri delle comunicazioni spesso si occupano di ingressi sinusoidali o di una combinazione di segnali sinusoidali, il che si allinea bene con la loro attenzione alle funzioni di trasferimento sinusoidali.\nTuttavia, per gli ingegneri di controllo, la situazione è leggermente diversa. Non sempre lavoriamo con ingressi sinusoidali. Infatti, in molti casi, i sistemi che progettiamo e analizziamo potrebbero non incontrare mai input sinusoidali. Tuttavia, preferiamo ancora il formalismo nel dominio della frequenza a causa dei suoi numerosi vantaggi.\nUno di questi vantaggi è una comprensione più chiara delle caratteristiche del rumore di un sistema. L’approccio nel dominio della frequenza ci consente di analizzare e interpretare le caratteristiche di filtraggio del rumore di un sistema in modo più efficace di quanto potremmo osservare esclusivamente gli effetti nel dominio del tempo. Ad esempio, concetti come la larghezza di banda sono compresi in modo più intuitivo nel dominio della frequenza. La larghezza di banda si riferisce al modo in cui un sistema filtra il rumore, che non è rappresentato così chiaramente da parametri nel dominio del tempo come il tempo di salita.\nIn sintesi, l’approccio nel dominio della frequenza offre diversi vantaggi chiave:\n\nCaratteristiche del rumore: fornisce una visione più chiara del comportamento di filtraggio del rumore del sistema.\nFlessibilità con modelli di sistema: questo metodo può funzionare con modelli matematici meno accurati o anche con modelli sperimentali.\nFacilità di analisi e progettazione: i metodi nel dominio della frequenza spesso offrono tecniche più semplici e dirette per l’analisi e la progettazione del sistema.\n\nPertanto, mentre il metodo del luogo delle radici è vantaggioso per visualizzare direttamente le risposte transitorie attraverso i poli a circuito chiuso, l’approccio nel dominio della frequenza eccelle in altre aree critiche, in particolare nell’analisi delle caratteristiche del rumore e nell’offerta di flessibilità con i modelli di sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#luogo-delle-radici-e-formalismo-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#luogo-delle-radici-e-formalismo-nel-dominio-della-frequenza",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Luogo delle radici e formalismo nel dominio della frequenza",
    "text": "Luogo delle radici e formalismo nel dominio della frequenza\n\nMetodo del luogo delle radici\n\nIl metodo del luogo delle radici richiede un modello matematico dettagliato del sistema, tipicamente una funzione di trasferimento o un modello polo-zero.\nQuesto metodo è intuitivo per visualizzare la risposta transitoria in termini di poli ad anello chiuso.\n\n\n\nFormalismo nel dominio della frequenza\n\nNell’analisi nel dominio della frequenza, la modellazione matematica diretta non è un prerequisito.\nSi possono invece utilizzare dati sperimentali ottenuti dal test sinusoidale del sistema.\nQuesto approccio è utile quando l’esatto modello matematico del sistema è sconosciuto o difficile da determinare.\n\n\n\nImportanza dell’analisi nel dominio della frequenza\n\nVersatilità: gli ingegneri di controllo spesso lavorano con ingressi non sinusoidali, tuttavia l’approccio nel dominio della frequenza rimane applicabile grazie alla sua versatilità.\nCaratteristiche del rumore: comprendere le caratteristiche del rumore di un sistema è più semplice nel dominio della frequenza. Ciò include la larghezza di banda e il comportamento di filtraggio del rumore.\n\n\n\nVantaggi del formalismo nel dominio della frequenza\n\nFiltrazione del rumore: il dominio della frequenza fornisce informazioni più chiare sulle caratteristiche di filtraggio del rumore di un sistema.\nIndipendenza dal modello: può funzionare con modelli meno accurati o sperimentali.\nFacilità di analisi e progettazione: offre metodi di analisi e progettazione più semplici rispetto al metodo del luogo delle radici.\n\n\n\nNatura complementare dei metodi di analisi\n\nLocus delle radici e dominio della frequenza: questi metodi non si escludono a vicenda ma si completano a vicenda, ciascuno con i suoi vantaggi unici.\nEvoluzione continua: il campo dell’ingegneria di controllo è in continua evoluzione e non esiste un unico metodo di progettazione infallibile. Pertanto, comprendere vari metodi, compresi quelli che vanno oltre il luogo delle radici e il dominio della frequenza, è fondamentale per un ingegnere di controllo.\n\nDomanda pop-up: Perché si preferisce il formalismo nel dominio della frequenza quando il modello matematico del sistema è sconosciuto?\nRisposta: Il formalismo nel dominio della frequenza è preferito perché consente l’analisi e la progettazione direttamente dai dati sperimentali, evitando la necessità di un modello matematico preciso.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#introduzione-allanalisi-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#introduzione-allanalisi-nel-dominio-della-frequenza",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Introduzione all’analisi nel dominio della frequenza",
    "text": "Introduzione all’analisi nel dominio della frequenza\n\nPassaggi fondamentali dell’analisi nel dominio della frequenza\n\nAnalisi di stabilità\n\nLa stabilità viene determinata utilizzando il criterio di Routh-Hurwitz o il luogo delle radici stesso.\nNell’analisi nel dominio della frequenza utilizziamo il criterio di stabilità di Nyquist, una caratteristica centrale di questo approccio.\n\nSpecifiche prestazionali\n\nDominio temporale: le specifiche includono tempo di salita, tempo di assestamento, superamento del picco, ecc.\nDominio della frequenza: le specifiche includono larghezza di banda, picco di risonanza e frequenza di risonanza. Alcune di queste caratteristiche dovranno essere interpretate indirettamente quando tradotte nel dominio del tempo. Questa è la principale limitazione dei metodi nel dominio della frequenza.\n\nProgettazione\n\nCompensatori simili (lag, lead, lag-lead) vengono utilizzati sia nei metodi del luogo delle radici che nel dominio della frequenza. Tuttavia, il processo di progettazione è spesso più semplice nel dominio della frequenza.\n\nNel contesto della progettazione del dominio del tempo o del dominio s-plane, un elemento critico sono le condizioni di dominanza. Quando queste condizioni non vengono soddisfatte, il ricorso principale spesso si rivolge a tentativi ed errori, lasciando ai progettisti la scelta binaria di accettare o rifiutare il progetto così com’è. Tuttavia, nel dominio della frequenza, il ricorso a tentativi ed errori è significativamente ridotto. Abbiamo invece accesso a metodi più precisi e sistematici per affrontare le sfide progettuali, offrendo una gamma più ampia di soluzioni e aggiustamenti.\n\nDomanda pop-up: Qual è la differenza fondamentale tra le specifiche prestazionali nel dominio del tempo e nel dominio della frequenza?\nRisposta: Nel dominio del tempo, le specifiche si concentrano sulle caratteristiche di risposta ai transitori come il tempo di salita e l’overshoot, mentre nel dominio della frequenza sono incentrate sulle caratteristiche di risposta allo stato stazionario come la larghezza di banda e la frequenza di risonanza.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#criterio-di-stabilità-di-nyquist---stabilità-nellanalisi-nel-dominio-della-frequenza",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#criterio-di-stabilità-di-nyquist---stabilità-nellanalisi-nel-dominio-della-frequenza",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Criterio di stabilità di Nyquist - Stabilità nell’analisi nel dominio della frequenza",
    "text": "Criterio di stabilità di Nyquist - Stabilità nell’analisi nel dominio della frequenza\nIl criterio di stabilità di Nyquist si basa sulla teoria delle variabili complesse e sul Principio dell’Argomento di Cauchy. Fornisce un modo per determinare la stabilità di un sistema analizzando la funzione di trasferimento ad anello aperto nel dominio della frequenza.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#comprendere-il-criterio",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#comprendere-il-criterio",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Comprendere il criterio",
    "text": "Comprendere il criterio\nFunzione di trasferimento a ciclo chiuso:\nConsideriamo un sistema generale a ciclo singolo in cui la funzione di trasferimento ad anello chiuso è \\[ \\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)H(s )} \\].\n\n\n\n\n\n\n\nDeterminazione della stabilità:\n\nIl denominatore della funzione di trasferimento ad anello chiuso è: $ 1 + G(s)H(s) $, e questa è l’equazione su cui dobbiamo concentrarci.\nLa stabilità viene determinata analizzando il luogo di $ 1 + G(s)H(s) $ nel piano complesso.\nSe nessun punto nella metà destra del piano s, compreso l’asse immaginario, soddisfa $ 1 + G(s)H(s) = 0 $, il sistema è stabile.\n\nIn altre parole:\n\nIl piano S: immagina il piano s come un piano complesso in cui ogni punto ‘s’ rappresenta un numero complesso con una parte reale (\\(\\sigma\\)) e una parte immaginaria (\\(j\\omega\\)) .\nRegioni di interesse: siamo particolarmente interessati alla metà destra e alla metà sinistra di questo piano s. La metà destra include l’asse immaginario (asse \\(j\\omega\\)).\nDefinizione di stabilità: Un sistema di controllo è considerato stabile se tutti i poli del circuito chiuso (le soluzioni dell’equazione caratteristica del sistema) si trovano nella metà sinistra del piano s.\n\n\nComprendere G(s)H(s) - La funzione di trasferimento ad anello aperto\n\nComposizione di G(s)H(s): Questa funzione rappresenta il prodotto di tutte le singole funzioni di trasferimento nel circuito di controllo quando il circuito è aperto. In genere include funzioni di processo, compensatore e trasferimento del sensore. Questa funzione è nota.\n\n\n\n\n\n\n\n\n\nRappresentazione polinomiale: spesso esprimiamo \\(G(s)H(s)\\) come rapporto di due polinomi, \\(N(s)\\) e \\(\\Delta(s)\\).\n\n\\[G(s)H(s) = \\frac{N(s)}{\\Delta(s)}\\]\nNella maggior parte dei casi, \\(G(s)H(s)\\) assume questa forma, tranne in scenari specifici come i tempi morti rappresentati da $ e^{-s_d} $. Per ora limitiamo l’analisi a \\(G(s)H(s)\\) come rapporto tra due polinomi, ma possiamo estenderla al caso più generale.\n\nPoli e zeri di G(s)H(s)\n\nPoli e zeri: sono fondamentali per determinare il comportamento del sistema. Gli zeri di \\(G(s)H(s)\\) sono le radici del polinomio al numeratore \\(N(s)\\), mentre i poli sono le radici del polinomio al denominatore \\(\\Delta(s)\\).\nQuantità note: nell’analisi ad anello aperto, questi poli e questi zeri sono noti e costituiscono la base per ulteriori analisi di stabilità.\n\n\n\n\nStabilità nei sistemi ad anello aperto e ad anello chiuso\n\nStabilità a circuito aperto: se i poli di \\(G(s)H(s)\\) si trovano nella metà sinistra del piano s, il sistema è stabile a circuito aperto. Al contrario, se qualche polo si trova nella metà destra, il sistema è instabile a circuito aperto.\nFocus sulla stabilità a circuito chiuso: il nostro interesse primario risiede nella stabilità del sistema in condizioni a circuito chiuso, ovvero quando viene applicato il feedback. Anche un sistema instabile a circuito aperto può essere stabilizzato con un feedback appropriato.\n\nSi noti che un sistema instabile a ciclo aperto non ha importanza: vogliamo studiare le proprietà di stabilità quando il ciclo è chiuso, cioè sotto feedback. Allo stesso tempo, mi sono noti i poli (e gli zeri) ad anello aperto.\n\n\nAnalisi della stabilità a circuito chiuso\nLa funzione di trasferimento ad anello chiuso è:\n\\[ \\frac{Y(s)}{R(s)} = \\frac{Sol(s)}{1 + G(s)H(s)} \\]\n\nLa funzione $ 1 + $: per analizzare la stabilità a ciclo chiuso, ci concentriamo su questa funzione. Rappresenta il denominatore della funzione di trasferimento ad anello chiuso.\n\nPossiamo espandere questa funzione come:\n\\[ 1 + \\frac{N(s)}{\\Delta(s)} = \\frac{\\Delta(s) + N(s)}{\\Delta(s)}\\]\n\nForma polinomiale: Supponendo che \\(\\Delta(s)\\) sia un polinomio di ordine ennesimo, possiamo esprimerlo in forma fattorizzata come:\n\n\\[ \\Delta(s) = (s - \\alpha_1)(s - \\alpha_2)...(s - \\alpha_n) \\]\nL’ordine del numeratore (\\(\\Delta(s) + N(s)\\)) è \\(n\\). Questo perché il \\(\\text{order}[N(s)] \\le \\text{order}[\\Delta(s)]\\) garantisce la realizzabilità fisica.\nPer questo motivo possiamo quindi riscrivere la nostra funzione come:\n\\[ 1+G(s)H(s) = 1 + \\frac{N(s)}{\\Delta(s)} = \\frac{\\Delta(s) + N(s)}{\\Delta(s )} = \\frac{(s - \\beta_1)(s - \\beta_2)...(s - \\beta_n)}{(s - \\alpha_1)(s - \\alpha_2)...(s - \\alpha_n) }\\]\nRicorda, se qualsiasi valore di ‘s’ nella metà destra del piano o sull’asse immaginario soddisfa l’equazione (1 + G(s)H(s) = 0), allora il sistema è considerato instabile . Ciò costituisce la base della nostra congettura riguardo alla stabilità del sistema.\nDomanda pop-up: Perché ci concentriamo sulla metà sinistra del piano S per la stabilità?\nRisposta: la metà sinistra del piano s indica che tutti i poli hanno parti reali negative, che corrispondono a risposte in decadimento nel dominio del tempo, una caratteristica chiave di un sistema stabile.\nDomanda pop-up: Qual è il principio alla base del criterio di stabilità di Nyquist?\nRisposta: Il criterio di stabilità di Nyquist si basa sul principio dell’argomentazione in analisi complessa, che mette in relazione il numero di circonferenze di un punto da parte di una funzione nel piano complesso al numero di zeri e poli di quella funzione.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#comprendere-il-piano-s-e-il-piano-w",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#comprendere-il-piano-s-e-il-piano-w",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Comprendere il piano S e il piano W",
    "text": "Comprendere il piano S e il piano W\n\nIl piano S\n\nDescrizione: Il piano s è un piano complesso in cui ogni punto ‘s’ rappresenta un numero complesso, con una parte reale (\\(\\sigma\\)) e una parte immaginaria (\\(j\\omega\\)).\nRappresentazione di variabili complesse: ogni punto sul piano s è una variabile complessa, rappresentata come σ + jω.\n\n\n\nIl piano W\n\nRelazione con il piano S: Quando applichiamo la funzione \\(1 + G(s)H(s)\\) a un punto sul piano s, si mappa su un punto su un altro piano complesso, chiamato W- aereo.\nVariabile complessa sul piano W: anche questo punto mappato sul piano W è una variabile complessa, rappresentata come \\(u + jv\\).\n\n(vedi immagine a sinistra, sotto.)\n\nMappatura dal piano S al piano W\n\nApplicazione della funzione: La funzione \\(1 + G(s)H(s)\\) trasforma ogni punto ‘s’ sul piano s in un punto corrispondente sul piano W.\nMappatura uno-a-uno: per una funzione razionale (come quella che abbiamo), per ogni punto sul piano s, esiste un punto corrispondente unico sul piano W.\n\n(vedi immagine a destra, sotto.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalisi di stabilità utilizzando la mappatura \\(1+G(s)H(s)\\)\n\nObiettivo: Per analizzare la stabilità di un sistema, esaminiamo come la metà destra del piano s, compreso l’asse immaginario, si mappa sul piano W utilizzando $1 + G(s)H(s) $.\nCriteri di stabilità: se l’origine del piano W non è coperta da questa mappatura, il sistema è stabile. Se l’origine è coperta, il sistema è instabile.\n\nQuesta è l’affermazione equivalente a dire “l’equazione \\(1 + G(s)H(s)\\) non ha radici nella RHP (incluso l’asse immaginario)”.\n\n\nMappatura dei contorni\n\nConcetto di contorni: un contorno nel piano s, che è un insieme connesso di punti (un contorno è un percorso continuo nel piano s, che può essere una curva semplice o un anello chiuso), sarà mappare su un contorno corrispondente nel piano W a causa della natura uno a uno della mappatura.\nMappatura al piano W: quando mappiamo questo contorno al piano W utilizzando la nostra funzione di trasferimento, il percorso risultante nel piano W riflette le caratteristiche dei poli e degli zeri del sistema.\n\n\n\nFocus sulla mappatura qualitativa\n\nAnalisi qualitativa: il nostro interesse primario non è l’esatta mappatura quantitativa uno a uno, ma la comprensione di come la mappatura influisca qualitativamente sulla stabilità del sistema, in particolare attorno all’origine del piano \\(\\omega\\). In altre parole vorremmo sapere se l’origine del piano W è coperta oppure no.\n\nNella nostra analisi, l’attenzione si concentra principalmente sulle caratteristiche qualitative di come i contorni specifici nel piano s, che possono circondare punti chiave come zeri o poli, vengono trasformati e rappresentati nel piano W.\nIn effetti, se dovessimo enfatizzare una mappatura precisa e quantitativa uno a uno tra questi piani, il compito diventerebbe estremamente complesso. Un simile approccio diminuirebbe l’utilità pratica e la rilevanza del criterio di Nyquist nell’analisi dei sistemi.\nDomanda pop-up: Perché ci concentriamo sulla mappatura qualitativa piuttosto che quantitativa nell’analisi del sistema?\nRisposta: Ci concentriamo sulla mappatura qualitativa perché rivela come si comporta il sistema in prossimità di punti critici, come l’origine del piano \\(\\omega\\), che è cruciale per valutare la stabilità del sistema.\n\nEsempio di mappatura dei contorni\n\nScenario: Considera un contorno nel piano s che racchiude uno zero della funzione \\(1 + G(s)H(s)\\) e analizza la sua mappatura sul piano W.\nAnalisi: la chiave è capire come gli angoli forniti da diversi punti su questo contorno risultano nella mappatura sul piano W.\n\nLa nostra funzione di trasferimento svolge il compito di trasformare un punto dal piano s in un punto corrispondente in un nuovo piano, indicato come piano \\(\\omega\\).\n\nQuando selezioniamo numerosi punti sul piano s che sono collegati per formare un percorso continuo (noto come contorno), questi punti vengono mappati per formare un percorso continuo anche nel piano \\(\\omega\\).\nNello specifico, quando scegliamo punti lungo un contorno nel piano s, che è essenzialmente una linea che forma un anello e si ricollega a se stessa, ciò si traduce in un anello chiuso nel piano \\(\\omega\\). Chiamiamo questo ciclo chiuso un plot.\nÈ importante sottolineare che questo grafico nel piano \\(\\omega\\) incapsula informazioni cruciali sul sistema. Trasmette sia il modulo che l’angolo di fase associati a ciascun polo e zero del sistema.\n\n\n\n\nCodice di visualizzazione per mappare un contorno dal piano s al piano \\(\\omega\\).\nPossiamo verificarlo con Python come mostrato di seguito.\nQuesto codice mostra una rappresentazione grafica di un contorno nel piano s e il suo percorso corrispondente nel piano \\(\\omega\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the subplots\nfig, axs = plt.subplots(1, 2, figsize=(15, 7))\n\n# Improve plot aesthetics (axis, grids, scale)\nfor i in range(len(axs)):\n    axs[i].axhline(0, color='black', linewidth=1.5, linestyle='--') # horizontal axis\n    axs[i].axvline(0, color='black', linewidth=1.5, linestyle='--') # vertical axis\n    axs[i].axis([-4, 3, -3, 3]) # scale the axis\n    axs[i].grid(True, which='both', linestyle='--', linewidth=0.5) # add grid\n    axs[i].set_aspect('equal', 'box')\n    axs[i].set_xticks(np.arange(-4, 4, 1))\n    axs[i].set_yticks(np.arange(-3, 4, 1))\n    axs[i].set_xlabel('Real')\n    axs[i].set_ylabel('Imaginary')\n\naxs[0].set_title('S-Plane')\naxs[1].set_title('$\\omega$-Plane')\n\n# Plot poles and zeros in the s-plane with annotations\npole = (-3, 0)\nzero = (-2, 0)\naxs[0].plot(pole[0], pole[1], 'bo', markersize=12) # blue circle for pole\naxs[0].plot(zero[0], zero[1], 'rx', markersize=12) # red cross for zero\naxs[0].text(pole[0], pole[1]+0.1, '  Pole', verticalalignment='bottom', horizontalalignment='right')\naxs[0].text(zero[0], zero[1]-0.2, '  Zero', verticalalignment='top', horizontalalignment='right')\n\n# Mapping from s-plane to w-plane\nfor xi in np.linspace(0, 2*np.pi, 100):\n    s_point = np.sin(xi), 3*np.cos(xi) # pick one s-point\n    axs[0].plot(s_point[0], s_point[1], 'm.', markersize=12) # plot the s-point in the s-plane\n    \n    # Map one s_point to a W_point\n    W_point = (complex(s_point[0], s_point[1]) + 3)/(complex(s_point[0], s_point[1]) + 2)\n    axs[1].plot(np.real(W_point), np.imag(W_point), 'r.', markersize=12) # plot the W_point\n\nplt.show()",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#esempio-di-analisi-del-contorno-nel-piano-s-e-sua-mappatura-sul-piano-omega",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#esempio-di-analisi-del-contorno-nel-piano-s-e-sua-mappatura-sul-piano-omega",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Esempio di analisi del contorno nel piano S e sua mappatura sul piano \\(\\omega\\)",
    "text": "Esempio di analisi del contorno nel piano S e sua mappatura sul piano \\(\\omega\\)\nConsideriamo un percorso specifico, o contorno, nel piano s che include uno zero della funzione di trasferimento \\(1 + G(s)H(s)\\). Il nostro obiettivo è capire come questo contorno si traduce nel piano \\(\\omega\\).\n\n\n\n\n\n\n\nDato che tutti i poli e gli zeri di \\(1 + G(s)H(s)\\) sono noti, lo esprimiamo come:\n\\[\n  1 + G(s)H(s) = \\frac{(s-\\beta_1)(s-\\beta_2)...}{(s-\\alpha_1)(s-\\alpha_2)...}\n  \\]\n\nMappatura di un punto dal piano S al piano \\(\\omega\\)\n\nEsempio con un punto specifico \\(s_1\\): Per illustrare, concentriamoci su un punto particolare \\(s_1\\) sul nostro contorno del piano s.\n\\[\n1 + G(s_1)H(s_1) = \\frac{(s_1-\\beta_1)(s_1-\\beta_2)...}{(s_1-\\alpha_1)(s_1-\\alpha_2)...}\n\\]\nQui, ogni termine $ (s_1-_i) $ rappresenta un ‘fasore numeratore’, e ogni $ (s_1-_i) $ è un ‘fasore denominatore’.\nCalcolo dell’ampiezza e della fase del punto mappato:\n\nGrandezza: La grandezza del punto mappato sul piano \\(\\omega\\) si ottiene moltiplicando ciascun fasore del numeratore e dividendo per ciascun fasore del denominatore.\nFase: l’angolo di fase del punto mappato viene calcolato sommando le fasi dei fasori del numeratore e sottraendo le fasi dei fasori del denominatore.\n\nPunto mappato risultante \\(w_1\\): questo processo risulta in un punto nel piano \\(\\omega\\), indicato come \\(w_1\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizzazione dei fasori e della mappatura dei contorni\n\nRappresentazione grafica: I fasori corrispondenti al punto \\(s_1\\) sono rappresentati graficamente di seguito (a sinistra), mostrando come contribuiscono al processo di mappatura.\nMovimento e mappatura del contorno: Mentre continuiamo a muoverci lungo il contorno nel piano s, diciamo in senso orario, creiamo un contorno corrispondente nel piano \\(\\omega\\) (a destra sotto).\n\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ipywidgets import interact, FloatSlider\n\n# Define the transfer function\ndef transfer_function(s):\n    return s + 2\n\n# Zero of the transfer function\nzero = -2\n\n# Define the contour in the s-plane (a circle of radius 3)\ndef s_plane_contour(theta):\n    return 3 * np.exp(1j * theta)\n\n# Map the contour to the omega-plane using the transfer function\ndef omega_plane_mapping(s):\n    return transfer_function(s)\n\n# Pre-calculate all the points on the contour for the omega-plane\ntheta_values = np.linspace(0, 2*np.pi, 300)\nomega_points = [omega_plane_mapping(s_plane_contour(theta)) for theta in theta_values]\n\n# Function to plot the contours\ndef plot_contours(theta):\n    s_point = s_plane_contour(theta)\n    omega_point = omega_plane_mapping(s_point)\n\n    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n    # Plotting in the s-plane\n    axs[0].plot(np.real(s_point), np.imag(s_point), 'ro', label='Current Point')  # current point\n    axs[0].plot(zero, 0, 'gX', markersize=10, label='Zero')  # zero of the transfer function\n    circle = plt.Circle((0, 0), 3, color='b', fill=False)\n    axs[0].add_artist(circle)\n    axs[0].set_xlim([-4, 4])\n    axs[0].set_ylim([-4, 4])\n    axs[0].axhline(0, color='black')\n    axs[0].axvline(0, color='black')\n    axs[0].grid(True)\n    axs[0].set_title('S-Plane')\n    axs[0].set_xlabel('Real')\n    axs[0].set_ylabel('Imaginary')\n    axs[0].legend()\n\n    # Plotting in the omega-plane\n    axs[1].plot([np.real(wp) for wp in omega_points], [np.imag(wp) for wp in omega_points], 'b-', alpha=0.7)  # all points\n    axs[1].plot(np.real(omega_point), np.imag(omega_point), 'ro', label='Current Point')  # current point\n    axs[1].set_xlim([-5, 5])\n    axs[1].set_ylim([-5, 5])\n    axs[1].axhline(0, color='black')\n    axs[1].axvline(0, color='black')\n    axs[1].grid(True)\n    axs[1].set_title('$\\omega$-Plane')\n    axs[1].set_xlabel('Real')\n    axs[1].set_ylabel('Imaginary')\n    axs[1].legend()\n\n    plt.show()\n\n# Create a slider for interactive plot\ninteract(plot_contours, theta=FloatSlider(min=0, max=2*np.pi, step=0.01, value=0, description='Theta:'))\n\n\n\n\n&lt;function __main__.plot_contours(theta)&gt;\n\n\nConsideriamo ancora una volta il nostro contorno arbitrario:\n\n\n\n\n\n\n\n\n\n\nConsideriamo il comportamento dei singoli fasori, come il fasore $ (s - _1) $, mentre si muovono lungo un contorno specifico nel piano s.\n\n**Fasore $ (s - _1) $**: Mentre viaggiamo lungo il contorno che include lo zero $ _1 $, il fasore $ (s - _1) $ contribuirà a un cambiamento totale dell’angolo. Quando inizi da un certo punto del contorno e ti muovi completamente attorno ad esso, la modifica dell’angolo apportata da $ (s - _1) $ ammonta a $ -2$ radianti.\n**Fasore $ (s - _2) $**: Ora, se consideriamo un fasore diverso, $ (s - _2) $, dove $ _2 $ non è racchiuso dal contorno, lo scenario cambia. Mentre segui lo stesso contorno partendo da un punto e ritornando ad esso, la variazione netta dell’angolo apportata da $ (s - _2) $ finisce per essere zero. Questo perché qualsiasi variazione angolare positiva durante una parte del viaggio viene annullata da una corrispondente variazione negativa dell’angolo in un’altra parte.\n\nQuesta comprensione è cruciale per il criterio di stabilità di Nyquist. Ci dice che:\n\nSe uno zero della funzione $ 1 + G(s)H(s) $ è racchiuso all’interno del contorno, contribuisce con un angolo di $ 2$ radianti alla variazione totale dell’angolo mentre attraversiamo il contorno.\nSe tutti gli altri poli e zeri si trovano all’esterno del contorno, non contribuiscono alla variazione dell’angolo netto.\n\nPertanto, indipendentemente dalla forma del contorno, se racchiude uno zero di $ 1 + G(s)H(s) $, il contorno risultante mappato nel piano \\(\\omega\\) circonderà l’origine esattamente una volta, e in una direzione in senso orario, a causa della variazione angolare totale di $ -2$ radianti.\n\n\nCaso in cui è racchiuso uno zero\n\nRacchiudere uno Zero: Supponiamo che il nostro contorno nel piano s circondi uno zero della funzione \\(1 + G(s)H(s)\\). In questo scenario, mentre attraversiamo il contorno in senso orario, la variazione angolare totale apportata da questo zero racchiuso è $ -2$ radianti.\nCirconferenza risultante: Ciò significa che il contorno corrispondente nel piano \\(\\omega\\) circonderà l’origine in senso orario esattamente una volta.\n\n\n\nCaso di recinzione di un palo\n\nRacchiudere un Polo: Ora, immagina invece che il contorno racchiuda un polo (non uno zero) di \\(1 + G(s)H(s)\\). Tutti gli altri zeri e poli sono fuori da questo contorno.\n\n\n\n\n\n\n\n\n\nEffetto sul contributo angolare: il contributo angolare per un polo è l’opposto di quello per uno zero. Pertanto, la variazione totale dell’angolo è $ +2$ radianti, indicando un accerchiamento in senso antiorario nel piano \\(\\omega\\).\nCircondamento netto: Ciò si traduce in una rotazione completa in senso antiorario attorno all’origine nel piano \\(\\omega\\).\n\n\n\nCombinazione di poli e zeri\n\nCombinazione di poli e zeri: considera un contorno che racchiude entrambi i poli e uno zero. Ad esempio, un contorno con due poli e uno zero.\nCalcolo della rotazione netta: la rotazione netta nel piano W è determinata dalla differenza tra rotazioni in senso antiorario (contribuite dai poli) e rotazioni in senso orario (contribuite dagli zeri). Nel nostro esempio, abbiamo due rotazioni in senso antiorario (poli) e una rotazione in senso orario (zero), risultando in una rotazione netta in senso antiorario (\\(2 - 1 = 1\\)).\n\n\n\nImplicazioni per il criterio di Nyquist\nQueste osservazioni costituiscono la base del criterio di stabilità di Nyquist. È importante notare che, sebbene abbiamo discusso gli aspetti qualitativi della mappatura, la forma esatta del contorno nel piano W non è la nostra preoccupazione principale.\nCon questa comprensione, siamo ora pronti ad approfondire l’affermazione e l’applicazione del criterio di stabilità di Nyquist nell’analisi del sistema di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#principio-argomentativo-di-cauchy",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#principio-argomentativo-di-cauchy",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Principio argomentativo di Cauchy",
    "text": "Principio argomentativo di Cauchy\nPossiamo individuare la differenza relativa tra il numero di poli e di zeri all’interno di un contorno contando quante volte il diagramma gira intorno all’origine e in quale direzione.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#il-criterio-di-stabilità-di-nyquist",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#il-criterio-di-stabilità-di-nyquist",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Il criterio di stabilità di Nyquist",
    "text": "Il criterio di stabilità di Nyquist\nApplicheremo il Principio dell’Argomento di Cauchy a un contorno specifico nel piano s, come illustrato a sinistra nella figura seguente.\nQuesto contorno circonda l’intero semipiano destro (RHP), compreso l’asse immaginario. Questo contorno è chiamato Contorno di Nyquist.\nPer l’analisi iniziale, assumeremo che non vi siano poli situati sul contorno stesso. Considereremo le implicazioni della presenza di poli sul contorno in una fase successiva.\nAttraverso la funzione \\(1 + G(s)H(s)\\), questo contorno specifico nel piano s viene mappato sul piano \\(\\omega\\), mostrato a destra nell’immagine.\n\n\n\n\n\n\n\nPunti chiave da notare:\n\nPoli ad anello aperto: I poli di \\(1 + G(s)H(s)\\) sono gli stessi poli ad anello aperto del sistema, che conosciamo dagli zeri e dai poli di \\(G(s )H(s)\\).\nPoli ad anello chiuso: gli zeri di \\(1 + G(s)H(s)\\) corrispondono ai poli ad anello chiuso del sistema. Questi zeri non sono noti in anticipo e sono ciò che miriamo a determinare per l’analisi di stabilità.\n\nSecondo il criterio di Nyquist:\n\nSe la mappatura nel Piano W circonda l’origine \\(N\\) volte in senso antiorario, questo numero di accerchiamenti (\\(N\\)) è matematicamente espresso come il numero di poli di \\(1 + G(s)H(s )\\) (indicato come \\(P\\)) meno il numero dei suoi zeri (indicato come \\(Z\\)). Questa relazione è catturata nell’equazione di Nyquist:\n\\[\nN = P-Z\n\\]\nL’equazione di Nyquist costituisce la base del Criterio di Nyquist, che asserisce che il numero totale di accerchiamenti in senso antiorario dell’origine nel Piano W da parte della funzione \\(1 + G(s)H(s)\\) è uguale alla differenza tra il numero dei suoi poli e degli zeri.\n\nPertanto, per determinare la stabilità a circuito chiuso del sistema, è necessario mappare il contorno sul piano W e contare il numero di volte (\\(N\\)) che questa mappatura circonda l’origine.\nDall’equazione di Nyquist otteniamo direttamente quanti zeri di \\(1+G(s)H(s)\\) ci sono nel semipiano destro.\n\nCommenti laterali\n\nPer quanto riguarda lo scenario in cui uno zero di \\(1 + G(s)H(s)\\) (polo in anello chiuso) giace sul contorno, sarà importante considerarne l’impatto. Se sul contorno è presente uno zero, ciò implica che il contorno passerà attraverso l’origine nel piano W. Tale situazione indica tipicamente una condizione di marginale stabilità per il sistema. In altre parole, quando il contorno nel piano s, trasformato dalla funzione \\(1 + G(s)H(s)\\), passa per l’origine nel piano W, rappresenta un caso speciale in cui gli zeri della funzione (che sono i poli del circuito chiuso) coincidono con il contorno. Questo scenario richiede un’attenta analisi in quanto riguarda il margine di stabilità del sistema.\nUn’altra considerazione importante si pone quando un polo della funzione di trasferimento ad anello aperto $ G(s)H(s) $ cade sul contorno di Nyquist. In tali casi, la mappatura di quel punto sul piano W risulta in un valore infinito. Questo evento richiede particolare attenzione nell’analisi della stabilità del sistema.\nGli zeri di \\(G(s)H(s)\\) non creano alcun problema. A differenza dei poli, che possono mappare all’infinito sul piano W e complicare l’analisi (poiché i valori infiniti richiedono una considerazione speciale), gli zeri non danno luogo a valori così estremi nel processo di mappatura. Pertanto, non aggiungono complessità all’interpretazione grafica del diagramma di Nyquist.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#traslare-il-diagramma-di-nyquist",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#traslare-il-diagramma-di-nyquist",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Traslare il diagramma di Nyquist",
    "text": "Traslare il diagramma di Nyquist\nNel nostro studio dei sistemi di controllo ci siamo concentrati sull’analisi del diagramma di Nyquist della funzione\n\\[\n1 + G(s)H(s)\n\\]\ne ne osservò il comportamento in termini di numero di volte che gira attorno all’origine nel piano W.\nCreare il diagramma di questa funzione può essere difficile a causa della sua complessità. Per semplificare la nostra analisi possiamo invece considerare il Nyquist Plot della sola funzione $ G(s)H(s) $. Questo approccio prevede il conteggio degli accerchiamenti attorno al punto critico \\(-1 + 0j\\) sul piano complesso.\nQuesto metodo non solo semplifica il processo di tracciamento ma ci fornisce anche le informazioni essenziali necessarie per valutare la stabilità del sistema di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#interpretazione-del-criterio-di-stabilità-di-nyquist",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#interpretazione-del-criterio-di-stabilità-di-nyquist",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Interpretazione del criterio di stabilità di Nyquist",
    "text": "Interpretazione del criterio di stabilità di Nyquist\nIl criterio si riferisce alla risposta in frequenza di un sistema ed è espresso come:\n\\[\nN = P-Z\n\\]\nDove: - \\(N\\) è il numero di accerchiamenti in senso antiorario del punto $-1+0j $ nel piano W. - \\(P\\) è il numero di poli di \\(1 + G(s)H(s)\\) nella metà destra del piano s. - \\(Z\\) è il numero di zeri di \\(1 + G(s)H(s)\\) sullo stesso piano.",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#applicazione-del-criterio",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#applicazione-del-criterio",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Applicazione del criterio",
    "text": "Applicazione del criterio\nPer applicare questo criterio, seguiamo questi passaggi:\n\nMappatura del contorno: considera un contorno nel piano s che comprende la metà destra, compreso l’asse immaginario. Assumiamo inizialmente che nessun polo si trovi direttamente su questo contorno (affronteremo lo scenario con i poli sul contorno in seguito).\nTrasformazione nel piano W: questo contorno viene quindi mappato sul piano W tramite la funzione \\(G(s)H(s)\\).\nConteggio degli accerchiamenti: il numero di volte in cui questo contorno mappato circonda il punto -1 nel piano W (in senso antiorario) ci dà \\(N\\). Ciò significa anche che \\(N\\) è positivo quando il contorno circonda il punto -1 in senso antiorario.\nDeterminazione della stabilità:\n\nUsiamo l’equazione \\(N = P - Z\\) per determinare \\(Z\\) gli zeri di \\(1 + G(s)H(s)\\) nella RHP, che corrispondono ai poli ad anello chiuso nella RHP.\n\n\n\nSistemi stabili a circuito aperto\n\nPer un sistema stabile a ciclo aperto (dove \\(P = 0\\)), il sistema a ciclo chiuso è stabile se il diagramma di Nyquist nel piano W non circonda l’origine.\nQuando \\(P=0\\) (il sistema ad anello aperto è stabile)\n\\(Z=N \\Rightarrow N=0\\) oppure nessun accerchiamento del punto \\(-1\\) per avere un sistema a ciclo chiuso stabile (per stabilità \\(Z=0\\)).\nQuesto è il caso che incontriamo più spesso.\n\nAd esempio, dato un sistema stabile ad anello aperto vorremmo un diagramma di Nyquist come:\n\n\n\n\n\n\n\n\n\nSistemi instabili a circuito aperto\n\nPer un sistema instabile ad anello aperto, diciamo con un polo nel semipiano destro (\\(P = 1\\)), il sistema è stabile in funzionamento ad anello chiuso se il diagramma G(s)H(s) circonda il punto \\(-1 + j0\\) una volta in senso antiorario.\nPer garantire che non ci siano zeri (radici di \\(1+G(s)H(s)\\)) nel semipiano destro (\\(Z=0\\)), dobbiamo avere esattamente 1 in senso antiorario (CCW) accerchiamento del punto -1 per ciascun polo ad anello aperto nel semipiano destro:\n\n\\[\nP = N\n\\]",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#controlla-la-tua-comprensione",
    "href": "IT_🇮🇹/introduction_to_frequency_domain_analysis_in_control_systems_it.html#controlla-la-tua-comprensione",
    "title": "Introduzione all’analisi nel dominio della frequenza nei sistemi di controllo",
    "section": "Controlla la tua comprensione",
    "text": "Controlla la tua comprensione\n\nDomanda: Cosa significa \\(N = P - Z\\) nel criterio di Nyquist?\nRisposta: Rappresenta la relazione tra il numero di circonferenze in senso antiorario dell’origine nel piano W, il numero di poli e il numero di zeri della funzione di trasferimento ad anello aperto nella metà destra del s-aereo.\nDomanda: Per un sistema stabile a ciclo aperto, qual è la condizione chiave per la stabilità a ciclo chiuso?\nRisposta: Il diagramma di Nyquist di \\(G(s)H(s)\\) nel piano W non dovrebbe circondare il punto \\(-1 + j0\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Introduzione all'analisi nel dominio della frequenza nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "",
    "text": "Prima di approfondire l’applicazione del criterio di stabilità di Nyquist nei sistemi di controllo, è essenziale rivisitare il concetto fondamentale del criterio. Il criterio di stabilità di Nyquist è un metodo grafico utilizzato nell’ingegneria di controllo per valutare la stabilità di un sistema a circuito chiuso.\n\n\nIl criterio di Nyquist ruota attorno ad un contorno specifico nel piano complesso, noto come contorno di Nyquist. Nel piano s (dominio di Laplace), questo contorno comprende l’intero semipiano destro, compreso l’asse immaginario.\n\nContorno Nyquist: il contorno è rappresentato matematicamente come un semicerchio con un raggio infinito nel semipiano destro, che si estende da \\(+j\\infty\\) a \\(-j\\infty\\).\nRappresentazione di \\(s\\): Qualsiasi punto su questo semicerchio è rappresentato come \\(s = R e^(j\\theta)\\), dove \\(R\\rightarrow \\infty\\) e \\(\\theta\\) varia da +90° a -90°.\n\n\n\n\n\n\n\n\n\n\n\nQuando applichiamo il criterio di Nyquist, ci concentriamo su come questo contorno si mappa nel piano \\(G(s)H(s)\\), dove \\(G(s)H(s)\\) rappresenta la funzione di trasferimento ad anello aperto del sistema.\n\n\n\nRealizzabilità: \\(G(s)H(s)\\) è una funzione di trasferimento fisicamente realizzabile.\n\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\n\nOrdine dei polinomi: Generalmente, l’ordine del polinomio del numeratore \\(N(s)\\) è inferiore o uguale all’ordine del polinomio del denominatore \\(\\Delta(s)\\).\n\n\n\n\nPremesso che il contorno di Nyquist può essere pensato composto da due parti principali:\n\nL’asse immaginario, cioè la linea \\(j\\omega\\), con \\(\\omega \\in [-\\infty, +\\infty]\\)\nIl resto del contorno, cioè la parte che inizia a \\(+\\infty\\) sull’asse immaginario, fa tutto il giro per arrivare a \\(+\\infty\\) sull’asse reale e poi ritorna a \\(-\\infty\\) sull’asse immaginario\n\nDiventa particolarmente importante comprendere il comportamento della mappatura quando \\(R\\rightarrow \\infty\\).\n\nRaggio infinito: quando \\(R\\rightarrow \\infty\\), l’intero semicerchio nel piano s viene mappato su un singolo punto nel piano \\(G(s)H(s)\\).\nCondizione: Se l’ordine di \\(N(s)\\) è inferiore a \\(\\Delta(s)\\), questo punto è l’origine. Se sono uguali, viene mappato su un punto costante sull’asse reale.\n\n\n\n\n\nApprofondiamo ora i dettagli della funzione di trasferimento ad anello aperto $ G(s)H(s) $ e il suo comportamento, soprattutto nei punti tendenti all’infinito nel piano s.\nConsideriamo la funzione di trasferimento ad anello aperto espressa come:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nQui, $ N(s) $ e $ (s) $ sono rispettivamente i polinomi del numeratore e del denominatore, con l’ordine di $ N(s) $ (indicato come $ m $) inferiore all’ordine di $ (s)$. Lo denotiamo come $ [N(s)] = m &lt; [(s)] $. Per la nostra analisi, esaminiamo i punti sul contorno di Nyquist, rappresentati come $ s = R e^{j} $, dove $ R $.\nQuando esploriamo il comportamento di $ G(s)H(s) $ nel piano W, possiamo scomporlo in due componenti: fase e guadagno.\n\n\nLa fase di $ G(s)H(s) $ nel piano W può essere determinata dai contributi angolari dei suoi zeri e poli:\n\\[\n\\angle G(s)H(s) = \\sum \\angle \\text{zeri} - \\sum \\angle \\text{poli}\n\\]\nQuesto angolo di fase è la somma degli angoli di tutti gli zeri meno la somma degli angoli di tutti i poli di $ G(s)H(s) $.\n\n\n\nL’entità del guadagno di $ G(s)H(s) $ nel piano W è data da:\n\\[\n| G(s)H(s) | = \\frac{K \\prod | \\text{zeri} |}{\\prod |\\text{poli}|}\n\\]\nQui, $ K $ rappresenta qualsiasi moltiplicatore costante nella funzione di trasferimento. Il guadagno viene calcolato come il prodotto delle magnitudini degli zeri diviso per il prodotto delle magnitudini dei poli.\n\n\n\nPer i punti sul contorno di Nyquist dove $ R $, il guadagno di $ G(s)H(s) $ si avvicina a zero. Ciò si verifica perché il numero di poli supera il numero di zeri, portando alla divisione per un valore infinitamente grande all’aumentare di $ R $.\nDi conseguenza, qualsiasi punto sul contorno di Nyquist, poiché $ R $ tende all’infinito, corrisponde all’origine nel piano W. Sebbene l’angolo di fase di $ G(s)H(s) $ vari mentre il punto $ s $ si muove lungo il contorno, non influenza in modo significativo la posizione della mappatura nel piano W, poiché il guadagno si avvicina a zero e il punto costantemente mappe all’origine.\n\n\n\n\nQuando gli ordini dei polinomi del numeratore e del denominatore in una funzione di trasferimento ad anello aperto $ G(s)H(s) $ sono uguali, indicati come $ m = n $, il comportamento della funzione di trasferimento, in particolare nei punti che si avvicinano all’infinito su il contorno di Nyquist, è distinto dal caso in cui $ m &lt; n $.\nConsideriamo la funzione di trasferimento ad anello aperto:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nIn questo scenario, dove $ m = n $, l’ordine del polinomio al numeratore $ N(s) $ è uguale all’ordine del polinomio al denominatore $ (s) $. Ciò implica che $ G(s)H(s) $ ha un numero uguale di zeri e poli in termini di ordine.\n\n\n\n\nGuadagno all’infinito: Quando $ s = R e^{j} $ e $ R $, a differenza del caso $ m &lt; n $, il guadagno $ |G(s)H (s)| $ non tende a zero. Questo perché gli infiniti nel numeratore e nel denominatore si annullano effettivamente, lasciando un valore finito.\nAngolo di fase: L’angolo di fase $ G(s)H(s) $ è determinato dai contributi angolari degli zeri e dei poli, simile al caso $ m &lt; n $. Tuttavia, poiché esiste un numero uguale di zeri e poli (in termini di ordine), i loro contributi angolari potrebbero bilanciarsi in modo diverso.\n\n\n\n\n\nMappatura all’infinito: per i punti all’infinito sul contorno di Nyquist, $ G(s)H(s) $ mappa su un punto costante sul piano W. La posizione esatta di questo punto dipende dai valori specifici e dalla distribuzione degli zeri e dei poli della funzione di trasferimento.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#revisione-del-criterio-di-stabilità-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#revisione-del-criterio-di-stabilità-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "",
    "text": "Prima di approfondire l’applicazione del criterio di stabilità di Nyquist nei sistemi di controllo, è essenziale rivisitare il concetto fondamentale del criterio. Il criterio di stabilità di Nyquist è un metodo grafico utilizzato nell’ingegneria di controllo per valutare la stabilità di un sistema a circuito chiuso.\n\n\nIl criterio di Nyquist ruota attorno ad un contorno specifico nel piano complesso, noto come contorno di Nyquist. Nel piano s (dominio di Laplace), questo contorno comprende l’intero semipiano destro, compreso l’asse immaginario.\n\nContorno Nyquist: il contorno è rappresentato matematicamente come un semicerchio con un raggio infinito nel semipiano destro, che si estende da \\(+j\\infty\\) a \\(-j\\infty\\).\nRappresentazione di \\(s\\): Qualsiasi punto su questo semicerchio è rappresentato come \\(s = R e^(j\\theta)\\), dove \\(R\\rightarrow \\infty\\) e \\(\\theta\\) varia da +90° a -90°.\n\n\n\n\n\n\n\n\n\n\n\nQuando applichiamo il criterio di Nyquist, ci concentriamo su come questo contorno si mappa nel piano \\(G(s)H(s)\\), dove \\(G(s)H(s)\\) rappresenta la funzione di trasferimento ad anello aperto del sistema.\n\n\n\nRealizzabilità: \\(G(s)H(s)\\) è una funzione di trasferimento fisicamente realizzabile.\n\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\n\nOrdine dei polinomi: Generalmente, l’ordine del polinomio del numeratore \\(N(s)\\) è inferiore o uguale all’ordine del polinomio del denominatore \\(\\Delta(s)\\).\n\n\n\n\nPremesso che il contorno di Nyquist può essere pensato composto da due parti principali:\n\nL’asse immaginario, cioè la linea \\(j\\omega\\), con \\(\\omega \\in [-\\infty, +\\infty]\\)\nIl resto del contorno, cioè la parte che inizia a \\(+\\infty\\) sull’asse immaginario, fa tutto il giro per arrivare a \\(+\\infty\\) sull’asse reale e poi ritorna a \\(-\\infty\\) sull’asse immaginario\n\nDiventa particolarmente importante comprendere il comportamento della mappatura quando \\(R\\rightarrow \\infty\\).\n\nRaggio infinito: quando \\(R\\rightarrow \\infty\\), l’intero semicerchio nel piano s viene mappato su un singolo punto nel piano \\(G(s)H(s)\\).\nCondizione: Se l’ordine di \\(N(s)\\) è inferiore a \\(\\Delta(s)\\), questo punto è l’origine. Se sono uguali, viene mappato su un punto costante sull’asse reale.\n\n\n\n\n\nApprofondiamo ora i dettagli della funzione di trasferimento ad anello aperto $ G(s)H(s) $ e il suo comportamento, soprattutto nei punti tendenti all’infinito nel piano s.\nConsideriamo la funzione di trasferimento ad anello aperto espressa come:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nQui, $ N(s) $ e $ (s) $ sono rispettivamente i polinomi del numeratore e del denominatore, con l’ordine di $ N(s) $ (indicato come $ m $) inferiore all’ordine di $ (s)$. Lo denotiamo come $ [N(s)] = m &lt; [(s)] $. Per la nostra analisi, esaminiamo i punti sul contorno di Nyquist, rappresentati come $ s = R e^{j} $, dove $ R $.\nQuando esploriamo il comportamento di $ G(s)H(s) $ nel piano W, possiamo scomporlo in due componenti: fase e guadagno.\n\n\nLa fase di $ G(s)H(s) $ nel piano W può essere determinata dai contributi angolari dei suoi zeri e poli:\n\\[\n\\angle G(s)H(s) = \\sum \\angle \\text{zeri} - \\sum \\angle \\text{poli}\n\\]\nQuesto angolo di fase è la somma degli angoli di tutti gli zeri meno la somma degli angoli di tutti i poli di $ G(s)H(s) $.\n\n\n\nL’entità del guadagno di $ G(s)H(s) $ nel piano W è data da:\n\\[\n| G(s)H(s) | = \\frac{K \\prod | \\text{zeri} |}{\\prod |\\text{poli}|}\n\\]\nQui, $ K $ rappresenta qualsiasi moltiplicatore costante nella funzione di trasferimento. Il guadagno viene calcolato come il prodotto delle magnitudini degli zeri diviso per il prodotto delle magnitudini dei poli.\n\n\n\nPer i punti sul contorno di Nyquist dove $ R $, il guadagno di $ G(s)H(s) $ si avvicina a zero. Ciò si verifica perché il numero di poli supera il numero di zeri, portando alla divisione per un valore infinitamente grande all’aumentare di $ R $.\nDi conseguenza, qualsiasi punto sul contorno di Nyquist, poiché $ R $ tende all’infinito, corrisponde all’origine nel piano W. Sebbene l’angolo di fase di $ G(s)H(s) $ vari mentre il punto $ s $ si muove lungo il contorno, non influenza in modo significativo la posizione della mappatura nel piano W, poiché il guadagno si avvicina a zero e il punto costantemente mappe all’origine.\n\n\n\n\nQuando gli ordini dei polinomi del numeratore e del denominatore in una funzione di trasferimento ad anello aperto $ G(s)H(s) $ sono uguali, indicati come $ m = n $, il comportamento della funzione di trasferimento, in particolare nei punti che si avvicinano all’infinito su il contorno di Nyquist, è distinto dal caso in cui $ m &lt; n $.\nConsideriamo la funzione di trasferimento ad anello aperto:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nIn questo scenario, dove $ m = n $, l’ordine del polinomio al numeratore $ N(s) $ è uguale all’ordine del polinomio al denominatore $ (s) $. Ciò implica che $ G(s)H(s) $ ha un numero uguale di zeri e poli in termini di ordine.\n\n\n\n\nGuadagno all’infinito: Quando $ s = R e^{j} $ e $ R $, a differenza del caso $ m &lt; n $, il guadagno $ |G(s)H (s)| $ non tende a zero. Questo perché gli infiniti nel numeratore e nel denominatore si annullano effettivamente, lasciando un valore finito.\nAngolo di fase: L’angolo di fase $ G(s)H(s) $ è determinato dai contributi angolari degli zeri e dei poli, simile al caso $ m &lt; n $. Tuttavia, poiché esiste un numero uguale di zeri e poli (in termini di ordine), i loro contributi angolari potrebbero bilanciarsi in modo diverso.\n\n\n\n\n\nMappatura all’infinito: per i punti all’infinito sul contorno di Nyquist, $ G(s)H(s) $ mappa su un punto costante sul piano W. La posizione esatta di questo punto dipende dai valori specifici e dalla distribuzione degli zeri e dei poli della funzione di trasferimento.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#attraversando-il-contorno-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#attraversando-il-contorno-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Attraversando il contorno di Nyquist",
    "text": "Attraversando il contorno di Nyquist\nChiariamo il concetto di mappatura del contorno di Nyquist nei sistemi di controllo. Questo processo implica tracciare un percorso specifico nel piano complesso, partendo da un certo punto e procedendo attraverso luoghi chiave.\nMentre esegui i passaggi seguenti, utilizza il diagramma seguente come riferimento.\n\nPunto iniziale: la mappatura inizia all’origine del piano s, dove \\(\\omega = 0\\). Questo è indicato come \\(\\omega = 0^+\\).\nPercorso lungo l’asse immaginario: Dall’origine, il percorso si estende lungo l’asse immaginario del piano s. Ciò significa che lasciamo \\(s = j\\omega\\) e \\(\\omega\\) aumenta da 0 a infinito. Questo segmento è spesso descritto come \\(\\omega = 0^+\\) to \\(\\omega = +\\infty\\).\nSemicerchio infinito: il contorno passa quindi attraverso un semicerchio infinito nel semipiano destro. Questo è concettualizzato come \\(\\omega\\) che passa da \\(+\\infty\\) a \\(-\\infty\\). Durante questa transizione, il raggio del semicerchio (\\(R\\)) tende all’infinito.\nCompletamento del contorno: Infine, il percorso ritorna all’origine lungo l’asse immaginario negativo. Questo è descritto come \\(\\omega\\) che si sposta da \\(-\\infty\\) a \\(0\\), indicato come \\(\\omega = 0^-\\).\nSimmetria e semplificazione: il segmento da \\(\\omega = 0\\) a \\(\\omega = +\\infty\\) è un’immagine speculare del segmento da \\(\\omega = -\\infty\\) a $= 0 $. A causa di questa simmetria, il grafico di Nyquist viene spesso semplificato per considerare solo la prima metà del contorno (da \\(\\omega = 0^+\\) a \\(\\omega = +\\infty\\)). La seconda metà è semplicemente una riflessione sull’asse reale.\nImportanza nell’analisi della stabilità: l’intero contorno di Nyquist comprende la metà destra del piano s. Il criterio di Nyquist utilizza questo contorno per determinare se ci sono poli a circuito chiuso (zeri di \\(1 + G(s)H(s)\\)) nel semipiano destro, che indicano l’instabilità del sistema.\nTecnica in pratica: Sebbene questa spiegazione delinei l’approccio teorico, nella mappatura pratica, l’attenzione è spesso sul segmento dell’asse immaginario e sul comportamento all’infinito. La simmetria del diagramma semplifica l’analisi, rendendola più gestibile e approfondita.\n\nIn sintesi, la mappatura effettiva del contorno di Nyquist implica tracciare un percorso dall’origine lungo l’asse immaginario fino all’infinito, attorno a un semicerchio infinito, e ritorno all’origine. Questa mappatura è cruciale nell’applicazione del criterio di Nyquist per valutare la stabilità dei sistemi di controllo.\n\n\n\n\n\n\n\nFigura: Nyquist Countour e Nyquist Plot. In questo caso il sistema in CL è stabile anche se non conosciamo P.\n\nAnalisi del criterio di stabilità di Nyquist attraverso la mappatura di G(s)H(s) sul contorno di Nyquist\n\nMappatura della funzione di trasferimento: Il compito da svolgere è mappare $ G(s)H(s) $ mentre la variabile complessa $ s $ attraversa il contorno di Nyquist. Questo viaggio lungo il contorno creerà un diagramma nel piano \\(G(s)H(s)\\).\nCreazione del grafico di Nyquist: Mentre $ s $ si muove lungo il contorno di Nyquist, osserviamo come cambia il valore di $ G(s)H(s) $. Il grafico risultante nel piano \\(G(s)H(s)\\) è il nostro obiettivo principale.\nNatura qualitativa del terreno: Sebbene gli esatti valori quantitativi del terreno non siano la nostra principale preoccupazione, la sua forma qualitativa è cruciale. L’asse reale e l’asse immaginario del piano \\(G(s)H(s)\\) sono punti di riferimento importanti per la nostra analisi.\nPunto cruciale nel diagramma: Un elemento chiave nel diagramma di Nyquist è il punto \\(-1 + j0\\). Questo punto è fondamentale perché abbiamo spostato la nostra prospettiva da \\(1 + G(s)H(s)\\) a solo \\(G(s)H(s)\\).\nConteggio degli accerchiamenti: L’essenza del criterio sta nel contare il numero di accerchiamenti in senso antiorario del punto \\(-1 + j0\\) mediante il diagramma di Nyquist. Questo conteggio è indicato con \\(N\\).\nIl criterio di stabilità di Nyquist: il numero totale di accerchiamenti in senso antiorario, \\(N\\), è correlato a due variabili chiave: \\(P\\) e \\(Z\\). Qui, \\(N = P - Z\\), dove \\(P\\) rappresenta il numero di poli ad anello aperto all’interno della regione di Nyquist e \\(Z\\) corrisponde al numero di zeri, che equivale al numero di poli ad anello chiuso nella regione sistema.\n\nIn sintesi, il criterio di stabilità di Nyquist ruota attorno alla mappatura di $ G(s)H(s) $ lungo il contorno di Nyquist e all’analisi del grafico risultante, concentrandosi in particolare sul numero di accerchiamenti in senso antiorario attorno al punto critico \\(-1 + j0\\) . Questa analisi è fondamentale per determinare la stabilità del sistema di controllo in esame.\n\n\nEsempi",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempi-pratici",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempi-pratici",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Esempi pratici",
    "text": "Esempi pratici\nPer rafforzare questi concetti analizziamo alcuni esempi:\n\nEsempio 1: sistema in feedback con funzione di trasferimento ad anello aperto\nConsidera un sistema in feedback con\n\\[\nG(s)H(s) = \\frac{1}{(T_1 s + 1)(T_2 s + 1)}\n\\]\nNel campo dell’analisi nel dominio della frequenza, la forma della costante di tempo di una funzione di trasferimento è tipicamente più pratica e facile da usare.\nQuesto approccio contrasta con la Forma Zero-Pole utilizzata nel metodo del luogo delle radici. Per illustrare, si consideri la seguente forma a polo zero della funzione di trasferimento ad anello aperto ( G(s)H(s) ):\n\\[\nG(s)H(s) = \\frac{1}{(s + p_1)(s + p_2)}\n\\]\nIn questa forma, la funzione di trasferimento è esplicitamente espressa in termini di poli (e zeri, se presenti). Ciò è particolarmente utile per il metodo del luogo delle radici, dove i punti di partenza (poli e zeri) sono fondamentali per costruire il luogo delle radici.\nTuttavia, per l’analisi della risposta in frequenza, la forma della costante di tempo offre una comprensione più diretta e intuitiva del comportamento del sistema. Questa forma semplifica il processo di calcolo della risposta in ampiezza e fase del sistema, che sono cruciali nei metodi nel dominio della frequenza.\nLa conversione tra queste due forme, da Zero-Pole a Time Constant o viceversa, è semplice. Implica la riorganizzazione della funzione di trasferimento nel formato desiderato, garantendo che le caratteristiche essenziali del sistema, come i poli, gli zeri e il guadagno, rimangano coerenti in entrambe le rappresentazioni.\nQuando ci viene presentata una funzione di trasferimento in forma di costante di tempo, la trasformiamo nel suo equivalente sinusoidale ponendo $ s = j$:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)}\n\\]\nQuesta forma della funzione di trasferimento caratterizza la risposta del sistema agli ingressi sinusoidali.\nMotivazione alla base della funzione di trasferimento sinusoidale L’obiettivo principale è mappare l’intero contorno di Nyquist. Un’osservazione fondamentale è che il segmento più importante di questo contorno è la metà positiva dell’asse immaginario. Una volta mappato questo segmento, il resto della mappatura diventa relativamente semplice, poiché questo segmento riflette la risposta in frequenza del sistema ad anello aperto.\n\nCollegamento della risposta in frequenza con Nyquist Contour\n\nRisposta in frequenza: definita come l’uscita del sistema quando esposto a ingressi sinusoidali, con frequenze che vanno da $ = 0 $ a $ = $.\nMappatura sul contorno di Nyquist: mappare la metà positiva dell’asse immaginario nel piano s equivale effettivamente ad analizzare la risposta in frequenza del sistema a circuito aperto.\n\nIn questo contesto, la funzione di trasferimento sinusoidale $ G(j)H(j) $ subisce una trasformazione corrispondente alla sostituzione $ s = j$:\n\\[\nG(j\\omega)H(j\\omega) \\xrightarrow{s = j\\omega} G(s)H(s)\n\\]\nLa grandezza e la fase di questa funzione sono rappresentate da $ |G(j)H(j)| $ e $ G(j)H(j) $, rispettivamente.\n\nAmpiezza $ |G(j)H(j)| $: quantifica il rapporto di ampiezza del sistema ad anello aperto in risposta a un ingresso sinusoidale.\nAngolo di fase $ G(j)H(j) $: indica la variazione dell’angolo di fase dell’ingresso sinusoidale elaborato dal sistema ad anello aperto.\n\nConoscere questi due parametri per ogni data frequenza ci permette di comprendere l’uscita del sistema quando incontra un ingresso sinusoidale.\nQuesta analisi rivela che $ G(j)H(j) $ rappresenta essenzialmente la risposta in frequenza del sistema a circuito aperto. Inoltre, anche se la forma analitica di $ G(s)H(s) $ non è disponibile, è possibile determinare sperimentalmente queste grandezze e angoli di fase, consentendo l’applicazione del criterio di Nyquist utilizzando dati sperimentali.\nDomanda pop-up: Perché la mappatura della metà positiva dell’asse immaginario è importante nell’analisi di Nyquist?\nRisposta: questa mappatura corrisponde alla risposta in frequenza del sistema ad anello aperto, fornendo informazioni critiche sulle caratteristiche di stabilità del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#come-disegnare-qualitativamente-il-diagramma-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#come-disegnare-qualitativamente-il-diagramma-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Come disegnare qualitativamente il diagramma di Nyquist",
    "text": "Come disegnare qualitativamente il diagramma di Nyquist\nLe seguenti linee guida, basate sull’esperienza pratica, delineano quattro punti critici necessari per disegnare qualitativamente il diagramma di Nyquist. Questi punti sono particolarmente rilevanti per valutare la stabilità dei sistemi di controllo.\n\nIndividuazione di quattro punti chiave\n\nGrandezza e angolo a $ = 0 $\nGrandezza e angolo a $ = $\nIntersezione con l’asse immaginario\nIntersezione con l’asse reale\n\nQuesti punti forniscono una visione completa della risposta del sistema e sono generalmente sufficienti per uno schizzo approssimativo del diagramma di Nyquist, soprattutto quando la preoccupazione principale è la stabilità del sistema.\n\n\nEsame dettagliato di ciascun punto per il nostro esempio\n\n1. Grandezza e angolo a $ = 0 $\n\nPer la data funzione di trasferimento sinusoidale\n\n\\[ G(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} \\]\na $ = 0 $, la grandezza è 1 e l’angolo è 0 gradi.\nQuesto ci dà il nostro primo punto critico sul diagramma di Nyquist:\n\\[\n1\\angle{0^\\circ}\\;\\;\\; \\omega=0\n\\]\n\n\n2. Grandezza e angolo a $ = $\n\nQuando $ $ si avvicina all’infinito, la grandezza si avvicina a zero e l’angolo tende a -180 gradi. Questo comportamento è cruciale per comprendere come si comporta il diagramma alle alte frequenze.\n\nPoiché $ = $ possiamo approssimare:\n\\[ G(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} = \\frac{1}{j^2\\omega ^2T_1T_2}\\]\nAdesso calcoliamo:\n\\[\n\\lim_{\\omega = \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2}\n\\]\nottenere:\n\\[\n0\\angle{-180^\\circ}\\;\\;\\; \\omega=\\infty\n\\]\n\n\n\n\nBARRA LATERALE - Calcolo del limite\nPer capire perché\n\\[\n\\lim_{\\omega \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2} = 0\\angle{-180^\\circ}\n\\]\ndobbiamo analizzare sia la grandezza che l’angolo di fase dell’espressione complessa quando \\(\\omega\\) si avvicina all’infinito.\n\nAnalisi della magnitudo\n\nSemplificazione dell’espressione: l’espressione data è \\(\\frac{1}{j^2\\omega^2T_1T_2}\\). Innanzitutto, semplifichiamo \\(j^2\\). Poiché \\(j\\) è l’unità immaginaria, \\(j^2 = -1\\). Pertanto, l’espressione diventa \\(\\frac{1}{-1\\cdot\\omega^2T_1T_2}\\) o \\(-\\frac{1}{\\omega^2T_1T_2}\\).\nLa grandezza quando \\(\\omega\\) si avvicina all’infinito: Quando \\(\\omega\\) diventa molto grande, anche il denominatore \\(\\omega^2T_1T_2\\) diventa molto grande. La grandezza di una frazione con un denominatore molto grande si avvicina allo zero. Quindi \\(\\lim_{\\omega \\rightarrow \\infty} \\left| -\\frac{1}{\\omega^2T_1T_2} \\right| = 0\\).\n\n\n\nAnalisi dell’angolo di fase\n\nFase dell’espressione originale: nell’espressione originale \\(\\frac{1}{j^2\\omega^2T_1T_2}\\), il termine \\(j^2\\) contribuisce alla fase. Poiché \\(j^2 = -1\\), può essere visto come avente una fase di \\(180^\\circ\\) (o \\(-180^\\circ\\), poiché uno sfasamento di \\(180^\\circ\\) equivale a \\(-180 ^\\circ\\)).\nFase all’infinito: la fase di un numero complesso non è influenzata dalla grandezza del numero. Anche se la magnitudo va a zero, l’angolo di fase contribuito da \\(j^2\\) rimane a \\(-180^\\circ\\).\n\nCombinando le analisi di magnitudo e fase:\n\nLa grandezza di \\(\\frac{1}{j^2\\omega^2T_1T_2}\\) si avvicina a zero quando \\(\\omega\\) si avvicina all’infinito.\nL’angolo di fase rimane a \\(-180^\\circ\\) a causa del contributo di \\(j^2\\).\n\nPertanto, concludiamo che:\n\\[\n\\lim_{\\omega \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2} = 0\\angle{-180^\\circ}\n\\]\nCiò indica che a frequenze molto elevate (\\(\\omega \\rightarrow \\infty\\)), la risposta di un sistema descritto da questa funzione di trasferimento diminuisce fino a zero in grandezza, con uno sfasamento di \\(-180^\\circ\\).\nFINE DELLA BARRA LATERALE\n\n\n\n\nIntersezioni con assi reali e immaginari\nPer trovare le intersezioni della funzione di trasferimento con gli assi reale e immaginario, possiamo esprimere la funzione di trasferimento nella forma di $ x + jy $:\n\\[\nG(s)H(s) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} = x + jy\n\\]\ne quindi analizzarlo per condizioni specifiche:\n\nIntersezione con l’asse reale: imposta la parte immaginaria, $ y $, su zero e risolvi $ $ per trovare dove la funzione di trasferimento interseca l’asse reale.\nIntersezione con l’asse immaginario: imposta la parte reale, $ x $, su zero per determinare i punti di intersezione con l’asse immaginario.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#costruzione-del-diagramma-polare-della-risposta-in-frequenza",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#costruzione-del-diagramma-polare-della-risposta-in-frequenza",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Costruzione del diagramma polare della risposta in frequenza",
    "text": "Costruzione del diagramma polare della risposta in frequenza\n\nIl diagramma polare\nPrima di immergerci nel diagramma di Nyquist, creiamo innanzitutto un diagramma polare della risposta in frequenza del sistema a circuito aperto. Questo grafico inizia da $ = 0 $ e si estende fino a $ = $.\nUsiamo i punti che abbiamo calcolato prima:\n\n\n\n\\(\\omega = 0\\)\n\\(1\\angle{0^\\circ}\\)\n\n\n\\(\\omega = \\infty\\)\n\\(0\\angle{-180^\\circ}\\)\n\n\n\ne disegniamo il diagramma:\n\n\n\n\n\n\n\n\n\n\n\nPunti chiave dell’analisi\n\nOmega = 0: A $ = 0 $, la grandezza è 1 e l’angolo è 0 gradi.\nOmega = Infinito: Quando $ $ si avvicina all’infinito, la grandezza tende verso zero e l’angolo si avvicina a -180 gradi.\n\nInfine dobbiamo capire come mappare il punto:\n\\[\ns = Re^{j\\theta}\n\\]\nPer questo considereremo la funzione originale \\(G(s)H(s)\\). Abbiamo utilizzato la funzione di trasferimento sinusoidale solo per mappare l’asse immaginario.\n\\[\nG(s)H(s) = \\frac{1}{(T_1 s + 1)(T_2 s + 1)}\n\\]\nIn questo caso:\n\\[\nG(s)H(s)\\Big|_{s = Re^{j\\theta}} = \\frac{1}{(T_1 Re^{j\\theta} + 1)(T_2 Re^{j\\theta } + 1)}\n\\]\nQuando \\(R \\rightarrow \\infty\\), la funzione diventa:\n\\[\n\\frac{1}{T_1 T_2 R^2e^{j2\\theta}}\n\\]\ndove \\(\\theta\\) varia da \\(+90^\\circ\\) a \\(-90^\\circ\\) passando per \\(0^\\circ\\).\n\nQuando \\(R \\rightarrow \\infty\\), la grandezza tende a zero.\nL’angolo è \\(e^{-j2\\theta}\\): l’angolo varia quindi da \\(-180^\\circ\\) attraverso \\(0^\\circ\\) fino a \\(180^\\circ\\).\n\nPossiamo aggiornare il diagramma polare per riflettere questo:\n\n\n\n\n\n\n\nIn questo schizzo, il modo più efficace per dimostrare il concetto è considerare come si comporta il diagramma quando $ $ si avvicina all’infinito. Interpretiamolo come segue:\n\nAt $ = +$: Questo punto del grafico corrisponde a $ $ che tende all’infinito positivo.\nAt ( = -): Allo stesso modo, un altro punto sul grafico rappresenta $ $ che si avvicina all’infinito negativo.\n\nIn questo scenario il contorno di cui stiamo discutendo tende verso l’origine del piano complesso.\n\n\nComprendere l’approccio del contorno all’origine\n\nAvvicinamento e allontanamento: il contorno si avvicina asintoticamente all’origine con un angolo di -180 gradi e si allontana asintoticamente dall’origine con un angolo di +180 gradi.\nSignificato di $ $ in $ R e^{j} $: L’angolo $ $ gioca un ruolo in questa mappatura. Al variare di $ $, viene illustrato come il contorno entra ed esce dalle vicinanze dell’origine. Quando entra, il contorno lo fa in modo asintotico a -180 gradi, mentre quando esce si allontana asintoticamente a +180 gradi.\nInterpretazione della mappatura: questo comportamento riflette la mappatura $ s = R e^{j} $ sul grafico di Nyquist. L’angolo $ $ influenza in modo significativo il modo in cui il grafico si avvolge attorno all’origine, descrivendo la risposta del sistema mentre la frequenza $ $ si muove attraverso un ampio intervallo.\n\n\n\n\nSemplificazione del diagramma di Nyquist\n\nFocus sui punti critici: per l’analisi della stabilità, il nostro interesse primario si trova in prossimità del punto \\(-1 + j0\\). La forma del grafico attorno all’origine, sebbene matematicamente intrigante, potrebbe non avere un impatto significativo sull’analisi della stabilità.\nApproccio pratico: in molti scenari, l’intera mappatura del contorno attorno all’origine può essere semplificata. Possiamo considerare l’origine stessa come la mappa totale di un particolare contorno, purché siamo lontani dal punto critico \\(-1 + j0\\).\n\n\n\nAnalizzare l’approccio all’origine\n\nComportamento asintotico: l’avvicinamento del diagramma all’origine è importante. È importante se si avvicina asintoticamente a \\(-180^\\circ\\) o \\(+180^\\circ\\), o in altro modo, soprattutto perché potrebbe comportare l’accerchiamento del punto \\(-1\\).\n\n\n\n\n\n\n\n\n\nDeterminazione dell’asintoto: sebbene il contorno dettagliato attorno all’origine possa non essere essenziale per la stabilità, la direzione in cui il grafico si avvicina all’origine può essere davvero importante. Questa direzione, o asintoto, indica potenziali accerchiamenti del punto critico.\n\nDomanda pop-up: Perché il diagramma polare è un passaggio importante prima di creare il diagramma di Nyquist?\nRisposta: il diagramma polare ci fornisce una rappresentazione visiva della risposta in frequenza del sistema, che è un elemento fondamentale per comprendere e costruire il diagramma di Nyquist.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#transizione-alla-costruzione-pratica-del-diagramma-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#transizione-alla-costruzione-pratica-del-diagramma-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Transizione alla costruzione pratica del diagramma di Nyquist",
    "text": "Transizione alla costruzione pratica del diagramma di Nyquist\nDopo aver creato il diagramma polare, che illustra la risposta in frequenza del sistema, il passo successivo è costruire il diagramma di Nyquist. Ciò si ottiene riflettendo il diagramma polare lungo l’asse reale. Il diagramma di Nyquist così formato rappresenta la mappatura dell’intero contorno di Nyquist.\nÈ importante notare che nel contesto della risposta in frequenza, il concetto di frequenze negative (\\(\\omega &lt; 0\\)) doesn’t have a direct physical interpretation. Frequencies are inherently positive values. The consideration of negative \\(\\omega\\) values in our analysis is a mathematical tool, allowing us to create a mirror image of the plot for completeness.\n\nVisualization of the Nyquist Plot\nImagine the polar plot as a graphical representation of the system’s response to varying positive frequencies. To extend this plot to the Nyquist plot, we simply mirror the existing plot across the real axis. This mirrored portion represents what would be the system’s response if negative frequencies were physically meaningful.\n\n\n\n\n\n\n\nLa figura sopra mostra il diagramma polare e la sua immagine speculare per formare il diagramma di Nyquist completo dell’esempio che stiamo considerando.\n\nComprendere la risposta in frequenza\nIl nucleo della nostra analisi dipende dalla comprensione della risposta in frequenza del sistema. Una volta che abbiamo un quadro chiaro di come il sistema risponde alle diverse frequenze (come mostrato nel diagramma polare), estendere questa comprensione al diagramma di Nyquist diventa semplice. Il diagramma di Nyquist, a sua volta, è un potente strumento per rispondere alle domande relative alla stabilità del sistema.\nDomanda pop-up: Perché consideriamo le frequenze negative nel diagramma di Nyquist quando non hanno alcun significato fisico?\nRisposta: Considerare le frequenze negative è un metodo matematico per garantire la completezza del diagramma di Nyquist. Aiuta a visualizzare l’intera risposta del sistema, inclusa la simmetria attorno all’asse reale, che è cruciale per l’analisi della stabilità.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempio-2---contorni-passanti-per-singolarità",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempio-2---contorni-passanti-per-singolarità",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Esempio 2 - Contorni passanti per singolarità",
    "text": "Esempio 2 - Contorni passanti per singolarità\n\\[\nG(s) = \\frac{1}{s(\\tau s + 1)}\n\\]\nInnanzitutto, il diagramma polare può essere ottenuto utilizzando la funzione di trasferimento sinusoidale:\n\\[\nG(j\\omega) = \\frac{1}{j\\omega(\\tau j\\omega + 1)}\n\\]\n\n\n\n\\(\\omega = 0\\)\n\\(\\infty\\angle{-90^\\circ}\\)\n\n\n\\(\\omega = \\infty\\)\n\\(0\\angle{-180^\\circ}\\)\n\n\n\nTorneremo tra poco sulla fase \\(\\omega = 0\\).\nPer calcolare le Intersezioni con asse reale e immaginario convertiamo \\(G(j\\omega)\\) nella sua rappresentazione \\(x+jy\\):\n\\[\nG(j\\omega) = x+jy = \\frac{-T}{1+\\omega^2T^2} - j\\frac{1}{\\omega(1+\\omega^2T^2)}\n\\]\nDa questa equazione è chiaro che non ci sono intersezioni con l’asse reale o immaginario. Se c’è un’intersezione, è per \\(\\omega=\\infty\\) che abbiamo già calcolato.\n\nPer \\(\\omega=0\\) \\(\\rightarrow\\) \\(G(j0) = -T -j\\infty\\)\n\nQuesto ci fornisce informazioni aggiuntive. Va all’infinito lungo l’asintoto in \\(-T\\).\nPossiamo disegnarlo:\n\n\n\n\n\n\n\nQuesto grafico mostra anche perché per \\(\\omega = 0\\), \\(\\angle{-90^\\circ}\\). Il comportamento asintotico e la fase mostrano la stessa informazione.\n\n\n\n\n\n\n\nL’unico problema è che abbiamo un polo ad anello aperto nell’origine e la mappatura di quel punto specifico dà un valore infinito.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#affrontare-i-poli-ad-anello-aperto-nella-costruzione-del-diagramma-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#affrontare-i-poli-ad-anello-aperto-nella-costruzione-del-diagramma-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Affrontare i poli ad anello aperto nella costruzione del diagramma di Nyquist",
    "text": "Affrontare i poli ad anello aperto nella costruzione del diagramma di Nyquist\nQuando si ha a che fare con poli ad anello aperto situati all’origine o lungo l’asse immaginario, sono necessarie tecniche speciali per costruire il diagramma di Nyquist, poiché la mappatura diretta di questi poli dà come risultato valori infiniti.\n\nMetodo di rientro per Nyquist Contour\n\nTecnica di rientro del contorno: per aggirare questa sfida, il contorno di Nyquist viene modificato rientrando attorno al palo in questione. Questo viene fatto disegnando un piccolo semicerchio di raggio $ $ adiacente al polo, con $ $ prossimo allo zero.\nMotivazione alla base del rientro: questa regolazione è una misura pratica. È importante notare che avere un polo esattamente nell’origine o sull’asse immaginario rappresenta spesso una situazione idealizzata. Nei sistemi del mondo reale, tali poli sarebbero tipicamente posizionati molto vicini, ma non esattamente sul lato sinistro del piano complesso (LHP).\nImplicazioni per l’analisi di stabilità: questo metodo di indentazione è una strategia matematica per semplificare il grafico di Nyquist pur mantenendo un’accurata analisi di stabilità. L’aspetto essenziale dell’analisi rimane invariato.\n\n\n\nModifica del contorno di Nyquist e analisi della stabilità\n\nDirezione di deviazione: La direzione in cui il contorno viene deviato attorno al palo non costituisce un problema. Tuttavia, è fondamentale notare le implicazioni di questa deviazione sul criterio di stabilità.\nInclusione di pali nel contorno di Nyquist: se la deviazione include un palo ad anello aperto all’interno del contorno di Nyquist, questo deve essere tenuto in considerazione nell’analisi di stabilità. Il polo racchiuso contribuisce al conteggio di $ P $ nel criterio di stabilità di Nyquist, formulato come $ N = P - Z $.\nRisultati coerenti in termini di stabilità: indipendentemente dalla direzione della deviazione, la valutazione risultante della stabilità a circuito chiuso rimane coerente. Ciò che cambia è il valore specifico di $ N $ ottenuto nel criterio di Nyquist, mentre la conclusione complessiva sulla stabilità del sistema rimane la stessa.\n\nApplicando attentamente la tecnica di indentazione e considerando in modo appropriato gli effetti della deviazione sul criterio di stabilità di Nyquist, possiamo garantire un’analisi di stabilità robusta e accurata per sistemi di controllo con poli ad anello aperto sopra o vicino all’asse immaginario.\nVediamo come funziona con il nostro esempio:\nPer comprendere la mappatura del diagramma di Nyquist attorno ad un polo ad anello aperto, in particolare quando il polo è all’origine o sull’asse immaginario, consideriamo il percorso semicircolare definito da:\n\\[\ns = \\epsilon e^{j\\theta}\n\\]\nQui, $ $ varia da $ -90^$ a \\(0^\\circ\\) fino a \\(+90^\\circ\\), tracciando effettivamente un semicerchio nel piano complesso.\nSostituendo questa espressione nella funzione di trasferimento, abbiamo:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon e^{j\\theta}(T \\epsilon e^{j\\theta} + 1)}\n\\]\nDato il piccolo valore di $ $ (vicino allo zero), questa espressione può essere approssimata come:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon e^{j\\theta}}\n\\]\nSemplificando ulteriormente, otteniamo:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon} e^{-j\\theta}\n\\]\nQuesta approssimazione porta a due importanti osservazioni sulla funzione di trasferimento mentre ci muoviamo lungo il semicerchio:\n\nGrandezza: La grandezza della funzione di trasferimento tende all’infinito. Ciò è dovuto alla presenza di $ $ al denominatore, che si avvicina allo zero, facendo tendere l’espressione complessiva verso l’infinito.\nAngolo: l’angolo cambia da $ +90^$ attraverso $ 0^$ fino a $ -90^$. Questo cambiamento di angolo è fondamentale poiché riflette lo spostamento di fase che si verifica mentre ci muoviamo attorno al semicerchio.\n\n\n\n\n\n\n\n\n\n\n\nLa stabilità di un sistema nel contesto del criterio di Nyquist è determinata dal fatto che il suo diagramma di Nyquist circondi il punto critico (-1 + j0). Per il sistema dato:\n\\[\nG(s) = \\frac{K}{s(sT+1)}\n\\]\npossiamo analizzare la sua stabilità in base al comportamento del diagramma di Nyquist.\n\n\nAnalisi di stabilità basata sul diagramma di Nyquist\n\nAssenza di accerchiamento del punto \\(-1\\): Il sistema è considerato stabile se il diagramma di Nyquist non circonda il punto \\(-1\\) sul piano complesso. In questo caso, il diagramma di Nyquist del sistema non si aggira mai intorno al punto \\(-1\\), il che significa che il sistema è stabile.\nEffetto dell’aumento di \\(K\\): all’aumentare del guadagno \\(K\\), aumenta l’entità della risposta del sistema. Tuttavia, questo aumento di grandezza non porta ad un accerchiamento del punto \\(-1\\). Pertanto, anche con valori più elevati di \\(K\\), il grafico di Nyquist rimane lontano dal punto \\(-1\\).\n\n\n\nConclusione sulla stabilità\n\nStabilità per tutti i valori di (K): Dato il comportamento del diagramma di Nyquist per questo sistema, si può concludere che il sistema è stabile per tutti i valori di (K). Questa conclusione si trae dal fatto che non ci sono accerchiamenti del punto critico (-1), indipendentemente dal guadagno (K).\n\nLa stabilità del sistema, analizzata attraverso il criterio di Nyquist, non è quindi influenzata dalle variazioni di \\(K\\), rendendolo stabile in un intervallo di valori di guadagno.",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempio-3",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#esempio-3",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Esempio 3",
    "text": "Esempio 3\n\\[\nG(s)H(s) = \\frac{4s + 1}{s^2(s + 1)(2s + 1)}\n\\]\nAnalizziamo questa funzione per comprenderne le implicazioni per la stabilità del sistema utilizzando il criterio di stabilità di Nyquist.\n\nValutazione dei punti chiave del diagramma di Nyquist\nPer questa funzione di trasferimento, il diagramma di Nyquist viene costruito valutando quanto segue:\n\\[\nG(j\\omega)H(s) = \\frac{4j\\omega + 1}{(j\\omega)^2(j\\omega + 1)(2j\\omega + 1)}\n\\]\n\nA $ = 0 $: la funzione di trasferimento diventa $ ^$. Ciò suggerisce che il diagramma inizia dall’infinito sull’asse reale negativo.\nAt $ = $: Semplificando, troviamo che l’angolo è $ 0 ^$ o equivalentemente $ 0 ^$.\nIntersezioni con l’asse immaginario\n\nConvertire la funzione di trasferimento in una forma vettoriale $ x + jy $ ci permette di trovare intersezioni con l’asse immaginario. Tuttavia, per questa particolare funzione di trasferimento, non ci sono intersezioni tranne che in $ = 0 $ e $ = $.\n\n\nCostruzione del diagramma di Nyquist\n\n\n\n\n\n\n\n\n\n\n\nConsiderazione sull’origine: La presenza di un doppio polo all’origine richiede particolare attenzione. Aggiriamo questo polo utilizzando un semicerchio di raggio infinitesimo $ $.\nMappatura del semiciclo: la mappatura di questo semicerchio, rappresentato come $ e^{j} $, risulta in un grafico che si estende da $ +180^$ a $ -180^ circ$ con raggio infinito.\n\nCome prima, per comprendere la mappatura del diagramma di Nyquist attorno ai due poli ad anello aperto nell’origine, consideriamo il percorso semicircolare definito da:\n\\[\ns = \\epsilon e^{j\\theta}\n\\]\nQui, $ $ varia da $ -90^$ a \\(0^\\circ\\) fino a \\(+90^\\circ\\), tracciando effettivamente un semicerchio nel piano complesso.\nSostituendo questa espressione nella funzione di trasferimento, otteniamo che possiamo approssimare \\(G(s)H(s)\\) come:\n\\[\nG(s)H(s) = \\frac{1}{s^2}\n\\]\nDato il piccolo valore di $ $ (vicino allo zero), questa espressione può essere approssimata come:\n\\[\nG(s)H(s) = \\frac{1}{\\epsilon e^{2j\\theta}}\n\\]\nE semplificando ulteriormente, otteniamo:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon} e^{-j2\\theta}\n\\]\ne l’angolo va da \\(+180^\\circ\\) a \\(-180^\\circ\\), mentre \\(\\theta\\) va da \\(-90^\\circ\\) a \\(90^\\circ\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#analisi-di-stabilità-basata-sul-criterio-di-nyquist",
    "href": "IT_🇮🇹/application_of_nyquist_stability_criterion_it.html#analisi-di-stabilità-basata-sul-criterio-di-nyquist",
    "title": "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo",
    "section": "Analisi di stabilità basata sul criterio di Nyquist",
    "text": "Analisi di stabilità basata sul criterio di Nyquist\n\nImpatto del guadagno del sistema ($ K $): Variazione di $ K $ nel sistema\n\n\\[\nG(s)H(s) = K \\frac{4s + 1}{s^2(s + 1)(2s + 1)}\n\\]\ninfluenza la grandezza del diagramma di Nyquist. Ciò potrebbe portare all’accerchiamento del punto \\(-1\\) e la stabilità del sistema dipende dal valore specifico di \\(K\\).",
    "crumbs": [
      "IT_🇮🇹",
      "Applicazione del criterio di stabilità di Nyquist nei sistemi di controllo"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html",
    "href": "IT_🇮🇹/intro_it.html",
    "title": "Principi di controllo automatico",
    "section": "",
    "text": "Benvenuti al corso sui Principi del Controllo Automatico. In questa serie di quaderni Jupyter interattivi discuteremo i principi fondamentali, i concetti e le terminologie utilizzate nel campo dell’ingegneria dei controlli.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html#introduzione-ai-sistemi-di-controllo",
    "href": "IT_🇮🇹/intro_it.html#introduzione-ai-sistemi-di-controllo",
    "title": "Principi di controllo automatico",
    "section": "Introduzione ai sistemi di controllo",
    "text": "Introduzione ai sistemi di controllo\nL’ingegneria di controllo o l’ingegneria dei sistemi di controllo si occupa della progettazione di sistemi in modo che si comportino nel modo desiderato. Oggi i sistemi di controllo sono parte integrante della nostra vita quotidiana e hanno una vasta gamma di applicazioni.\n\nTerminologia del sistema di controllo\nNelle nostre discussioni iniziali, ci concentreremo sulle terminologie utilizzate nei sistemi di controllo. È fondamentale acquisire familiarità con questi termini per avere una chiara comprensione degli argomenti successivi.\nCominciamo!\n\n\nIl ruolo dei sistemi di controllo nella tecnologia moderna\nI sistemi di controllo svolgono un ruolo chiave nello sviluppo della civiltà e della tecnologia moderne. Gli esempi abbondano nella vita quotidiana:\n\nElettrodomestici: sistemi di riscaldamento domestico, frigoriferi, condizionatori d’aria, automobili.\nApplicazioni industriali: controllo delle scorte, linee di assemblaggio automatiche, controllo di macchine utensili.\nTecnologia avanzata: tecnologia spaziale, sistemi d’arma, robotica, centrali elettriche.\n\nQuesti sistemi garantiscono operazioni efficienti, affidabili e sicure in vari settori.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa teoria del controllo del feedback, su cui ci concentreremo in questo corso, viene utilizzata anche nel controllo delle scorte e nei sistemi socioeconomici.\nMentre il nostro focus principale sarà sui sistemi ingegneristici, dove il sistema da controllare obbedisce a leggi fisiche specifiche.\nÈ essenziale notare che il sistema di controllo può essere applicato anche a sistemi socio-economici e biologici (cibernetica), ma non ne parleremo in questo corso.\n\n\nContesto storico ed evoluzione\nL’applicazione delle tecniche di controllo iniziò principalmente nel controllo di processo all’inizio del XX secolo (1900-1940). La seconda guerra mondiale accelerò lo sviluppo dei sistemi di controllo con l’avvento dei piloti automatici di aerei, dei sistemi di posizionamento delle armi, dei radar e dei sistemi di controllo delle antenne.\nQuesto periodo segnò la nascita dei servomeccanismi, derivati ​​da “servo” (che significa schiavo o servitore) e “meccanismo”, che indica un sistema che risponde ai comandi. Questa convergenza di discipline ha portato alla teoria del controllo del feedback unificato che studiamo oggi.\n\n\nTerminologie di base dei sistemi di controllo\nPrima di andare avanti, definiamo alcune delle terminologie di base utilizzate nei sistemi di controllo:\n\n1. Il Processo o Impianto o Sistema Controllato\n\nDefinizione: Il sistema che viene controllato. Può trattarsi di qualsiasi sistema, macchina o processo che necessita di controllo automatizzato.\nEsempi in settori: prodotti chimici, petrolio, energia a vapore, ecc., dove è richiesto il controllo di temperatura, pressione, livello del liquido, umidità e composizione. Queste applicazioni vengono spesso definite “applicazioni di controllo del processo”.\n\n\n\n2. Risposta o variabile controllata\n\nDefinizione: L’output o la variabile del processo che intendiamo controllare.\nEsempio: Temperatura in un impianto di riscaldamento.\n\n\n\n3. Variabile manipolata\n\nDefinizione: La variabile regolata dal controller per influenzare la variabile di risposta.\nEsempio: La posizione della valvola in un impianto di riscaldamento per regolare il flusso di calore.\n\n\n\n4. Controllore\n\nRuolo: regolare la variabile manipolata per garantire che la variabile controllata segua i comandi impostati.\n\n\n\n5. Disturbo\n\nCaratteristiche: un segnale indesiderato, incontrollabile, spesso casuale che influenza il processo. Questo segnale è fuori dal nostro controllo.\nFonti: fattori ambientali esterni o cambiamenti dei processi interni.\nEsempio: Oscillazioni della temperatura ambiente che interessano un impianto di riscaldamento (esterno); I parametri cambiano nel tempo (interni)\n\n\n\n\nRappresentazione del diagramma a blocchi\nPer comprendere come funziona un sistema di controllo di base, è utile utilizzare una rappresentazione in diagramma a blocchi.\n\n\n\n\n\n\n\noppure possiamo anche vedere il segnale di comando arrivare a un singolo blocco, che produce la variabile di risposta:\n\n\n\n\n\n\nFigura: diagramma a blocchi che rappresenta la struttura del sistema di controllo di base e i suoi componenti e segnali principali.\nSi noti che sebbene il disturbo sia visualizzato come un segnale proveniente dall’esterno, potrebbe trattarsi di una modifica interna (ad esempio, modifica di un parametro).\nQuest’ultimo diagramma a blocchi mostra che il nostro obiettivo è avere una variabile di risposta che segua i comandi impostati. Vediamo ora come raggiungere questo obiettivo.\n\n\nSistema di controllo ad anello aperto\n\nStruttura: Il controller riceve il segnale di comando e regola di conseguenza la variabile manipolata, indipendentemente da eventuali disturbi.\nLimitazione: Mancanza di feedback; il sistema non si adatta a disturbi o cambiamenti nel processo.\n\nTuttavia, un tale sistema può essere vulnerabile ai disturbi. Se un disturbo casuale colpisce il sistema e il controller non è a conoscenza di questo cambiamento, potrebbe non riuscire a far sì che la variabile di risposta segua il comando.\n\n\nSistema di controllo a circuito chiuso\nPer affrontare questo problema, viene utilizzato un sistema più intelligente, noto come sistema di “controllo a circuito chiuso”. Qui, il controller riceve feedback dalla variabile di risposta, consentendogli di regolare la variabile manipolata in tempo reale e garantendo che l’uscita segua da vicino il comando, anche quando si verificano disturbi.\n\nL’intelligenza dei sistemi a circuito chiuso\nIl sistema a circuito chiuso monitora continuamente il processo che controlla e apporta modifiche in tempo reale per mantenere le cose senza intoppi. Ecco come funziona:\n\nMeccanismo di feedback: il controllore in un sistema a circuito chiuso è costantemente informato sullo stato attuale del processo (la variabile di risposta). Questo flusso continuo di feedback è il modo in cui il sistema tiene il dito sul polso.\nRegolazione dinamica: sulla base di questo feedback, il controller apporta modifiche immediate alla variabile manipolata, il componente del sistema che influenza direttamente l’uscita.\n\n\n\nAffrontare i disturbi\nIn uno scenario ideale, se potessimo prevedere ogni disturbo, potremmo adattare preventivamente i nostri sistemi per contrastarli. Ma in realtà i disturbi sono spesso casuali e imprevedibili. È qui che entra in gioco la capacità di misurazione e reazione del sistema a circuito chiuso:\n\nQuando un disturbo colpisce il processo, questo impatto si riflette nella variabile di risposta.\nMisurando questa variabile il sistema raccoglie indirettamente informazioni sul disturbo.\nIl controller confronta quindi l’uscita effettiva (variabile controllata) con l’uscita prevista (segnale di comando) e identifica eventuali discrepanze.\nQuesto confronto produce un segnale di errore, che il controller utilizza per generare un segnale di controllo correttivo. Questo segnale viene reimmesso nel processo, riducendo l’errore verso zero.\n\nI sistemi di controllo del feedback sono fondamentali in vari settori grazie alla loro capacità di minimizzare gli errori. Funzionano secondo un principio semplice ma efficace: utilizzare il feedback per ridurre il divario tra ciò che si desidera (il segnale di comando) e ciò che sta effettivamente accadendo (il risultato effettivo).\n\n\nComponenti di un sistema di controllo a circuito chiuso\n\nSensore: Questo componente misura la variabile controllata, rilevando effettivamente la temperatura del sistema.\nComparatore: Agendo come giudice, confronta le letture del sensore con il segnale di comando desiderato.\nController: in base ai risultati del comparatore, il controller altera la variabile manipolata per correggere eventuali errori.\n\n\n\n\n\n\n\nDiagramma: diagramma a blocchi che rappresenta il sistema di controllo a circuito chiuso. La struttura illustra il feedback dalla variabile di risposta al controller.\n\n\n\nStruttura dei sistemi di controllo del feedback\nIl meccanismo di un sistema di controllo del feedback è un processo di autoannullamento dell’errore.\nIl sistema verifica continuamente la presenza di discrepanze tra il comando desiderato e l’output effettivo, impiegando azioni del controller per mitigare questi errori. Un sistema di questo tipo è comunemente noto come sistema a circuito chiuso a causa della sua struttura ad anello, che facilita il processo di feedback.\nI componenti di questo sistema possono essere intesi come segue:\n\nSegnale di comando: l’uscita o il setpoint desiderato.\nVariabile controllata: l’output effettivo del sistema.\nSegnale di errore: differenza tra il segnale di comando e la variabile controllata.\nController: elabora il segnale di errore per produrre il segnale di controllo.\nImpianto: L’effettivo sistema controllato.\nSensore: misura la potenza dell’impianto\n\n\n\nSfide nel sistema di controllo del feedback\nNonostante la loro efficacia, i sistemi a circuito chiuso presentano sfide specifiche:\n\nRumore del sensore: Una delle principali fonti di problemi nel sistema di controllo del feedback è il sensore. L’inclusione del sensore, assente nei sistemi a circuito aperto, presenta una serie di problemi:\n\nRumore: Il sensore potrebbe introdurre rumore, soprattutto alle alte frequenze, durante la misurazione. Questo rumore può disturbare il corretto funzionamento dell’impianto e del controllore, riducendo così l’efficienza del sistema.\nSoluzioni al rumore: l’installazione di filtri antirumore adeguati può risolvere questo problema, garantendo che il rumore ad alta frequenza non interferisca con il funzionamento del circuito.\n\nRequisiti del controller: Un aspetto significativo del sistema di feedback è il suo controllore.\n\nLo scopo primario del titolare del trattamento è rendere robusto il sistema. Un sistema robusto implica che la variabile controllata segua fedelmente il segnale di comando, anche in presenza di disturbi esterni o variazioni dei parametri dell’impianto. Per raggiungere questo obiettivo è necessario un attento equilibrio tra accuratezza e stabilità del sistema, un delicato compromesso che costituisce il nucleo della teoria del controllo del feedback.\nL’obiettivo è che la variabile controllata segua il comando. Ciò significa che il controllore in un sistema a circuito chiuso dovrebbe raggiungere:\n\nPrecisione allo stato stazionario: riduzione al minimo dell’errore a lungo termine tra la variabile controllata e il segnale di comando.\nVelocità di risposta: Rispondere rapidamente ai cambiamenti nel comando o ai disturbi.\n\n\nPreoccupazioni sulla stabilità (compromesso tra accuratezza e stabilità):\n\nPoiché ci impegniamo per una maggiore precisione del sistema, la stabilità potrebbe essere compromessa. Questo compromesso è una sfida intrinseca della struttura del feedback. La teoria del controllo del feedback e i suoi progetti mirano a trovare un equilibrio tra questi requisiti contrastanti.\n\n\n\n\nVantaggi del controllo del feedback\nI sistemi di controllo del feedback sono indispensabili, principalmente a causa della loro natura robusta. Nonostante le sfide associate, la loro capacità di filtrare i disturbi e adattarsi alle variazioni dei parametri li rende superiori ai sistemi a circuito aperto. Senza strutture di controllo del feedback, sarebbe difficile ottenere in modo efficace la precisione del sistema.\n\n\n\nEsempio\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint\n\n\ndef open_loop_system(y, t, K, tau):\n    \"\"\"Open-loop system model.\"\"\"\n    u = 1  # step input\n    if 3 &lt;= t &lt;= 8:  # Adding a disturbance between time 3 and 5\n        u += 1.0\n    dydt = (-y + K * u) / tau\n    return dydt\n\ndef closed_loop_system(states, t, K, tau, Ki, Kd):\n    \"\"\"Closed-loop system model with PID control.\"\"\"\n    y, e_prev, e_int = states  # y is system output, e_prev is previous error, e_int is integral of error\n    setpoint = 1  # desired setpoint\n    disturbance = 0\n    \n    if 3 &lt;= t &lt;= 5:  # Adding a disturbance between time 3 and 5\n        disturbance += 1.0\n        \n    # Error\n    e = setpoint - y\n    \n    # PID Controller\n    u = K * e + Ki * e_int + Kd * (e - e_prev)\n    \n    dydt = (-y + u + disturbance) / tau  # Disturbance is added directly to the system dynamics\n    deintdt = e  # Integral of error over time\n    dedt = e - e_prev\n    \n    return [dydt, dedt, deintdt]\n\n\n# System parameters\nK = 2.5\ntau = 1.0\nKi = 1.0  # Integral gain\nKd = 0.5  # Derivative gain\n\n# Time array\nt = np.linspace(0, 10, 100)\n\n# Solve ODE for the open-loop system\ny_open = odeint(open_loop_system, 0, t, args=(K, tau))\nerror_open = 1 - y_open.squeeze()  # desired setpoint is 1, so error is 1 - output\n\n# Solve ODE for the closed-loop system\ninitial_conditions = [0, 0, 0]  # initial values for y, e_prev, and e_int\ny_closed, error_closed, _ = odeint(closed_loop_system, initial_conditions, t, args=(K, tau, Ki, Kd)).T\n\n# Plot Responses\nplt.figure(figsize=(10,6))\nplt.subplot(2, 1, 1)\nplt.plot(t, y_closed, 'r-', label='Closed-loop Response (PID)')\nplt.plot(t, y_open, 'b--', label='Open-loop Response')\nplt.ylabel('Response')\nplt.title('Control System Response with Disturbance')\nplt.legend()\nplt.grid()\n\n# Plot Errors\nplt.subplot(2, 1, 2)\nplt.plot(t, error_closed, 'r-', label='Closed-loop Error (PID)')\nplt.plot(t, error_open, 'b--', label='Open-loop Error')\nplt.xlabel('Time')\nplt.ylabel('Error')\nplt.title('Control System Errors with Disturbance')\nplt.legend()\nplt.grid()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIl sistema che stiamo simulando è un sistema base del primo ordine. È uno dei sistemi dinamici più semplici, utilizzato spesso come elemento fondamentale nella teoria del controllo. Le equazioni che governano la sua dinamica, in generale, assomigliano a:\n\\[\n\\tau \\frac{dy(t)}{dt} + y(t) = Ku(t)\n\\]\nQui: - \\(\\tau\\) è la costante di tempo del sistema. Dà un’idea della velocità con cui il sistema risponde ai cambiamenti nell’input. - \\(K\\) è il guadagno del sistema. Ti dice quanto cambia l’output del sistema per una determinata modifica nell’input. - \\(u(t)\\) è l’input del sistema al tempo \\(t\\). - \\(y(t)\\) è l’output del sistema al tempo \\(t\\).\nIl sistema ad anello aperto agisce direttamente sul sistema con l’ingresso \\(u(t)\\). Non c’è feedback, quindi se c’è un disturbo o il sistema non si comporta come previsto, il sistema a circuito aperto non può correggerlo.\nIl sistema a circuito chiuso, invece, utilizza il feedback. L’uscita del sistema \\(y(t)\\) viene costantemente misurata e confrontata con il setpoint desiderato per determinare l’errore. Un controller regola quindi l’ingresso del sistema \\(u(t)\\) in base a questo errore per far sì che l’uscita del sistema corrisponda al setpoint desiderato. Ciò consente al sistema a circuito chiuso di correggere i disturbi e il comportamento del sistema che si discosta dal comportamento desiderato.\nNella nostra simulazione specifica: - Il sistema ad anello aperto è stato modellato per mostrare come reagisce direttamente a un input e ad un disturbo senza alcun meccanismo di feedback. - Il sistema a circuito chiuso è stato modellato utilizzando un semplice controllore proporzionale con un termine derivativo. Il controller cerca di minimizzare l’errore, che è la differenza tra l’uscita desiderata (setpoint + disturbo) e l’uscita effettiva del sistema. Ciò consente al sistema a circuito chiuso di correggere eventuali disturbi o altri comportamenti imprevisti.\nCon questo meccanismo di feedback, il controller può regolare e correggere dinamicamente eventuali deviazioni, garantendo che il sistema rimanga stabile e funzioni come desiderato.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html#approcci-progettuali-per-sistemi-di-controllo-feedback",
    "href": "IT_🇮🇹/intro_it.html#approcci-progettuali-per-sistemi-di-controllo-feedback",
    "title": "Principi di controllo automatico",
    "section": "Approcci progettuali per sistemi di controllo feedback",
    "text": "Approcci progettuali per sistemi di controllo feedback\nProgettare un controller efficace è fondamentale. Esistono vari approcci a questo proposito e possono essere classificati come segue:\n\nApproccio sperimentale (ottimizzazione del controller):\n\nMetodo: regolazione del controller in base all’esperienza pratica e al feedback in tempo reale. Viene installato un controller basato sulle esperienze passate e quindi regolato in tempo reale fino al raggiungimento dei risultati desiderati.\nCaso d’uso: comunemente utilizzato nel controllo di processo in cui è difficile ottenere modelli di processo accurati o molto complessi (ad esempio, impianti altamente non lineari).\nNatura: è un approccio ad hoc, che si basa più sulla conoscenza empirica che sui modelli teorici.\n\nApproccio basato su modelli (approccio analitico):\n\nMetodo: Sviluppo di un modello matematico del sistema (equazioni differenziali, funzioni di trasferimento, modelli delle variabili di stato) e progettazione del controllore basato su questo modello.\nCaso d’uso: questo è un metodo utilizzato per sistemi complessi in cui i requisiti di controllo sono rigorosi, un approccio basato su modello è più adatto. Qui la dinamica del sistema viene catturata in un modello matematico, che viene poi utilizzato per progettare analiticamente il controller.\nVantaggio: Fornisce un controllo più preciso, soprattutto per i sistemi complessi.\n\nApproccio basato sulla conoscenza o sui dati:\n\nTendenze recenti: include metodi come controllo esperto, controllo fuzzy, reti neurali e apprendimento per rinforzo. L’idea centrale è quella di utilizzare linee guida qualitative o regole derivate dalla conoscenza degli esperti (un utente esperto o dati) per progettare il controller.\nApplicazione: Sempre più popolare nelle applicazioni industriali.\n\n\nNell’ambito di questo corso, ci concentreremo principalmente sul controllo basato su modello. Ciò comporta la derivazione di un modello matematico del sistema fisico, che può essere basato su leggi fisiche o sperimentazione.\n\nApproccio\nPer un sistema fisico otterremo un modello metematico. Questo può essere derivato:\n\nUtilizzo delle leggi fisiche: derivazione di equazioni differenziali basate sui principi fisici che governano il sistema, che possono poi essere tradotte in una rappresentazione più conveniente, ad esempio funzioni di trasferimento o variabili dello spazio degli stati.\nEsecuzione di sperimentazioni: condurre esperimenti per determinare le relazioni input-output e modellarle utilizzando forme matematiche adeguate, ad esempio funzioni di trasferimento. Questa si chiama identificazione del sistema.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html#contesto-storico",
    "href": "IT_🇮🇹/intro_it.html#contesto-storico",
    "title": "Principi di controllo automatico",
    "section": "Contesto storico:",
    "text": "Contesto storico:\nL’evoluzione dei metodi di progettazione del controllo può essere sostanzialmente classificata in due epoche principali:\n\nProgettazione classica dei controlli (1940-1960): questo periodo ha visto lo sviluppo di metodi di progettazione nel dominio della frequenza. Sono emerse tecniche come i metodi di stabilità di Nyquist, i grafici di Bode e i grafici del luogo delle radici. Sono ancora molto utilizzati, soprattutto nelle applicazioni di controllo industriale (sviluppo di servomeccanismi).\nModern Control Design (dagli anni ’60 in poi): i requisiti di controllo dei veicoli spaziali hanno dato vita a tecniche di stato-spazio, note come Modern Control Design. Sebbene questi metodi siano definiti “moderni”, è fondamentale comprendere che sia i metodi classici che quelli moderni sono ancora prevalenti e fondamentali nelle rispettive applicazioni.\n\nIl termine “progettazione di controlli moderna” potrebbe essere un po’ fuorviante. È emerso principalmente dai requisiti specifici del tracciamento nei veicoli spaziali. Tuttavia, nel campo del controllo industriale, i metodi classici di progettazione sono ancora ampiamente prevalenti. Infatti, circa il 75% degli odierni problemi di controllo industriale vengono affrontati utilizzando queste tecniche classiche.\nSebbene i metodi moderni abbiano le loro origini e vantaggi, in particolare in applicazioni specializzate come i veicoli spaziali, è ancora discutibile quale metodo offra maggiore robustezza. La robustezza, dopo tutto, è il requisito primario per la maggior parte dei sistemi.\nQuesto dibattito in corso rende imperativo rinunciare alla terminologia del controllo classico e moderno, poiché entrambi sono ugualmente rilevanti a seconda dell’applicazione.\nNell’ambito di questo corso, la nostra concentrazione principale sarà sui metodi di progettazione nel dominio della frequenza. Ciò ti fornirà una comprensione completa dei metodi fondamentali nella progettazione dei controlli.\nTuttavia, non trascureremo del tutto i metodi delle variabili di stato. Verranno invece introdotti non dal punto di vista della progettazione ma piuttosto per la simulazione del sistema. La simulazione del sistema, se affrontata attraverso la formulazione delle variabili di stato, può essere più intuitiva ed efficace.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html#esempi-illustrativi-di-sistemi-di-controllo",
    "href": "IT_🇮🇹/intro_it.html#esempi-illustrativi-di-sistemi-di-controllo",
    "title": "Principi di controllo automatico",
    "section": "Esempi illustrativi di sistemi di controllo",
    "text": "Esempi illustrativi di sistemi di controllo\nSpesso è utile mettere in relazione i concetti teorici con esempi del mondo reale. Ciò aiuta a comprendere le applicazioni più ampie e le sfumature dei sistemi di controllo nella vita di tutti i giorni.\n\nEsempi di sistemi controllati:\n\nSerbatoio del WC del bagno: un sistema apparentemente semplice, ma in sostanza è un meccanismo di controllo a feedback.\nGuida automobilistica: comprende vari sistemi di controllo, dalla regolazione della velocità al servosterzo.\nRiscaldamento residenziale: i termostati e i sistemi HVAC si affidano al feedback per mantenere le temperature desiderate.\nMeccanismo di sterzo idraulico: un componente critico per molti veicoli e sistemi pesanti.\nServosistema antenna: utilizzato per il monitoraggio e le comunicazioni.\nSistema di controllo della velocità: presente in varie macchine, dalle installazioni industriali agli elettrodomestici.\n\nApprofondiremo ulteriormente questi esempi, inquadrandoli nel contesto dei sistemi di controllo del feedback. In tal modo, miriamo a fornire una comprensione più profonda di come questi principi vengono applicati in scenari pratici.\n\n\n\n\n\n\n\n\nSpaceX Nails atterra un razzo riutilizzabile sulla terra, da Bloomberg Technology\n\n\n\n\n\n\n\n\n\n\n\n\nSpaceX Nails Atterraggio di un razzo riutilizzabile sulla terra (primo piano)\n\n\n\n\n\nDove entra in gioco l’ingegneria dei sistemi di controllo?\n\nControllo dell’atteggiamento\nControllo dell’atterraggio\nMonitoraggio della traiettoria\nControllo del territorio (ad esempio, tracciamento dell’antenna)\n\n\n\n\n\n\n\n\nTraghetti autonomi (Rolls-Royce)\n\n\n\n\n\n\n\n\n\n\n\n\nAtlas (Boston Dynamics)",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/intro_it.html#conclusioni",
    "href": "IT_🇮🇹/intro_it.html#conclusioni",
    "title": "Principi di controllo automatico",
    "section": "Conclusioni",
    "text": "Conclusioni\nI sistemi di controllo del feedback costituiscono la spina dorsale di molte applicazioni ingegneristiche moderne. La capacità di fornire un meccanismo per regolare automaticamente il comportamento del sistema in base al feedback degli output rende questi sistemi indispensabili. Tuttavia, la progettazione e l’implementazione di questi sistemi richiedono una comprensione completa della loro struttura, delle sfide, dei vantaggi e dei vari approcci disponibili. Nei capitoli successivi approfondiremo ciascuno di questi aspetti, fornendo uno sguardo più dettagliato alle complessità dei sistemi di controllo del feedback.",
    "crumbs": [
      "IT_🇮🇹",
      "Principi di controllo automatico"
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html",
    "href": "IT_🇮🇹/syllabus_it.html",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "",
    "text": "Instructors: - Andrea Munafo (andrea.munafo@unipi.it) - Riccardo Costanzi (riccardo.costanzi@unipi.it)",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#risultati-dellapprendimento",
    "href": "IT_🇮🇹/syllabus_it.html#risultati-dellapprendimento",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Risultati dell’apprendimento",
    "text": "Risultati dell’apprendimento\n\nComprendere i principi fondamentali del controllo automatico, inclusi concetti come controllo del feedback, stabilità e controllabilità.\nAnalizzare e progettare sistemi di controllo utilizzando modelli e strumenti matematici, comprese trasformate di Laplace, funzioni di trasferimento e diagrammi a blocchi.\nApplicare strategie di controllo a vari problemi ingegneristici del mondo reale, come il controllo della temperatura, il controllo della velocità, ecc.\nValutare le prestazioni dei sistemi di controllo e identificare modi per migliorarli, inclusa la regolazione dei parametri di controllo e la modifica dei componenti del sistema.\nSviluppare il pensiero critico e capacità di risoluzione dei problemi applicando principi di controllo a problemi ingegneristici nuovi e complessi e comunicando i risultati in modo efficace.\n\nSarai ben preparato per applicare i principi del controllo automatico a una varietà di campi dell’ingegneria, come la robotica, l’aerospaziale e la produzione, ecc.",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#descrizione-del-corso",
    "href": "IT_🇮🇹/syllabus_it.html#descrizione-del-corso",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Descrizione del corso",
    "text": "Descrizione del corso\nQuesto corso introduce la progettazione di sistemi di controllo del feedback. Gli argomenti includono:\n\n\n\n\n\nIntroduzione a python a Python/Jupyter Notebook\n\n\nCiclo aperto e Ciclo chiuso\n\n\nFunzioni di trasferimento e trasformazione di Laplace\n\n\nDiagrammi a blocchi\n\n\nRisposta di un sistema\n\n\nRisposta in frequenza e grafici di Bode\n\n\nTeorema del valore finale e stato stazionario\n\n\n\n\n\n\nStabilità e controllo del sistema\n\n\nIl metodo del luogo delle radici\n\n\nController PID\n\n\nGain e margini di fase\n\n\nFunzioni di sensibilità\n\n\nCompensatori di piombo/ritardo\n\n\nAnalisi dello spazio statale",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#tutorial-e-tclab",
    "href": "IT_🇮🇹/syllabus_it.html#tutorial-e-tclab",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Tutorial e TCLab",
    "text": "Tutorial e TCLab\nLa componente pratica del nostro corso prevede l’utilizzo del Laboratorio di controllo della temperatura (TCLab). Questo approccio pratico migliora la comprensione dei problemi di controllo.\n\n\n\n\n\n\n\nPuoi acquistare TCLab su amazon.com per circa $ 50, ma acquistarlo non è obbligatorio per questo corso. Fornirò un numero limitato di schede e TCLab offre simulatori, che solitamente sono sufficienti per comprendere i concetti del corso.\nLinee guida per l’utilizzo di TCLab: - Solo una tavola alla volta. - Pianifica il tuo tempo in TCLab utilizzando il foglio di calcolo del canale Teams del corso. Quando restituisci la tavola, assicurati di effettuare il check-out. La responsabilità del consiglio spetta all’ultima persona elencata come ad averlo sul foglio di calcolo.\nSettimana 1: Introduzione e nozioni di base - I Quaderni: - Introduzione (01_intro) - Nozioni di base sul controllo del feedback (02_basics_of_feedback_control) - Obiettivi: - Comprendere i sistemi di controllo e la loro importanza nella tecnologia moderna. Discussioni su terminologie e concetti di base nei sistemi di controllo. Distinzione tra sistemi di controllo Open-Loop e Closed-Loop. Esplorare la struttura e le sfide dei sistemi di controllo del feedback. Approcci progettuali per sistemi di controllo feedback. Contesto storico ed evoluzione dei sistemi di controllo.\n\nIntegrazione TCLab: Familiarizzazione con il laboratorio e configurazione di base.\n\nNotebook: 00_Spacecraft_Thermal_Control_Systems, 01_TCLab, 01_Understanding_TCLab\nLaboratorio: 02_TCLab_Lab_1_Coding_a_relay_controller\n\nAttività: Discussioni di gruppo sulle applicazioni reali dei sistemi di controllo.\nIncarico:\n\nInstalla Python. Python è un linguaggio di programmazione di uso generale. Viene utilizzato in questo corso per la dinamica e il controllo dei processi.\nInstalla le librerie TCLab\n\n\nSettimana 2: Modellazione matematica - I Quaderni: - Modelli matematici (03_introduction_to_control_problem), - Trasformate di Laplace e funzioni di trasferimento (04_dynamic_systems), - Risposta del sistema e teorema del valore finale; Caratteristiche dei sistemi del Primo e del Secondo Ordine (05_dynamic_response)\n\nObiettivi:\n\nComprensione dei modelli matematici e delle funzioni di trasferimento nei sistemi di controllo. Esempi reali di sistemi di controllo: controllo del livello dell’acqua, sistema di guida dell’automobile, meccanismo del servosterzo idraulico, sistema di riscaldamento residenziale. Introduzione ai sistemi Multi-Input Multi-Output (MIMO). Analisi di sistemi di controllo complessi e dei loro componenti. Diagramma a blocchi della struttura di feedback di base.\n\nIntegrazione TCLab: Identificazione della modellazione\n\nNotebook: 03_System_Model_and_Identification_TCLab, 04_Step_Testing_TCLab, 05_Fitting_Step_Test_Data_to_Empirical_Models, (opzionale: 05b_First-Order-Model-for-a-Single-Heater)\nLaboratorio: 06_TCLab_Lab_2_Model_Identification\n\nAttività: Sessioni di problem solving per applicare modelli matematici a scenari teorici.\nCompito: TCLab Simulate Step Response. Descrizione: Risposta dinamica della temperatura di un riscaldatore e sensore di temperatura con un Arduino\n\nSettimana 3: risposta e feedback del sistema - I Quaderni: - Trasformata di Laplace inversa (06_inverse_laplace_transform) - Modellazione di sistemi dinamici: modellazione meccanica e termica (07_modeling_dynamic_systems) - Componenti di un controller (08_control_system_components) - Modelli di dispositivi e sistemi di controllo (09_Models_of_Control_Devices_and_Systems) - Hardware e alcuni casi di studio (10_hardware_and_case_studies, 11_AC_hardware_and_case_studies)\n\nObiettivi:\n\nEsplorare la risposta del sistema a vari input e il ruolo del feedback nei sistemi di controllo. Analisi dei sistemi nel dominio del tempo, introduzione alla modellistica dei sistemi fisici. Comprensione dell’hardware e casi di studio esemplari per la comprensione pratica. Applicazione della trasformata inversa di Laplace nei sistemi di controllo. Metodi di scomposizione di frazioni parziali per funzioni complesse.\n\nIntegrazione TCLab: dati i dati di un esperimento di identificazione, il compito successivo è trovare uno o più modelli che riproducano accuratamente la risposta del processo ai cambiamenti nella variabile manipolata. Questo notebook illustra un approccio pratico per adattare modelli di ordine inferiore ai dati di risposta al gradino.\n\nI Quaderni: -\nLaboratorio: 07_CLab_Lab_2_Fitting\n\nAttività: Simulazioni interattive per dimostrare l’impatto del feedback sulla stabilità del sistema.\nCompito: TCLab Convective Heat Transfer. Descrizione: Previsione del trasferimento di calore convettivo con un riscaldatore a transistor. !!!\n\nSettimana 4: Stabilità e controllori - I Quaderni: - Una prima applicazione completa, sistema di controllo della temperatura (12_A_First_Complete_Application) - Controllo del feedback (13_Principles_of_Feedback_Control, 14_Feedback_systems_and_ir_effects) - Approfondimento sui sistemi di controllo: controllori PID (“Introduzione ai sistemi di controllo”) - Analisi della stabilità nei sistemi di controllo (16_Stability, 17_Stability_and_Routh_Criterion)\n\nObiettivi:\n\nApplicare le conoscenze teoriche ad un’applicazione completa del sistema di controllo. Studio dettagliato dei principi del controllo del feedback e delle loro applicazioni. Analisi degli effetti dei meccanismi di feedback nei sistemi di controllo. Rivisitazione dei concetti fondamentali nei sistemi di controllo. Studiare i concetti di stabilità nei sistemi e nei sistemi di feedback e le basi dei controllori PID. Studio dettagliato del criterio di Routh e della sua applicazione nella valutazione della stabilità.\n\nIntegrazione TCLab: Implementa i controller utilizzando TCLab.\n\nNotebook: 08_Relay_Control, 09_PID_Control\nLab: 10_Lab-Assignment-PID-Control, 11_Lab-Assignment-PI-Control\n\nAttività: Esercizi di gruppo per progettare regolatori PID di base per determinate specifiche.\nRisorse: Modello TCLab FOPDT. Descrizione: Modello di risposta dinamica lineare alla temperatura di un riscaldatore e sensore di temperatura con un Arduino\n\nSettimana 5: Strategie di controllo avanzate - I Quaderni: - Prestazioni dei sistemi di feedback (18_Performance_of_Feedback_Systems) - Progettazione del controllo del feedback: sistemi del secondo ordine (19_Design_of_feedback_control, 20_Design_of_feedback_control_continued) - Precisione allo stato stazionario e un esempio di progettazione completo (21_Steady_State_Accuracy_And_Design_Principles)\n\nObiettivi:\n\nStudiare i concetti di prestazione nei sistemi di feedback. Valutare e migliorare le prestazioni dei sistemi di controllo del feedback. Introduzione alla precisione in regime stazionario. Discussioni iniziali su strategie e metodologie per la progettazione di sistemi di controllo del feedback efficaci.\n\nIntegrazione TCLab: Continua con l’implementazione di semplici controller PID utilizzando TCLab.\n\nSettimana 6: Strategie di controllo avanzate: luogo delle radici - I Quaderni: - Luogo delle radici (22_Compensator_Design_Using_Root_Locus, 23_Design_with_the_root_locus, 24_Compensators_and_Root_Locus)\n\nObiettivi:\n\nComprendere il luogo delle radici e come utilizzarlo per progettare sistemi di controllo.\n\nIntegrazione TCLab: da confermare\nAttività: Casi di studio di diverse strategie di controllo nei sistemi informatici.\nCompito: Metodo grafico: da FOPDT a Step Test. Descrizione: Un sistema lineare del primo ordine con ritardo temporale è una descrizione empirica comune di molti processi dinamici. Il codice sorgente Python mostra come simulare uno step test e confrontarlo con un’approssimazione FOPDT.\n\nRegressione TCLab FOPDT. Descrizione: Modello di risposta dinamica lineare alla temperatura di un riscaldatore e sensore di temperatura con un Arduino\nSettimana 7: Strategie di controllo avanzate: risposta in frequenza - I Quaderni: - Risposta in frequenza e criterio di Nyquist (25_Introduction_to_Frequency_Domain_Analysis_in_Control_Systems) - Applicazione del criterio di Nyquist (26_Application_of_Nyquist_Stability_Criterion) - Stabilità relativa (27_The_Nyquist_Stability_Criterion_and_Relative_Stability) - Obiettivi: - Comprensione della Risposta in Frequenza, del Criterio di Nyquist e del concetto di stabilità relativa.\n\nIntegrazione TCLab: Progetta e implementa un controller utilizzando TCLab.\nAttività: Casi di studio di diverse strategie di controllo nei sistemi informatici.\nAssegnazione: TCLab Controller Design. Descrizione: Progettare un controller per l’automazione della regolazione della temperatura su un setpoint. Il controller regola un riscaldatore per regolare la temperatura.\n\nSettimana 8: grafici di Bode, controllo e commenti finali - I Quaderni: - Grafici di Bode (“28_Body_Plots”) - Prestazioni del sistema nel dominio della frequenza (29_Feedback_system_performance_based_on_frequency_response) - Modellazione del loop (30_Loop_Shaping)\n\nObiettivi:\n\nComprensione dei grafici di Bode. Analisi delle prestazioni nel dominio della frequenza. Il loop shaping come strategia di controllo. Ripasso dei concetti chiave e preparazione all’esame finale.\n\nIntegrazione TCLab: Modellazione nello spazio degli stati con TCLab.\nAttività: sessioni di domande e risposte, test simulati e discussioni di gruppo.\nIncarico:\n\nControllo solo proporzionale TCLab. Descrizione: TCLab con controllo solo proporzionale presenta un offset tra il setpoint e la temperatura misurata. Lo scopo di questa attività di laboratorio è quantificare e verificare l’offset.\nTCLab PI Controllo. Descrizione: TCLab con controllo proporzionale integrale (PI) elimina l’offset tra il setpoint e la temperatura misurata\nControllo PID TCLab. Descrizione: TCLab con controllo proporzionale integrale derivativo (PID). Utilizzare l’ottimizzazione IMC e ITAE e confrontare la risposta",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#libri-di-testo",
    "href": "IT_🇮🇹/syllabus_it.html#libri-di-testo",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Libri di testo",
    "text": "Libri di testo\nItaliano - Bolzern, Scattolini, Schiavoni. Fondamenti di Controlli Automatici, 2a ed. McGraw-Hill.\n\nOgata, Katsuhiko. Ingegneria dei controlli moderna. 4a ed. Prentice Hall, 2002.\n\nInglese\n\nOgata, Katsuhiko. Ingegneria dei controlli moderna. 4a ed. Prentice Hall, 2002.\nM. Gopal, Principi e progettazione dei sistemi di controllo, McGraw-Hill (3a edizione).\nRichard C. Dorf e Robert H. Bishop IE, Modern Control Systems (13a edizione).\n\nAltri testi che potrebbero essere utili:\n\nG. Marro, Controlli Automatici, Zanichelli\nFranklin, Gene, J. David Powell e Abbas Emami-Naeini. Controllo del feedback dei sistemi dinamici. 6a ed. Prentice Hall, 2009. ISBN: 9780136019695.\nVan de Vegte, John. Sistemi di controllo del feedback. 3a ed. Prentice Hall, 1994. ISBN: 9780002085069.\nKuo, Beniamino. Sistemi di controllo automatico. 8a ed. John Wiley & Sons, 2003. ISBN: 9780471381488.\nOgata, Katsuhiko. Risolvere problemi di ingegneria di controllo con MATLAB. Prentice Hall, 1993. ISBN: 9780130459077.",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#il-ruolo-del-software-nello-studio-dei-sistemi-di-feedback",
    "href": "IT_🇮🇹/syllabus_it.html#il-ruolo-del-software-nello-studio-dei-sistemi-di-feedback",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Il ruolo del software nello studio dei sistemi di feedback",
    "text": "Il ruolo del software nello studio dei sistemi di feedback\n\nL’utilizzo di un pacchetto software come Python o MATLAB è molto utile nello studio dei sistemi di feedback.\nIl software può essere utilizzato al meglio inizialmente per controllare il lavoro che viene inizialmente eseguito tradizionalmente con carta e matita.\nCiò è particolarmente utile quando si verificano i grafici polari (grafici di Nyquist), i diagrammi di Bode e i luoghi delle radici quando si tenta per la prima volta di disegnare queste funzioni.\nLe risposte al gradino nel dominio del tempo possono essere esaminate per costruire un senso intuitivo delle relazioni tra il comportamento nel dominio del tempo e della frequenza.\nLe approssimazioni semplificate che spesso vengono fatte durante l’esecuzione dei progetti preliminari possono essere verificate per verificarne la validità utilizzando Python.\nÈ possibile studiare problemi più complessi con un pacchetto di progettazione assistita dal computer senza l’enorme onere di eseguire calcoli estesi.\nSuggeriamo a tutti di familiarizzare con l’uso di Python o MATLAB.\nRicordare che il computer deve aiutare a raggiungere la comprensione e dovrebbe essere utilizzato in modo intelligente come strumento di ingegneria.\nL’obiettivo è che tu acquisisca una comprensione approfondita della teoria del feedback.",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/syllabus_it.html#domande-frequenti-faq",
    "href": "IT_🇮🇹/syllabus_it.html#domande-frequenti-faq",
    "title": "Programma del corso “Principi del controllo automatico”",
    "section": "Domande frequenti (FAQ)",
    "text": "Domande frequenti (FAQ)\n\nvedere il notebook 00_FAQ.ipynb",
    "crumbs": [
      "IT_🇮🇹",
      "Programma del corso \"Principi del controllo automatico\""
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html",
    "href": "IT_🇮🇹/faq_it.html",
    "title": "Domande frequenti (FAQ)",
    "section": "",
    "text": "Benvenuti nella pagina delle FAQ del corso “Principi dei Controlli Automatici”. Qui troverai le informazioni chiave e le risposte alle domande più comuni.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#informazioni-generali",
    "href": "IT_🇮🇹/faq_it.html#informazioni-generali",
    "title": "Domande frequenti (FAQ)",
    "section": "Informazioni generali",
    "text": "Informazioni generali\nD: Dove posso trovare il sito web del corso?\nR: Il sito web del corso è qui.\nD: Quali materiali didattici sono disponibili?\nR: Il materiale didattico è disponibile sul sito del corso sia in inglese che in italiano. Sono forniti come notebook Jupyter.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#completamento-del-corso",
    "href": "IT_🇮🇹/faq_it.html#completamento-del-corso",
    "title": "Domande frequenti (FAQ)",
    "section": "Completamento del corso",
    "text": "Completamento del corso\nD: Come posso superare il corso?\nR: Per completare con successo il corso, dovresti frequentare le lezioni e studiare prima i libri di testo suggeriti. Successivamente, integra il tuo apprendimento con il materiale disponibile sul sito web del corso.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#esami",
    "href": "IT_🇮🇹/faq_it.html#esami",
    "title": "Domande frequenti (FAQ)",
    "section": "Esami",
    "text": "Esami\nD: Qual è il formato degli esami?\nR: Gli esami sono orali. Implicano prima il completamento degli esercizi per iscritto, seguito da una discussione di questi esercizi e altri argomenti con l’istruttore.\nD: Quali contenuti sono inclusi negli esami?\nR: Tutti gli argomenti discussi in classe fanno parte dell’esame, ad eccezione della programmazione Python. La programmazione TCLab non è un requisito e non farà parte dell’esame. Tuttavia, i concetti alla base di TCLab sono inclusi nell’esame.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#software-e-strumenti",
    "href": "IT_🇮🇹/faq_it.html#software-e-strumenti",
    "title": "Domande frequenti (FAQ)",
    "section": "Software e strumenti",
    "text": "Software e strumenti\nD: Imparare Python o MATLAB è importante per studiare i sistemi di feedback in questo corso?\nR: Sì, l’utilizzo di un pacchetto software come Python o MATLAB è molto utile per comprendere i sistemi di feedback. Sebbene non siano obbligatori per gli esami, questi strumenti possono migliorare notevolmente la tua capacità di visualizzare e analizzare i sistemi di controllo. Forniscono esperienza pratica e una visione più approfondita dei concetti teorici trattati nel corso.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#compiti-tclab",
    "href": "IT_🇮🇹/faq_it.html#compiti-tclab",
    "title": "Domande frequenti (FAQ)",
    "section": "Compiti TCLab",
    "text": "Compiti TCLab\nD: I compiti TCLab sono obbligatori per questo corso?\nR: Gli studenti sono tenuti a completare i compiti TCLab. Sebbene non siano obbligatori per superare il corso, sono altamente raccomandati. Il completamento di questi incarichi fornirà esperienza pratica e una comprensione pratica dei sistemi di controllo. Si suggerisce inoltre di preparare una breve relazione su questi compiti, che potrà essere consegnata prima dell’esame. Questo rapporto può fungere da prezioso riferimento durante la preparazione all’esame.\nD: È disponibile un modello per il report degli incarichi TCLab?\nR: Sì, viene fornito un modello di report per aiutarti con i tuoi compiti TCLab. È disponibile come notebook 00_TCLab_Exercises_Report_Template nella cartella TCLab sul sito web del corso. Questo modello ti guiderà nell’organizzazione e nella presentazione dei risultati degli esercizi TCLab. La relazione dovrebbe essere concisa, con una lunghezza massima di 4 pagine, concentrandosi sull’evidenziazione dei punti chiave degli esercizi.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "IT_🇮🇹/faq_it.html#risorse-addizionali",
    "href": "IT_🇮🇹/faq_it.html#risorse-addizionali",
    "title": "Domande frequenti (FAQ)",
    "section": "Risorse addizionali",
    "text": "Risorse addizionali\nD: Sono disponibili risorse aggiuntive per facilitare lo svolgimento del corso?\nR: Sì, oltre ai materiali didattici principali, consigliamo di partecipare a forum online e gruppi di studio relativi ai sistemi di controllo. Questi possono fornire preziosi spunti e prospettive alternative che possono migliorare la tua comprensione. Inoltre, rivedere regolarmente i materiali del corso e applicare i concetti attraverso esercizi pratici, come l’utilizzo del kit TCLab o simulazioni software, può essere di grande aiuto.\nD: Ci sono risorse esterne disponibili per esplorare l’uso dell’IA nei sistemi di controllo?\nR: Sì, per coloro che sono interessati ad esplorare l’uso dell’Intelligenza Artificiale nei sistemi di controllo, consiglio vivamente di visitare Collimator.ai. Questa piattaforma offre intuizioni preziose e strumenti per comprendere e applicare l’IA nel campo dei sistemi di controllo. Può essere un ottimo supplemento ai materiali del corso, fornendo esempi pratici e un approfondimento su come le tecnologie IA stanno trasformando le metodologie dei sistemi di controllo.",
    "crumbs": [
      "IT_🇮🇹",
      "Domande frequenti (FAQ)"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html",
    "href": "basics_of_feedback_control.html",
    "title": "Introduction to Feedback Control Systems",
    "section": "",
    "text": "In today’s discussion, we will delve into the fundamentals of feedback control systems. Let’s start with some simple real-world examples to illustrate the underlying feedback structure.\n\n\nConsider a common household item - a bathroom toilet tank. The main purpose of this system is to maintain the water level inside the tank.\nObjective: Control the water level in the tank to a preset level.\n\nControlled Variable: Water level in the tank.\nCommand Signal: Preset height, \\(\\bar{H}\\)\nDisturbance: Outflow from the tank.\nManipulated Variable: Inflow to the tank.\n\n\n\n\n\n\n\nIf there’s any deviation from the desired water level, the difference (error, \\(e\\)) will activate the controller - the float and lever mechanism. This controller adjusts the valve position, \\(u\\), proportional to the error signal.\n\\[\n\\text{Control variable}\\;\\;\\;\\;u = \\frac{l_1}{l_1+l_2}e = Ke\n\\]\nAs water flows in, the error decreases, eventually reaching zero, causing the valve to close. Note that we can change \\(K\\) changing the position of the point \\(B\\).\n\n\n\n\n\n\n\n\n\nor in a more general form:\n\n\n\n\n\n\nFrom Raymond T. Stefani, Bahram Shahian and Clement J. Savant, “Design of feedback control systems”, 4th edition, Oxford University press, 2001.\nNote that the disturbance is the water outflowing the water tank.\nTerminology: - Set-point: constant command signal - Regulator: control system that aims at keeping the controlled variable at the set-point.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html#basics-of-feedback-control",
    "href": "basics_of_feedback_control.html#basics-of-feedback-control",
    "title": "Introduction to Feedback Control Systems",
    "section": "",
    "text": "In today’s discussion, we will delve into the fundamentals of feedback control systems. Let’s start with some simple real-world examples to illustrate the underlying feedback structure.\n\n\nConsider a common household item - a bathroom toilet tank. The main purpose of this system is to maintain the water level inside the tank.\nObjective: Control the water level in the tank to a preset level.\n\nControlled Variable: Water level in the tank.\nCommand Signal: Preset height, \\(\\bar{H}\\)\nDisturbance: Outflow from the tank.\nManipulated Variable: Inflow to the tank.\n\n\n\n\n\n\n\nIf there’s any deviation from the desired water level, the difference (error, \\(e\\)) will activate the controller - the float and lever mechanism. This controller adjusts the valve position, \\(u\\), proportional to the error signal.\n\\[\n\\text{Control variable}\\;\\;\\;\\;u = \\frac{l_1}{l_1+l_2}e = Ke\n\\]\nAs water flows in, the error decreases, eventually reaching zero, causing the valve to close. Note that we can change \\(K\\) changing the position of the point \\(B\\).\n\n\n\n\n\n\n\n\n\nor in a more general form:\n\n\n\n\n\n\nFrom Raymond T. Stefani, Bahram Shahian and Clement J. Savant, “Design of feedback control systems”, 4th edition, Oxford University press, 2001.\nNote that the disturbance is the water outflowing the water tank.\nTerminology: - Set-point: constant command signal - Regulator: control system that aims at keeping the controlled variable at the set-point.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html#automobile-driving-control-system",
    "href": "basics_of_feedback_control.html#automobile-driving-control-system",
    "title": "Introduction to Feedback Control Systems",
    "section": "Automobile Driving Control System",
    "text": "Automobile Driving Control System\nAnother familiar example is an automobile driving system, which can control both its direction (heading) and speed.\nObjective: Control the vehicle’s heading and speed.\n\nControlled Variables: Heading and Speed.\nCommand Signals: Direction of the highway and speed limits.\nDisturbances: Wind force, road, and traffic conditions.\nManipulated Variables: Steering and accelerator/brake position.\n\n\n\n\n\n\n\nFrom M. Gopal, “Control System Principles and Design”, McGraw-Hill, 3rd Edition.\nThis system presents an interesting aspect: it has multiple input and output variables. Such systems are commonly referred to as MIMO (Multi-Input Multi-Output) or multivariable systems. This is in contrast to the bathroom toilet tank example, which was a SISO (Single Input Single Output) or scalar system.\nThe complexity in designing MIMO systems often arises from the interactions (or couplings) between inputs and outputs. For instance, while steering primarily affects the vehicle’s direction, applying brakes, which might lock up the wheel, could impact both speed and direction.\nIn many cases, however, these interactions may be negligibly small. When that happens, the system can be treated as two separate single input single output (SISO) systems. For example:\n\nSystem 1: Where the input is a steering command and the output is the heading of the vehicle.\nSystem 2: Where the input is acceleration or brake position and the output is the speed of the vehicle.\n\nBreaking down a multivariable system into SISO systems can greatly simplify the design process. This is why, despite the prevalence of multivariable systems in the industrial sector, many designs focus on SISO systems. They are foundational and crucial.\nWe primarily focus on the design of single input single output systems. This approach does not imply that industries only deal with SISO systems. Instead, it highlights the frequent instances where interactions in a multivariable system can be neglected, allowing it to be treated as multiple SISO systems.\nLet’s go back to the Automobile Control System and deep dive into the variuos components:\n\nActuator: This transforms an electrical signal into mechanical action. In our vehicle system, we can think of the accelerator pedal as an actuator. Similarly, for braking, our foot acts as an actuator.\nError Detector: Essential for feedback systems, this block detects the difference between the desired and actual state. In the context of driving, our eyes serve as the error detector.\nControl Logic: Located in the brain of the driver, it processes information to make decisions.\nCommands: These are dynamic and change based on external factors such as traffic signals and road directions.\n\nTerminology - When the system’s purpose is to make the controlled variable (like speed or direction) follow time-varying commands, it’s referred to as a tracking system or command following system. - We refer to regulators when their purpose is to follow a non-time varying signal.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html#hydraulic-power-steering-mechanism",
    "href": "basics_of_feedback_control.html#hydraulic-power-steering-mechanism",
    "title": "Introduction to Feedback Control Systems",
    "section": "Hydraulic Power Steering Mechanism",
    "text": "Hydraulic Power Steering Mechanism\nHydraulic power steering offers an intuitive example of a feedback system.\nThe hydraulic power steering mechanism is a vital component in many vehicles, allowing the driver to steer the car with ease. It leverages hydraulic pressure to assist the steering action, thus ensuring smoother control, especially when parking or navigating tight spaces.\n\nHow it Works\n\nSteering Wheel Movement: When the driver turns the steering wheel, it rotates the steering gear.\nHydraulic Fluid Flow: This rotation acts on the control valve, which directs the hydraulic fluid either to the left or right of the piston.\nPiston Movement: The hydraulic fluid pressure acts on the piston inside the cylinder, making it move to one side. This movement assists in turning the wheels of the car.\nFeedback: The movement of the wheels generates feedback, which adjusts the flow of hydraulic fluid, ensuring that the steering wheel and the actual wheels of the vehicle are in alignment.\n\n\n\n\n\n\n\nTo properly analyze and design for such a system:\n\nModel the System: Develop a mathematical representation. For instance, a physical model for this mechanical system might interconnect mass, spring, and friction elements.\nConstruct a Block Diagram: This would depict how different components like the command signal, error detector, plant (like piston and load), and others interact.\nConsider Disturbances: Every feedback mechanism should account for external disturbances. In the context of driving, this could be wind or variations in load on the vehicle.\n\nThe previous system can be approximated with (we will see the details in a later notebook):\n\n\n\n\n\n\nand represented via the following block-diagram:\n\n\n\n\n\n\nNote that: - The feedback part is highligthed within the dashed line - We will focus on this part during the rest of the course. - Additional blocks might be needed to convert signals as needed: - Set of reference input elements; Adjustment mechanisms (steering gear) - Indirectly controlled system elements\nTerminology - The reference signal (or reference variable) \\(x\\) is proportional to the command signal \\(\\theta_r\\), and the steering gear is in between. - The command signal and the reference variable in a particular system may be one and the same thing, but they might be different - The output signal \\(\\theta_0\\) (position of the wheels) is dependent on the controlled variable \\(y\\). We talk about an indirectly controlled variable.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html#residential-heating-system",
    "href": "basics_of_feedback_control.html#residential-heating-system",
    "title": "Introduction to Feedback Control Systems",
    "section": "Residential Heating System",
    "text": "Residential Heating System\nA feedback control system regulates the behavior of a system by comparing its output with a desired command (or reference) signal. The difference between these two signals forms an error signal, which the control system uses to adjust its output to minimize or eliminate the error. We’ll now delve into this concept using a residential heating system as an example.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure: Open-loop temperature control (From Control systems principles and design)\n\nIn an open-loop system, there is no automatic adjustment of any errors in output temperature that may occur (or any other disturbances like radiator aging, etc).\nIf there is any error, it must be spotted by the heating-system operator and then the required alteration must be done manually.\nIn open-loop control, we must reset the controller input values or live with the consequences overheated rooms, excessive use of energy, etc. The way to rectify this is to inform the controller on-line about what is going wrong.\n\n\nMaking the residential heating system a feedback system\nComponents:\n\nCommand Signal: This is the desired system output. In our residential heating example, it’s the preset temperature the user desires for the room.\nReference Variable: This translates the command signal into a form the system can use. For the heating system, it’s the displacement of a set screw which adjusts the gap between the thermostat and a snap action switch (or the steam flow rate - however we can consider this also as an indirectly controlled variable).\nPlant: room radiator\nControlled Variable: It’s the room temperature.\nIndirectly Controlled Variable: This is a translation of the controlled variable to achieve the desired work. For the heating system, it might be the amount of steam flow or the valve opening.\n\nWe need a sensor. In this case, we use a the thermostat made of a bimetallic strip made of materials with very different thermal expansion characteristsis so that is curls due to temperature changes.\n\n\n\n\n\n\n\n\n\nA dial sets the desired room temperature (Command Signal).\nThis desired temperature sets the distance between the thermostat and a snap action switch (Reference Variable).\nThe thermostat, made of a bimetallic strip, curls due to temperature changes. The strip’s curling controls the snap action switch, which in turn controls the solenoid and plunger, adjusting the valve opening and the steam flow.\nThe actual room temperature is affected by this steam flow (Controlled Variable).\nIf the room temperature goes above or below the set temperature, the bimetallic strip moves, causing a series of actions that adjust the steam flow to bring the temperature back to the desired level.\n\nThe described system works on an “on-off” control logic. The valve is either fully open (on) or fully closed (off). This approach can result in the room temperature oscillating between two setpoints around the desired temperature.\nSuch an oscillatory behavior is often acceptable for residential heating. The range of temperature fluctuation can be adjusted based on user preferences or system design.\nThe importance of Feedback\nThe system will work perfectly provided there is no disturbance on the system. A feedback system can adjust and adapt to disturbances or changes in the environment. For instance: - If environmental temperature changes, an open-loop heating system might not maintain the desired room temperature. But a feedback system would adjust its output (steam flow in our case) to counteract these disturbances. - The design and efficiency of the radiator can change over time due to wear, aging, and other factors. A feedback system can adapt to these changes and maintain consistent performance.\nDisturbances: Two types of disturbances can affect a system:\n\nInternal Disturbances: Changes within the system itself, like the aging of radiator tubes.\nExternal Disturbances: External factors affecting the system, such as the external environmental temperature.\n\nA feedback system is especially valuable in environments with frequent or significant disturbances. It continuously adjusts and adapts to maintain the desired output, ensuring consistent performance.\nLet’s write a Python script to simulate and plot the temperature control of a room using an on-off controller\n\nThe room has a desired temperature (set_point).\nThe on-off controller will turn on the heater when the temperature drops below set_point - delta and will turn off when the temperature goes above set_point + delta (where delta is a small temperature difference to prevent frequent on-off switches).\nThe temperature will rise when the heater is on and drop due to environmental effects when the heater is off.\nFor the sake of simplicity, we will model the temperature change with linear equations.\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Parameters\nset_point = 20  # Desired room temperature in degrees Celsius\ndelta = 1   # Tolerance in degrees Celsius. This is simulating the time it takes for the thermostat to kick in.\nduration = 300  # Simulation time in minutes\nheating_rate = 0.1  # Temperature rise per minute when heater is on\ncooling_rate = 0.05  # Temperature drop per minute when heater is off\ninitial_temp = 18  # Initial room temperature\n\n# Initialize lists to store results\ntimes = np.arange(0, duration, 1)\ntemperatures = [initial_temp]\nheater_status = [0]  # 0: off, 1: on\n\n# On-off controller simulation\nfor t in times[1:]:\n    current_temp = temperatures[-1]\n    if current_temp &lt; set_point - delta:\n        heater_status.append(1)\n        temperatures.append(current_temp + heating_rate)\n    elif current_temp &gt; set_point + delta:\n        heater_status.append(0)\n        temperatures.append(current_temp - cooling_rate)\n    else:\n        heater_status.append(heater_status[-1])\n        if heater_status[-1] == 1:\n            temperatures.append(current_temp + heating_rate)\n        else:\n            temperatures.append(current_temp - cooling_rate)\n\n# Plotting\nfig, ax1 = plt.subplots()\n\nax1.set_xlabel('Time (minutes)')\nax1.set_ylabel('Temperature (°C)', color='tab:blue')\nax1.plot(times, temperatures, label='Room Temperature', color='tab:blue', linewidth=3)\nax1.axhline(y=set_point, color='r', linestyle='--', label='Set Point')\nax1.tick_params(axis='y', labelcolor='tab:blue')\nax1.legend(loc='upper left')\n\nax2 = ax1.twinx()\nax2.set_ylabel('Heater Status', color='tab:orange')\nax2.step(times, heater_status, label='Heater Status', color='tab:orange')\nax2.tick_params(axis='y', labelcolor='tab:orange')\n\nplt.title('On-Off Temperature Controller')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nIn a residential heating application the oscillation (e.g., 20 degree centigrade plus minus 1 degree) might be tolerated\nThis type of control logic is called on/off control (or bang/bang control)\n\nWe can place this within a more general block diagram:\n\n\n\n\n\n\n\n\nThe temperature regulation loop can be broken down into several components:\n\nFeedback Action (Sensor): Represented by the thermostat. The desired room temperature, θ, is continuously compared against the actual temperature by this thermostat.\nController: The amalgamation of the thermostat and the switch functions as the controller. The role of the controller is to modulate the current based on feedback.\nActuator: This is a vital component that produces a suitable manipulated signal for the plant, often amplifying the input to a level suitable for driving the plant. In our heating system, the actuator is a combination of the solenoid and valve. Its output is the steam flow that heats the room.\nPlant: This is the system we want to control—in this case, the room radiator.\nDisturbance: External factors, such as environmental temperature, that might affect the plant.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "basics_of_feedback_control.html#block-diagram-of-the-basic-feedback-structure",
    "href": "basics_of_feedback_control.html#block-diagram-of-the-basic-feedback-structure",
    "title": "Introduction to Feedback Control Systems",
    "section": "Block Diagram of the Basic Feedback Structure",
    "text": "Block Diagram of the Basic Feedback Structure\n\n\n\n\n\n\n\n\\(y_r\\): The command signal. This could represent temperature, displacement, water level, etc.\n\\(A\\): Block for reference input elements responsible for generating the reference signal, \\(r\\).\n\\(b\\): Feedback signal compared against \\(r\\) to produce an actuating error signal, \\(\\hat{e}\\)\n\\(D\\): The controller or control logic block that generates a control signal \\(u\\) based on \\(\\hat{e}\\). Sometime the definition of the controller includes the error detector.\n\\(G_A\\): The actuator block, increasing the power level of the signal to drive the plant, producing a manipulated signal.\n\\(G_P\\): The plant or process, which takes in the manipulated signal \\(m\\) and disturbances \\(w\\) to produce the output \\(y\\).\n\\(w\\): disturbance acting on the plant\n\\(y\\): manipulated variable (output)\n\\(H\\): feedback system element (sensor), which produces the feedback signal \\(b\\).\n\\(Z\\): indirectly controlled system (not part of the feedback)\n\\(q\\): indirectly controlled output\n\nNote: Not every system will include every block or variable listed, but this structure serves as a foundation for understanding the information flow in feedback control systems.",
    "crumbs": [
      "Introduction to Feedback Control Systems"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Feedback Control",
    "section": "",
    "text": "The course provides an extensive foundation in control engineering, covering both theoretical concepts and practical applications.\nIt is for second-year undergraduate students and anyone interested in understanding the principles of automatic controls.\nTeaching semester: Spring 2024\nLanguage of instruction: Italian and English",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#course-coordinator",
    "href": "index.html#course-coordinator",
    "title": "Feedback Control",
    "section": "Course coordinator",
    "text": "Course coordinator\nAndrea Munafo",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#lecturers",
    "href": "index.html#lecturers",
    "title": "Feedback Control",
    "section": "Lecturer(s)",
    "text": "Lecturer(s)\nAndrea Munafo",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Feedback Control",
    "section": "How to use",
    "text": "How to use\nEach notebook is thought to be independent from every other, so it is possible to run them in any order you prefer.",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Feedback Control",
    "section": "Install",
    "text": "Install\nThe notebooks run with python 3.9 and use the following python libraries: - python control - numpy - pandas - matplotlib\nYou can optionally install ‘sympy’ to do symbolic computations in Python.\nNotebook 01_Getting_started_with_Python_and_Jupyter_Notebook.ipynb provides a short introduction on how to set up an anaconda environment to get you started.\nTo use all notebooks you might need to install the feedback control package. You can do this entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package during development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#acknowledgements-and-references",
    "href": "index.html#acknowledgements-and-references",
    "title": "Feedback Control",
    "section": "Acknowledgements and references",
    "text": "Acknowledgements and references\n\nRelevant textbooks used to prepare these notebooks are reported in 00_Syllabus.ipynb.",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Feedback Control",
    "section": "Additional resources",
    "text": "Additional resources\n\nControl systems academy\nProcess Dynamics and Control in Python\nKarl J. Åström and Richard M. Murray, Feedback Systems: An Introduction for Scientists and Engineers\nLecture series on Control Engineering by Prof. Madan Gopal\nDesigning Lead and Lag Compensators in Matlab and Simulink\nControl Systems Basics",
    "crumbs": [
      "Feedback Control"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html",
    "href": "ac_hardware_and_case_studies.html",
    "title": "AC Motion Control Systems",
    "section": "",
    "text": "In previous notebooks, we discussed motion control systems using specific hardware. We touched upon the utilization of a DC motor as an actuator, a DC tachogenerator as a speed sensor, a potentiometer for position sensing, and other associated hardware. Our exploration was majorly rooted in DC-based components.\nThis notebook focuses on a different set of hardware to have AC Motion Control Systems.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#comparing-dc-and-ac-systems",
    "href": "ac_hardware_and_case_studies.html#comparing-dc-and-ac-systems",
    "title": "AC Motion Control Systems",
    "section": "Comparing DC and AC Systems",
    "text": "Comparing DC and AC Systems\nBefore we dive deep, let’s recall our earlier discussions. In motion control systems, we analyzed two main types: Position Control Systems and Speed Control Systems. The principle remains the same, but the hardware and sometimes the intricacies change when we transition from DC to AC components.\n\nDC System Components:\n\nActuator: DC Motor\nSpeed Sensor: DC Tachogenerator\nPosition Sensor: Potentiometer\n\n\n\nAC System Components:\n\nActuator: Two-phase Servo Motor\nSpeed and Position Sensor: Synchro (and other devices which we will discuss)",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#the-two-phase-servo-motor",
    "href": "ac_hardware_and_case_studies.html#the-two-phase-servo-motor",
    "title": "AC Motion Control Systems",
    "section": "The Two-phase Servo Motor",
    "text": "The Two-phase Servo Motor\nOur first point of discussion is the two-phase servo motor.\nThis actuator is tasked with producing the required torque to drive the load.\n\n\n\n\n\nIt’s called ‘two-phase’ because, as evident from its name, it operates using two phases. One phase is dubbed the ‘control phase’, and its importance will become apparent soon. The other is termed the ‘reference phase’. The rotor carries the load, which can either be directly on the rotor or via a gear train.\n\nThe key reason behind using two phases (or the “split-phase” concept) in certain types of AC motors is to generate a rotating magnetic field which is essential for motor operation. In a three-phase AC motor, the three phases naturally create a rotating magnetic field. In a single-phase AC motor, the magnetic field merely alternates but doesn’t rotate. To overcome this, dual-phase motors utilize two windings, with a phase difference, to simulate the rotating field.\nRole of the Two Phases: - Starting Torque: One of the primary reasons for having two windings (or phases) is to produce a starting torque. Single-phase motors, without any phase-shifting mechanism, don’t inherently have a starting torque, which means they won’t start rotating on their own. - Rotating Magnetic Field: By introducing a phase difference between the two windings, usually through a capacitor or by designing the windings differently, a phase lag is created between the currents in the two windings. This phase difference results in a rotating magnetic field essential for the motor operation.\n\nFor simplification, let’s represent the load parameters as ‘J’ and ‘B’. The rotor generates a torque \\(T_M\\) and faces a disturbance torque \\(T_\\omega\\) which opposes \\(T_M\\).\n\nGiven this setup, the next component of interest is the phase-shifting capacitor** in the reference phase. Its role is pivotal. It ensures that we can derive a two-phase supply from a single-phase voltage source. This capacitor induces a phase difference of 90 degrees between the two phases.\n\nThe reference phase gets a voltage supply of the form \\(E_r\\cos\\omega_{c}t\\), where \\(\\omega_{c}\\) is termed the carrier wave frequency, and \\(E_r\\)is the reference voltage.\n\nThe control phase is connected to a Modulator. The input to the Modulator is the control voltage \\(e_c\\). This is always a low frequency voltage in a control system.\n\n\nComments\n\nRemember that in a control system the objective is to make the error zero. For example, the error could be a position or speed error.\nIf the control system is functioning well, the error will be a low frequency signal and small signal.\n\nIf we consider \\(e_c\\) as the error signal and enter as the input for the motor I would like to modulate this signal with frequency \\(\\omega_c\\), the carrier frequency.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#ac-motors-and-precision-control",
    "href": "ac_hardware_and_case_studies.html#ac-motors-and-precision-control",
    "title": "AC Motion Control Systems",
    "section": "AC Motors and precision control",
    "text": "AC Motors and precision control\nThis notebook focuses on two-phase AC motors that are used in precision control applications. In this context, modulated control is implemented to achieve a desired performance characteristic, particularly in systems like servo drives. Let’s break down the components:\n\n1. Control Phase Voltage (\\(e_c\\)):\nThis is essentially the ‘input’ or the ‘control’ voltage. It carries the information about how you want the motor to behave. For instance, if you want the motor to rotate at a certain speed or move to a certain position, this is encoded in \\(e_c\\). It’s your way of telling the motor what to do.\n\n\n2. Modulated Voltage (\\(e_m\\)):\nThis is the ‘output’ voltage, which is generated after modulating the control voltage with a reference. Modulation serves multiple purposes:\n\nImproved Performance: By modulating with a high-frequency carrier, motor performance can be enhanced. For instance, high-frequency modulation can reduce torque ripples in the motor.\nNoise Immunity: High-frequency signals tend to be less susceptible to low-frequency noise. This is beneficial in an industrial environment where there might be lots of electrical noise.\n\nThe control phase voltage (\\(e_c\\)) encodes the desired behavior of the motor. This might represent a desired speed, torque, or position. When this control voltage is combined (modulated) with the high-frequency reference voltage (\\(E_r\\)), the resulting modulated voltage (\\(e_m\\)) is applied to the second winding (often called the control or modulation phase).\n\n\n3. Reference Voltage (\\(E_r\\)):\n\\(E_r\\) is the carrier wave. This is a high-frequency signal that does not inherently contain any information about motor control. However, when \\(e_c\\) (the low-frequency control signal) is modulated with \\(E_r\\), the result is \\(e_m\\), which has properties of both the control signal and the carrier wave.\n\n\nWhy is the reference voltage applied only to the reference phase?\nBy applying the reference voltage to only one phase (often called the reference phase), the modulation is more effective in creating a differential or relative control across the phases. This differential can be more effective in creating the desired torque and speed in the motor.\n\nA two-phase AC motor has two windings, typically set 90 degrees apart. The currents through these windings, when they’re out of phase, produce magnetic fields that combine to form a resultant rotating magnetic field. This rotating field is what causes the rotor to turn.\nApplying the reference voltage, typically a high-frequency signal, to this phase establishes a baseline or “reference” magnetic field.\n\nBy applying the reference voltage only to the reference phase, the motor setup can create a differential magnetic field. This differential magnetic field, relative to the reference, effectively governs the behavior of the motor.\nWhen the high-frequency reference voltage is applied to the reference phase and the modulated control voltage is applied to the other phase, the resultant magnetic field’s orientation and magnitude depend on the modulated signal. This allows for precise control of the motor’s position or speed based on the characteristics of the modulated signal.\nIf the reference voltage were applied to both phases, it would not produce a differential effect and would fail to produce the desired precision control.\nIn essence, by designating one winding as a “reference” and the other as “control,” and then applying appropriate voltages to each, the system can create a rotating magnetic field with a controllable direction and magnitude, which is essential for precision control in applications like servo systems.\n\n\nRole of the AC Supply:\nDespite all these control methodologies, the motor still requires power to operate. The AC supply provides this necessary power to drive the motor. All the aforementioned voltages (\\(e_c\\), \\(e_m\\), \\(E_r\\)) are about control and modulation, but none of them directly provide the bulk power needed to turn the motor. That’s where the AC supply comes in.\n\n\nIn Summary:\nThink of the entire process as analogous to an FM radio. In FM (Frequency Modulation) broadcasting, you have a base high-frequency signal (similar to \\(E_r\\)), which is modulated by a low-frequency audio signal (similar to \\(e_c\\)). The result is a modulated high-frequency signal (like \\(e_m\\)) that can be transmitted. The radio then demodulates this signal to extract and play the audio. Similarly, in the motor control scenario, modulation is used to combine control information with a high-frequency carrier for better motor performance. The actual power to make everything work, however, comes from the main AC supply.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#amplitude-modulation-am",
    "href": "ac_hardware_and_case_studies.html#amplitude-modulation-am",
    "title": "AC Motion Control Systems",
    "section": "Amplitude Modulation (AM)",
    "text": "Amplitude Modulation (AM)\nIn AM, the amplitude of the high-frequency carrier wave (\\(E_r\\)) is varied in accordance with the instantaneous amplitude of the control signal (\\(e_c\\)).\nTo modulate the carrier using the error signal, we’ll take the product of the error signal and the carrier signal. This results in an Amplitude Modulated (AM) signal.\nThe envelope of an amplitude modulated (AM) signal corresponds to the instantaneous amplitude of the signal, which in our case is represented by the error signal.\n\nModulation process:\n\nCarrier Wave (\\(E_r\\)):\n\nThis is a high-frequency sinusoidal waveform, which acts as a reference signal. Mathematically, it can be represented as:\n\\[\nE_r(t) = A_c\\sin(2\\pi f_ct)\n\\]\nwhere - \\(A_c\\) = Amplitude of the carrier wave - \\(f_c\\) = frequency of the carrier wave\n\nControl Signal (\\(e_c\\)): This is the signal you want the motor to follow. It could represent desired speed, position, etc.\n**Modulated Signal (\\(e_m\\)): The result of the modulation process. In AM: \\[\ne_m(t) = \\big[ A_c+e_c(t)\\big]\\sin(2\\pi f_ct)\n\\]\n\n\n\nPractical Modulation Circuit:\nA common circuit used to achieve amplitude modulation is the multiplier circuit. This circuit multiplies two input signals to produce an output signal.\n\nFeed \\(E_r\\) and \\(e_c\\) into the two inputs of the multiplier\nThe output \\(e_m\\) is the product of the two input signals\nhis output, which contains frequency components of both \\(E_r\\) and \\(e_c\\), is then passed through a bandpass filter to extract the desired modulated signal if needed.\n\nNowadays with communication transceivers being very digitized, the modulation is mostly done in the digital domain using a DSP type block.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time values\nt = np.linspace(0, 10, 1000)\n\n# Define the error signal (decreasing oscillating signal starting from its maximum)\nerror_signal = (1 / (1 + 0.2 * t)) * np.sin(2 * np.pi * .2 * t + np.pi/2)  # Added phase shift of pi/2\n\n# Define the carrier signal\nomega_c = 2 * np.pi * 5  # carrier frequency (for example, 10Hz)\ncarrier_signal = np.cos(omega_c * t)\n\n# Modulate the carrier using the error signal\nmodulated_signal = error_signal * carrier_signal\n\n# Plot\nplt.figure(figsize=(12, 8))\n\n# Plot the error signal\nplt.subplot(3, 1, 1)\nplt.plot(t, error_signal, label=r'Error Signal $e_c$', color='blue')\nplt.title(r'Error Signal $e_c$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the carrier signal\nplt.subplot(3, 1, 2)\nplt.plot(t, carrier_signal, label='Carrier Signal: cos(ωc t)', color='green')\nplt.title('Carrier Signal')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the modulated signal\nplt.subplot(3, 1, 3)\nplt.plot(t, modulated_signal, label='Modulated Signal', color='red')\nplt.title(r'Amplitude Modulated Signal $e_m$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the positive envelope (absolute value of the error signal)\nplt.plot(t, np.abs(error_signal), '--', label='Positive Envelope', color='blue', linewidth=1.5)\n\n# Plot the negative envelope (negative of the absolute value of the error signal)\nplt.plot(t, -np.abs(error_signal), '--', label='Negative Envelope', color='green', linewidth=1.5)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nNote that when the sign of \\(e_c\\) changes, the phase of the modulated signal \\(e_m\\) reverses (maximum of \\(e_c\\) are the minimum of \\(e_m\\)).\nBecause of this phase reversal, the magnetic flux takes place and the direction of the motor also reverses. This is a bi-directional control:\n\nwhen \\(e_c&gt;0\\) the motor moves in one direction\nwhen \\(e_c&lt;0\\) the motor moves in the opposite direction\n\n\\(e_m\\) is a carrier modulated wave at the frequency \\(\\omega_c\\)\nthe reference voltage \\(e_c\\) is at the frequency \\(\\omega_c\\)\n\nIn conclusion: These two voltages applied to the two motor phases will produce a torque on the motor. The torque will be a function of \\(e_c\\) (\\(e_r\\) being a fixed voltage) and its direction will be a function of the sign of \\(e_c\\).\n\n\nTorque-speed characteristics of the AC motor\nA comparative view with the DC motor shows that while the latter presents almost linear torque-speed characteristics, the AC motor’s curve is evidently non-linear.\nThe torque-speed curve of a typical shunt DC motor is relatively straightforward compared to an AC motor. The torque is roughly linearly dependent on the armature current, and as the speed increases, the torque generally decreases linearly due to the motor’s back EMF (electromotive force) opposing the supply voltage.\nThe linear characteristics of DC motors is an advantage because the model is simpler.\nIf we do an experiment these are typical curves that we would obtain:\n\n\n\n\n\nOnce torque-speed curves for motors are determined experimentally, the resultant data can pave the way for the formulation of precise mathematical models.\nSuch a non-linear characteristic of AC motors can pose challenges, especially if we wish to operate them over a wide range. But, one of the saving graces for AC motors is their almost linear behavior around the zero speed, making them suitable for position control systems.\nAt steady state, the speed is zero and the position of the load is equal to the commanded position: the motor does not move. Around this point you have a linear behaviour that we can use and model.\nFor this reason, we will only focus on the linear models of the AC motors, under the assumption that the operating point is speed = 0.\n\n\nLinear Torque Equation for AC Motors\nGiven that for our position control problem we can assume that the operating point is \\(\\text{speed}=0\\), the torque equation is a function of the control voltage \\(e_c\\), and of the speed \\(\\dot{\\theta}\\):\n\\[\nT_M = K_1e_c-K_2\\dot{\\theta}\n\\]\nwhere: - \\(K_2\\) is the determining factor to relate torque and speed and is the slope of the linear approximation of the Torque-Speed curves in the AC Motors plot above (when speed \\(\\approx\\) 0). - The control voltage \\(e_c\\) is key because it causes it to move from one curve to another (in the diagram above \\(e_{c_1}&gt;e_{c_2}&gt;e_{c_3}\\)) - When the control voltage increases, the torque increases - When the speed increases, the torque decreases\nOnce the curves are experimentally determined, we can get the corresponding parameters for our linear model.\n\nFrom the Torque-Speed curves in the AC Motors plot above we can directly infer the constant \\(K_2\\)\nTo obtain \\(K_1\\), one could plot the control phase voltage \\(e_c\\) against the torque \\(T_m\\) (see plot below). The slope of the resultant line under conditions of constant speed (say \\(\\omega = 0\\)), will provide the value for \\(K_1\\). This approach assumes a linearity model for a device, which holds true for certain operation ranges.\n\n\n\n\n\n\n\n\nAC Motor Equation\nWe are now ready to write the mathematical model of the AC motor:\n\\[\nT_M = K_1e_c-K_2\\dot{\\theta} = J \\ddot{\\theta} + B\\dot{\\theta} + T_W\n\\]\nwhere we have now added the load and: - \\(T_M\\) is the Torque developed by the motor - \\(e_c\\) is the control phase voltage - \\(\\dot{\\theta}\\) is the speed of the motor - \\(K_1\\) and \\(K_2\\) are constant experimentally determined - \\(J \\ddot{\\theta}\\) is the inertial load - \\(B\\dot{\\theta}\\) is the damping - \\(T_W\\) is the disturbance torque on the system.\nWe can re-write the equation above as:\n\\[\nK_1e_c = J \\ddot{\\theta} + (B+K_2)\\dot{\\theta} + T_W\n\\]\nwhere \\(e_c\\) is my input.\n\n\nAC Motor Block Diagram\nThis entire discourse can be visually represented using a block diagram, highlighting the relationships between \\(e_c\\), \\(\\theta\\), \\(\\omega\\), and other system parameters.\n\n\n\n\n\nThrough the block diagram representing the system, it is possible to derive a transfer function, linking \\(e_c\\) (input) and \\(\\omega\\) or \\(\\theta\\) (output).\n\nTransfer function between \\(\\omega\\) and \\(e_c\\):\n\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_1}{Js+B+K_2}\n\\]\n\nNote that \\(K_2\\) is adding to the system’s mechanical damping, reminiscent of the DC armature controlled motor’s behavior.\n\\(K_2\\) directly adds to the damping, affecting the stability and response of the system. Moreover, the time constant of the system becomes \\[\n\\tau = \\frac{J}{B+K_2}\n\\]\n\nindicating that \\(K_2\\) influences how fast the system responds to changes.\n🤔 Popup Question: How does the magnitude of \\(K_2\\) impact the damping and time constant of the system?\nAnswer: \\(K_2\\) directly adds to the damping, affecting the stability and response of the system. Moreover, the time constant of the system becomes \\(\\tau = \\frac{J}{B+K_2}\\) indicating that \\(K_2\\) influences how fast the system responds to changes.\n\nSidebar - a typical induction motor\nThe torque speed characteristics of a normal induction motor is reported in the graph below.\n\n\n\n\n\nCan we use this two-phase induction motor for servo applications?\nTo answer this question consider the transfer function\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_1}{Js+B+K_2}\n\\]\nwhere \\(K_2\\) adds to the damping.\nIf \\(K_2\\) is negative, depending on its relationship to \\(B\\) (remember that it enters in \\(B+K_2\\)), might lead to instability.\nA characteristic curve, especially one that exhibits a negative slope, may introduce negative damping, leading to excessive oscillations and possibly culminating in instability or excessive oscillations (hunting) in the system. \\(B\\) should be extremly high to counteract the effects of a negative \\(K_2\\).\nFor this reason, a normal induction motor is never used for servo applications (position or speed controlled systems).\n🤔 Popup Question: Why might an ordinary induction motor not be suitable for servo applications?\nAnswer: An ordinary induction motor might exhibit characteristics where the slope becomes negative, introducing the possibility of negative damping, which could lead to instability or excessive oscillations in the system, especially in the context of servo applications where precise control is important.\nRecall that the torque-speed characterists of the AC servo motors that we used are reported in the picture below (left):\n\n\n\n\n\n\nThese characteristics have an always positive \\(K_2\\).\n\n\n\nAchieving positive slope torque-speed characteristics\n\nThese characteristics are obtained directly from the induction motor, specifically by using a high rotor resistance.\n\nA higher rotor resistance ensures that the motor’s response characteristics remain positive.\nIn essence, a servo motor is an induction motor with high rotor resistance. Such a design choice ensures the servo motor’s characteristics always exhibit a positive slope. However, this choice comes with trade-offs:\n\nHigh rotor resistance means the overall system efficiency will be reduced.\nDespite the reduction in efficiency, the design is essential for specific applications like servo systems where a negative slope could be detrimental.\n\n— END OF SIDEBAR\n\n\n\nGoing Back to the Motor Model\nLet’s look at the mathematical representation of the motor:\nThe motor model is given by:\n\\[\n\\frac{\\omega}{e_c} = \\frac{K_m}{\\tau_m s + 1}\n\\]\nwhere: - \\(\\omega\\) is the speed of the motor - \\(e_c\\) represents the control voltage - \\(K_m\\) is the motor gain - \\(\\tau_m\\) is the mechanical time constant of the motor.\nThis is a first-order system between speed and the control voltage.\n🤔 Popup Question: Why is the equation between \\(\\theta\\) (position) and control voltage is a second-order system?\nAnswer: The equation for \\(\\theta\\) incorporates an additional factor of ‘s’ due to the integral relationship between speed and position.\nThe motor model between \\(e_c\\) and \\(\\theta\\) is given by:\n\\[\n\\frac{\\theta}{e_c} = \\frac{K_m}{s\\big(\\tau_m s + 1\\big)}\n\\]\nAnd this is the same as the armature controlled DC motor (which is a second-order model).\n\n\nUnderstanding Control Phase Voltage\n\n\\(e_c\\) or control phase voltage is typically a low-frequency signal.\n\n\n\n\n\n\n\nConsider the situation where the control phase voltage might directly be a high-frequency modulated signal.\n\nIn this case your input is \\(e_m\\) and the output is \\(\\theta\\). Let’s see what is the transfer function between them.\n\n\nSidebar - understanding the input of the AC motor - Carrier Modulated Signal\nTo understand the input to the motor let’s consider a feedback system:\n\n\n\n\n\n\nThe input to the motor is the control phase voltage \\(e_c\\). That however depends on the device (e.g., an amplifier) between the summing junction and the motor.\nThe control phase voltage \\(e_c\\) depends on ‘Device’. This device might produce a low frequency signal exactly as we discussed so far.\nSuppose instead that this devide produces a Carrier Modulated Signal and this is the signal used as control phase voltage \\(e_c\\)\n\nIf the input signal is the one reported below (ampliture modulated signa):\n\nThe actual control information is embedded in the envelope of the modulated signal.\nThe carrier frequency (like 50 Hz, 400 Hz, 1000 Hz) is primarily an operational aspect and depends on the motor design. It is the operational frequency of the motor. It depends on what the manufacturer has given us.\nThe operating frequency (the carrier frequency) can be selected for example based on the noise frequency. If we know that the motor will work in an environment where there are low frequency noise I should choose a high carrier frequency. In environments like aircraft systems, there’s abundant low-frequency noise. Using a high-frequency motor like 1000 Hz helps reduce the impact of this noise. For ground applications we typically use lower frequency. It depends on the application.\n\nIn this case, the mathematical model of the system can be taken as the relationship between the speed (\\(\\omega\\)) or the position (\\(\\theta\\)) - output - and the envelope of the carrier modulated signal - input -.\nIn summary:\n\nif the input signal is directly a low frequency signal and is going to the AC motor through a modulator, that low frequency signal will be taken as the input for the motor\nif the input signal to the motor is a carrier modulated signal, then our input from a control perspective is the envelope of the modulated signal. This is what is carrying the information, for example represents the difference between the commanded position and actual position.\n\n\nLinking to the Mathematical Model\nTo reiterate, the mathematical model we use, \\(\\frac{\\omega}{e_c} = \\frac{K_m}{\\tau_m s+ 1}\\), focuses on the relationship between motor speed (\\(\\omega\\)) and the information-carrying signal \\(e_c\\). The carrier signal’s frequency is not of primary concern for our control applications.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Time values\nt = np.linspace(0, 10, 1000)\n\n# Define the error signal (decreasing oscillating signal starting from its maximum)\nerror_signal = (1 / (1 + 0.2 * t)) * np.sin(2 * np.pi * .2 * t + np.pi/2)  # Added phase shift of pi/2\n\n# Define the carrier signal\nomega_c = 2 * np.pi * 5  # carrier frequency (for example, 10Hz)\ncarrier_signal = np.cos(omega_c * t)\n\n# Modulate the carrier using the error signal\nmodulated_signal = error_signal * carrier_signal\n\n# Plot\nplt.figure(figsize=(6, 3))\n\n# Plot the modulated signal\nplt.subplot(1, 1, 1)\nplt.plot(t, modulated_signal, label='Modulated Signal', color='red')\nplt.title(r'Amplitude Modulated Signal $e_m$')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.grid(True)\nplt.legend()\n\n# Draw x=0 and y=0 axes\nplt.axvline(0, color='black', linewidth=2, linestyle='-')\nplt.axhline(0, color='black', linewidth=2, linestyle='-')\n\n# Plot the positive envelope (absolute value of the error signal)\nplt.plot(t, np.abs(error_signal), '--', label='Positive Envelope', color='blue', linewidth=1.5)\n\n# Plot the negative envelope (negative of the absolute value of the error signal)\nplt.plot(t, -np.abs(error_signal), '--', label='Negative Envelope', color='green', linewidth=1.5)\n\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nCarrier Modulated Signal (CMS) - further comments\nThe concept of a Carrier Modulated Signal (CMS) often arises in the context of communication and control systems, particularly when we need to transmit or utilize a signal that, by itself, isn’t suitable for direct transmission or application due to certain limitations.\nCarrier Modulated Signal (CMS): In essence, modulation involves changing some aspect of a higher frequency carrier wave in proportion to the lower frequency message signal that you want to send. The carrier wave, on its own, doesn’t carry any useful information. It’s the modifications made to it (modulation) by the message signal that conveys the desired information.\nWhy Modulate?: Let’s consider an analogy. Imagine you want to send a small paper boat across a large pond. If you simply place it in the water, it might not go far. But if you place it on top of a larger, powered boat (the carrier), it can travel across the pond effectively. In this analogy, the paper boat is like your low-frequency signal, and the larger boat is your carrier signal.\nLow-Frequency Signal vs. CMS: In many practical applications, low-frequency signals are challenging to transmit, apply, or detect for several reasons: - They might not effectively induce a response in certain systems. - They might be more susceptible to interference or noise. By modulating a carrier signal with the low-frequency signal, we can overcome these limitations.\nRelation to Motors: If you’re talking about using CMS in the context of motor control, the concept can be seen as similar to Pulse Width Modulation (PWM). With PWM, a high-frequency carrier (a square wave) is modulated in such a way that its duty cycle (the proportion of time it’s “on” versus “off”) represents the desired control signal, often for controlling motor speed or position.\nFor motors, this has benefits: - It allows for more efficient and rapid control. - The high-frequency nature of the carrier ensures efficient energy transfer and can reduce wear on motor components. - The actual power applied to the motor can be finely controlled by simply varying the duty cycle.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#ac-error-detector-and-synchro-transmitters-transformers-for-position-control-systems",
    "href": "ac_hardware_and_case_studies.html#ac-error-detector-and-synchro-transmitters-transformers-for-position-control-systems",
    "title": "AC Motion Control Systems",
    "section": "AC Error Detector and Synchro Transmitters-Transformers for Position Control Systems",
    "text": "AC Error Detector and Synchro Transmitters-Transformers for Position Control Systems\nOne key component necessary for understanding and executing position control systems is the AC error detector. In the given discourse, the AC error detector is explained through the introduction of two devices: the synchro transmitter and the synchro Control Transformer.\n\nSynchro Transmitter\nThe transmitter is a device that transmits an electrical signal corresponding to the angle of rotation of its shaft.\nFrom the outside, a synchro transmitter (or receiver) looks much like an ordinary small motor\n\n\n\n\n\nFigure from USNavy AUTOMATIC CONTROL EQUIPMENT\n\nA synchro transmitter is an AC transmitter. It’s constructed with a dumbbell-shaped rotor, through which an AC voltage is supplied via slip rings. The stator has three windings, schematically shown as S1, S2, and S3.\nThe three windings, with a 120-degree space distribution, allow for encoding the position of the rotor in a way that can be represented through three different voltages. You are not changing the AC voltage, you change the rotor position. When you change the rotor position the three voltages at the three terminal changes accordingly.\nThe AC voltage (a fixed voltage) given to the rotor produces a magnetic flux which, when linked with the stator windings, induces an EMF at terminals 1, 2, and 3. The voltages at these terminals carry the information of the rotor position, represented as theta (\\(\\theta\\)).\n\n\n\n\n\n\nWith respect to the diagram above, taking \\(S_2\\) as reference axis: - When \\(\\theta=0\\), the maximum flux (i.e., the maximumm voltage) is on \\(S_2\\) with value: $ e_{S_2n} = KE_r(_c t) $, where \\(K\\) is a constant that adjusts the amplitude as needed. - When \\(\\theta=0\\), the flux (i.e., the voltage) on \\(S_2\\) has value: \\(0\\)\nIn general, the mathematical relationship between the rotor position (\\(\\theta\\)) and the voltage (with respect to neutral \\(n\\)) can be expressed as:\n\\[\n\\begin{align}\ne_{S_2n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta)\\\\\ne_{S_1n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta -120^o)\\\\\ne_{S_3n} &= KE_r\\sin(\\omega_c t) \\cos(\\theta -240^o)\n\\end{align}\n\\]\nsince we do not have access to neutral, we have:\n\\[\n\\begin{align}\ne_{S_1S_2} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta+240^o)\\\\\ne_{S_2S_3} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta+120^o)\\\\\ne_{S_3S_1} &= \\sqrt{3}KE_r\\sin(\\omega_c t) \\sin(\\theta)\n\\end{align}\n\\]\nWe can calculate the above expression as:\n\\[\ne_{S_1S_2} = e_{S_1n} + e_{nS_2} = e_{S_1n} - e_{S_2n}\n\\]\nWith reference to equations (4-6):\n\nwhen \\(\\theta=0\\), \\(e_{S_3S_1} =0\\) and the rotor is in its null position (reference position of the rotor).\nwhen the rotor is in the null position, the maximum voltage is on the \\(S_2\\) winding, and the voltage across \\(S_3\\) and \\(S_1\\), \\(e_{S_3S_1} =0\\)\n\nNote also that only the amplitude of the voltages are changing. This is a single phase device. The three voltages are in phase.\nA synchro transmitter has an input which is the rotation of its shaft (\\(\\theta\\)) and the output are the three voltages\n\n\nSynchro Control Transformer\nIn the context of the position control system, another essential device is the synchro Control Transformer. This device shares many similarities with the synchro transmitter, except for its rotor construction. The rotor in this transformer is more cylindrical. This construction ensures a constant impedance as viewed by an accompanying signal conditioning device, ensuring that this impedance remains unaffected by the rotor’s position.\nIf the rotor is not cylindrical then impedance seen by the signal conditioning device is a function of the rotor position.\n\n\n\n\n\nNote that nothing prevented as to use a cylindrical rotor in the Synchro transmitter described above as well. However in that case was not a requirement and using a dambbell rotor probably is less expensive.\nThe signal conditioning device processes the output from the synchro Control Transformer and drives a motor. This motor controls the position of the rotor in the synchro Control Transformer. The two stator windings of the synchro transmitter and the synchro Control Transformer are interconnected, with the rotor position of one representing the reference and the other the controlled position.\nIn the control tranformer, the output of the signal conditioning device is going to a motor which controls the position of the cylindrical rotor.\nThe input for the overall system, composed of both a transmitter and a transformer, is the difference of the movements of the two shafts \\(\\theta_R\\) and \\(\\theta_C\\), and the output is the signal at the entry of the signal conditioning device, which is proportional to the difference of the two shaft positions.\n\nPotentiometer Pair Recall\nYou might recall our discussion about a potentiometer pair. To illustrate:\n\n\n\n\n\nFrom our study, the signal \\(e\\) can be represented as:\n\\[\ne = K_p\\big(\\theta_R - \\theta_C\\big)\n\\]\nhere, \\(K_p\\) is a potentiometric constant, and the expression emphasizes the difference between the two shaft positions.\n\n\n\nSynchro Pair Mechanics\nThe synchro pair operates in a similar way, but it specifically manages AC and focuses to high-frequency signals.\nLet’s continue reference our Synchro pair:\n\n\n\n\n\n\n\\(\\theta_R\\) denotes the reference position.\n\\(\\theta_C\\) symbolizes the controlled position.\n\nOur ultimate goal is to harness this device as an error detector, obtaining a signal that represents the difference (or error) between \\(\\theta_R\\) and \\(\\theta_C\\).\nIf we have this, we have in fact everything we need complete our position control feedback loop, where \\(\\theta_R\\) is the input and \\(\\theta_C\\) is the output that we want to control.\n\n\nSynchro Transmitter Working\nConsidering the synchro transmitter, imagine the following flux pattern:\n\n\n\n\n\nThe synchro transmitter sends out a specific flux pattern based on its position. The synchro control transformer receives a similar flux pattern. The angle between the synchro transmitter and the synchro control transformer is represented by the angles θ (for the transmitter) and α (for the control transformer).\nGiven that the induced EMF because of this flux pattern is directed to the synchro control transformer, we can conclude that the flux pattern in the latter will be identical.\nWith a certain rotor position of the synchro control transformer, the voltage induced in its rotor can be represented as \\(e\\).\n🤔 Pop-up Question: What is the induced voltage in the rotor of the control transformer when the synchro transmitter is in the null position?\nAnswer: The induced voltage is zero. When the synchro transmitter is in its null or zero position, the flux pattern aligns in such a way that no voltage is induced in the rotor winding of the synchro control transformer.\n\n\nVoltage Induction as Positions Change\nIf the synchro transmitter rotates by \\(\\theta\\) and the control transmitter rotor rotates by \\(\\alpha\\), the net angle between the transmitter and the control transformer’s axis is \\(90-\\theta-\\alpha\\).\nIn this case, the induced voltage \\(e_m\\) is given by:\n\\[\ne_m = K^{'}E_R\\cos(90-\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nHere, when the angle difference between \\(\\theta\\) and \\(\\alpha\\) is 90 degrees, we term the synchro pair’s operational state as the “electrical zero position”. In this position, the voltage induced in the rotor winding will be zero.\nAnd this is what we also discussed before (see equations 1-6).\nIn other words:\nIf the synchro transmitter rotor rotates by an angle \\(\\theta\\) and the synchro control transformer rotor rotates by an angle \\(\\alpha\\), the net angle between the axes of the transmitter and the control transformer is given by \\(90−\\theta+\\alpha\\). The voltage \\(e_m\\) induced in the control transformer under these conditions is:\n\\[\ne_m = K^{'}E_R\\cos(90-\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nWhere: - \\(K^{'}\\) is a constant. - \\(E_R\\) is the voltage related to the transmitter. - \\(\\omega_c\\) is the operational frequency.\nSimplification: The above expression can be simplified to:\n\\[\ne_m = K^{'}E_R\\sin(\\theta-\\alpha)\\sin(\\omega_c t)\n\\]\nThis representation makes it clear that the induced voltage \\(e_m\\) is a function of the difference in the angles \\(\\theta\\) and \\(\\alpha\\).\n\n\nFor Feedback Control Systems\nIn the context of a feedback control system, the difference between the angles \\(\\theta\\) and \\(\\alpha\\) represents the error \\(\\phi\\).\nAs soon as \\(\\theta - \\alpha = \\phi\\) is different from zero, a good control system will try to get it back to zero. This is because a good control system will try to minimize this error.\nIn the context of a feedback control system, the difference between the angles \\(\\theta\\) and \\(\\alpha\\) will be small (designated as \\(\\phi\\)). This is because a good control system will try to minimize this error.\nWhen this difference is small, \\(\\sin(\\theta-\\alpha) \\approx \\phi\\) and the expression for \\(e_m\\) can be approximated as:\n\\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t)\n\\]\nThis simplifies the complex non-linear sinusoidal relationship into a linear one, especially when considering the device as an error detector in a feedback mechanism.\nNote that this is an approximation that only holds if \\(\\phi\\) is small. In a control system that is actively trying to reduce \\(\\phi\\) this is a reasonable assumption. When the synchro pair is not part of a feedback control system and \\(\\phi\\) can take any value, this assumption is no longer valid.\n\n\nDeriving the transfer function\nNow, let’s turn our attention to the device’s input-output configuration.\nGiven the model:\n\\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t)\n\\]\nThe input for the device is \\(\\phi(t)\\), which represents the error between the positions of the reference shaft and the feedback or controlled shaft.\nThe output is \\(e_m\\), which is available at the rotor terminals of the control transformer.\nHowever, deriving a transfer function for this system is more complicated. The relationship between \\(e_m\\) and \\(\\phi\\) includes a term \\(\\sin(\\omega_c t)\\), making the mathematical representation complex (Note that this is a modulation operation).\nAs we discussed before, here \\(\\omega_c\\) denotes the operational frequency of the device, which could be values like 50 Hz, 400 Hz, or 1000 Hz. Since it’s the operational frequency, it doesn’t inherently provide information about the system’s error.\n\nwe can write: \\[\ne_m = K^{'}E_R\\phi(t)\\sin(\\omega_c t) = e_c(t)\\sin(\\omega_c t)\n\\]\n\nwhich will be of the form (output of the synchro error detector):\n\n\n\n\n\n\nThe error \\(\\phi(t)\\) is given by \\(e_c(t)\\), which is the envelope of the signal above. The carrier does not contain any information about the control action. If it present only because the device is operating at frequency \\(\\omega_c\\).\n\nThis realization implies that for a mathematical model, we should be concerned primarily with the envelope \\(e_c\\) and not the entire modulated output \\(e_m\\). Thus, the model becomes more straightforward, treating \\(\\phi\\) as the input and \\(e_c\\) as the output.\nAnd now we can write the transfer function of the Synchro Error Detector as:\n\\[\n\\frac{E_c(s)}{\\phi} = K_s\n\\]\nThis constant \\(K_s\\), known as the sensitivity of the synchro error detector, plays a pivotal role in understanding the flow of information in the system. This constant does not depend on the carrier frequency.\nThis sensitivity, akin to the potentiometric constant \\(K_P\\) in the potentiometer pair, remains constant regardless of the carrier frequency.\nTo reiterate, while the carrier frequency, \\(\\omega_c\\), is essential for device operation, our analytical focus is more on the error envelop \\(e_c\\) rather than the modulated signal \\(e_m\\). This distinction arises from the nature of control systems: it’s the error, not the carrier frequency, that imparts valuable information about system performance.\n\n\nSymbolic representation of the synchro error detector",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#linear-variable-differential-transformer-lvdt",
    "href": "ac_hardware_and_case_studies.html#linear-variable-differential-transformer-lvdt",
    "title": "AC Motion Control Systems",
    "section": "Linear Variable Differential Transformer (LVDT)",
    "text": "Linear Variable Differential Transformer (LVDT)\nAfter understanding the synchro error detector’s rotary motion, we can further explore a linear device that demonstrates similar action. This device, called the Linear Variable Differential Transformer (LVDT), gives an output signal proportional to linear motion.\nPICTURE\nThe functioning of LVDT is intuitive. When the core is positioned centrally, the net voltage is zero due to equal linkage of flux lines to both secondary coils (the secondary windings are in phase oppoistion). Moving the core in one direction links more flux lines to one coil, resulting in a voltage of a specific polarity. The opposite movement reverses the polarity. The voltage’s polarity and magnitude indicate the direction and extent of the core’s displacement, respectively.\n\npolarity: gives you direction\nmagnitude: give you extent of displacement\n\nJust like the synchro device gives an output related to angular motion, LVDT provides an output based on linear motion. The relationship can be represented as:\n\\[\ne_m = KE_ry(t)\\sin(\\omega_c t)\n\\]\n\n\\(e_m\\) is the output which is a modulated signal.\n\nSimilar to the previous discussion, we focus on the envelope \\(e\\), which is\n\\[e=KE_ry(t)=K_sy(t)\\]\nwhich is the part that carries the information, to construct our mathematical model (\\(K_s\\) is the sensitivity of the device).",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#tachogenerator",
    "href": "ac_hardware_and_case_studies.html#tachogenerator",
    "title": "AC Motion Control Systems",
    "section": "Tachogenerator",
    "text": "Tachogenerator\nLet’s take a moment to look closely at the tachogenerator. The tachogenerator is a device that translates rotational speed into an electrical signal, commonly used for feedback in motor control systems.\n\n\n\n\n\nThe input for the tachogenerator is denoted as \\(\\dot{\\theta}\\).\nThe tachogenerator has a reference winding and takes \\(E_r\\sin(\\omega_c t)\\) as its input.\nThe output is a modulated signal, represented as \\(e_m\\) and depends on the frequency \\(\\omega_c\\) (the carrier) and \\(\\dot{\\theta}\\) (the mechanical input to the rotor). The full expression for \\(e_m\\) is:\n\\[\ne_m = KE_r\\omega(t)\\sin(\\omega_c t)\n\\]\nThis modulated signal contrasts with the output from a DC tachogenerator, which was a direct low-frequency signal proportional to speed. The output of the DC tachogenerator was directly proportional to speed, the output was a DC signal. However, mathematical modeling provides a similar representation for both.\nThe DC tachogenerator produces a direct low-frequency signal proportional to speed, while the AC tachogenerator produces a modulated signal.\nThe error signal, \\(e\\), is represented as:\n\\[\ne= K_t \\omega(t)\n\\]\n(similar to the DC motor).\nHere, it’s essential to understand that the signal’s information is carried by the envelope, not the carrier. Thus, demodulation is assumed to extract this envelope.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#the-control-problem",
    "href": "ac_hardware_and_case_studies.html#the-control-problem",
    "title": "AC Motion Control Systems",
    "section": "The Control Problem",
    "text": "The Control Problem\nLet us consider a situation where we have a heavy telephoto camera. The goal is to precisely control the position of this camera. To accomplish this, we will utilize an AC motor. To ensure a smooth motion and precision, we will also consider other devices and mechanisms to aid the motor.\n\n\n\n\n\nThe system has the following components:\n\nA gear train for torque magnification and speed reduction. The primary and secondary gears have teeth \\(N_1\\) and \\(N_2\\) respectively.\nA disturbance, \\(T_W\\), acting on the system.\nAn AC motor that generates a torque labeled as \\(T_M\\) and has a position of \\(\\theta_M\\). The motor has two windings, a reference winding with the phase shifting capacitor, and a control phase winding which has the modulated signal \\(e_m\\). The modulated signal should be proportional to the error between the commanded position and the actual position \\(\\theta_L\\).\nA spotting scope which provides a command signal \\(\\theta_R\\).\nThe error \\(\\theta_R - \\theta_L\\) should be reflected through the voltage \\(e_m\\). This is obtained using a synchro pair, comprising a synchro transmitter and a synchro control transformer. The synchro control is mechanically connected to the camera to read the camera position \\(\\theta_L\\). The synchro transmitter is connected to a spotting scope that provides the reference input \\(\\theta_R\\).\n\n🤔 Popup Question: How do we give the command? Answer: The spotting scope gives the reference signal. A synchro error detector that measures the difference between the commanded and actual positions.\n🤔 Popup Question: Why is a gear train required in the system? Answer: A gear train is required to magnify the torque because the motor alone cannot produce the substantial torque necessary to rotate the heavy telephoto camera.\n\nUnderstanding the Synchro Pair\nThe synchro pair, comprising of a transmitter and a control transformer, is crucial. The transmitter is influenced by \\(\\theta_R\\) and the control transformer rotor by \\(\\theta_L\\). This creates a modulated signal, which is essentially a mix of a constant carrier frequency and an amplitude that depends on the error between \\(\\theta_R\\) and \\(\\theta_L\\).\n\n\nRole of the Amplifier\nSince the modulated signal might not have enough power to drive the AC motor, an amplifier is introduced. It enhances the strength of the signal, ensuring the motor operates effectively.\n\n\nSignals\nAs stated, the signals in this case don’t require modulation or demodulation. This is because they’re inherently compatible with the devices they interact with. The equation \\(\\theta_R - \\theta_L\\) involves DC signals, and the output of the synchro control is a modulated signal that can be used to drive the motor.\nThe synchro device indeed acts as a modulator. It takes in a DC signal (\\(\\theta_R - \\theta_C\\)) and outputs a modulated signal with frequency \\(\\omega_c\\). This signal is then amplified by an AC amplifier to produce another modulated signal.\nNote that the reference frequency for these two devices (synchro and motor) must be \\(\\omega_c\\) for compatibility.\n\n\nAC Motor as a Demodulator\nThe AC motor’s role can be likened to a demodulator since it processes the modulated signal to produce a torque \\(T_M\\) and position (\\(\\theta_M\\)), both DC signals. This implies the synchro device (modulator) and the AC motor (demodulator) are harmonious in their operation, ensuring the input and output of the entire system remain DC signals.\n\n\nMathematical Model & Block Diagram\nBased on the dicussions above, to derive a mathematical model, we remove the carrier frequency.\nTo do this, we will start with a block diagram and then reduce it to a suitable transfer function.\n\n\n\n\n\nNotably, \\(\\theta R\\) is compared with \\(\\theta_L\\) to produce an error signal. This resulting signal undergoes various transformations involving constants like \\(K_s\\), \\(K_A\\), and \\(K_1\\). And finally, we can include disturbance signals and feedback mechanisms:\nThe disturbance \\(T_W\\) affects the motor indirectly via a gear set, causing a reflected disturbance of \\(nT_W\\). Similarly, parameters like \\(J_L\\) and \\(B_L\\) from the telephoto camera, when reflected onto the motor shaft, morph into equivalent values \\(J\\) and \\(B\\).\nThe primary objective of this control system is for \\(\\theta_L\\) (telephoto camera position) to mimic \\(\\theta_R\\) (spotting scope position) seamlessly. It’s desirable to have no transients in this motion, and the steady-state error should be minimal or zero. This outlines the control design problem.\n\n\nControl Design\nNote that this block diagram includes a controller in the form of a proportional controller. This is the pure amplifier \\(K_A\\). In the future it might be replaced with a more advanced controller that could employ proportional, integral, derivative, or even other advanced control actions that will take into account the desired performance specifications.",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "ac_hardware_and_case_studies.html#using-a-dc-motor",
    "href": "ac_hardware_and_case_studies.html#using-a-dc-motor",
    "title": "AC Motion Control Systems",
    "section": "Using a DC Motor",
    "text": "Using a DC Motor\nLet’s consider a feedback control system where we want to drive a specific load. We can imagine this load as a component that needs to be operated upon by an external entity, say a motor.\n\n\n\n\n\nThe given parameters for this load are:\n\nMoment of inertia: \\(J_L\\)\nDamping coefficient: \\(B_L\\)\nDisturbance torque: \\(T_W\\)\nPosition: \\(\\theta_L\\)\n\n🤔 Popup Question: What is the significance of each of these parameters in determining the load’s behavior?\nAnswer: Moment of inertia (\\(J_L\\)) gives us an idea of the load’s resistance to changes in motion. Damping coefficient (\\(B_L\\)) is a measure of the resisting force when the load is in motion. Disturbance torque (\\(T_W\\)) is an external force affecting the load. The position (\\(\\theta_L\\)) tells us the current state or position of the load.\nWe have been given two constraints for our control system: - We must use a DC motor and not an AC motor as our actuator. The reason is that DC motors exhibit linear torque-speed characteristics, and they can handle more torque for a given size compared to an AC motor. - Instead of a potentiometric error detector, we’ll use a synchro error detector. The synchro error detector is preferred due to its better resolution, linearity, ruggedness, and absence of contact problems commonly found in potentiometric error detectors.\nWe need to determine how to interface the synchro control transformer’s output signal with the DC motor’s armature, post amplification.\n\nWe want to use the DC motoro as an actuator and the syncro pair as an error detector.\nWe also assume that our controller is a PD controller\n\nIn the diagram below, how to we connect the components together?\n\n\n\n\n\n\nLinking the Synchro Pair to the DC Motor:\nTo interface the synchro pair to the DC motor:\n\nExtract the envelope of the synchro control transformer’s output using a demodulator. This is crucial because we’re interested in the information signal about the error and not the carrier signal.\nFeed the extracted envelope to a PD (Proportional Derivative) circuit. This circuit will produce an output proportional to both the error and its derivative.\n\nNote: The PD action should act only on the information about the error. We should avoid taking the derivative of the carrier signal. We only want to take the derivative of the envelope.\nNote also that, if we did not use a PD controller, we could have used directly an AC amplifier and a rectifier to obtain a DC signal directly. This however would only work if a derivative action is not required. If instead a derivative is required, then the derivative must be taken on the information signal.\n\nAmplify the output of the PD circuit using an amplifier with amplification \\(K_A\\).\nConnect the amplified signal to the armature voltage input \\(e_a\\) of the DC motor, which will then drive the load through the gear train.\nConnect the output shaft of the motor back to the synchro control transformer to close the feedback loop.\n\n\n\n\n\n\n🤔 Popup Question: Why is there a need to extract the envelope of the synchro control transformer’s output?\nAnswer: The envelope contains the information about the error, which is crucial for feedback. By extracting the envelope, we eliminate unnecessary carrier signal components and focus only on the desired information signal.\n\nImportant Considerations:\n\nInverting Amplifier: When deriving the transfer function for the Op-Amp PD controller, you’ll notice a negative sign being introduced. To address this, use an inverting amplifier. This will ensure that the transfer function remains positive.\nDemodulator’s Transfer Function: Ideally, the transfer function of the demodulator (which extracts the envelope from the modulated signal) is unity (input is the envelope, and output is the envelope).\n\n\n\n\nBlock diagram\n\n\n\n\n\nAnd here is if we explicit the block diagram of the DC motor:",
    "crumbs": [
      "AC Motion Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html",
    "href": "application_of_nyquist_stability_criterion.html",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "",
    "text": "Before we dive into the application of the Nyquist stability criterion in control systems, it’s essential to revisit the fundamental concept of the criterion. The Nyquist stability criterion is a graphical method used in control engineering to assess the stability of a closed-loop system.\n\n\nThe Nyquist criterion revolves around a specific contour in the complex plane, known as the Nyquist contour. In the s-plane (Laplace domain), this contour comprises the entire right-half plane, including the imaginary axis.\n\nNyquist Contour: The contour is mathematically represented as a semicircle with an infinite radius in the right-half plane, extending from \\(+j\\infty\\) to \\(-j\\infty\\).\nRepresentation of \\(s\\): Any point on this semicircle is represented as \\(s = R e^(j\\theta)\\), where \\(R\\rightarrow \\infty\\) and \\(\\theta\\) varies from +90° to -90°.\n\n\n\n\n\n\n\n\n\n\n\nWhen applying the Nyquist criterion, we focus on how this contour maps in the \\(G(s)H(s)\\) plane, where \\(G(s)H(s)\\) represents the open-loop transfer function of the system.\n\n\n\nRealizability: \\(G(s)H(s)\\) is a physically realizable transfer function.\n\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\n\nPolynomial Order: Generally, the order of the numerator polynomial \\(N(s)\\) is less than or equal to the order of the denominator polynomial \\(\\Delta(s)\\).\n\n\n\n\nGiven that the Nyquist contour can be thought of composed of two main parts:\n\nThe imaginary axis, i.e., the \\(j\\omega\\) line, with \\(\\omega \\in  [-\\infty, +\\infty]\\)\nThe rest of the countour, i.e., the part that starts at \\(+\\infty\\) on the imaginary axis, goes all around to get to \\(+\\infty\\) on the real axis and then goes back to \\(-\\infty\\) on the imaginary axis\n\nIt becomes particularly important to understand the behaviour of the mapping when \\(R\\rightarrow \\infty\\).\n\nInfinite Radius: When \\(R\\rightarrow \\infty\\), the entire semicircle in the s-plane maps to a single point in the \\(G(s)H(s)\\) plane.\nCondition: If the order of \\(N(s)\\) is less than \\(\\Delta(s)\\), this point is the origin. If they are equal, it maps to a constant point on the real axis.\n\n\n\n\n\nLet’s delve deeper into the details of the open-loop transfer function $ G(s)H(s) $ and its behavior, especially at points tending towards infinity in the s-plane.\nConsider the open-loop transfer function expressed as:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nHere, $ N(s) $ and $ (s) $ are the numerator and denominator polynomials respectively, with the order of $ N(s) $ (denoted as $ m $) being less than the order of $ (s) $. We denote this as $ [N(s)] = m &lt; [(s)] $. For our analysis, we examine points on the Nyquist contour, represented as $ s = R e^{j} $, where $ R $.\nWhen exploring the behavior of $ G(s)H(s) $ in the W-plane, we can break it down into two components: phase and gain.\n\n\nThe phase of $ G(s)H(s) $ in the W-plane can be determined by the angular contributions of its zeros and poles:\n\\[\n\\angle G(s)H(s) = \\sum \\angle \\text{zeros} - \\sum \\angle \\text{poles}\n\\]\nThis phase angle is the sum of the angles of all zeros minus the sum of the angles of all poles of $ G(s)H(s) $.\n\n\n\nThe gain magnitude of $ G(s)H(s) $ in the W-plane is given by:\n\\[\n| G(s)H(s) | = \\frac{K \\prod | \\text{zeros} |}{\\prod |\\text{poles}|}\n\\]\nHere, $ K $ represents any constant multiplier in the transfer function. The gain is calculated as the product of the magnitudes of the zeros divided by the product of the magnitudes of the poles.\n\n\n\nFor points on the Nyquist contour where $ R $, the gain of $ G(s)H(s) $ approaches zero. This occurs because the number of poles exceeds the number of zeros, leading to division by an infinitely large value as $ R $ increases.\nConsequently, any point on the Nyquist contour, as $ R $ tends to infinity, maps to the origin in the W-plane. Although the phase angle of $ G(s)H(s) $ varies as the point $ s $ moves along the contour, it does not significantly affect the mapping location in the W-plane, since the gain approaches zero and the point consistently maps to the origin.\n\n\n\n\nWhen the orders of the numerator and denominator polynomials in an open-loop transfer function $ G(s)H(s) $ are equal, denoted as $ m = n $, the behavior of the transfer function, particularly at points approaching infinity on the Nyquist contour, is distinct from the case where $ m &lt; n $.\nLet’s consider the open-loop transfer function:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nIn this scenario, where $ m = n $, the order of the numerator polynomial $ N(s) $ is equal to the order of the denominator polynomial $ (s) $. This implies that $ G(s)H(s) $ has an equal number of zeros and poles in terms of their order.\n\n\n\n\nGain at Infinity: When $ s = R e^{j} $ and $ R $, unlike the $ m &lt; n $ case, the gain $ |G(s)H(s)| $ does not tend to zero. This is because the infinities in the numerator and denominator effectively cancel out, leaving a finite value.\nPhase Angle: The phase angle $ G(s)H(s) $ is determined by the angular contributions of the zeros and poles, similar to the $ m &lt; n $ case. However, since there is an equal number of zeros and poles (in terms of order), their angular contributions might balance out differently.\n\n\n\n\n\nMapping at Infinity: For points at infinity on the Nyquist contour, $ G(s)H(s) $ maps to a constant point on the W-plane. The exact location of this point depends on the specific values and distribution of zeros and poles of the transfer function.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#reviewing-the-nyquist-stability-criterion",
    "href": "application_of_nyquist_stability_criterion.html#reviewing-the-nyquist-stability-criterion",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "",
    "text": "Before we dive into the application of the Nyquist stability criterion in control systems, it’s essential to revisit the fundamental concept of the criterion. The Nyquist stability criterion is a graphical method used in control engineering to assess the stability of a closed-loop system.\n\n\nThe Nyquist criterion revolves around a specific contour in the complex plane, known as the Nyquist contour. In the s-plane (Laplace domain), this contour comprises the entire right-half plane, including the imaginary axis.\n\nNyquist Contour: The contour is mathematically represented as a semicircle with an infinite radius in the right-half plane, extending from \\(+j\\infty\\) to \\(-j\\infty\\).\nRepresentation of \\(s\\): Any point on this semicircle is represented as \\(s = R e^(j\\theta)\\), where \\(R\\rightarrow \\infty\\) and \\(\\theta\\) varies from +90° to -90°.\n\n\n\n\n\n\n\n\n\n\n\nWhen applying the Nyquist criterion, we focus on how this contour maps in the \\(G(s)H(s)\\) plane, where \\(G(s)H(s)\\) represents the open-loop transfer function of the system.\n\n\n\nRealizability: \\(G(s)H(s)\\) is a physically realizable transfer function.\n\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\n\nPolynomial Order: Generally, the order of the numerator polynomial \\(N(s)\\) is less than or equal to the order of the denominator polynomial \\(\\Delta(s)\\).\n\n\n\n\nGiven that the Nyquist contour can be thought of composed of two main parts:\n\nThe imaginary axis, i.e., the \\(j\\omega\\) line, with \\(\\omega \\in  [-\\infty, +\\infty]\\)\nThe rest of the countour, i.e., the part that starts at \\(+\\infty\\) on the imaginary axis, goes all around to get to \\(+\\infty\\) on the real axis and then goes back to \\(-\\infty\\) on the imaginary axis\n\nIt becomes particularly important to understand the behaviour of the mapping when \\(R\\rightarrow \\infty\\).\n\nInfinite Radius: When \\(R\\rightarrow \\infty\\), the entire semicircle in the s-plane maps to a single point in the \\(G(s)H(s)\\) plane.\nCondition: If the order of \\(N(s)\\) is less than \\(\\Delta(s)\\), this point is the origin. If they are equal, it maps to a constant point on the real axis.\n\n\n\n\n\nLet’s delve deeper into the details of the open-loop transfer function $ G(s)H(s) $ and its behavior, especially at points tending towards infinity in the s-plane.\nConsider the open-loop transfer function expressed as:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nHere, $ N(s) $ and $ (s) $ are the numerator and denominator polynomials respectively, with the order of $ N(s) $ (denoted as $ m $) being less than the order of $ (s) $. We denote this as $ [N(s)] = m &lt; [(s)] $. For our analysis, we examine points on the Nyquist contour, represented as $ s = R e^{j} $, where $ R $.\nWhen exploring the behavior of $ G(s)H(s) $ in the W-plane, we can break it down into two components: phase and gain.\n\n\nThe phase of $ G(s)H(s) $ in the W-plane can be determined by the angular contributions of its zeros and poles:\n\\[\n\\angle G(s)H(s) = \\sum \\angle \\text{zeros} - \\sum \\angle \\text{poles}\n\\]\nThis phase angle is the sum of the angles of all zeros minus the sum of the angles of all poles of $ G(s)H(s) $.\n\n\n\nThe gain magnitude of $ G(s)H(s) $ in the W-plane is given by:\n\\[\n| G(s)H(s) | = \\frac{K \\prod | \\text{zeros} |}{\\prod |\\text{poles}|}\n\\]\nHere, $ K $ represents any constant multiplier in the transfer function. The gain is calculated as the product of the magnitudes of the zeros divided by the product of the magnitudes of the poles.\n\n\n\nFor points on the Nyquist contour where $ R $, the gain of $ G(s)H(s) $ approaches zero. This occurs because the number of poles exceeds the number of zeros, leading to division by an infinitely large value as $ R $ increases.\nConsequently, any point on the Nyquist contour, as $ R $ tends to infinity, maps to the origin in the W-plane. Although the phase angle of $ G(s)H(s) $ varies as the point $ s $ moves along the contour, it does not significantly affect the mapping location in the W-plane, since the gain approaches zero and the point consistently maps to the origin.\n\n\n\n\nWhen the orders of the numerator and denominator polynomials in an open-loop transfer function $ G(s)H(s) $ are equal, denoted as $ m = n $, the behavior of the transfer function, particularly at points approaching infinity on the Nyquist contour, is distinct from the case where $ m &lt; n $.\nLet’s consider the open-loop transfer function:\n\\[\nG(s)H(s) = \\frac{N(s)}{\\Delta(s)}\n\\]\nIn this scenario, where $ m = n $, the order of the numerator polynomial $ N(s) $ is equal to the order of the denominator polynomial $ (s) $. This implies that $ G(s)H(s) $ has an equal number of zeros and poles in terms of their order.\n\n\n\n\nGain at Infinity: When $ s = R e^{j} $ and $ R $, unlike the $ m &lt; n $ case, the gain $ |G(s)H(s)| $ does not tend to zero. This is because the infinities in the numerator and denominator effectively cancel out, leaving a finite value.\nPhase Angle: The phase angle $ G(s)H(s) $ is determined by the angular contributions of the zeros and poles, similar to the $ m &lt; n $ case. However, since there is an equal number of zeros and poles (in terms of order), their angular contributions might balance out differently.\n\n\n\n\n\nMapping at Infinity: For points at infinity on the Nyquist contour, $ G(s)H(s) $ maps to a constant point on the W-plane. The exact location of this point depends on the specific values and distribution of zeros and poles of the transfer function.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#traversing-the-nyquist-contour",
    "href": "application_of_nyquist_stability_criterion.html#traversing-the-nyquist-contour",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Traversing the Nyquist Contour",
    "text": "Traversing the Nyquist Contour\nLet’s clarify the concept of mapping the Nyquist contour in control systems. This process involves tracing a specific path in the complex plane, starting from a certain point and progressing through key locations.\nAs you go through the following steps, use the diagram below as a reference.\n\nStarting Point: The mapping begins at the origin of the s-plane, where \\(\\omega = 0\\). This is denoted as \\(\\omega = 0^+\\).\nPath Along the Imaginary Axis: From the origin, the path extends along the imaginary axis of the s-plane. This means we let \\(s = j\\omega\\), and \\(\\omega\\) increases from 0 to infinity. This segment is often described as \\(\\omega = 0^+\\) to \\(\\omega = +\\infty\\).\nInfinite Semicircle: The contour then transitions through an infinite semicircle in the right-half plane. This is conceptualized as \\(\\omega\\) transitioning from \\(+\\infty\\) to \\(-\\infty\\). During this transition, the radius of the semicircle (\\(R\\)) approaches infinity.\nCompleting the Contour: Finally, the path returns to the origin along the negative imaginary axis. This is described as \\(\\omega\\) moving from \\(-\\infty\\) back to \\(0\\), denoted as \\(\\omega = 0^-\\).\nSymmetry and Simplification: The segment from \\(\\omega = 0\\) to \\(\\omega = +\\infty\\) is a mirror image of the segment from \\(\\omega = -\\infty\\) to \\(\\omega = 0\\). Because of this symmetry, the Nyquist plot is often simplified to only consider the first half of the contour (from \\(\\omega = 0^+\\) to \\(\\omega = +\\infty\\)). The second half is simply a reflection across the real axis.\nSignificance in Stability Analysis: The entire Nyquist contour encompasses the right-half s-plane. The Nyquist criterion uses this contour to determine if there are any closed-loop poles (zeros of \\(1 + G(s)H(s)\\)) in the right-half plane, which are indicative of system instability.\nTechnique in Practice: Although this explanation outlines the theoretical approach, in practical mapping, the focus is often on the imaginary axis segment and the behavior at infinity. The symmetry of the plot simplifies the analysis, making it more manageable and insightful.\n\nIn summary, the effective mapping of the Nyquist contour involves tracing a path from the origin along the imaginary axis to infinity, around an infinite semicircle, and back to the origin. This mapping is crucial in applying the Nyquist criterion to assess the stability of control systems.\n\n\n\n\n\n\n\nFigure: Nyquist Countour and Nyquist Plot. In this case, the system in CL is stable even though we do not know P.\n\nAnalysis of Nyquist Stability Criterion through Mapping of G(s)H(s) on the Nyquist Contour\n\nMapping the Transfer Function: The task at hand is to map $ G(s)H(s) $ as the complex variable $ s $ traverses the Nyquist contour. This journey along the contour will create a plot in the \\(G(s)H(s)\\) plane.\nCreating the Nyquist Plot: As $ s $ moves along the Nyquist contour, we observe how the value of $ G(s)H(s) $ changes. The resulting plot in the \\(G(s)H(s)\\) plane is our primary focus.\nQualitative Nature of the Plot: While the exact quantitative values of the plot are not our main concern, its qualitative shape is crucial. The real axis and the imaginary axis of the \\(G(s)H(s)\\) plane are important reference points for our analysis.\nCrucial Point on the Plot: A key element in the Nyquist plot is the point \\(-1 + j0\\). This point is critical because we have shifted our perspective from \\(1 + G(s)H(s)\\) to \\(G(s)H(s)\\) only.\nCounting Encirclements: The essence of the criterion lies in counting the number of counter-clockwise encirclements of the point \\(-1 + j0\\) by the Nyquist plot. This count is denoted by \\(N\\).\nThe Nyquist Stability Criterion: The total number of counter-clockwise encirclements, \\(N\\), is related to two key variables: \\(P\\) and \\(Z\\). Here, \\(N = P - Z\\), where \\(P\\) represents the number of open-loop poles within the Nyquist region, and \\(Z\\) corresponds to the number of zeros, which equates to the number of closed-loop poles in the system.\n\nIn summary, the Nyquist stability criterion revolves around mapping $ G(s)H(s) $ along the Nyquist contour and analyzing the resulting plot, particularly focusing on the number of counter-clockwise encirclements around the critical point \\(-1 + j0\\). This analysis is key in determining the stability of the control system under examination.\n\n\nExamples",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#practical-examples",
    "href": "application_of_nyquist_stability_criterion.html#practical-examples",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Practical Examples",
    "text": "Practical Examples\nTo reinforce these concepts, let’s analyze some examples:\n\nExample 1: Feedback System with Open-Loop Transfer Function\nConsider a feedback system with\n\\[\nG(s)H(s) = \\frac{1}{(T_1 s + 1)(T_2 s + 1)}\n\\]\nIn the realm of frequency domain analysis, the Time Constant Form of a transfer function is typically more practical and user-friendly.\nThis approach contrasts with the Zero-Pole Form utilized in the root locus method. To illustrate, consider the following Zero-Pole Form of the open-loop transfer function ( G(s)H(s) ):\n\\[\nG(s)H(s) = \\frac{1}{(s + p_1)(s + p_2)}\n\\]\nIn this form, the transfer function is explicitly expressed in terms of its poles (and zeros, if present). This is particularly useful for the root locus method, where the starting points (poles and zeros) are fundamental to constructing the locus.\nHowever, for frequency response analysis, the Time Constant Form offers a more direct and intuitive understanding of the system’s behavior. This form simplifies the process of calculating the magnitude and phase response of the system, which are crucial in frequency domain methods.\nThe conversion between these two forms, from Zero-Pole to Time Constant or vice versa, is straightforward. It involves rearranging the transfer function into the desired format, ensuring that the essential characteristics of the system, such as its poles, zeros, and gain, remain consistent across both representations.\nWhen presented with a transfer function in time constant form, we transform it into its sinusoidal equivalent by setting $ s = j$:\n\\[\nG(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)}\n\\]\nThis form of the transfer function characterizes the system’s response to sinusoidal inputs.\nRationale Behind the Sinusoidal Transfer Function The primary goal is to map the entire Nyquist contour. A critical observation is that the most important segment of this contour is the positive half of the imaginary axis. Once this segment is mapped, the rest of the mapping becomes relatively straightforward, as this segment reflects the frequency response of the open-loop system.\n\nLinking Frequency Response with Nyquist Contour\n\nFrequency Response: Defined as the output of the system when exposed to sinusoidal inputs, with frequencies ranging from $ = 0 $ to $ = $.\nMapping on Nyquist Contour: Mapping the positive half of the imaginary axis in the s-plane effectively equates to analyzing the open-loop system’s frequency response.\n\nIn this context, the sinusoidal transfer function $ G(j)H(j) $ undergoes a transformation corresponding to the substitution $ s = j$:\n\\[\nG(j\\omega)H(j\\omega) \\xrightarrow{s = j\\omega} G(s)H(s)\n\\]\nThe magnitude and phase of this function are represented by $ |G(j)H(j)| $ and $ G(j)H(j) $, respectively.\n\nMagnitude $ |G(j)H(j)| $: This quantifies the amplitude ratio of the open-loop system in response to a sinusoidal input.\nPhase Angle $ G(j)H(j) $: This indicates the change in phase angle of the sinusoidal input as processed by the open-loop system.\n\nKnowing these two parameters for any given frequency allows us to understand the system’s output when it encounters a sinusoidal input.\nThis analysis reveals that $ G(j)H(j) $ essentially represents the open-loop system’s frequency response. Additionally, even if the analytical form of $ G(s)H(s) $ is not available, one can experimentally determine these magnitudes and phase angles, allowing the application of the Nyquist criterion using experimental data.\nPop-up Question: Why is the mapping of the positive half of the imaginary axis important in Nyquist analysis?\nAnswer: This mapping corresponds to the frequency response of the open-loop system, providing critical information about the system’s stability characteristics.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#sketching-the-nyquist-plot",
    "href": "application_of_nyquist_stability_criterion.html#sketching-the-nyquist-plot",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Sketching the Nyquist Plot",
    "text": "Sketching the Nyquist Plot\nThe following guideline, based on practical experience, outlines four critical points needed to sketch an effective Nyquist plot. These points are particularly relevant for evaluating the stability of control systems.\n\nIdentifying Four Key Points\n\nMagnitude and Angle at $ = 0 $\nMagnitude and Angle at $ = $\nIntersection with the Imaginary Axis\nIntersection with the Real Axis\n\nThese points provide a comprehensive view of the system’s response and are typically sufficient for a rough sketch of the Nyquist plot, especially when the primary concern is system stability.\n\n\nDetailed Examination of Each Point for our Example\n\n1. Magnitude and Angle at $ = 0 $\n\nFor the given sinusoidal transfer function\n\n\\[ G(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} \\]\nat $ = 0 $, the magnitude is 1, and the angle is 0 degrees.\nThis gives us our first critical point on the Nyquist plot:\n\\[\n1\\angle{0^\\circ}\\;\\;\\; \\omega=0\n\\]\n\n\n2. Magnitude and Angle at $ = $\n\nAs $ $ approaches infinity, the magnitude approaches zero, and the angle tends towards -180 degrees. This behavior is crucial in understanding how the plot behaves at high frequencies.\n\nAs $ = $ we can approximate:\n\\[ G(j\\omega)H(j\\omega) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} = \\frac{1}{j^2\\omega^2T_1T_2}\\]\nNow we calculate:\n\\[\n\\lim_{\\omega = \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2}\n\\]\nto obtain:\n\\[\n0\\angle{-180^\\circ}\\;\\;\\; \\omega=\\infty\n\\]\n\n\n\n\nSIDEBAR - Calculating the limit\nTo understand why\n\\[\n\\lim_{\\omega \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2} = 0\\angle{-180^\\circ}\n\\]\nwe need to analyze both the magnitude and phase angle of the complex expression as \\(\\omega\\) approaches infinity.\n\nMagnitude Analysis\n\nExpression Simplification: The given expression is \\(\\frac{1}{j^2\\omega^2T_1T_2}\\). First, let’s simplify \\(j^2\\). Since \\(j\\) is the imaginary unit, \\(j^2 = -1\\). Thus, the expression becomes \\(\\frac{1}{-1\\cdot\\omega^2T_1T_2}\\) or \\(-\\frac{1}{\\omega^2T_1T_2}\\).\nMagnitude as \\(\\omega\\) Approaches Infinity: As \\(\\omega\\) becomes very large, the denominator \\(\\omega^2T_1T_2\\) also becomes very large. The magnitude of a fraction with a very large denominator approaches zero. Hence, \\(\\lim_{\\omega \\rightarrow \\infty} \\left| -\\frac{1}{\\omega^2T_1T_2} \\right| = 0\\).\n\n\n\nPhase Angle Analysis\n\nPhase of the Original Expression: In the original expression \\(\\frac{1}{j^2\\omega^2T_1T_2}\\), the term \\(j^2\\) contributes to the phase. Since \\(j^2 = -1\\), it can be seen as having a phase of \\(180^\\circ\\) (or \\(-180^\\circ\\), as a phase shift of \\(180^\\circ\\) is equivalent to \\(-180^\\circ\\)).\nPhase at Infinity: The phase of a complex number is not affected by the magnitude of the number. Even as the magnitude goes to zero, the phase angle contributed by \\(j^2\\) remains at \\(-180^\\circ\\).\n\nCombining the magnitude and phase analyses:\n\nThe magnitude of \\(\\frac{1}{j^2\\omega^2T_1T_2}\\) approaches zero as \\(\\omega\\) approaches infinity.\nThe phase angle remains at \\(-180^\\circ\\) due to the contribution of \\(j^2\\).\n\nThus, we conclude that:\n\\[\n\\lim_{\\omega \\rightarrow \\infty} \\frac{1}{j^2\\omega^2T_1T_2} = 0\\angle{-180^\\circ}\n\\]\nThis indicates that at very high frequencies (\\(\\omega \\rightarrow \\infty\\)), the response of a system described by this transfer function diminishes to zero in magnitude, with a phase shift of \\(-180^\\circ\\).\nEND OF SIDEBAR\n\n\n\n\nIntersections with Real and Imaginary Axes\nTo find the intersections of the transfer function with the real and imaginary axes, we can express the transfer function in the form of $ x + jy $:\n\\[\nG(s)H(s) = \\frac{1}{(1 + j\\omega T_1)(1 + j\\omega T_2)} = x + jy\n\\]\nand then analyze it for specific conditions:\n\nIntersection with the Real Axis: Set the imaginary part, $ y $, to zero and solve for $ $ to find where the transfer function intersects the real axis.\nIntersection with the Imaginary Axis: Set the real part, $ x $, to zero to determine the points of intersection with the imaginary axis.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#constructing-the-polar-plot-of-the-frequency-response",
    "href": "application_of_nyquist_stability_criterion.html#constructing-the-polar-plot-of-the-frequency-response",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Constructing the Polar Plot of the Frequency Response",
    "text": "Constructing the Polar Plot of the Frequency Response\n\nThe Polar Plot\nBefore diving into the Nyquist plot, we first create a polar plot of the frequency response of the open-loop system. This plot starts at $ = 0 $ and extends to $ = $.\nWe use the points we have calculated before:\n\n\n\n\\(\\omega = 0\\)\n\\(1\\angle{0^\\circ}\\)\n\n\n\\(\\omega = \\infty\\)\n\\(0\\angle{-180^\\circ}\\)\n\n\n\nand we draw the Plot:\n\n\n\n\n\n\n\n\n\n\n\nKey Points of Analysis\n\nOmega = 0: At $ = 0 $, the magnitude is 1, and the angle is 0 degrees.\nOmega = Infinity: As $ $ approaches infinity, the magnitude tends towards zero, and the angle approaches -180 degrees.\n\nFinally, we need to understand how to map the point:\n\\[\ns = Re^{j\\theta}\n\\]\nFor this we will consider the original \\(G(s)H(s)\\) function. We used the sinusoidal transfer function only to map the imaginary axis.\n\\[\nG(s)H(s) = \\frac{1}{(T_1 s + 1)(T_2 s + 1)}\n\\]\nIn this case:\n\\[\nG(s)H(s)\\Big|_{s = Re^{j\\theta}} = \\frac{1}{(T_1 Re^{j\\theta} + 1)(T_2 Re^{j\\theta} + 1)}\n\\]\nWhen \\(R \\rightarrow \\infty\\), the function becomes:\n\\[\n\\frac{1}{T_1 T_2 R^2e^{j2\\theta}}\n\\]\nwhere \\(\\theta\\) varies from \\(+90^\\circ\\) through \\(0^\\circ\\) to \\(-90^\\circ\\).\n\nWhen \\(R \\rightarrow \\infty\\), the magnitude tends to zero.\nThe angle is \\(e^{-j2\\theta}\\): the angle hence varies from \\(-180^\\circ\\) through \\(0^\\circ\\) to \\(180^\\circ\\).\n\nWe can update the Polar Plot to reflect this:\n\n\n\n\n\n\n\nIn this sketch, the most effective way to demonstrate the concept is by considering how the plot behaves as $ $ approaches infinity. Let’s interpret this as follows:\n\nAt $ = +$: This point on the plot corresponds to $ $ tending towards positive infinity.\nAt ( = -): Similarly, another point on the plot represents $ $ approaching negative infinity.\n\nIn this scenario, the contour we are discussing tends towards the origin of the complex plane.\n\n\nUnderstanding the Contour’s Approach to the Origin\n\nApproach and Departure: The contour approaches the origin asymptotically at an angle of -180 degrees and departs from the origin asymptotically at an angle of +180 degrees.\nSignificance of $ $ in $ R e^{j} $: The angle $ $ plays a role in this mapping. As $ $ varies, it illustrates how the contour enters and exits the vicinity of the origin. When entering, the contour does so asymptotically to -180 degrees, and when exiting, it moves away asymptotically to +180 degrees.\nMapping Interpretation: This behavior is a reflection of the mapping $ s = R e^{j} $ on the Nyquist plot. The angle $ $ significantly influences how the plot wraps around the origin, depicting the system’s response as the frequency $ $ moves through a wide range.\n\n\n\n\nSimplifying the Nyquist Plot\n\nFocus on Critical Points: For stability analysis, our primary interest lies in the vicinity of the point \\(-1 + j0\\). The shape of the plot around the origin, though mathematically intriguing, may not significantly impact stability analysis.\nPractical Approach: In many scenarios, the entirety of the contour’s mapping around the origin can be simplified. We can consider the origin itself as the total map of a particular contour, as long as we are far from the critical point of \\(-1 + j0\\).\n\n\n\nAnalyzing the Approach to the Origin\n\nAsymptotic Behavior: The approach of the plot to the origin is important. Whether it approaches asymptotically to \\(-180^\\circ\\) or \\(+180^\\circ\\), or in another manner, is important, especially since it may involve the encircling of the \\(-1\\) point.\n\n\n\n\n\n\n\n\n\nDetermining the Asymptote: While the detailed contour around the origin may not be essential for stability, the direction in which the plot approaches the origin can be really important. This direction, or asymptote, indicates potential encirclements of the critical point.\n\nPop-Up Question: Why is the polar plot an important step before creating the Nyquist plot?\nAnswer: The polar plot gives us a visual representation of the system’s frequency response, which is a foundational element in understanding and constructing the Nyquist plot.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#transitioning-to-practical-nyquist-plot-construction",
    "href": "application_of_nyquist_stability_criterion.html#transitioning-to-practical-nyquist-plot-construction",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Transitioning to Practical Nyquist Plot Construction",
    "text": "Transitioning to Practical Nyquist Plot Construction\nAfter we have created the polar plot, which illustrates the frequency response of the system, our next step is to construct the Nyquist plot. This is achieved by reflecting the polar plot across the real axis. The Nyquist plot thus formed represents the entire Nyquist contour’s mapping.\nIt’s important to note that in the context of frequency response, the concept of negative frequencies (\\(\\omega &lt; 0\\)) doesn’t have a direct physical interpretation. Frequencies are inherently positive values. The consideration of negative \\(\\omega\\) values in our analysis is a mathematical tool, allowing us to create a mirror image of the plot for completeness.\n\nVisualization of the Nyquist Plot\nImagine the polar plot as a graphical representation of the system’s response to varying positive frequencies. To extend this plot to the Nyquist plot, we simply mirror the existing plot across the real axis. This mirrored portion represents what would be the system’s response if negative frequencies were physically meaningful.\n\n\n\n\n\n\n\nThe figure above showe the polar plot and its mirrored image to form the complete Nyquist plot of the example we are considering.\n\nUnderstanding the Frequency Response\nThe core of our analysis hinges on understanding the system’s frequency response. Once we have a clear picture of how the system responds to different frequencies (as shown in the polar plot), extending this understanding to the Nyquist plot becomes straightforward. The Nyquist plot, in turn, is a powerful tool in answering stability-related questions about the system.\nPop-up Question: Why do we consider negative frequencies in the Nyquist plot when they have no physical meaning?\nAnswer: Considering negative frequencies is a mathematical method to ensure the completeness of the Nyquist plot. It helps in visualizing the entire response of the system, including the symmetry about the real axis, which is crucial for stability analysis.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#example-2---contours-passing-through-singularities",
    "href": "application_of_nyquist_stability_criterion.html#example-2---contours-passing-through-singularities",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Example 2 - Contours passing through singularities",
    "text": "Example 2 - Contours passing through singularities\n\\[\nG(s) = \\frac{1}{s(\\tau s + 1)}\n\\]\nFirst, the Polar Plot can be obtained using the sinusoidal transfer function:\n\\[\nG(j\\omega) = \\frac{1}{j\\omega(\\tau j\\omega + 1)}\n\\]\n\n\n\n\\(\\omega = 0\\)\n\\(\\infty\\angle{-90^\\circ}\\)\n\n\n\\(\\omega = \\infty\\)\n\\(0\\angle{-180^\\circ}\\)\n\n\n\nWe will come back to the phase of the \\(\\omega = 0\\) in a moment.\nTo calculate the Intersections with real and imaginary axis we convert \\(G(j\\omega)\\) to its \\(x+jy\\) representation:\n\\[\nG(j\\omega) = x+jy = \\frac{-T}{1+\\omega^2T^2} - j\\frac{1}{\\omega(1+\\omega^2T^2)}\n\\]\nFrom this equation, it is clear that there are no intersections with the real or imaginary axis. If there is an intersection, it is for \\(\\omega=\\infty\\) which we have calculated already.\n\nFor \\(\\omega=0\\) \\(\\rightarrow\\) \\(G(j0) = -T -j\\infty\\)\n\nThis gives us additional information. It goes to infinity along the asymptote at \\(-T\\).\nWe can sketch it:\n\n\n\n\n\n\n\nThis plot also shows why for \\(\\omega = 0\\), the \\(\\angle{-90^\\circ}\\). The asymptotic behaviour and the phase show the same information.\n\n\n\n\n\n\n\nThe only problem is that we have an open-loop pole at the origin, and mapping that specific point gives an infinite value.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#addressing-open-loop-poles-in-nyquist-plot-construction",
    "href": "application_of_nyquist_stability_criterion.html#addressing-open-loop-poles-in-nyquist-plot-construction",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Addressing Open-Loop Poles in Nyquist Plot Construction",
    "text": "Addressing Open-Loop Poles in Nyquist Plot Construction\nWhen dealing with open-loop poles located at the origin or along the imaginary axis, special techniques are required for constructing the Nyquist plot, as direct mapping of these poles results in infinite values.\n\nIndentation Method for Nyquist Contour\n\nTechnique of Contour Indentation: To navigate around this challenge, the Nyquist contour is modified by indenting around the pole in question. This is done by sketching a small semicircle with radius $ $ adjacent to the pole, with $ $ approaching zero.\nRationale Behind Indentation: This adjustment is a practical measure. It’s important to note that having a pole exactly at the origin or on the imaginary axis often represents an idealized situation. In real-world systems, such poles would typically be located very close to, but not exactly on, the left-hand side of the complex plane (LHP).\nImplication for Stability Analysis: This indentation method is a mathematical strategy to simplify the Nyquist plot while retaining accurate stability analysis. The essential aspect of the analysis remains unchanged.\n\n\n\nNyquist Contour Modification and Stability Analysis\n\nDirection of Detouri|ng: The direction in which the contour is detoured around the pole does not pose a problem. However, it’s crucial to note the implications of this detouring on the stability criterion.\nInclusion of Poles in Nyquist Contour: If the detouring includes an open-loop pole within the Nyquist contour, this must be accounted for in the stability analysis. The enclosed pole contributes to the count of $ P $ in the Nyquist stability criterion, formulated as $ N = P - Z $.\nConsistent Results in Stability: Regardless of the detouring direction, the resulting assessment of closed-loop stability remains consistent. What changes is the specific value of $ N $ obtained in the Nyquist criterion, while the overall stability conclusion for the system stays the same.\n\nBy carefully applying the indentation technique and appropriately considering the effects of detouring on the Nyquist stability criterion, we can ensure a robust and accurate stability analysis for control systems with open-loop poles on or near the imaginary axis.\nLet’ see how this works with our example:\nTo understand the mapping of the Nyquist plot around an open-loop pole, particularly when the pole is at the origin or on the imaginary axis, we consider the semicircular path defined by:\n\\[\ns = \\epsilon e^{j\\theta}\n\\]\nHere, $ $ varies from \\(-90^\\circ\\) through \\(0^\\circ\\) to \\(+90^\\circ\\), effectively tracing a semicircle in the complex plane.\nWhen substituting this expression into the transfer function, we have:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon e^{j\\theta}(T \\epsilon e^{j\\theta} + 1)}\n\\]\nGiven the small value of $ $ (approaching zero), this expression can be approximated as:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon e^{j\\theta}}\n\\]\nFurther simplifying, we get:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon} e^{-j\\theta}\n\\]\nThis approximation leads to two important observations about the transfer function as we move along the semicircle:\n\nMagnitude: The magnitude of the transfer function tends towards infinity. This is due to the presence of $ $ in the denominator, which approaches zero, making the overall expression tend towards infinity.\nAngle: The angle changes from $ +90^$ through $ 0^$ to $ -90^$. This change in angle is critical as it reflects the phase shift occurring as we move around the semicircle.\n\n\n\n\n\n\n\n\n\n\n\nThe stability of a system in the context of the Nyquist criterion is determined by whether its Nyquist plot encircles the critical point (-1 + j0). For the given system:\n\\[\nG(s) = \\frac{K}{s(sT+1)}\n\\]\nwe can analyze its stability based on the Nyquist plot behavior.\n\n\nStability Analysis Based on Nyquist Plot\n\nAbsence of Encirclement of \\(-1\\) Point: The system is deemed stable if the Nyquist plot does not encircle the \\(-1\\) point on the complex plane. In this case, the system’s Nyquist plot never goes around the \\(-1\\) point, which means that the system is stable.\nEffect of Increasing \\(K\\): As the gain \\(K\\) increases, the magnitude of the system’s response increases. However, this increase in magnitude does not lead to an encirclement of the \\(-1\\) point. Therefore, even with higher values of \\(K\\), the Nyquist plot remains clear of the \\(-1\\) point.\n\n\n\nConclusion on Stability\n\nStability for All Values of (K): Given the behavior of the Nyquist plot for this system, it can be concluded that the system is stable for all values of (K). This conclusion is drawn from the fact that there are no encirclements of the critical (-1) point, regardless of the gain (K).\n\nThe stability of the system, as analyzed through the Nyquist criterion, is thus not affected by variations in \\(K\\), making it stable across a range of gain values.",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#example-3",
    "href": "application_of_nyquist_stability_criterion.html#example-3",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Example 3",
    "text": "Example 3\n\\[\nG(s)H(s) = \\frac{4s + 1}{s^2(s + 1)(2s + 1)}\n\\]\nLet’s analyze this function to understand its implications for system stability using the Nyquist stability criterion.\n\nEvaluating Key Points on the Nyquist Plot\nFor this transfer function, the Nyquist plot is constructed by evaluating the following:\n\\[\nG(j\\omega)H(s) = \\frac{4j\\omega + 1}{(j\\omega)^2(j\\omega + 1)(2j\\omega + 1)}\n\\]\n\nAt $ = 0 $: The transfer function becomes $ ^$. This suggests that the plot starts from infinity on the negative real axis.\nAt $ = $: Simplifying, we find the angle to be $ 0 ^$ or equivalently $ 0 ^$.\nIntersections with the Imaginary Axis\n\nConverting the transfer function into a vector form $ x + jy $ allows us to find intersections with the imaginary axis. However, for this particular transfer function, there are no intersections except at $ = 0 $ and $ = $.\n\n\nNyquist Plot Construction\n\n\n\n\n\n\n\n\n\n\n\nOrigin Consideration: The presence of a double pole at the origin requires special attention. We detour around this pole using a semicircle with an infinitesimal radius $ $.\nMapping of the Semicycle: The mapping of this semicircle, represented as $ e^{j} $, results in a plot that spans from $ +180^$ to $ -180^$ with an infinite radius.\n\nAs before, to understand the mapping of the Nyquist plot around the two open-loop poles at the origin, we consider the semicircular path defined by:\n\\[\ns = \\epsilon e^{j\\theta}\n\\]\nHere, $ $ varies from \\(-90^\\circ\\) through \\(0^\\circ\\) to \\(+90^\\circ\\), effectively tracing a semicircle in the complex plane.\nWhen substituting this expression into the transfer function, we have that we can approximate \\(G(s)H(s)\\) as:\n\\[\nG(s)H(s) = \\frac{1}{s^2}\n\\]\nGiven the small value of $ $ (approaching zero), this expression can be approximated as:\n\\[\nG(s)H(s) = \\frac{1}{\\epsilon e^{2j\\theta}}\n\\]\nAnd further simplifying, we get:\n\\[\nG(s)H(s) = \\frac{K}{\\epsilon} e^{-j2\\theta}\n\\]\nand the angle goes from \\(+180^\\circ\\) to \\(-180^\\circ\\), when \\(\\theta\\) goes from \\(-90^\\circ\\) to \\(90^\\circ\\).",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "application_of_nyquist_stability_criterion.html#stability-analysis-based-on-nyquist-criterion",
    "href": "application_of_nyquist_stability_criterion.html#stability-analysis-based-on-nyquist-criterion",
    "title": "Application of Nyquist Stability Criterion in Control Systems",
    "section": "Stability Analysis Based on Nyquist Criterion",
    "text": "Stability Analysis Based on Nyquist Criterion\n\nImpact of System Gain ($ K $): Varying $ K $ in the system\n\n\\[\nG(s)H(s) = K \\frac{4s + 1}{s^2(s + 1)(2s + 1)}\n\\]\naffects the magnitude of the Nyquist plot. This might lead to the encirclement of the \\(-1\\) point, and the system stability depends on the specific value of \\(K\\).",
    "crumbs": [
      "Application of Nyquist Stability Criterion in Control Systems"
    ]
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html",
    "href": "JUPYTER-BOOK-INTEGRATION.html",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "This document provides a detailed overview of the modifications and enhancements made to integrate and optimize Jupyter Book within the existing project repository. The enhancements primarily focus on improving the visual appeal of the Jupyter Book PDF output and ensuring efficient workflow.\n\n\n\nCopy the files into the nbs/ folder of your typical nbdev repository.\nModify file _toc.yml to reflect the structure you want to have for your pdf.\nRun\n\n   python bin/build_jupyterbook_with_images.py\nYou should now have a pdf file of your notebooks in folder _build/pdf.\n\n\n\nTo enhance the visual appeal of the Jupyter Book, custom CSS styles have been implemented. These styles affect the layout, typography, and overall aesthetic of both the HTML and PDF versions generated by Jupyter Book.\n\n\n\nTypography: Customized fonts and line spacing for improved readability.\nColor Scheme: A carefully selected color palette that is consistent across all pages.\nCode Styling: Enhanced styling for code blocks and inline code for better distinction from regular text.\nNavigation Menu: A revamped navigation menu with intuitive design for ease of navigation.\n\nThe custom styles can be found in the _static/custom_styles.css file. To modify these styles, edit this file and rebuild the book using Jupyter Book commands.\n\n\n\n\nThe build_jupyterbook_with_images.py script has been developed to streamline the process of including images in the PDF version of the Jupyter Book. This script automates the copying of image files to the correct directory and triggers the Jupyter Book build process.\n\n\n\nPlace the script in the bin directory at the root of your Jupyter Book project.\nRun the script using the command:\npython bin/build_jupyterbook_with_images.py\n\nThe script prompts for confirmation before proceeding with the operations, ensuring user control over the process.\n\n\n\n\nA common issue encountered during PDF generation (pyppeteer.errors.TimeoutError) has been addressed by modifying the pdf.py file in the Jupyter Book or pyppeteer environment.\n\n\nThe line in pdf.py responsible for page navigation has been altered to:\nawait page.goto(f\"file:///{html_file}\", {\"timeout\": 0, \"waitUntil\": [\"networkidle2\"]})\nThis change eliminates the timeout restriction, allowing for the complete loading of pages, thereby resolving the timeout issue during PDF creation.\n\n\n\n\nIf you encounter the error\nVersionConflict(dist, req).with_context(dependent_req) pkg_resources.ContextualVersionConflict: (mdit-py-plugins 0.4.0 (lib/python3.10/site-packages), Requirement.parse('mdit-py-plugins~=0.3.1'), {'myst-parser'})\nThis error is a dependency conflict, specifically with the mdit-py-plugins package. The core of the issue is that your environment has mdit-py-plugins version 0.4.0 installed, but myst-parser, a dependency for Jupyter Book, requires a version close to 0.3.1 (~=0.3.1 indicates a version compatible with 0.3.1 but less than 0.4.0).\nTo resolve this issue, you need to downgrade mdit-py-plugins to a version compatible with myst-parser. Here’s how you can do it:\n\nActivate your environment: Ensure you’re working in the correct environment where Jupyter Book is installed.\nsource activate underwatersystems\nDowngrade mdit-py-plugins: Use pip to install a version of mdit-py-plugins that is compatible with myst-parser.\npip install \"mdit-py-plugins~=0.3.1\"\nThis command will uninstall the current version of mdit-py-plugins and install a version that is compatible with your current setup.\nVerify the installation: After downgrading, it’s a good practice to check if the correct versions are installed and if there are any other conflicting dependencies.\npip list\nLook through the list to confirm that mdit-py-plugins is now the correct version and there are no other conflicting packages.\nRetry building your Jupyter Book: Once the dependencies are sorted out, try rebuilding your Jupyter Book.\npython bin/build_jupyterbook_with_images.py\nCheck for further dependency conflicts: If you encounter additional dependency issues, you might need to repeat a similar process—identifying the conflict and adjusting package versions accordingly.\n\n\n\n\nWhen converting Jupyter Notebooks to PDF, especially through Jupyter Book, it is often necessary to control the pagination by inserting page breaks. This can be achieved through raw HTML or LaTeX commands, depending on the method used for PDF generation.\n\n\n\nInserting a Page Break: In your Jupyter Notebook, add a new cell and change its type to “Raw”. In this cell, input the following HTML code:\n&lt;div style=\"page-break-after: always;\"&gt;&lt;/div&gt;\nEffect in PDF: This tag will instruct the PDF renderer (when using HTML-based conversion like pdfhtml in Jupyter Book) to insert a page break at that point in the document.\n\n\n\n\n\nInserting a LaTeX Page Break: Add a new “Raw” cell in your notebook and input the following LaTeX command:\n\\newpage\nEffect in PDF: This command will cause a new page to start at that point when converting the notebook to PDF using LaTeX-based methods.\n\n\n\n\n\nCompatibility: The method chosen for inserting page breaks should align with the conversion tool used (HTML vs. LaTeX).\nNotebook Interface: These commands are only functional in the PDF output and will not affect the appearance of the notebook in the Jupyter interface.\nCustom Styles: Ensure that any custom CSS or LaTeX styling in your Jupyter Book configuration does not override these page break commands."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#how-to-use-this-repository",
    "href": "JUPYTER-BOOK-INTEGRATION.html#how-to-use-this-repository",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "Copy the files into the nbs/ folder of your typical nbdev repository.\nModify file _toc.yml to reflect the structure you want to have for your pdf.\nRun\n\n   python bin/build_jupyterbook_with_images.py\nYou should now have a pdf file of your notebooks in folder _build/pdf."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#custom-styling-for-jupyter-book",
    "href": "JUPYTER-BOOK-INTEGRATION.html#custom-styling-for-jupyter-book",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "To enhance the visual appeal of the Jupyter Book, custom CSS styles have been implemented. These styles affect the layout, typography, and overall aesthetic of both the HTML and PDF versions generated by Jupyter Book.\n\n\n\nTypography: Customized fonts and line spacing for improved readability.\nColor Scheme: A carefully selected color palette that is consistent across all pages.\nCode Styling: Enhanced styling for code blocks and inline code for better distinction from regular text.\nNavigation Menu: A revamped navigation menu with intuitive design for ease of navigation.\n\nThe custom styles can be found in the _static/custom_styles.css file. To modify these styles, edit this file and rebuild the book using Jupyter Book commands."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#script-for-image-inclusion-and-book-building",
    "href": "JUPYTER-BOOK-INTEGRATION.html#script-for-image-inclusion-and-book-building",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "The build_jupyterbook_with_images.py script has been developed to streamline the process of including images in the PDF version of the Jupyter Book. This script automates the copying of image files to the correct directory and triggers the Jupyter Book build process.\n\n\n\nPlace the script in the bin directory at the root of your Jupyter Book project.\nRun the script using the command:\npython bin/build_jupyterbook_with_images.py\n\nThe script prompts for confirmation before proceeding with the operations, ensuring user control over the process."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#fix-for-pyppeteer.errors.timeouterror",
    "href": "JUPYTER-BOOK-INTEGRATION.html#fix-for-pyppeteer.errors.timeouterror",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "A common issue encountered during PDF generation (pyppeteer.errors.TimeoutError) has been addressed by modifying the pdf.py file in the Jupyter Book or pyppeteer environment.\n\n\nThe line in pdf.py responsible for page navigation has been altered to:\nawait page.goto(f\"file:///{html_file}\", {\"timeout\": 0, \"waitUntil\": [\"networkidle2\"]})\nThis change eliminates the timeout restriction, allowing for the complete loading of pages, thereby resolving the timeout issue during PDF creation."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#fix-for",
    "href": "JUPYTER-BOOK-INTEGRATION.html#fix-for",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "If you encounter the error\nVersionConflict(dist, req).with_context(dependent_req) pkg_resources.ContextualVersionConflict: (mdit-py-plugins 0.4.0 (lib/python3.10/site-packages), Requirement.parse('mdit-py-plugins~=0.3.1'), {'myst-parser'})\nThis error is a dependency conflict, specifically with the mdit-py-plugins package. The core of the issue is that your environment has mdit-py-plugins version 0.4.0 installed, but myst-parser, a dependency for Jupyter Book, requires a version close to 0.3.1 (~=0.3.1 indicates a version compatible with 0.3.1 but less than 0.4.0).\nTo resolve this issue, you need to downgrade mdit-py-plugins to a version compatible with myst-parser. Here’s how you can do it:\n\nActivate your environment: Ensure you’re working in the correct environment where Jupyter Book is installed.\nsource activate underwatersystems\nDowngrade mdit-py-plugins: Use pip to install a version of mdit-py-plugins that is compatible with myst-parser.\npip install \"mdit-py-plugins~=0.3.1\"\nThis command will uninstall the current version of mdit-py-plugins and install a version that is compatible with your current setup.\nVerify the installation: After downgrading, it’s a good practice to check if the correct versions are installed and if there are any other conflicting dependencies.\npip list\nLook through the list to confirm that mdit-py-plugins is now the correct version and there are no other conflicting packages.\nRetry building your Jupyter Book: Once the dependencies are sorted out, try rebuilding your Jupyter Book.\npython bin/build_jupyterbook_with_images.py\nCheck for further dependency conflicts: If you encounter additional dependency issues, you might need to repeat a similar process—identifying the conflict and adjusting package versions accordingly."
  },
  {
    "objectID": "JUPYTER-BOOK-INTEGRATION.html#specifying-page-breaks-in-jupyter-notebooks-for-pdf-output",
    "href": "JUPYTER-BOOK-INTEGRATION.html#specifying-page-breaks-in-jupyter-notebooks-for-pdf-output",
    "title": "Jupyter Book Integration",
    "section": "",
    "text": "When converting Jupyter Notebooks to PDF, especially through Jupyter Book, it is often necessary to control the pagination by inserting page breaks. This can be achieved through raw HTML or LaTeX commands, depending on the method used for PDF generation.\n\n\n\nInserting a Page Break: In your Jupyter Notebook, add a new cell and change its type to “Raw”. In this cell, input the following HTML code:\n&lt;div style=\"page-break-after: always;\"&gt;&lt;/div&gt;\nEffect in PDF: This tag will instruct the PDF renderer (when using HTML-based conversion like pdfhtml in Jupyter Book) to insert a page break at that point in the document.\n\n\n\n\n\nInserting a LaTeX Page Break: Add a new “Raw” cell in your notebook and input the following LaTeX command:\n\\newpage\nEffect in PDF: This command will cause a new page to start at that point when converting the notebook to PDF using LaTeX-based methods.\n\n\n\n\n\nCompatibility: The method chosen for inserting page breaks should align with the conversion tool used (HTML vs. LaTeX).\nNotebook Interface: These commands are only functional in the PDF output and will not affect the appearance of the notebook in the Jupyter interface.\nCustom Styles: Ensure that any custom CSS or LaTeX styling in your Jupyter Book configuration does not override these page break commands."
  }
]